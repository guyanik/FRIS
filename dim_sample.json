{
    "9852805": {
        "title": "Quantifying trophic niches to measure the resilience of marine predators",
        "abstract": "This project aims to pair global movement with feeding ecology datasets to characterise relationships between space use and diet breadth, and tests the effects of marine industries on functional roles of marine predators. This expects to generate knowledge about population and individual specalisation using innovative biochemical approaches and shark\u2019s unique dental anatomy. Expected outcomes include a biochemical database facilitating global collaborations, and a vulnerability scale to rank resilience to impacts based on relative specalisation. This should benefit managers by accounting for previously unknown effects of marine industries on specialists at elevated extinction risk, with limited resilience to local impacts and global change.",
        "disciplines": [
            "4101",
            "4104",
            "3103"
        ],
        "publications": {
            "10.3389/fmars.2023.1254461": {
                "title": "Towards unlocking the trophic roles of rarely encountered squid: Opportunistic samples of Taningia danae and a Chiroteuthis aff. veranii reveal that the Southern Ocean top predators are nutrient links connecting deep-sea and shelf-slope environments",
                "abstract": "Deep-sea squids are presumably vital components of largely undescribed marine ecosystems, yet limited access to specimens has hampered efforts to detail their ecological roles as predators and preys. Biochemical techniques such as stable isotope analyses, fatty acid analyses, and bomb calorimetry are increasingly recognized for their ability to infer trophic ecology and dietary information from small quantities of tissue. This study used five opportunistically collected Taningia danae specimens and one Chiroteuthis aff. veranii specimen retrieved from the Great Australian Bight, South Australia, to detail the trophic ecology of these poorly understood squids. Four body tissue types (i.e., arm, buccal mass, mantle, and digestive gland) were assessed for their utility in stable isotope (SI) and fatty acid (FA) analyses, and we found that the arm, buccal mass, and mantle tissues had similar SI and FA profiles, suggesting that they can be used interchangeably when the entire specimen is unavailable. \u03b413C, \u03b415N, and fatty acid data suggests that the T. danae and C. aff. veranii specimens lived in the Southern Ocean and were high-trophic-level predators, feeding on deep-sea fishes and small squids, while also taking advantage of the summer upwelling region of the Great Australian Bight. The fatty acid analysis and bomb calorimetry results indicate that these squids might be important reservoirs of essential FAs (EPA and DHA) for Southern Ocean predators and that the whole-body energy content of T. danae individuals can reach up to 362,250 kJ. Our findings indicate that these squids may be contributing greatly to the transport of nutrients and energy between the Southern Ocean deep-sea and the Great Australian Bight shelf\u2013slope environments. In addition to building our understanding of the trophic ecology of two poorly understood deep-sea squids, these findings also highlight the utility of partial specimens and demonstrate the important ecological information that can be obtained from few samples that may be opportunistically collected.",
                "disciplines": [
                    "3103"
                ]
            }
        }
    },
    "13062422": {
        "title": "An argumentation-based platform  for e-democracy \u2013 AGGREEY",
        "abstract": "E-democracy is a form of government that allows everybody to participate in the development of laws. It has numerous benefits since it strengthens the integration of citizens in the political debate. Several on-line platforms exist; most of them propose to represent a debate in the form of a graph, which allows humans to better grasp the arguments and their relations. However, once the arguments are entered in the system, little or no automatic treatment is done by such platforms. Given the development of online consultations, it is clear that in the near future we can expect thousands of arguments on some hot topics, which will make the manual analysis difficult and time-consuming. The goal of this project is to use artificial intelligence, computational argumentation theory and natural language processing in order to detect the most important arguments, estimate the acceptability degrees of arguments and predict the decision that will be taken.",
        "disciplines": [
            "4408"
        ],
        "publications": {
            "10.1007/978-3-031-49133-7_8": {
                "title": "Towards Ethical Argumentative Persuasive Chatbots",
                "abstract": "Argumentative persuasive technologies are technologies that use argumentation in order to persuade the persuadee to believe in something or not, which can later lead the persuadee to perform an action or not. The use of such tools opens numerous ethical considerations. In this paper, we survey the literature on persuasion that might be useful for argumentative persuasive chatbots, we cover the existing legal framework and ethical principles and we critically analyze the new proposal for a regulation on artificial intelligence of the European Commission. We also show how to use argumentation to enhance explainability and transparency of the persuasion systems. We propose to show the graphical representation of the arguments used during the persuasion to the user at the end of the dialogue, containing the relations between the arguments (attacks, supports), their origin (source), who uttered them (i.e. the machine or the human participant) and the persuasive methods employed. Our approach has several benefits. Namely, it makes the system more transparent and enhances the human understanding of the system, which is a benefit per se. Furthermore, the fact that the system is transparent increases the trust of the user, which (apart from being one of the goals of AI in general) can increase the chance that the user is persuaded by the system. Finally, the user can give a feedback on the presented arguments (e.g. how much they believe the arguments are ethical), which can be later used to improve the persuasion system.",
                "disciplines": [
                    "4608"
                ]
            },
            "10.1007/978-3-031-43619-2_15": {
                "title": "A Principle-Based Analysis of Bipolar Argumentation Semantics",
                "abstract": "In this paper, we introduce and study seven types of semantics for bipolar argumentation frameworks, each extending Dung\u2019s interpretation of attack with a distinct interpretation of support. First, we introduce three types of defence-based semantics by adapting the notions of defence. Second, we examine two types of selection-based semantics that select extensions by counting the number of supports. Third, we analyse two types of traditional reduction-based semantics under deductive and necessary interpretations of support. We provide full analysis of twenty-eight bipolar argumentation semantics and ten principles.",
                "disciplines": []
            },
            "10.1080/11663081.2023.2246863": {
                "title": "An empirical and axiomatic comparison of ranking-based semantics for abstract argumentation",
                "abstract": "Argumentation is the process of evaluating and comparing a set of arguments. A way to compare them consists in using a ranking-based semantics which rank-order arguments from the most to the least acceptable ones. Recently, a number of such semantics have been proposed independently, often associated with some desirable properties. In this work, we provide a thorough analysis of ranking-based semantics in two different ways. The first is an empirical comparison on randomly generated argumentation frameworks which reveals insights into similarities and differences between ranking-based semantics. The second is an axiomatic comparison of all these semantics with respect to the proposed properties aiming to better understand the behaviour of each semantics.",
                "disciplines": [
                    "4605"
                ]
            }
        }
    },
    "13528070": {
        "title": "What makes us groove?",
        "abstract": "If you would visit a museum that is showcasing early human cultures (The British Museum in London, for example), there would almost certainly be a few sections relating to our ancestors\u2019 musical activities around the globe. It is known that ancient humans danced and made music, for instance, during dry seasons to beg for rain, or during agriculture and hunting to have enough food to survive. In fact, to observe the relatedness of dance and music and their significance in our lives, one does not need to travel in time. If we look at babies, we see that they are sensitive to movement patterns to music as early as 7 months of age (Phillips-Silver & Trainor, 2005). This could be because music is so rewarding. It captures our attention easily, gives us pleasure, makes us dance, and makes us feel connected to other people. In the field of musicology, this combination of musical experiences relates to the concept of groove. Previous groove literature demonstrated its applications in interpersonal synchronisation and social interaction, prosocial behaviour, clinical groups with perception, and both motor- and mood-related problems. \n\nThe primary motivation of my dissertation is to explore granularity of groove from various angles by using multiple naturalistic methodical approaches. The goal is to help us better understand the variables that influence people\u2019s groove experiences. In developing previous literature, in my dissertation first, I proposed an updated comprehensive and contemporary working definition of groove. Second, the findings suggested that the concept of groove is closely linked to functions of music listening such as \u201cregulation of mood and arousal\u201d and \u201cexpression of social relatedness\u201d. Third, with additional studies I contributed to development of a musicological model of groove. Finally, I investigated an under-researched aspect related to groove, namely how naturalistic groove-related music is processed in the brain.",
        "disciplines": [
            "3603",
            "3604"
        ],
        "publications": {
            "10.1177/03057356231165327": {
                "title": "Groove as a multidimensional participatory experience",
                "abstract": "Groove is a popular and widely used concept in the field of music. Yet, its precise definition remains elusive. Upon closer inspection, groove appears to be used as an umbrella term with various connotations depending on the musical era, the musical context, and the individual using the term. Our aim in this article was to explore different definitions and connotations of the term groove so as to reach a more detailed understanding of it. Consequently, in an online survey, 88 participants provided free-text descriptions of the term groove. A thematic analysis revealed that groove is a multifaceted phenomenon, and participants\u2019 descriptions fit into two main categories: music- and experience-related aspects. Based on this analysis, we propose a contemporary working definition of the term groove as used in the field of music psychology: \u201cGroove is a participatory experience (related to immersion, movement, positive affect, and social connection) resulting from subtle interaction of specific music- (such as time- and pitch-related features), performance-, and/or individual-related factors.\u201d Importantly, this proposed definition highlights the participatory aspect of the groove experience, which participants frequently mentioned, for example describing it as an urge to be \u201cinvolved in\u201d the music physically and/or psychologically. Furthermore, we propose that being immersed in music might be a prerequisite for other experiential qualities of groove, whereas the social aspect could be a secondary quality that comes into play as a consequence of musical activity. Overall, we anticipate that these findings will encourage a greater variety of research on this significant yet still not fully elucidated aspect of the musical experience.",
                "disciplines": [
                    "3603"
                ]
            }
        }
    },
    "13057717": {
        "title": "Nanomedicine-based approach for characterizing the epigenome in prevention of inflammation-induced preterm birth.",
        "abstract": "PROJECT SUMMARY Preterm birth (PTB), or birth before 37 weeks of gestation, was the second leading cause of infant death in the US in 2017. Each year, more than $26 billion is spent on treatment and care of babies born prematurely, not accounting for the lifelong impact of developmental and cognitive impairments. Earlier this year, the FDA issued a recommendation that the synthetic progestin 17-hydroxyprogesterone caproate (OHPC, Makena\u00ae), the only approved product for PTB prevention, be withdrawn from the market due to lack of clinical benefit in a required post-market study. New and innovative therapeutic options for preventing PTB are desperately needed, but the etiology of PTB is complex and the potential for tissue sampling and clinical trials during pregnancy is limited. We recently developed an adapted mouse model of inflammation-induced PTB and a unique nanomedicine-based approach for more efficient vaginal delivery of therapeutics to the reproductive tract. Together, these new tools led to the first demonstration of therapeutic prevention of early intrauterine inflammation-induced PTB that led to full term delivery of litters with high percentages of pup viability and neurotypical motor development. The therapeutics delivered via the nanoformulation were histone deacetylase inhibitors (HDACi) dosed with or without the need for additional exogenous progesterone (P4). HDACi prevent deacetylation of histones, leading to more transcriptionally active chromatin, and thus, changes in gene expression. We also observed that the P4/HDACi combination inhibited human myometrial cell contractility and led to an increase in the ratio of P4 receptor (PR) isoform B (PR-B) compared to P4 receptor isoform A (PR-A), which is thought to maintain uterine quiescence and cervical competence. This supports the idea that HDACi- induced hyperacetylation creates a more favorable chromatin structure for ligand-bound PR to change the gene expression profile in a manner that prevents PTB. The overarching goals of this proposal are to determine the role of PR-B in the prevention of inflammation-induced PTB, to map epigenetic changes that are specific to therapeutic treatment, and to evaluate whether the epigenetic changes are sufficient to reset the uterine environment for normal fetal development. If these preclinical studies are successful, we will generate fundamental mechanistic knowledge of epigenetic regulation in PTB, as well as identify new cellular pathways that may be important targets for PTB prevention.",
        "disciplines": [
            "3215",
            "3213"
        ],
        "publications": {
            "10.1016/j.jconrel.2024.05.037": {
                "title": "Hypotonic, gel-forming delivery system for vaginal drug administration",
                "abstract": "Vaginal drug delivery is often preferred over systemic delivery to reduce side effects and increase efficacy in treating diseases and conditions of the female reproductive tract (FRT). Current vaginal products have drawbacks, including spontaneous ejection of drug-eluting rings and unpleasant discharge from vaginal creams. Here, we describe the development and characterization of a hypotonic, gel-forming, Pluronic-based delivery system for vaginal drug administration. The rheological properties were characterized with and without common hydrogel polymers to demonstrate the versatility. Both qualitative and quantitative approaches were used to determine the Pluronic F127 concentration below the critical gel concentration (CGC) that was sufficient to achieve gelation when formulated to be hypotonic to the mouse vagina. The hypotonic, gel-forming formulation was found to form a thin, uniform gel layer along the vaginal epithelium in mice, in contrast to the rapidly forming conventional gelling formulation containing polymer above the CGC. When the hypotonic, gel-forming vehicle was formulated in combination with a progesterone nanosuspension (ProGel), equivalent efficacy was observed in the prevention of chemically-induced preterm birth (PTB) compared to commercial Crinone\u00ae vaginal cream. Further, ProGel showed marked benefits in reducing unpleasant discharge, reducing product-related toxicity, and improving compatibility with vaginal bacteria in vitro. A hypotonic, gel-forming delivery system may be a viable option for therapeutic delivery to the FRT.",
                "disciplines": [
                    "3215"
                ]
            },
            "10.1007/s13346-024-01618-6": {
                "title": "Locally administered nanosuspension increases delivery of estradiol for the treatment of vaginal atrophy in mice",
                "abstract": "Vaginal atrophy affects up to 57% of post-menopausal women, with symptoms ranging from vaginal burning to dysuria. Estradiol hormone replacement therapy may be prescribed to alleviate these symptoms, though many vaginal products have drawbacks including increased discharge and local tissue toxicity due to their hypertonic nature. Here, we describe the development and characterization of a Pluronic F127-coated estradiol nanosuspension (NS) formulation for improved vaginal estradiol delivery. We compare the pharmacokinetics to the clinical comparator vaginal cream (Estrace) and demonstrate increased delivery of estradiol to the vaginal tissue. We utilized ovariectomized (OVX) mice as a murine model of post-menopausal vaginal atrophy and demonstrated equivalent efficacy in vaginal re-epithelialization when dosed with either the estradiol NS or Estrace cream. Further, we demonstrate compatibility of the estradiol NS with vaginal bacteria in vitro. We demonstrate that a Pluronic F127-coated estradiol NS may be a viable option for the treatment of post-menopausal vaginal atrophy.Graphical Abstract",
                "disciplines": [
                    "3215"
                ]
            },
            "10.1002/smll.202303682": {
                "title": "Nanomedicine for Maternal and Fetal Health",
                "abstract": "Conception, pregnancy, and childbirth are complex processes that affect both mother and fetus. Thus, it is perhaps not surprising that in the United States alone, roughly 11% of women struggle with infertility and 16% of pregnancies involve some sort of complication. This presents a clear need to develop safe and effective treatment options, though the development of therapeutics for use in women's health and particularly in pregnancy is relatively limited. Physiological and biological changes during the menstrual cycle and pregnancy impact biodistribution, pharmacokinetics, and efficacy, further complicating the process of administration and delivery of therapeutics. In addition to the complex pharmacodynamics, there is also the challenge of overcoming physiological barriers that impact various routes of local and systemic administration, including the blood-follicle barrier and the placenta. Nanomedicine presents a unique opportunity to target and sustain drug delivery to the reproductive tract and other relevant organs in the mother and fetus, as well as improve the safety profile and minimize side effects. Nanomedicine-based approaches have the potential to improve the management and treatment of infertility, obstetric complications, and fetal conditions.",
                "disciplines": [
                    "3206",
                    "3215"
                ]
            }
        }
    },
    "13308163": {
        "title": "Modelling Interactions between Climate Change and Agriculture in the Ancient West \u2013 MICA",
        "abstract": "The multidisciplinary MICA project aims to assess the impact of climatic variations on crop productivity (wheat, barley, millet, grapevine, olive) and their influence, in interaction with social factors, on the transformation of agrarian economies and agrobiodiversity. MICA focuses on four areas of interest in Western Europe and the Mediterranean, over a multi-millennial period between the Bronze Age and the end of Roman times (2000 B.C. - 600 A.D.), which underwent major agricultural changes, some of which associated with key economic developments (onset of olive growing, viticulture, cereal trade, etc.). The complexity of the questions that underlie this project requires the implementation of innovative research which integrates various disciplinary fields: archaeobotany, paleogenomics, spatial archaeology, agronomy, paleoclimatology and modelling. The various methods employed are the build-up of archaeobotanical and archaeological databases, the realization of morphometric, palaeogenomic and isotopic analyses on plant remains, as well as the analysis of multidisciplinary data by geostatistical methods and modelling (agroecosystemic modelling, Multi-Agent Systems). The investigation will focus on four geographical areas selected for their archaeological and archaeobotanical potential, distributed along a north-south transect, in environmentally and climatically varied regions: the Paris Basin, Mediterranean France, south-eastern Spain (Andalusia, Valencia region) and Morocco. Beyond agriculture, the primary source of food and wealth before the industrial revolution, the challenge of MICA is 1) to achieve a better understanding of the impact of climate on demographics and the economy, 2) to identify the adaptations and choices made by societies to ensure the resilience and transformation of production systems.",
        "disciplines": [
            "4301",
            "4303"
        ],
        "publications": {
            "10.1371/journal.pone.0298895": {
                "title": "The impact of climate change on the agriculture and the economy of Southern Gaul: New perspectives of agent-based modelling",
                "abstract": "What impact did the Roman Climate Optimum (RCO) and the Late Antique Little Ice Age (LALIA) have on the rise and fall of the Roman Empire? Our article presents an agent-based modelling (ABM) approach developed to evaluate the impact of climate change on the profitability of vineyards, olive groves, and grain farms in Southern Gaul, which were the main source of wealth in the roman period. This ABM simulates an agroecosystem model which processes potential agricultural yield values from paleoclimatic data. The model calculates the revenues made by agricultural exploitations from the sale of crops whose annual volumes vary according to climate and market prices. The potential profits made by the different agricultural exploitations are calculated by deducting from the income the operating and transportation costs. We conclude that the warm and wet climate of the Roman period may have had an extremely beneficial effect on the profitability of wine and olive farms between the 2nd century BCE and the 3rd century CE, but a more modest effect on grain production. Subsequently, there is a significant decrease in the potential profitability of farms during the Late Antique Little Ice Age (4th-7th century CE). Comparing the results of our model with archaeological data enables us to discuss the impact of these climatic fluctuations on the agricultural and economic growth, and then their subsequent recession in Southern Gaul from the beginning to the end of antiquity.",
                "disciplines": [
                    "4301",
                    "4303"
                ]
            },
            "10.1007/s00334-024-00992-y": {
                "title": "Comparison of image acquisition techniques and morphometric methods to distinguish between Vitis vinifera subspecies and cultivars",
                "abstract": "For decades, it has been known that the morphology of wild Vitis vinifera (grape) pips differ from domesticated ones. Based on these differences, computerised image analysis and morphometrics allow us to obtain excellent results to identify the domestication status of archaeological grape pips. However, various image analysis methodologies and morphometric methods have been applied in previous studies for this purpose. Our study has examined, for the first time, the different techniques of digital image acquisition (digital camera vs. scanner) of grape pips, with the aim of testing the identification performance using both traditional and geometric morphometric features to distinguish wild from domestic grape pips. The performance of different morphometric methods established that all image acquisition techniques and morphometric methods correctly distinguished between wild and domestic grapes. The use of the combined geometric morphometric features of both dorsal and lateral views of the pips provided the best accuracy in distinguishing individual cultivars.",
                "disciplines": [
                    "4301"
                ]
            },
            "10.1038/s41598-023-44445-4": {
                "title": "Disentangling the origins of viticulture in the western Mediterranean",
                "abstract": "We present direct evidence of early grape domestication in southern Italy via a multidisciplinary study of pip assemblage from one site, shedding new light on the spread of viticulture in the western Mediterranean during the Bronze Age. This consist of 55 waterlogged pips from Grotta di Pertosa, a Middle Bronze Age settlement in the south of the Italian peninsula. Direct radiocarbon dating of pips was carried out, confirming the chronological consistency of the samples with their archaeological contexts (ca. 1450\u20131200 BCE). The extraordinary state of conservation of the sample allowed to perform geometric morphometric (GMM) and paleogenetic analyses (aDNA) at the same time. The combination of the two methods has irrefutably shown the presence of domestic grapevines, together with wild ones, in Southern Italy during the Middle/Late Bronze Age. The results converge towards an oriental origin of the domestic grapes, most likely arriving from the Aegean area through the Mycenaeans. A parent/offspring kinship was also recognised between a domestic/wild hybrid individual and a domestic clonal group. This data point out a little known aspect of the diffusion of the first viticulture in Italy, and therefore in the western Mediterranean, which involved the hybridization between imported domestic varieties with, likely local, wild vines.",
                "disciplines": [
                    "4301",
                    "4303"
                ]
            },
            "10.1101/2023.09.15.557939": {
                "title": "Deep learning versus geometric morphometrics for archaeobotanical domestication study and subspecific identification",
                "abstract": "Abstract Taxonomical identification of archaeological fruit and seed is of prime importance for any archaeobotanical studies. We compared the relative performance of deep learning and geometric morphometrics at identifying pairs of plant taxa. We used their seeds and fruit stones that are the most abundant recovered organs in archaeobotanical assemblages, and whose morphological identification, chiefly between wild and domesticated types, allow to document their domestication and biogeographical history. We used existing modern datasets of four plant taxa (date palm, barley, olive and grapevine) corresponding to photographs of two orthogonal views of their seeds that were analysed separately to offer a larger spectrum of shape diversity. On these eight datasets, we compared the performance of a deep learning approach, here convolutional neural networks (CNN), to that of a geometric morphometric approach, here outline analyses using elliptical Fourier transforms (EFT). Sample sizes were at minimum eight hundred seeds in each class, which is quite small when training deep learning models but of typical magnitude for archaeobotanical studies. Our objectives were twofold: i) to test whether deep learning can beat geometric morphometrics in taxonomic identification and if so, ii) to test which minimal sample size is required. We ran simulations on the full datasets and also on subsets, starting from 50 images in each binary class. For CNN networks, we deliberately used a candid approach relying on pre-parameterised VGG16 network. For EFT, we used a state-of-the art morphometrical pipeline. The main difference rests in the data used by each model: CNN used bare photographs where EFT used (x, y) outline coordinates. This \u201cpre-distilled\u201d geometrical description of seed outlines is often the most time-consuming part of morphometric studies. Results show that CNN beats EFT in most cases, even for very small datasets. We finally discuss the potential of CNN for archaeobotany, why outline analyses and morphometrics have not yet said their last word by providing quantitative descriptions, and how bioarchaeological studies could embrace both approaches, used in a complementary way, to better assess and understand the past history of species.",
                "disciplines": [
                    "4301"
                ]
            },
            "10.1016/j.jasrep.2023.104204": {
                "title": "Experimental waterlogging of grape seeds, impact on seed shape and geometrical reversing for morphometric inference",
                "abstract": "While the impact of charring on grape seed morphology is well documented, waterlogged pips have up to now been considered in morphometric studies to undergo very limited changes and to be directly comparable to reference collections of fresh seeds. In this study we investigate the impact of waterlogging using different chemicals (H2O2, HNO3, NaOH, KOH) on pips of various cultivars and wild grapevines. Pips are soaked individually in a given chemical solution for increasing periods of time, photographed at each stage, and their dorsal and lateral outlines analysed using Elliptic Fourier Transforms to quantify shape changes. We observe that the different products have comparable effects. The seeds start to swell and then return to their original shapes. Deformation is limited and primarily affects the beak which is slightly blunt and somewhat more pointed than on the original pips. These changes are reminiscent of the deformations observed in waterlogged archaeological seeds. Our results show that they are not strong enough to affect significantly the identification of wild and domesticated morphotypes by seed outline analyses. The effect is greater on the identifications at cultivars level but the accuracy can still be considered acceptable. We experiment the application of an average reverse vector of shape changes to compensate for some of the deformation of artificially waterlogged pips. This correction appears to have a positive effect on the accuracy of identifications for some cultivars. Our conclusion is that outline analysis can be confidently performed on archaeological waterlogged grape pips to identify wild or domesticated status and that it is more appropriate to aim at identifying groups of varieties than individual cultivars. Considering that deformations due to charring and waterlogging have differentiated effects on the identifications it is recommended to take into account both waterlogged and charred seed assemblages.",
                "disciplines": [
                    "4301"
                ]
            },
            "10.1016/j.palaeo.2023.111655": {
                "title": "The Holocene history of grapevine (Vitis vinifera) and viticulture in France retraced from a large-scale archaeobotanical dataset",
                "abstract": "Grapevine and wine have deeply shaped the landscapes, economy and cultures of Europe and the Mediterranean. In France, it is considered that viticulture started in the south via contacts with Mediterranean populations (Greeks, Etruscans, Phoenicians), during the second half of the 1st millennium BCE, and spread further with the Romans. Wild grapevines were nevertheless present in various areas of the country all through the Holocene. No archaeological or historical source allows us to follow the history of grapevine and viticulture over the entire Holocene period and over the whole territory. In this paper we investigate the potential of archaeological plant macroremains (seed/fruits and wood) to trace the history of the vine on a large scale. We have assembled the largest possible database of published and unpublished archaeobotanical data, comprising 4449 site-phases for seed and fruits and 1356 site-phases for wood remains. In spite of taphonomic discrepancies and imbalances in the datasets, the different types of macroremains and modes of preservation produce consistent patterns. They provide the first comprehensive picture of the spread of grapevine, fluctuations in the economic role of viticulture and grape uses over time, although some periods and regions are less documented. Grapevine remains are regularly recorded from the Mesolithic to the Iron Age in most regions showing that human societies were already familiar with the wild plant and its fruits, especially in the Mediterranean. In this region, Vitis remains become considerably more frequent and numerous during the Iron Age, from around 500\u00a0BCE onwards, testifying to the rapid and strong implantation of viticulture. Grapevine macroremains confirm that the spread of viticulture outside the Mediterranean area occurred mainly during the Roman period. However, this expansion was limited and mainly focused on the South. The main expansion into the temperate zone took place during the Middle Ages. However, the more detailed fluctuations of viticulture, particularly in relation to climate oscillations are still difficult to follow. Pip remains are mainly associated with urban sites. This is a consequence of the actual consumption of grapes and may be evidence of a viticulture centered around urban areas.",
                "disciplines": [
                    "3709",
                    "4301",
                    "4303"
                ]
            }
        }
    },
    "13827088": {
        "title": "Promotion of muon particle physics in an international framework",
        "abstract": "In this research, we have started research to strongly promote muon particle physics through a newly established international cooperation system. In addition to aiming to discover new physics through three of the world's most sensitive muon particle experiments, we are also developing large-intensity, high-brightness muon sources and measurement technology, aiming to realize next-generation experiments that will enable us to elucidate the entire picture of new physics. . The main objective is to develop excellent young human resources who will be responsible for next-generation experiments through a series of research processes. Fiscal year 2022 was the year the research began, and we focused on building a system to promote the research. This research focuses on the four pillars of research: technology development related to high-intensity muon beams, development of muon cooling/acceleration technology, development of muon decay particle measurement technology, and theoretical research on new physical theories and future muon collider. We have made preparations to employ young human resources using research funds, and created an environment where young researchers participating in this research, including graduate students, can concentrate on their research. As a concrete research result, in the development of technology related to high-intensity muon beams, we conducted a backward production test of pions using 8GeV protons at J-PARC, and the muons were transported to the laboratory as decay particles of pions. I confirmed that In the development of muon cooling and acceleration technology, we are actively preparing the necessary laser-related equipment and preparing for experiments using deep ultraviolet lasers (244 nm) to perform spectroscopy. In developing muon decay particle measurement technology, we installed a liquid xenon detector to capture gamma rays generated by \u03bc\u2192e\u03b3 decay.",
        "disciplines": [
            "5106",
            "5107"
        ],
        "publications": {
            "10.1007/jhep05(2024)154": {
                "title": "Probing lepton number violation: a comprehensive survey of dimension-7 SMEFT",
                "abstract": "Observation of lepton number violation would represent a groundbreaking discovery with profound consequences for fundamental physics and as such, it has motivated an extensive experimental program searching for neutrinoless double beta decay. However, the violation of lepton number can be also tested by a variety of other observables. We focus on the possibilities of probing this fundamental symmetry within the framework of the Standard Model Effective Field Theory (SMEFT) beyond the minimal dimension-5. Specifically, we study the bounds on \u2206L = 2 dimension-7 effective operators beyond the electron flavor imposed by all relevant low-energy observables and confront them with derived high-energy collider limits. We also discuss how the synergy of the analyzed multi-frontier observables can play a crucial role in distinguishing among different dimension-7 SMEFT operators.",
                "disciplines": [
                    "5106",
                    "5107"
                ]
            },
            "10.1140/epjc/s10052-024-12711-y": {
                "title": "Performances of a new generation tracking detector: the MEG II cylindrical drift chamber",
                "abstract": "The cylindrical drift chamber is the most innovative part of the MEG\u00a0II detector, the upgraded version of the MEG experiment. The MEG\u00a0II chamber differs from the MEG one because it is a single volume cylindrical structure, instead of a segmented one, chosen to improve its resolutions and efficiency in detecting low energy positrons from muon decays at rest. In this paper, we show the characteristics and performances of this fundamental part of the MEG\u00a0II apparatus and we discuss the impact of its higher resolution and efficiency on the sensitivity of the MEG\u00a0II experiment. Because of its innovative structure and high quality resolution and efficiency the MEG\u00a0II cylindrical drift chamber will be a cornerstone in the development of an ideal tracking detector for future positron-electron collider machines.",
                "disciplines": [
                    "5106",
                    "5110"
                ]
            },
            "10.1140/epjc/s10052-024-12416-2": {
                "title": "A search for \u03bc+\u2192e+\u03b3 with the first dataset of the MEG II experiment",
                "abstract": "The MEG\u00a0II experiment, based at the Paul Scherrer Institut in Switzerland, reports the result of a search for the decay \u03bc+\u2192e+\u03b3$$\\upmu ^+ \\rightarrow {\\textrm{e}}^+ \\upgamma $$ from data taken in the first physics run in 2021. No excess of events over the expected background is observed, yielding an upper limit on the branching ratio of B(\u03bc+\u2192e+\u03b3)<7.5\u00d710-13$${\\mathcal {B}} (\\upmu ^+ \\rightarrow {\\textrm{e}}^+ \\upgamma ) < 7.5 \\times 10^{-13}$$ (90% CL). The combination of this result and the limit obtained by MEG gives B(\u03bc+\u2192e+\u03b3)<3.1\u00d710-13$${\\mathcal {B}} (\\upmu ^+ \\rightarrow {\\textrm{e}}^+ \\upgamma ) < 3.1 \\times 10^{-13}$$ (90% CL), which is the most stringent limit to date. A ten-fold larger sample of data is being collected during the years 2022\u20132023, and data-taking will continue in the coming years.",
                "disciplines": [
                    "5107"
                ]
            },
            "10.1140/epjc/s10052-024-12415-3": {
                "title": "Operation and performance of the MEG II detector",
                "abstract": "The MEG\u00a0II experiment, located at the Paul Scherrer Institut (PSI) in Switzerland, is the successor to the MEG experiment, which completed data taking in 2013. MEG\u00a0II started fully operational data taking in 2021, with the goal of improving the sensitivity of the \u03bc+\u2192e+\u03b3$$\\upmu ^+ \\rightarrow {\\textrm{e}}^+ \\upgamma $$ decay down to \u223c6\u00d710-14$$\\sim 6 \\times 10^{-14}$$ almost an order of magnitude better than the current limit. In this paper, we describe the operation and performance of the experiment and give a new estimate of its sensitivity versus data acquisition time.",
                "disciplines": [
                    "5106"
                ]
            },
            "10.1007/jhep02(2024)124": {
                "title": "Quantum entanglement of ions for light dark matter detection",
                "abstract": "A detection scheme is explored for light dark matter, such as axion dark matter or dark photon dark matter, using a Paul ion trap system. We first demonstrate that a qubit, constructed from the ground and first excited states of vibrational modes of ions in a Paul trap, can serve as an effective sensor for weak electric fields due to its resonant excitation. As a consequence, a Paul ion trap allows us to search for weak electric fields induced by light dark matter with masses around the neV range. Furthermore, we illustrate that an entangled qubit system involving N ions can enhance the excitation rate by a factor of N2. The sensitivities of the Paul ion trap system to axion-photon coupling and gauge kinetic mixing can reach previously unexplored parameter space.",
                "disciplines": [
                    "5106",
                    "5107",
                    "5108",
                    "5102"
                ]
            },
            "10.1007/jhep11(2023)103": {
                "title": "Role of QCD in moduli stabilization during inflation and axion dark matter",
                "abstract": "Ignorance of the initial condition for the axion dynamics in the early Universe has led us to consider an O(1) valued initial amplitude, and that prefers the decay constant, Fa, of the QCD axion to be an intermediate scale such as 1012 GeV in order to explain the dark matter abundance. We explore a cosmological scenario of Fa being much larger than 1012 GeV by considering the axion and modulus dynamics during inflation to set the initial amplitude. We show that if the volume modulus (radion) of the extra-dimension is stabilized mainly by the QCD contribution to the modulus potential during inflation, the QCD axion with the string-scale decay constant obtains a mass around the inflationary Hubble parameter. This means that the axion rolls down to the \u03b8 = 0 minimum during the inflation realizing almost vanishing initial amplitude, and the inflationary quantum fluctuation can be the dominant source of the current number density of axions. We find natural parameter regions where the axion explains the cold dark matter of the Universe, while the constraint on the isocurvature perturbation is avoided. The presence of the axion miniclusters or axion stars are predicted in a wide range of parameters, including the one explains the Subaru-HCS microlensing event.",
                "disciplines": [
                    "5106",
                    "5107"
                ]
            },
            "10.1007/jhep06(2023)086": {
                "title": "Lepton flavor physics at \u03bc+\u03bc+ colliders",
                "abstract": "We discuss sensitivities to lepton flavor violating (and conserving) interactions at future muon colliders, especially at \u03bc+\u03bc+ colliders. Compared with the searches for rare decays of \u03bc and \u03c4, we find that the TeV-scale future colliders have better sensitivities depending on the pattern of hierarchy in the flavor mixings. As an example, we study the case with the type-II seesaw model, where the flavor mixing parameters have direct relation to the neutrino mass matrix. At a \u03bc+\u03bc+ collider, the number of events of the \u03bc+\u03bc+ \u2192 \u03bc+\u03c4+ process can be larger than O100$$ \\mathcal{O}(100) $$ with the center of mass energy s$$ \\sqrt{s} $$ = 2 TeV, and with an integrated luminosity L$$ \\mathcal{L} $$ = 1 ab\u22121, while satisfying bounds from rare decays of \u03bc and \u03c4. We discuss impacts of the overall mass scale of neutrinos as well as CP violating phases to the number of expected events.",
                "disciplines": [
                    "5106",
                    "5107"
                ]
            }
        }
    },
    "10007897": {
        "title": "Overcoming limits of miniaturisation to enhance spatial memory capacities",
        "abstract": "Ensuring optimal efficiency at the smallest possible physical limit is a challenge for technical systems, which has been elegantly solved by biological systems. This project aims to identify how insects with miniature brains enhance their memory capacities. It will leverage previous ARC funded research on navigation of Australian ants and apply sophisticated analytical tools to quantify the neural connectivity in the brain in the context of spatial memory. Expected outcomes include understanding how expensive neural tissue can be miniaturised for efficient spatial navigation, identifying the consequences of miniaturisation for developing miniature and autonomous agents, enhancing research capacity and institutional collaborations.",
        "disciplines": [
            "4611"
        ],
        "publications": {
            "10.1093/iob/obad026": {
                "title": "Parallel And Divergent Morphological Adaptations Underlying The Evolution of Jumping Ability in Ants",
                "abstract": "Jumping is a rapid locomotory mode widespread in terrestrial organisms. However, it is a rare specialization in ants. Forward jumping has been reported within four distantly related ant genera: <i>Gigantiops, Harpegnathos, Myrmecia</i>, and <i>Odontomachus</i>. The temporal engagement of legs/body parts during jump, however, varies across these genera. It is unknown what morphological adaptations underlie such behaviors and whether jumping in ants is solely driven directly by muscle contraction or additionally relies on elastic recoil mechanism. We investigated the morphological adaptations for jumping behavior by comparing differences in the locomotory musculature between jumping and non-jumping relatives using X-ray micro-CT and 3D morphometrics. We found that the size-specific volumes of the trochanter depressor muscle (<i>scm6</i>) of the middle and hind legs are 3-5 times larger in jumping ants, and that one coxal remotor muscle (<i>scm2</i>) is reduced in volume in the middle and/or hind legs. Notably, the enlargement in the volume of other muscle groups is directly linked to the legs or body parts engaged during the jump. Furthermore, a direct comparison of the muscle architecture revealed two significant differences between jumping vs. non-jumping ants: First, the relative Physiological Cross-Sectional Area (PCSA) of the trochanter depressor muscles of all three legs were larger in jumping ants, except in the front legs of <i>Odontomachus rixosus</i> and <i>Myrmecia nigrocincta</i>; second, the relative muscle fiber length was shorter in jumping ants compared to non-jumping counterparts, except in the front legs of <i>O. rixosus</i> and <i>M. nigrocincta</i>. These results suggest that the difference in relative muscle volume in jumping ants is largely invested in the area (PCSA), and not in fiber length. There was no clear difference in the pennation angle between jumping and non-jumping ants. Additionally, we report that the hind leg length relative to body length was longer in jumping ants. Based on direct comparison of the observed vs. possible work and power output during jumps, we surmise that direct muscle contractions suffice to explain jumping performance in three species, except for <i>O. rixosus</i>, where the lack of data on jumping performance prevents us from drawing definitive conclusions for this particular species. We suggest that increased investment in jumping-relevant musculature is a primary morphological adaptation that separates jumping from non-jumping ants. These results elucidate the common and idiosyncratic morphological changes underlying this rare adaptation in ants. \u307e\u3068\u3045\u307f (Okinawan language-Uchinaaguchi) (Japanese) \u0420\u0415\u0417\u042e\u041c\u0415 (Kazakh) ZUSAMMENFASSUNG (German).",
                "disciplines": [
                    "3103"
                ]
            },
            "10.1007/s00359-023-01629-7": {
                "title": "Physiological properties of the visual system in the Green Weaver ant, Oecophylla smaragdina",
                "abstract": "The Green Weaver ants, Oecophylla smaragdina are iconic animals known for their extreme cooperative behaviour where they bridge gaps by linking to each other to build living chains. They are visually oriented animals, build chains towards closer targets, use celestial compass cues for navigation and are visual predators. Here, we describe their visual sensory capacity. The major workers of O. smaragdina have more ommatidia (804) in each eye compared to minor workers (508), but the facet diameters are comparable between both castes. We measured the impulse responses of the compound eye and found their response duration (42\u00a0ms) was similar to that seen in other slow-moving ants. We determined the flicker fusion frequency of the compound eye at the brightest light intensity to be 132\u00a0Hz, which is relatively fast for a walking insect suggesting the visual system is well suited for a diurnal lifestyle. Using pattern-electroretinography we identified the compound eye has a spatial resolving power of 0.5 cycles deg\u22121 and reached peak contrast sensitivity of 2.9 (35% Michelson contrast threshold) at 0.05 cycles deg\u22121. We discuss the relationship of spatial resolution and contrast sensitivity, with number of ommatidia and size of the lens.",
                "disciplines": [
                    "3109"
                ]
            },
            "10.1101/2023.03.11.531676": {
                "title": "Parallel and divergent morphological adaptations underlying the evolution of jumping ability in ants",
                "abstract": "ABSTRACT  Jumping is a rapid locomotory mode widespread in terrestrial organisms. However, it is a rare specialization in ants. Forward jumping has been reported within four distantly related ant genera: Gigantiops , Harpegnathos , Myrmecia , and Odontomachus . The temporal engagement of legs/body parts during jump, however, varies across these genera. It is unknown what morphological adaptations underlie such behaviors, and whether jumping in ants is solely driven directly by muscle contraction or additionally relies on elastic recoil mechanism. We investigate the morphological adaptations for jumping behavior by comparing differences in the locomotory musculature between jumping and non-jumping relatives using x-ray micro- CT and 3D morphometrics. We found that the size-specific volumes of the trochanter depressor muscle ( scm6 ) of the middle and hind legs are 3-5 times larger in jumping ants, and that one coxal remotor muscle ( scm2 ) is reduced in volume in the middle and/or hind legs. Notably, the enlargement in the volume of other muscle groups is directly linked to the legs or body parts engaged during the jump. Furthermore, a direct comparison of the muscle architecture revealed two significant differences between in jumping versus non-jumping ants: First, the relative Physiological Cross-Sectional Area (PCSA) of the trochanter depressor muscles of all three legs were larger in jumping ants, except in the front legs of O. rixosus and M. nigrocincta ; second, the relative muscle fiber length was shorter in jumping ants compared to non-jumping counterparts, except in the front legs of O. rixosus and M. nigrocincta . This suggests that the difference in relative muscle volume in jumping ants is largely invested in the area (PCSA), and not in fiber length. There was no clear difference in the pennation angle between jumping and non-jumping ants. However, the length of hind legs relative to body length was longer in jumping ants. Based on direct comparison of the observed vs. possible work and power output during jumps, we surmise that direct muscle contractions suffice to explain jumping performance, in two species, but elastic recoil is likely important in one. We suggest that increased investment in jumping-relevant musculature is a primary morphological adaptation that separates jumping from non-jumping ants. These results elucidate the common and idiosyncratic morphological changes underlying this rare adaptation in ants. ",
                "disciplines": [
                    "3103"
                ]
            }
        }
    },
    "13022251": {
        "title": "INNATE Investigating the nature and origins of exoplanets in the Neptunian desert",
        "abstract": "Our knowledge of exoplanets has undergone a step change since the discovery of 51 Peg b 25 years ago. Planets are now commonplace, with most stars found to be hosting planetary systems. In the set of over 4300 planets known, trends and gaps in the distribution are seen with respect to planet size, composition and host star properties, arising from the formation and evolution processes which sculpt these worlds.\n\nA striking signature in the planet distribution is the 'Neptunian desert', a dearth of Neptune-like planets orbiting close to their host stars. Planets which arrive so close to their stars are evaporated away, or are disrupted entirely by the strong gravitational forces of the star. Yet, recently a number of planets have been discovered inside the desert, surprising expectations and highlighting a gap in our understanding. The origin of these hot Neptunes is unknown, and they present a unique opportunity to study the extreme outcomes of planet formation. Such outliers of the normal processes allow us to benchmark planetary formation theories, with many of the typical degeneracies stripped away.\n\nWith this proposal, we will combine photometric and spectroscopic observations from TESS, NGTS, CORALIE, HARPS and Gaia to carry out an ambitious and comprehensive research program investigating the nature and origins of planets in the desert. (1) We will uncover the unbiased demographic properties of the in-desert planets, finding the distributions of planet mass, radius, density, internal structure and host star properties. (2) We will establish the dynamical context of these systems by determining the presence of outer companions and local density of stars (3) We will connect the measured demographics, dynamics and internal structure to wider formation and evolution theory. The combined results will transform our understanding not only of the in-desert planets but of the wider formation, structure and evolution of planetary systems.",
        "disciplines": [
            "5109",
            "5101"
        ],
        "publications": {
            "10.1093/mnras/stae997": {
                "title": "Constraints on atmospheric water abundance and cloud deck pressure in the warm Neptune GJ 3470 b via CARMENES transmission spectroscopy",
                "abstract": "ABSTRACT Observations of cooler atmospheres of super-Earths and Neptune sized objects often show flat transmission spectra. The most likely cause of this trend is the presence of aerosols (i.e. clouds and hazes) in the atmospheres of such objects. High-resolution spectroscopy provides an opportunity to test this hypothesis by targeting molecular species whose spectral line cores extend above the level of such opaque decks. In this work, we analyse high-resolution infrared observations of the warm Neptune GJ 3470 b taken over two transits using CARMENES (R \u223c 80 000) and look for signatures of H2O (previously detected using Hubble Space Telescope (HST) WFC3 + Spitzer observations) in these transits with a custom pipeline fully accounting for the effects of data cleaning on any potential exoplanet signal. We find that our data are potentially able to weakly detect (\u223c3\u03c3) an injected signal equivalent to the best-fitting model from previous HST WFC3\u00a0+\u00a0Spitzer observations. However, we do not make a significant detection using the actual observations. Using a Bayesian framework to simultaneously constrain the H2O volume mixing ratio (VMR) and the cloud top pressure level, we select a family of models compatible with the non-detection. These are either very high VMR cloud-free models, solar-abundance models with a high cloud deck, or sub-solar abundance models with a moderate cloud deck. This is a broader range compared to published results from low-resolution spectroscopy, but is also compatible with them at a 1\u03c3 level.",
                "disciplines": [
                    "5109"
                ]
            },
            "10.1093/mnras/stae616": {
                "title": "The TESS-SPOC FFI target sample explored with Gaia",
                "abstract": "ABSTRACT The Transiting Exoplanet Survey Satellite (TESS) mission has provided the community with high-precision times-series photometry for \u223c2.8 million stars across the entire sky via the full frame image (FFI) light curves produced by the TESS Science Processing Operations Center (SPOC). This set of light curves is an extremely valuable resource for the discovery of transiting exoplanets and other stellar science. However, due to the sample selection, this set of light curves does not constitute a magnitude-limited sample. In order to understand the effects of this sample selection, we use Gaia Data Release 2 (DR2) and Data Release 3 (DR3) to study the properties of the stars in the TESS-SPOC FFI light-curve set, with the aim of providing vital context for further research using the sample. We report on the properties of the TESS-SPOC FFI targets in Sectors 1\u201355 (covering Cycles 1\u20134). We cross-match the TESS-SPOC FFI targets with the Gaia DR2 and DR3 catalogues of all targets brighter than Gaia magnitude 14 to understand the effects of sample selection on the overall stellar properties. This includes Gaia magnitude, parallax, radius, temperature, non-single star flags, luminosity, radial velocity, and stellar surface gravity. In total, there are \u223c16.7 million Gaia targets brighter than G\u00a0=\u00a014, which when cross-matched with the TESS-SPOC FFI targets leaves \u223c2.75 million. We investigate the binarity of each TESS-SPOC FFI target and calculate the radius detection limit from two detected TESS transits that could be detected around each target. Finally, we create a comprehensive main-sequence TESS-SPOC FFI target sample that can be utilized in future studies.",
                "disciplines": [
                    "5109"
                ]
            },
            "10.1051/0004-6361/202348958": {
                "title": "TESS and ESPRESSO discover a super-Earth and a mini-Neptune orbiting the K-dwarf TOI-238***",
                "abstract": " The number of super-Earth and mini-Neptune planet discoveries has increased significantly in the last two decades thanks to transit and radial velocity (RV) surveys. When it is possible to apply both techniques, we can characterise the internal composition of exoplanets, which in turn provides unique insights on their architecture, formation and evolution. We performed a combined photometric and RV analysis of TOI-238 (TYC 6398-132-1), which has one short-orbit super-Earth planet candidate announced by NASA\u2019s TESS team. We aim to confirm its planetary nature using radial velocities taken with the ESPRESSO and HARPS spectrographs, to measure its mass, and to detect the presence of other possible planetary companions. We carried out a joint analysis by including Gaussian processes and Keplerian orbits to account for the stellar activity and planetary signals simultaneously. We detected the signal induced by TOI-238 b in the RV time series, and the presence of a second transiting planet, TOI-238 c, whose signal appears in RV and TESS data. TOI-238 b is a planet with a radius of 1.402 \u22120.086 +0.084 R \u2295 and a mass of 3.40 \u22120.45 +0.46 M \u2295 . It orbits at a separation of 0.02118 \u00b1 0.00038 au of its host star, with an orbital period of 1.2730988 \u00b1 0.0000029 days, and has an equilibrium temperature of 1311 \u00b1 28 K. TOI-238 c has a radius of 2.18 \u00b1 0.18 R \u2295 and a mass of 6.7 \u00b1 1.1 M \u2295 . It orbits at a separation of 0.0749 \u00b1 0.0013 au of its host star, with an orbital period of 8.465652 \u00b1 0.000031 days, and has an equilibrium temperature of 696 \u00b1 15 K. The mass and radius of planet b are fully consistent with an Earth-like composition, making it a likely rocky super-Earth. Planet c could be a water-rich planet or a rocky planet with a small H-He atmosphere. ",
                "disciplines": [
                    "5109",
                    "5101"
                ]
            },
            "10.1093/mnras/stad3163": {
                "title": "Sandwiched planet formation: restricting the mass of a middle planet",
                "abstract": "ABSTRACT We conduct gas and dust hydrodynamical simulations of protoplanetary discs with one and two embedded planets to determine the impact that a second planet located further out in the disc has on the potential for subsequent planet formation in the region locally exterior to the inner planet. We show how the presence of a second planet has a strong influence on the collection of solid material near the inner planet, particularly when the outer planet is massive enough to generate a maximum in the disc\u2019s pressure profile. This effect in general acts to reduce the amount of material that can collect in a pressure bump generated by the inner planet. When viewing the inner pressure bump as a location for potential subsequent planet formation of a third planet, we therefore expect that the mass of such a planet will be smaller than it would be in the case without the outer planet, resulting in a small planet being sandwiched between its neighbours \u2013 this is in contrast to the expected trend of increasing planet mass with radial distance from the host star. We show that several planetary systems have been observed that do not show this trend but instead have a smaller planet sandwiched in between two more massive planets. We present the idea that such an architecture could be the result of the subsequent formation of a middle planet after its two neighbours formed at some earlier stage.",
                "disciplines": [
                    "5109"
                ]
            },
            "10.1093/mnras/stad2183": {
                "title": "Discovery and characterization of two Neptune-mass planets orbiting HD 212729 with TESS",
                "abstract": "ABSTRACT We report the discovery of two exoplanets orbiting around HD 212729 (TOI 1052, TIC 317060587), a Teff\u00a0= 6146 K star with V\u00a0=\u00a09.51 observed by TESS in Sectors 1 and 13. One exoplanet, TOI-1052b, is Neptune-mass and transits the star, and an additional planet TOI-1052c is observed in radial velocities but not seen to transit. We confirm the planetary nature of TOI-1052b using precise radial velocity observations from HARPS and determined its parameters in a joint RV and photometry analysis. TOI-1052b has a radius of $2.87^{+0.29}_{-0.24}$ R\u2295, a mass of 16.9\u00a0\u00b1\u00a01.7 M\u2295, and an orbital period of 9.14 d. TOI-1052c does not show any transits in the TESS data, and has a minimum mass of $34.3^{+4.1}_{-3.7}$ M\u2295 and an orbital period of 35.8 d, placing it just interior to the 4:1 mean-motion resonance. Both planets are best fit by relatively high but only marginally significant eccentricities of $0.18^{+0.09}_{-0.07}$ for planet b and $0.24^{+0.09}_{-0.08}$ for planet c. We perform a dynamical analysis and internal structure model of the planets as well as deriving stellar parameters and chemical abundances. The mean density of TOI-1052b is $3.9^{+1.7}_{-1.3}$ g cm\u22123 consistent with an internal structure similar to Neptune. A nearby star is observed in Gaia DR3 with the same distance and proper motion as TOI-1052, at a sky projected separation of $\\scriptstyle \\sim$1500 au, making this a potential wide binary star system.",
                "disciplines": [
                    "5109",
                    "5101"
                ]
            }
        }
    },
    "13057718": {
        "title": "Systematic Identification and Phenotypic Characterization of causal genetic variants in Rare Disease-Associated Birth Defects",
        "abstract": "Project Summary Although the implementation of whole exome sequencing (WES) and whole genome sequencing (WGS) in a clinical setting has greatly facilitated the identification of birth defect-associated genetic variants, distinguishing the specific variants that cause congenital defects remains a major challenge. More specifically, most variants detected in clinical sequencing occur in genes not previously associated with disease or in noncoding regions of the genome that lack predictable functional consequences. Enhancing the ability to illuminate causal variants holds the promise of improving the quality of life for patients and in some cases may provide a window for therapeutic intervention that would otherwise be missed. In this proposal we leverage our institute\u2019s unparalleled pediatric genetic data repository to guide the development of scalable cell-based systems that, when coupled with phenotypic validation in both animal and patient-derived organoid models, will systematically identify genetic variants that are responsible for congenital defects in our undiagnosed rare disease patient population. We will (Aim 1) catalog loss-of-function variants associated with the most prevalent congenital defects in our patient population, perform genome-scale CRISPR screens in relevant organoid models to distinguish variant-harboring genes that play a role in development, and validate the phenotypic consequences of gene loss in a zebrafish model. In parallel, we will (Aim 2) catalog noncoding variants (i.e. intronic, putative cis-regulatory) associated with prevalent congenital defects, develop a suite of massively parallel genomic assays capable of profiling the regulatory impact of noncoding genetic variants at scale, and perturb the expression of candidate variant- associated genes in a zebrafish model to determine the phenotypic consequences. Finally, we will (Aim 3) generate patient-derived organoid models, utilize precision genome engineering in combination with single-cell transcriptomics in patient-derived organoids to validate the causal role of specific variants in congenital defects, and characterize the impact of variants on development using spatial transcriptomics in patient-derived organoids as a proxy. We anticipate that the work outlined in this proposal will establish an experimental framework that can be deployed to identify genetic variants that are responsible for a wide variety of congenital defects.",
        "disciplines": [
            "3105"
        ],
        "publications": {
            "10.1101/2024.01.14.574481": {
                "title": "Emotion-related impulsivity is related to orbitofrontal cortical sulcation",
                "abstract": "Background: Emotion-related impulsivity (ERI) describes the trait-like tendency toward poor self-control when experiencing strong emotions. ERI has been shown to be elevated across psychiatric disorders and predictive of the onset and worsening of psychiatric syndromes. Recent work has correlated ERI scores with the neuroanatomy of the orbitofrontal cortex (OFC). Informed by a growing body of research indicating that the morphology of cortical folds (sulci) can produce insights into behavioral outcomes, the present study modeled the association between ERI and the sulcal morphology of OFC at a finer scale than previously conducted.\nMethods: Analyses were conducted in a transdiagnostic sample of 118 individuals with a broad range of psychiatric syndromes. We first manually defined over 2000 sulci across the 118 participants. We then implemented a model-based LASSO regression to relate OFC sulcal morphology to ERI and test whether effects were specific to ERI as compared to non-emotion-related impulsivity.\nResults: The LASSO regression revealed bilateral associations of ERI with the depth of eight OFC sulci. These effects were specific to ERI and were not observed in non-emotion-related impulsivity. In addition, we identified a new transverse component of the olfactory sulcus in every hemisphere that is dissociable from the longitudinal component based on anatomical features and correlation with behavior, which could serve as a new transdiagnostic biomarker.\nConclusions: The results of this data-driven investigation provide greater neuroanatomical and neurodevelopmental specificity on how OFC is related to ERI. As such, findings link neuroanatomical characteristics to a trait that is highly predictive of psychopathology.",
                "disciplines": [
                    "5202"
                ]
            }
        }
    },
    "13680169": {
        "title": "Conception of a State Estimator for Electric Power Systems Aimed at New Operation Paradigms",
        "abstract": "Technological developments, which Electrical Power Systems (EPS) have been going through since the beginning of this century, have led to an increase in the quantity and quality of data on the operating state of these systems, which are made available in real time to the operator. In this sense, it is vital to rethink the traditional State Estimator (EE) formulation, so that it is possible to take greater advantage of this scenario. Another factor that supports the reformulation of this application is the fact that the insertion of Distributed Energy Resources (RED) makes the behavior of the PES even more complex, requiring more accurate monitoring of the state of operation. In addition, currently, several components based on power electronics are present in EPS and how to represent them, within the state estimation process, is still a great challenge. It is noteworthy that although there are works in the literature addressing these points, most treat them in isolation, without presenting a hermetic solution, in view of the final objectives of the estimation process. In view of the above, this research project proposes the development of an EE that is capable of dealing with the current situation of the SEP, being able to adequately represent the behavior of current electrical networks, and consequently improve the accuracy of the state estimation process . For this, techniques of Bayesian Inference, modeling of power electronics devices for SEP analysis, non-linear optimization and parallel computing will be used. Computational, in Electric Power Systems (LACOSEP), from the School of Engineering of S\u00e3o Carlos, University of S\u00e3o Paulo.",
        "disciplines": [
            "4008"
        ],
        "publications": {
            "10.1007/s40313-024-01095-9": {
                "title": "Review of Power System State Estimation and Maturity Level of Market Solutions: Preceding Steps",
                "abstract": "Power system state estimation (PSSE) is a control center application that comprises a collection of algorithms aimed at providing essential information about the current operating condition of the power grid. As such, PSSE plays a vital role in the real-time operation of power systems. Accuracy and reliability of the estimator are closely connected to both quality and quantity of the real-time data that feed it. Therefore, such applications can benefit from functions that pre-filter the dataset, removing obvious spurious measurements or complementing it with reliable information. Moreover, some functionalities intended to analyze the dataset are desirable, since they indicate if state estimation can be performed with the currently available measurement set and if its vulnerabilities can be identified. Such analysis tools can assist in the design of measurement sets, or strengthen an existing one. They constitute preceding steps for PSSE and have drawn growing interest in recent years, with the evolution of computational techniques and the advent of new technologies. This paper provides a review of the literature on such preceding steps, namely pre-filtering, observability analysis, redundancy/criticality analysis, and metering system design, along with a market evaluation of existing solutions, with main focus on transmission systems.",
                "disciplines": [
                    "4007"
                ]
            },
            "10.1109/tpwrs.2023.3321700": {
                "title": "Angular Reference Problem for Three-Phase Distribution System State Estimation",
                "abstract": "State Estimator is a key monitoring feature for the conception of Smart Grids. Although largely used in transmission systems, the implementation of estimators that correctly capture the Distribution Systems' (DSs) behavior is challenging, partially due to these circuits' asymmetric and unbalanced nature. As a result, a three-phase representation of the network is required. Despite some good theoretical results with this formulation, they usually use a phase angle reference for each phase, assuming balanced voltage phase angles at the Reference Bus (RB), which does not enable the estimator to encompass the unbalanced nature of those circuits. This article investigates the number of reference angles required for a three-phase Distribution System State Estimator (DSSE) from an observability point of view. Based on this concept, this study derives a condition for the use of only one phase angle as the reference. The article also introduces a method that properly represents the RB and promotes the use of one reference in most cases. Results from IEEE 34, IEEE 123, and 1058 bus Brazilian test feeders show the approach's feasibility and the negative effect of the mistreatment of the RB.",
                "disciplines": [
                    "4009"
                ]
            }
        }
    },
    "10007752": {
        "title": "Adaptive and Ubiquitous Trust Framework for Internet of Things interactions",
        "abstract": "The aim of the project is to address the Trust challenges in Internet of Things (IoT) environments, thus enabling the wide deployment of potentially billions of IoT devices. This project will generate new knowledge in the area of IoT Trust by developing novel techniques to establish trust in highly dynamic crowdsourcing IoT environments. The project's main outcomes include the development of a ubiquitous and adaptive multi-component trust framework reflecting trust perspectives. The developed solutions will allow the establishment of trusted interactions among crowdsourced IoT devices and  wider deployment of convenient and just-in-time services, thus enabling the development of novel applications, such as the crowdsourcing of green energy.",
        "disciplines": [
            "4606",
            "4605"
        ],
        "publications": {
            "10.1109/tits.2024.3392914": {
                "title": "Reactive Composition of UAV Delivery Services in Urban Environments",
                "abstract": "We propose a novel failure-aware reactive UAV delivery service composition framework. A skyway network infrastructure is presented for the effective provisioning of services in urban areas. We present a formal drone delivery service model and a system architecture for reactive drone delivery services. We develop radius-based, cell density-based, and two-phased algorithms to reduce the search space and perform reactive service compositions when a service failure occurs. We conduct a set of experiments with a real drone dataset to demonstrate the effectiveness of our proposed approach.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1007/978-981-97-0989-2_24": {
                "title": "Immersive 3D Simulator for Drone-as-a-Service",
                "abstract": "We propose a 3D simulator tailored for the Drone-as-a-Service framework. The simulator enables employing dynamic algorithms for addressing realistic delivery scenarios. We present the simulator\u2019s architectural design and its use of an energy consumption model for drone deliveries. We introduce two primary operational modes within the simulator: the edit mode and the runtime mode. Beyond its simulation capabilities, our simulator serves as a valuable data collection resource, facilitating the creation of datasets through simulated scenarios. Our simulator empowers researchers by providing an intuitive platform to visualize and interact with delivery environments. Moreover, it enables rigorous algorithm testing in a safe simulation setting, thus obviating the need for real-world drone deployments. Demo: https://youtu.be/HOLfo1JiFJ0.",
                "disciplines": []
            },
            "10.1109/tsc.2023.3332701": {
                "title": "Determining Intent of Changes to Ascertain Fake Crowdsourced Image Services",
                "abstract": "We propose a novel framework for crowdsourced images to determine the likelihood of an image being fake. We use a service-oriented approach to model and represent crowdsourced images uploaded on social media, as image services. Trust may, in some circumstances, be determined by using only the non-functional attributes of an image service, i.e., image metadata. We define intention of changes as a key parameter to ascertain fake image services. A novel framework is proposed to estimate the intention of underlying changes considering change in semantics of an image. Our experiments show high accuracy using a large real dataset.",
                "disciplines": [
                    "4603"
                ]
            },
            "10.1007/978-3-031-48424-7_15": {
                "title": "Detecting Changes in Crowdsourced Social Media Images",
                "abstract": "We propose a novel service framework to detect changes in crowdsourced images. We use a service-oriented approach to model and represent crowdsourced images as image services. Non-functional attributes of an image service are leveraged to detect changes in an image. The changes are reported in form of a version tree. The version tree is constructed in a way that it reflects the extent of changes introduced in different versions. Afterwards, we find semantic differences in between different versions to determine the extent of changes introduced in a specific version. Preliminary experimental results demonstrate the effectiveness of the proposed approach.",
                "disciplines": [
                    "4603"
                ]
            },
            "10.1007/978-3-031-48424-7_13": {
                "title": "Context-Aware Trustworthy IoT Energy Services Provisioning",
                "abstract": "We propose an IoT energy service provisioning framework to ensure consumers\u2019 Quality of Experience (QoE). A novel context-aware trust assessment model is proposed to evaluate the trustworthiness of providers. Our model adapts to the dynamic nature of energy service providers to maintain QoE by selecting trustworthy providers. The proposed model evaluates providers\u2019 trustworthiness in various contexts, considering their behavior and energy provisioning history. Additionally, a trust-adaptive composition technique is presented for optimal energy allocation. Experimental results demonstrate the effectiveness and efficiency of the proposed approaches.",
                "disciplines": [
                    "4606"
                ]
            },
            "10.1145/3631353": {
                "title": "Positional Encoding-based Resident Identification in Multi-resident Smart Homes",
                "abstract": "We propose a novel resident identification framework to identify residents in a multi-occupant smart environment. The proposed framework employs a feature extraction model based on the concepts of positional encoding. The feature extraction model considers the locations of homes as a graph. We design a novel algorithm to build such graphs from layout maps of smart environments. The Node2Vec algorithm is used to transform the graph into high-dimensional node embeddings. A Long Short-Term Memory model is introduced to predict the identities of residents using temporal sequences of sensor events with the node embeddings. Extensive experiments show that our proposed scheme effectively identifies residents in a multi-occupant environment. Evaluation results on two real-world datasets demonstrate that our proposed approach achieves 94.5% and 87.9% accuracy, respectively.",
                "disciplines": [
                    "4605",
                    "4603"
                ]
            },
            "10.1145/3629517": {
                "title": "A Survey on Conflict Detection in IoT-based Smart Homes",
                "abstract": "As the adoption of IoT-based smart homes continues to grow, the importance of addressing potential conflicts becomes increasingly vital for ensuring seamless functionality and user satisfaction. In this survey, we introduce a novel conflict taxonomy, complete with formal definitions of each conflict type that may arise within the smart home environment. We design an advanced conflict model to effectively categorize these conflicts, setting the stage for our in-depth review of recent research in the field. By employing our proposed model, we systematically classify conflicts and present a comprehensive overview of cutting-edge conflict detection approaches. This extensive analysis allows us to highlight similarities, clarify significant differences, and uncover prevailing trends in conflict detection techniques. In conclusion, we shed light on open issues and suggest promising avenues for future research to foster accelerated development and deployment of IoT-based smart homes, ultimately enhancing their overall performance and user experience.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1109/icdcs57875.2023.00111": {
                "title": "CrowdWeb: A Visualization Tool for Mobility Patterns in Smart Cities",
                "abstract": "Human mobility patterns refer to the regularities and trends in the way people move, travel, or navigate through different geographical locations over time. Detecting human mobility patterns is essential for a variety of applications, including smart cities, transportation management, and disaster response. The accuracy of current mobility prediction models is less than 25%. The low accuracy is mainly due to the fluid nature of human movement. Typically, humans do not adhere to rigid patterns in their daily activities, making it difficult to identify hidden regularities in their data. To address this issue, we proposed a web platform to visualize human mobility patterns by abstracting the locations into a set of places to detect more realistic patterns. However, the platform was initially designed to detect individual mobility patterns, making it unsuitable for representing the crowd in a smart city scale. Therefore, we extend the platform to visualize the mobility of multiple users from a city-scale perspective. Our platform allows users to visualize a graph of visited places based on their historical records using a modified PrefixSpan approach. Additionally, the platform synchronizes, aggregates, and displays crowd mobility patterns across various time intervals within a smart city. We showcase our platform using a real dataset.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1109/icws60048.2023.00056": {
                "title": "Energy Loss Prediction in IoT Energy Services",
                "abstract": "We propose a novel Energy Loss Prediction(ELP) framework that estimates the energy loss in sharing crowdsourced energy services. Crowdsourcing wireless energy services is a novel and convenient solution to enable the ubiquitous charging of nearby IoT devices. Therefore, capturing the wireless energy sharing loss is essential for the successful deployment of efficient energy service composition techniques. We propose Easeformer, a novel attention-based algorithm to predict the battery levels of IoT devices in a crowdsourced energy sharing environment. The predicted battery levels are used to estimate the energy loss. A set of experiments were conducted to demonstrate the feasibility and effectiveness of the proposed framework. We conducted extensive experiments on real wireless energy datasets to demonstrate that our framework significantly outperforms existing methods.",
                "disciplines": [
                    "4605",
                    "4606",
                    "4608"
                ]
            },
            "10.1109/icws60048.2023.00031": {
                "title": "Federated Learning-driven Trust Prediction for Mobile Edge Computing-based IoT Systems",
                "abstract": "We propose a federated learning-based data-driven trust prediction method to meet the demand of high-accuracy IoT service trustworthiness prediction in Mobile Edge Computing (MEC) with low convergence time. Our research focuses on the mixture distribution and heterogeneity features of IoT trust information in distributed MEC environments and formulates the task of distributed IoT trust prediction on top of MEC network topologies as a federated optimization problem. We then employ Federated Expectation-Maximization to mitigate the federated optimization problem by taking into account the data mixture distribution and heterogeneity. We conduct a series of experiments upon simulated MEC-based IoT environments crafted on top of a real-world IoT dataset. The experimental results show that our proposed methods can achieve better balance between prediction accuracy and model training efficiency than a state-of-the-art data-driven MEC-based IoT service trust prediction method and a Federated Averaging-based method.",
                "disciplines": [
                    "4605",
                    "4606"
                ]
            },
            "10.1109/icws60048.2023.00068": {
                "title": "Failure-Sentient Composition For Swarm-Based Drone Services",
                "abstract": "We propose a novel failure-sentient framework for swarm-based drone delivery services. The framework ensures that those drones that experience a noticeable degradation in their performance (called soft failure) and which are part of a swarm, do not disrupt the successful delivery of packages to a consumer. The framework composes a weighted continual federated learning prediction module to accurately predict the time of failures of individual drones and uptime after failures. These predictions are used to determine the severity of failures at both the drone and swarm levels. We propose a speed-based heuristic algorithm with lookahead optimization to generate an optimal set of services considering failures. Experimental results on real datasets prove the efficiency of our proposed approach in terms of prediction accuracy, delivery times, and execution times.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1109/tsc.2023.3307143": {
                "title": "Flow-Based Energy Services Composition",
                "abstract": "We propose a novel spatio-temporal service composition framework for crowdsourcing multiple IoT energy services to cater to multiple energy requests. We define a new energy service model to leverage the wearable-based energy and wireless power transfer technologies. We reformulate the problem of spatio-temporal service composition to provision multiple energy requests as a matching problem. We leverage the fragmented nature of energy to offer partial services to maximize the utilization of energy services. We propose EnergyFlowComp, a modified Maximum Flow matching algorithm that efficiently provisions IoT energy services to accommodate multiple energy requests. Moreover, we propose PartialFlowComp, an extension of the EnergyFlowComp approach that considers the partial-temporal overlap between services and requests in provisioning. We conduct an extensive set of experiments to assess the effectiveness and efficiency of the proposed framework.",
                "disciplines": [
                    "4606"
                ]
            },
            "10.1145/3600232": {
                "title": "An End-to-end Trust Management Framework for Crowdsourced IoT Services",
                "abstract": " We propose a novel end-to-end trust management framework for crowdsourced Internet of Things (IoT) services. The framework targets three main aspects: trust assessment , trust information credibility and accuracy , and trust information storage . We harness the usage patterns of IoT consumers to offer a trust assessment that adapts to IoT consumers\u2019 uses. Additionally, our framework ascertains the credibility and accuracy of trust-related information before trust assessment. This is achieved by validating the data collected by IoT consumers and providers. In addition, our framework ensures the contextual fairness between IoT services and trust information. Moreover, we propose a blockchain-based trust information storage approach. Our proposed storage solution preserves the integrity and availability of trust information. ",
                "disciplines": [
                    "4606"
                ]
            },
            "10.1109/mic.2023.3267266": {
                "title": "Optimizing Drone Delivery in Smart Cities",
                "abstract": "We propose a novel context-aware drone delivery framework for optimizing package delivery through skyway networks in smart cities. We reformulate the problem of finding an optimal drone service delivery pathway as a more congruent and elegant drone delivery service composition problem. In this respect, we propose a novel line-of-sight heuristic-based context-aware composition algorithm that selects and composes near-optimal drone delivery services. We conducted an extensive experiment using a real dataset to show the robustness of our proposed approach.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1109/tsc.2023.3241975": {
                "title": "Edge Intelligence for Real-Time IoT Service Trust Prediction",
                "abstract": "Mobile Edge Computing (MEC)-based Internet of Things (IoT) systems generate trust information in a real-time and distributed manner. Predicting trustworthiness of IoT services in such an MEC environment requires new prediction strategies that cater for the aforementioned characteristics of trust information. More importantly, it is imperative to investigate how the real-time trust information could be effectively integrated into trust prediction strategies in order to capture the ever-evolving nature of trustworthiness of IoT services. In turn, such a strategy allows IoT service consumers to derive more relevant and accurate trust-based decisions. To that end, our work models trust prediction in MEC-based IoT systems as an online regularized finite-sum problem in a distributed MEC environment with a given MEC topology. We then adopt the Online Alternating Direction Method (OADM) to effectively train trust prediction models in parallel over the distributed MEC environment. OADM allows splitting the aforementioned finite-sum problem into multiple sub-problems that correspond to different local MEC environments. These sub-problems can then be solved iteratively within each local MEC environment by using the local trust data therein. This can avoid the movement of data across the core networks of mobile network providers. Experiments on real-world and synthetic datasets demonstrate the effectiveness and scalability of the proposed method.",
                "disciplines": [
                    "4605",
                    "4606"
                ]
            },
            "10.1109/tmc.2022.3230856": {
                "title": "Mobility-Aware and Privacy-Protecting QoS Optimization in Mobile Edge Networks",
                "abstract": "With the rapid development of 5G technologies, the demand of quality of service (QoS) from edge users, including high bandwidth and low latency, has increased dramatically. QoS within a mobile edge network is highly dependent on the allocation of edge users. However, the complexity of user movement greatly challenges edge user allocation, leading to privacy leakage. In addition, updating massive data constantly in a dynamic mobile edge network also crucial to ensure efficiency. To address these challenges, this paper proposes a dynamic QoS optimization strategy (MENIFLD_QoS) in mobile edge networks based on incremental learning and federated learning. MENIFLD_QoS optimizes service cache in edge regions and allocates edge servers to edge users according to the locations of edge servers accessed by edge users in mobile scenarios. While optimizing regional service quality, the system can effectively protect user privacy. In addition, for dynamic incremental data, MENIFLD_QoS trains updated data based on the strategy of incremental learning hence significantly improves optimization speed. Experimental results on an edge QoS dataset show that the proposed strategy achieves global optimization in both multi-variable and multi-peak user allocation scenarios and notably enhances the training efficiency of the regional invocation model.",
                "disciplines": [
                    "4606"
                ]
            },
            "10.1007/978-3-031-20984-0_9": {
                "title": "Mobility-Aware Proactive QoS Monitoring for Mobile Edge Computing",
                "abstract": "This article presents a novel probabilistic QoS (Quality of Service) monitoring approach called LSTM-BSPM (DonLSTM-Den based BayeSian Runtime Proactive Monitoring), which is based on the DouLSTM-Den model and Gaussian Hidden Bayesian Classifier for mobile edge environments. A DouLSTM-Den model is designed to predict a user\u2019s trajectory in mobile edge environments. The predicted trajectory is leveraged to obtain the mobility-aware QoS and capture its spatio-temporal dependency. Next, a parent attribute is constructed for each QoS attribute to reduce the influence of dependence between QoS attributes on monitoring accuracy. A Gaussian hidden Bayes classifier is trained for each edge server to proactively monitor the user\u2019s mobility-aware QoS. We conduct a set of experiments respectively upon a public data set and a real-world data set demonstrate the feasibility and effectiveness of the proposed approach.",
                "disciplines": [
                    "4605",
                    "4606"
                ]
            },
            "10.1109/tsc.2022.3160469": {
                "title": "Multi-Use Trust in Crowdsourced IoT Services",
                "abstract": "We introduce the concept of adaptive trust in crowdsourced IoT services. It is a customized fine-grained trust tailored for specific IoT consumers. Usage patterns of IoT consumers are exploited to provide an accurate trust value for service providers. A novel adaptive trust management framework is proposed to assess the dynamic trust of IoT services. The framework leverages a novel detection algorithm to obtain trust indicators that are likely to influence the trust level of a specific IoT service type. Detected trust indicators are then used to build service-to-indicator model to evaluate a service\u2019s trust at each indicator. Similarly, a usage-to-indicator model is built to obtain the importance of each trust indicator for a particular usage scenario. The per-indicator trust and the importance of each trust indicator are utilized to obtain an overall value of a given service for a specific consumer. We conduct a set of experiments on a real dataset to show the effectiveness of the proposed framework.",
                "disciplines": [
                    "4605"
                ]
            }
        }
    },
    "13238691": {
        "title": "Effects of Bilateral Motor Priming and Task Specific Training on Corticomotor Excitability and Transcallosal Inhibition in People with Upper Limb Hemiparesis Secondary to Stroke",
        "abstract": "Project Summary Over the last 20 years, upper limb rehabilitation intervention trials for severe and chronic post stroke hemiparesis have largely failed to find significant differences in functional improvement between intervention and control groups. This has resulted in a dearth of treatment options for at least 50% of stroke survivors who continue to experience deficits which limit their independence in activities of daily living. To remedy this shortcoming in field of neurorehabilitation, it is necessary to understand the neural mechanisms which are central to the motor recovery process following a stroke. We can then develop experiments to exploit these mechanisms with the goal of optimizing treatment efficacy and facilitating increased independence for the individual. Our lab recently published a pilot study on individuals with chronic stroke and moderate to severe impairments in the UL which suggests that bilateral motor priming in combination with task specific training is an effective treatment option that can benefit people with severe post-stroke hemiparesis. However, the neurophysiological mechanisms behind the positive behavioral changes remain unknown. This proposed research will use transcranial magnetic stimulation (TMS) data from an ongoing clinical trial to investigate the impact of bilateral motor priming on corticomotor excitability and transcallosal inhibition of the ipsilesional and contralesional hemispheres in people with chronic stroke (Aims 1 & 2) and determine the relationship between changes in neurophysiological and behavioral measures (Aim 3) to better understand how and why priming is effective. The proposed work will provide new insight into the mechanisms underlying priming and, more broadly, illuminate mechanisms of post stoke motor recovery. These results have the potential to improve functional restoration of the arm and hand thereby improving quality of life for stroke survivors. This research will be conducted in the Therapeutic Interventions for Neurological Disorders laboratory under the direction of Dr. Daniel Corcos at Northwestern University\u2019s (NU) department of Physical Therapy and Human Movement Sciences (PTHMS). The facilities at NU PTHMS provide everything needed to complete this research successfully including expert personnel, state-of-the-art laboratories, and the necessary equipment. The training plan as outlined, will include formal and informal educational opportunities, training in data processing and analysis and support for manuscript preparation and dissemination of findings.",
        "disciplines": [
            "4201",
            "4207"
        ],
        "publications": {
            "10.3389/fneur.2023.1182561": {
                "title": "Combining high dose therapy, bilateral motor priming, and vagus nerve stimulation to treat the hemiparetic upper limb in chronic stroke survivors: a perspective on enhancing recovery",
                "abstract": "Stroke is a leading cause of disability worldwide and upper limb hemiparesis is the most common post-stroke disability. Recent studies suggest that clinically significant motor recovery is possible in chronic stroke survivors with severe impairment of the upper limb. Three promising strategies that have been investigated are (1) high dose rehabilitation therapy (2) bilateral motor priming and (3) vagus nerve stimulation. We propose that the future of effective and efficient upper limb rehabilitation will likely require a combination of these approaches.",
                "disciplines": [
                    "5202",
                    "3202",
                    "3209"
                ]
            }
        }
    },
    "10007688": {
        "title": "A new class of titanium alloys developed for additive manufacturing",
        "abstract": "This project aims to develop a new class of (Ti-Cu)-based alloys featuring high strength, high toughness, and high hydrogen-embrittlement resistance specifically for additive manufacturing (AM). This project expects to generate new knowledge of grain refinement and phase transformations in dynamic temperature field of metal AM process and to solve the common weakness \u2013 strong mechanical anisotropy and poor fatigue life \u2013 of AM Ti components. The expected outcomes include a whole set of processing maps of AM (Ti-Cu)-based alloys tailored to demanding applications. This should provide significant benefits to aerospace, marine and biomedical industries by delivering better durability, sustainability, and cost-effectiveness.",
        "disciplines": [
            "4014"
        ],
        "publications": {
            "10.1038/s41598-024-57498-w": {
                "title": "Optimising the manufacturing of a \u03b2-Ti alloy produced via direct energy deposition using small dataset machine learning",
                "abstract": "Successful additive manufacturing involves the optimisation of numerous process parameters that significantly influence product quality and manufacturing success. One commonly used criteria based on a collection of parameters is the global energy distribution (GED). This parameter encapsulates the energy input onto the surface of a build, and is a function of the laser power, laser scanning speed and laser spot size. This study uses machine learning to develop a model for predicting manufacturing layer height and grain size based on GED constituent process parameters. For both layer height and grain size, an artificial neural network (ANN) reduced error over the data set compared with multi linear regression. Layer height predictions using ANN achieved an R2 of 0.97 and a root mean square error (RMSE) of 0.03\u00a0mm, while grain size predictions resulted in an R2 of 0.85 and an RMSE of 9.68\u00a0\u03bcm. Grain refinement was observed when reducing laser power and increasing laser scanning speed. This observation was successfully replicated in another \u03b1\u2009+\u2009\u03b2 Ti alloy. The findings and developed models show why reproducibility is difficult when solely considering GED, as each of the constituent parameters influence these individual responses to varying magnitudes.",
                "disciplines": [
                    "4014"
                ]
            },
            "10.1016/j.jmrt.2023.11.014": {
                "title": "Phase transformation pathways in a Ti-5.9Cu alloy modified with Fe and Al",
                "abstract": "Titanium alloys have been gaining importance in various industries due to their advantageous combination of strength, low density, excellent corrosion/oxidation resistance, and superior mechanical properties at elevated temperatures. Recently, eutectoid Ti\u2013Cu alloys have been explored as promising candidates for advanced processes. This work investigates the effects of Fe and Al on a Ti-5.9Cu alloy using multi-scale characterization techniques. While Fe acts as a \u03b2-stabilizing element (despite being a sluggish eutectoid former), Al acts as an \u03b1-stabilizer. This work focuses on the effects of combined addition of these elements, studied in different heat treatment conditions. The results show that a fine, equiaxed microstructure is obtained in the binary Ti-5.9Cu alloy, whereas the addition of 2\u00a0wt% Fe, or 2\u00a0wt% Fe combined with 2\u00a0wt% Al to the Ti-5.9Cu alloy deteriorates the effect of grain refinement and coarse, columnar grains result and a small amount of \u03b2-phase is retained. Further, the microstructure resulting from the eutectoid decomposition is altered dramatically from a lamellar pearlitic in the binary alloy to a lath-like \u03b1-phase with diverse decomposition products in the ternary and quaternary alloys accompanied by increasing hardness values. Evaluation of the \u03b1 misorientation suggests that a substantial amount of non-Burgers \u03b1 is present in the Ti-Cu alloy in contrast to the results of the ternary and quaternary alloys. The observed Cu-rich intermetallic compound was identified as Ti2Cu phase with off-stoichiometric composition. Results obtained explain how adding either Fe or Fe and Al leads to substantial hardening.",
                "disciplines": [
                    "4016"
                ]
            },
            "10.1016/j.jmst.2023.05.020": {
                "title": "Laser directed energy deposited, ultrafine-grained functional titanium-copper alloys tailored for marine environments: Antibacterial and anti-microbial corrosion studies",
                "abstract": "The microorganism-rich nature of the ocean imposes great challenges to the structural integrity of metals over their service lifespan, including titanium (Ti) alloys, which are usually prone to microbiologically influenced corrosion (MIC). So, multifunctional anti-MIC Ti alloys need to be developed and studied. This paper investigates the effect of copper (Cu) concentration on the MIC resistance of a series of additively manufactured, ultrafine-grained Ti-xCu (x= 3.5, 6.5 and 8.5 in wt.%) alloys. The dependence of the corrosion resistance and MIC resistance on the Cu concentration of Ti-Cu alloy is interpreted considering all conceivable mechanisms. The mechanisms for excellent corrosion resistance of Ti-Cu alloy in seawater are attributed to the strong passive film and small surface potential difference between phases. Microstructural characterization reveals that uniformly distributed, nanosized Ti2Cu phase led to increased reactive oxygen species in the bacterial membrane, which is the root reason for the superb anti-bacterial property (99.2%) for Ti-8.5Cu. Compared to pure Ti and Ti-6Al-4V, Ti-8.5Cu alloy features both high strength (yield stress > 1000\u00a0MPa) and the best MIC resistance (97.5%). The combination of such balanced properties enables this functional 3D printed Ti-Cu alloy to become an ideal material for load-bearing applications in the marine environment.",
                "disciplines": [
                    "4016"
                ]
            }
        }
    },
    "13037088": {
        "title": "CAREER: Bottom-Up Understanding of Liquid Breakup at Supercritical Conditions",
        "abstract": "The design of modern liquid-fueled engines is shifting toward higher pressures exceeding the fuel critical point (supercritical) to improve fuel-air mixing, enhance combustion efficiency, and reduce engine emissions. Liquid fuel injection generally entails liquid jet breakup into droplets, forming a spray. At supercritical conditions, however, spray formation transitions into a gas-like mixing behavior. The underlying mechanism of this transition, i.e., trans-critical breakup is elusive. Trans-critical breakup is linked to dramatic changes in fluid properties and reduced surface tension due to weakened intermolecular forces. However, the effect of molecular-level interactions on the breakup of microscopic droplets is not understood. This grant supports fundamental research to elucidate the mechanisms underlying liquid breakup at supercritical conditions from molecular interactions to higher scales to advance supercritical combustion. The results will enable new predictive capabilities in controlling supercritical mixing before combustion over multiple scales. This knowledge will promote the next generation of high-speed liquid-fueled propulsion systems for supersonic/hypersonic air and space transportation and supercritical power generation cycles. These benefits will promote U.S. clean energy initiatives and strengthen national security, defense, and economic competitiveness. The educational activities will cultivate an inclusive learning environment in multiphase flows and foster sustained mentorship for under-represented minorities and women to diversify the pipeline of future STEM leaders. Training teachers and informing students and parents at school\u2019s STEM events will enhance public literacy on fluid mixing to promote clean combustion. This project intends to fundamentally understand the breakup of an isolated liquid droplet at supercritical conditions in both low-speed and shock-laden flows where shockwave interaction with droplets promotes breakup. The trans-critical shock-driven breakup mechanism is not known, as experimental diagnostics are not adequate for such extreme conditions, and models are decoupled from the molecular interfacial behavior that dictates droplet breakup. This project will address these knowledge gaps and generates new knowledge on the relationship between surface tension and phase change at supercritical conditions and its effect on droplet breakup. Three research objectives will be to (1) Identify the molecular interfacial behavior of a trans-critical droplet from molecular- to microscale; (2) Understand the breakup mechanisms of a trans-critical droplet in low-speed crossflow, and (3) Determine the shock-driven breakup mechanisms of a trans-critical droplet. The technical approach involves a bottom-up approach based on first principles involving coupled Molecular Dynamics-Direct Numerical Simulations and high-speed experimental measurements. The generated knowledge is critical for controlling fuel-air mixing in high-pressure liquid injection systems in diesel, rocket, gas turbine, scramjet, and rotating detonation engines. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4017",
            "4002"
        ],
        "publications": {
            "10.1016/j.fuel.2023.130187": {
                "title": "Surface tension and evaporation behavior of liquid fuel droplets at transcritical conditions: Towards bridging the gap between molecular dynamics and continuum simulations",
                "abstract": "The phase transition from subcritical to supercritical conditions, referred to as transcritical behavior, significantly impacts the evaporation and fuel\u2013air mixing in high-pressure liquid-fuel propulsion systems. Transcritical behavior is characterized as a transition from classical two-phase evaporation to a single-phase gas-like diffusion regime as surface tension and latent heat of vaporization reduce. However, the interfacial behavior represented by the surface tension coefficient and evaporation rate during this transition which are crucial inputs for Computational Fluid Dynamics (CFD) simulations of practical transcritical fuel spray is still missing. This study aims at developing new evaporation rate and surface tension models for transcritical n-dodecane droplets using molecular dynamics (MD) simulations irrespective of the droplet size. As MD simulations are primarily limited to the nanoscale, the new models can bridge the gap between MD and continuum simulations and enable the direct application of these findings to microscopic droplets. A new characteristic timescale, i.e., \u201cundroplet time,\u201d is defined which marks the transition from classical two-phase evaporation to single-phase gas-like diffusion behavior. The undroplet time indicates the onset of droplet core disintegration and penetration of nitrogen molecules into the droplet, which occurs after the vanishment of the surface tension. By normalizing the time with respect to the undroplet time, the rate of surface tension decay, evaporation rate, and the rate of droplet mass depletion become independent of the droplet size. Calculation of pairwise correlation coefficients for the entire MD results shows that both surface tension coefficient and evaporation rate are strongly correlated with the background temperature, while pressure and droplet size play a less significant role past the critical point. Therefore, new models for surface tension coefficient and evaporation rate spanning from sub- to supercritical conditions are developed as a function of background pressure and temperature, which can be used in continuum simulations. The identified phase change behavior based on the undroplet time shows a good agreement with the phase change regime maps obtained using microscale experiments and nanoscale MD predictions.",
                "disciplines": [
                    "4004",
                    "4019",
                    "4012"
                ]
            }
        }
    },
    "13043525": {
        "title": "The Babylonian Talmud and Late Antique Book Culture",
        "abstract": "AbstractThe Talmud and Late Antique Book CultureThe multi-vocality of opinions and precise intellectual genealogies purported by the Babylonian Talmud together with some ambiguous claims towards this end in this sixth century compilation have long since led to the assumption that the work is the product of oral transmission. Scholarly models for the work\u2019s formation have posited that the rulings and stories we find in the Talmud were passed on from one generation to the next, with each generation adding their opinions on and interpretations of a given subject. Yet, such an oral formation process is unheard of in late antiquity and the model exoticizes the Talmud from its Greco-Roman environment and clouds the intellectual world of Sasanid Persia. Rather than taking the Talmud\u2019s discursive structure as a sign for orality or its few and ambiguous prohibitions of writing for granted, The Talmud and Late Antique Book Culture asks about the intellectual and material givens with which author-composers of this complex work had to be equipped: What were the intellectual tools they received during their education? Which material tools supported their goal? And what kinds of marks did both sets of tools leave on the text that we have now-in a completely different format-in front of us? The first chapter discusses the genre of the Talmud within late-antique genres as they can be delineated from a modern perspective. It shows that the discursive nature of the Talmudic text is also found among symposiac works such as Athenaeus\u2019 Learned Banqueters or Macrobius\u2019 Saturnalia. Within this framework, the Talmud can be classified as an erudite symposiac commentary on a miscellany, the Mishnah. The second chapter then looks at the material givens necessary to craft such an elaborate compilation. It suggests that the many small and closed units that make up the text, such as sayings, recipes, or stories, point to the use of excerpts from other texts or individual compositions rather than a memorized conversation. These excerpts would have been sorted by the compilers according to keywords prior to being used to craft entries to lemmas from the Mishnah. The excerpts, which were either purposefully copied onto thin wooden tablets or happened to already have been composed on similar loose writing carriers, allowed the composers to experiment with different arrangements before settling for one. They would then smooth the composition by adding clarifications, transitory notes, or, to maintain the aspired discursive (symposiac) structure of the Talmud, some interjections by fictitious dialogue partners. The arrangement of the composed entries on lemmas from the Mishnah appears to have followed the rhetorical fourfold pattern \u201cintroduction, narration of the case, proofs, and peroration,\u201d as the third chapter points out. This points to a rhetorical training of the composers that included at least the preliminary stage taught based on the progymnasmata. Quite in line with the way the progymnasmata taught students how to compose texts by twisting other texts by adding fitting sententiae or gnomai, talmudic stories are shown in the fourth chapter to be marked by rabbinic sayings, biblical verses, or even medical recipes. The use of medical recipes as sententiae conforms to the increasing non-discrimination between technical and poetic texts and the ideal of polymathy that prevailed in the imperial period and late antiquity.In fact, medical recipes, distributed over the entire Talmud and characterized by a distinct literary makeup and shared vocabulary, illustrate the process of excerpting, storing, and repurposing according to associative keywords very well. Thus, the fifth chapter argues that the previously discussed compilatory processes can also be reversed. Based on the recipes, a Jewish-Aramaic Euporiston is reconstructed that parallels Greek, Latin, and Syriac treatises in terms of formulaic structure, the range of conditions, and a comparable philosophy underlying the therapies.The Babylonian Talmud as such is the only Aramaic text of this size and scope from the Sasanid Empire. It is a powerful attestation of the literacy of Judeans and of Persian literary culture. By focussing on literary techniques instead of content, as previously done, a common intellectual and material culture between East and West becomes visible. The commonalities often remain hidden behind the polemical attacks on and denials of shared practices -which are, in fact, the result of shared educational principles as well.",
        "disciplines": [
            "4303",
            "4705"
        ],
        "publications": {
            "10.1017/9781009297349": {
                "title": "The Babylonian Talmud and Late Antique Book Culture",
                "abstract": "In this book, Monika Amsler explores the historical contexts in which the Babylonian Talmud was formed in an effort to determine whether it was the result of oral transmission. Scholars have posited that the rulings and stories we find in the Talmud were passed on from one generation to the next, each generation adding their opinions and interpretations of a given subject. Yet, such an oral formation process is unheard of in late antiquity. Moreover, the model exoticizes the Talmud and disregards the intellectual world of Sassanid Persia. Rather than taking the Talmud's discursive structure as a sign for orality, Amsler interrogates the intellectual and material prerequisites of composers of such complex works, and their education and methods of large-scale data management. She also traces and highlights the marks that their working methods inevitably left in the text. Detailing how intellectual innovation was generated, Amsler's book also sheds new light on the content of the Talmud. This title is also available as Open Access on Cambridge Core.",
                "disciplines": [
                    "4705"
                ]
            }
        }
    },
    "13560596": {
        "title": "Panpsychism and Pan(en)theism: Philosophy of Mind meets Philosophy of Religion",
        "abstract": "One of the deepest mysteries of contemporary science is how the brain produces consciousness. One of the deepest challenges of theology is trying to make sense of how a supernatural God could interact with the world, and why such a being would allow suffering. Recently there has emerged new interest in certain radical solutions to each of these problems. Panpsychists address the first problem by postulating consciousness at the fundamental level of physical reality. Pantheists address the second problem by identifying God with the universe, whilst panentheists do this by holding that the universe is within God.\nThis project is the first to bring these two radical movements (panpsychism and pantheism/panentheism) into dialogue, enabling the resources of each to address the challenges of the other. The project will (a) explore versions of panpsychism on which the universe is itself a conscious mind (b) ask whether on these 'cosmopsychist' views the universe can be regarded as divine. Our ultimate goal is to test whether a cosmopsychist conception of God might exemplify both the advantages of theism (explaining the fine-tuning of physics, and why there is something rather than nothing) and the advantages of atheism (avoiding the problem of evil, and the extravagance of postulating a supernatural realm). This may lead to a worldview more consonant with human flourishing either than traditional theism or traditional atheism. \nTo address this we will organize workshops and essay competitions, and publish the papers in open access special issues of journals, which we envisage will become core texts for the field. There will be a significant public engagement component: a trade book, episodes of high profile podcasts, and a prize for a popular article. The project will widen the scope of philosophy of religion, developing innovative conceptions of the divine which reflect our contemporary understanding of the universe and the conscious mind.",
        "disciplines": [
            "5004",
            "5003",
            "5005"
        ],
        "publications": {
            "10.1007/s11229-023-04282-4": {
                "title": "Emergent mental properties are not just double-preventers",
                "abstract": "We examine Sophie Gibb\u2019s emergent property-dualist theory of mental causation as double-prevention. Her account builds on a commitment to a version of causal realism based on a powers metaphysic. We consider three objections to her account. We show, by drawing out the implications of the ontological commitments of Gibb\u2019s theory of mental causation, that the first two objections fail. But, we argue, owing to worries about cases where there is no double-preventive role to be played by mental properties, her account, which solely affords mental properties a double-preventive role, is incomplete and vulnerable to a causal exclusion objection. We propose a friendly modification to her theory of mental causation that is consistent with her theory\u2019s ontological commitments. Specifically, we sketch an account on which mental properties have a more pronounced causal-structuring role that is not exhausted by the role Gibb assigns them as double-preventers. The result is a novel emergentist theory of mental causation.",
                "disciplines": [
                    "5003",
                    "5002"
                ]
            },
            "10.3390/rel14060758": {
                "title": "Pantheism, Omnisubjectivity, and the Feeling of Temporal Passage",
                "abstract": "By \u201cpantheism\u201d I mean to pick out a model of God on which God is identical with the totality of existents constitutive of the universe. I assume that, on pantheism, God is an omnispatiotemporal mind who is identical with the universe. I assume that, given divine omnispatiotemporality, God knows everything that can be known in the universe. This includes having knowledge de se of the minds of every conscious creature. Hence, if God has knowledge de se of the minds of every conscious creature, then divine omniscience implies omnisubjectivity. Assuming that eternalism is true, robust temporal passage is an illusion. But, conscious creatures, such as human persons, experience robust temporal passage. If God has the attribute of omnisubjectivity, then God experiences temporal passage. However, God also has a unified experience of the entire spatiotemporal continuum. God\u2019s having these two perspectives creates a tension for pantheism given that God would seem to experience both temporal passage and an absence of temporal passage. I compare non-personal pantheism and personal pantheism and consider which one has better resources to answer the foregoing puzzle. I argue that personal pantheism is better equipped to address this problem than non-personal pantheism.",
                "disciplines": [
                    "5003",
                    "5004"
                ]
            }
        }
    },
    "13252485": {
        "title": "Cure4Aqua: Curing EU aquaculture by co-creating health and welfare innovations",
        "abstract": "Farmed seafood is an important source of protein for food and feeds with a low-carbon footprint which has an important role to play in helping to build a sustainable food system. A strategic and long-term approach for the sustainable growth of a resilient EU aquaculture is, therefore, more relevant today than ever. However, the efficient and cost-effective control of pathogens remains among the main challenges for the sector, particularly relevant for Europe, where there is a great variety of species and production systems, which hinders the implementation of good husbandry practices tailored to each aquatic species. Through active engagement with key stakeholders, Cure4Aqua aims to jointly improve the resilience of EU aquaculture under environmental, biological, and socio-economic stress, by improving aquatic animal health and welfare and supporting the environmentally friendly, inclusive, safe, and healthy production of seafood. Cure4Aqua will do so by 1) developing cost-effective vaccines to prevent disease caused by 5 pathogens of economic significance to EU aquaculture; 2) Identifying markers with diagnostic capacity to be integrated to selective breeding programs to improve stress and disease management; 3) Developing innovative, bio-based and sustainable solutions as an alternative to antibiotics for controlling fish pathogens at various life stages and alleviate the pressure of global antimicrobial resistance; 4) Developing new tools and technology to improve health and welfare monitoring at the fish farm level and diagnostics of fish pathogens both at the laboratory and the fish farm levels; 5) Placing fish welfare at the foreground of aquaculture production, through the development of high welfare standards that consider different life-stages, production systems, and knowledge of welfare needs, and 6) Ensuring effective external communication, dissemination and exploitation of project activities and results to all relevant target groups.\nWorkday Project Setup Complete",
        "disciplines": [
            "4104",
            "4803",
            "3005"
        ],
        "publications": {
            "10.1002/smsc.202400096": {
                "title": "Micro\u2010Supercapacitors for Self\u2010Powered Biosensors",
                "abstract": "Although batteries are a highly popular energy source in biosensors, batteries can be an economic limitation for low\u2010cost sensing applications and pose significant challenges in miniaturization, biocompatibility, and disposal. To surmount such issues, \u201cself\u2010powered sensors\u201d gain the spotlight thanks to their energy harvesting from the environment through embedded miniaturized systems. In this review, the recent developments in self\u2010powered devices are summarized with a specific focus on the integration of supercapacitors with sensors and biosensors. The working principles of microsupercapacitors, fabrication methods, their integration with biosensors, and their ultimate applications (i.e., biomedical monitoring and analytical biomarker detection) are described. Different energy harvesting systems are summarized and their integration with self\u2010powered sensors or biosensors is highlighted. The limitations and challenges of the existing approaches and the future of supercapacitor\u2010integrated sensing systems are also critically discussed.",
                "disciplines": [
                    "4018"
                ]
            }
        }
    },
    "13560594": {
        "title": "An Immersive Research Program on Personality Growth: Psychological Cross-Training for Christian Theologians",
        "abstract": "From a Christian point of view, an essential task of human existence is to develop one's personality by growing from negative experiences, progressing in the life of virtue, and thus becoming more and more a person in the image of God. The project's focus will be discovering connections between what many psychologists often call \"personality growth\" and what the Christian tradition calls \"virtue development\" or \"spiritual growth\". \nOur Immersive Research Program (IRP) will allow theologians to acquire competence in empirical research methods in psychology. The joint leadership of a psychologist and a philosopher/theologian ensures interdisciplinarity. Participating theologians will be immersed in the process of designing, executing, and publishing psychological experiments. The output will be two two-semester-long immersion courses for theologians, content for an e-learning platform, 12 expert talks, 12 educational videos, 4 workshops, 2 research colloquia, 12 scientific papers, and an educational website (with high-quality learning videos) addressing theologians worldwide. \nThe psychological methods and topics used will be broadly situated within personality psychology, selected to facilitate a dialogue with theology. Successful cross-training is ensured by a hands-on approach in each step of the research process, and by the use of innovative teaching practices exclusively designed to immerse theologians into psychological research. Learning will take place in a variety of formats as we will use online learning and in-person teaching, for synchronous and asynchronous learning. \nThere is hardly any other country that has influenced Christian theology in the last 100 years more than Germany. While our IRP is international and will use the English language, it is uniquely situated in this rich and influential heritage. The leaders have an established track-record in managing large interdisciplinary projects, warranting successful completion of the present endeavor.",
        "disciplines": [
            "5005",
            "5205",
            "5201"
        ],
        "publications": {
            "10.1016/j.actpsy.2024.104252": {
                "title": "Heart rate variability and psychological health: The key role of trait emotional awareness",
                "abstract": "Studies have shown that Trait Emotional Awareness (TEA) - the ability to recognize one's emotions - and Heart Rate Variability (HRV) are both negatively associated with psychological disorders. Although these studies imply that TEA is related to HRV and may explain the association between HRV and psychological disorders, there is limited research investigating this implication. Such investigation is essential to illuminate the psychophysiological processes linked to psychological disorders. The present study aims to investigate a) the association between TEA and HRV, b) the association between HRV and psychological disorders, and c) whether TEA explains the association between HRV and psychological disorders. A sample of 41 German students completed self-report questionnaires as indicators of psychological disorders, including the Hospital Anxiety and Depression Scale (HADS; Snaith & Zigmond, 1983) for anxiousness and depressiveness, as well as the somatization scale of the Hopkins Symptom Checklist (HSCL; Derogatis et al., 1976) for physical complaints. HRV was measured at baseline (resting HRV) and during exposure to a fear-provoking movie clip (reactive HRV). As hypothesized, a) TEA showed a positive association with reactive HRV, b) HRV showed negative associations with anxiousness and physical complaints, and c) TEA explained the relationships between reactive HRV and anxiousness, as well as physical complaints. Contrary to our hypothesis, we did not find any association between HRV and depressiveness. We discussed the contribution of TEA to psychophysiological health, limited generalizability of the current study, and direct future research to explore the underlying mechanisms linking TEA to health.",
                "disciplines": [
                    "5203"
                ]
            },
            "10.1080/02691728.2024.2326828": {
                "title": "Gatekeeping in Science: Lessons from the Case of Psychology and Neuro-Linguistic Programming",
                "abstract": "Gatekeeping, or determining membership of your group, is crucial to science: the moniker \u2018scientific\u2019 is a stamp of epistemic quality or even authority. But gatekeeping in science is fraught with dangers. Gatekeepers must exclude bad science, science fraud and pseudoscience, while including the disagreeing viewpoints on which science thrives. This is a difficult tightrope, not least because gatekeeping is a human matter and can be influenced by biases such as groupthink. After spelling out these general tensions around gatekeeping in science, we shed light on them with a case study from psychology. This concerns whether academic psychologists rightly or wrongly classify the applied-psychology framework of NLP (\u2018neuro-linguistic programming\u2019) as unscientific and even pseudoscientific. This example of gatekeeping is particularly instructive because both the NLP community and the psychology community, we argue, make legitimate but also illegitimate moves. This case gives rise to several general insights about gatekeeping in science more generally.",
                "disciplines": [
                    "5002"
                ]
            },
            "10.5964/ejop.12031": {
                "title": "Personal Growth and Motto Goals: Strengthening Emotion Regulation Ability via Affirmatory Metaphors Coaching",
                "abstract": "Interventions can foster personal growth. However, our understanding of the specific mechanisms for change and the types of interventions driving this growth process remains limited. In this study, we focused on emotion regulation ability as a potential mechanism. We examined the effects of an affirmation coaching intervention on changes in emotion regulation ability, an important facet of personality. In this coaching intervention, participants created a personal mantra/goal derived from a selected image and positive associations linked to this image (motto goals). This is considered to enhance emotion regulation abilities by internalizing self-stabilizing value. We assigned sixty-six participants to either this affirmation coaching intervention or one of two control coaching interventions: specific-goal versus indulgence coaching. Before and after each intervention, participants completed questionnaires. Only the affirmation coaching intervention significantly increased in adaptive aspects of personality. Notably, the affirmation coaching intervention increased emotion regulation ability, and this effect persisted even when controlling for extraversion and neuroticism. Furthermore, exploratory analysis showed that extraversion increased following the affirmation coaching, while neuroticism remained unchanged. Our results suggest that emotion regulation ability might be the key factor in personality growth. It could be more malleable and/or respond more strongly to short-term coaching, compared to neuroticism. Thus, the malleability of personality traits may not be an all-or-nothing phenomenon; rather, it could depend on the facet of emotion regulation ability. We discuss potential mechanisms of personality growth, distinguishing between emotion regulation and emotion sensitivity.",
                "disciplines": [
                    "5205"
                ]
            },
            "10.1111/jopy.12805": {
                "title": "Dynamics of personality: The Zurich model of motivation revived, extended, and applied to personality",
                "abstract": "Personality researchers are increasingly interested in the dynamics of personality, that is, the proximal causal mechanisms underlying personality and behavior. Here, we review the Zurich Model of Social Motivation concerning its potential to explain central aspects of personality. It is a cybernetic model that provides a nomothetic structure of the causal relationships among needs for security, arousal, and power, and uses them to explain an individual's approach-avoidance or \"proximity-distance\" behavior. We review core features of the model and extend them by adding features based on recent behavioral and neuroscientific evidence. We close by discussing the model considering contemporary issues in personality science such as the dynamics of personality, five-factor personality traits and states, and personality growth.",
                "disciplines": [
                    "5205"
                ]
            }
        }
    },
    "13017684": {
        "title": "Exact RelaxatiOns for Sparse and low-rank optImizatiON \u2013 EROSION",
        "abstract": "Numerous problems in signal/image processing, statistics, and machine learning rely on the resolution of optimization problems with sparse or low-rank priors. These problems are very challenging to solve due to their combinatorial nature  and can be considered as open to a large extent. Within this context, the promise of EROSION is to push the frontiers of sparse and low-rank optimization by combining the strengths of exact relaxations and local optimization. To that end, EROSION will focus on two high-level research objectives: 1) deriving exact relaxations of the targeted problem with the same  global minimizers, less local minimizers and wider basin of attraction, and 2) developing initialization strategies that are guaranteed to lie within a basin of attraction of a global solution of the exact relaxation. Finally, these methodological developments will be applied to several signal processing and machine learning problems.",
        "disciplines": [
            "4006",
            "4603"
        ],
        "publications": {
            "10.1109/lsp.2023.3277792": {
                "title": "Sphere Refinement in Gap Safe Screening",
                "abstract": "The Gap safe screening technique is a powerful tool to accelerate the convergence of sparse optimization solvers. Its performance is largely based on the ability to determine the smallest sphere, centered at a given feasible dual point, that contains the dual solution. This can be achieved through an inner sphere refinement loop, applied at each screening step. In this work, we show that this refinement loop actually converges to the solution of a fixed-point equation for which we derive a closed-form expression for two common loss functions. This allows us to develop an analytic (i.e., non iterative), more concise and theoretically-grounded variant of the sphere refinement step.",
                "disciplines": [
                    "4006"
                ]
            }
        }
    },
    "13061376": {
        "title": "Development and Validation of a Rapid Test for Individual Differences in Sweet Liking",
        "abstract": "Project Summary Overconsumption of sugar is associated with obesity and related chronic disease, which in turn cost ~300,000 lives and ~$546 billion annually in the United States alone. Leading health agencies recommend reducing intake of added sugars, but pleasure (hedonics) from sweetness may hinder the effort to achieve this goal. People might acclimate to reduced sugar in the food supply over time, analogous to shifts toward preference for lower levels of salt that occur after reducing sodium intake, but this hypothesis remains untested. Because hedonic response drives consumption, collecting large-scale data to understand individual differences in sweet hedonics on a population level is a critical step in guiding public policy. To facilitate population-based studies, I will first determine whether two widely used but time- and labor-intensive psychophysical sensory tests do in fact measure the same individual differences in sweet hedonics (sub-aim 1). One test asks participants to compare pairs of sugar solutions that differ in concentration and decide which solution they prefer. The other test is based on subjective ratings of liking for sugar solutions of varying concentrations. Participants will be a representative sample of healthy, US adults (n = 111). The data will not only determine agreement between the two approaches to measure individual sweet hedonic patterns but also will be used to evaluate several brief tests (potential proxies for the more time-consuming tests), including the Simple Sweet test, as candidates for use in the field or in participants\u2019 homes to facilitate large-scale studies (sub-aim 2). For example, a briefer, valid test will facilitate data collection to examine population-level shifts in sweet hedonic response accompanying general reductions in sugar in processed foods and sweetened beverages. In addition, I will explore the relationship between sweet hedonic response and overall diet quality, especially sugar consumption (exploratory aim). The proposed work will advance our conceptual understanding of measurement of sweet hedonic response by confirming that common tests measure a single underlying trait. Furthermore, it will explore the relationship between sweet hedonics and diet quality using methods robust against misreporting. My study will also facilitate collection of data on hedonic response by validating more efficient tests, thereby supporting the NIDCD goal of Developing Tools to Measure Taste and Smell Function. As a postdoctoral trainee, this project will provide me with the foundation in the theory and practice of measuring hedonic response, a skill set that can be applied to other nutrients of concern for obesity and public health, including salt and fat. These skills will complement my expertise in nutrition science and prepare me to become a leading researcher in the field of sensory nutrition, with the long-term goal of facilitating public health through enhanced understanding of how diet and perception interact to drive food choice.",
        "disciplines": [
            "3006"
        ],
        "publications": {
            "10.21203/rs.3.rs-3644422/v1": {
                "title": "Understanding the Determinants of Sweet Liking in the African and East Asian Ancestry Groups in the U.S. \u2013 A Study Protocol",
                "abstract": "Background: The liking for sweet taste is a powerful driver for consuming added sugars, and therefore, understanding how sweet liking is formed is a critical step in devising strategies to lower added sugars consumption. However, current research on the influence of genetic and environmental factors on sweet liking is mostly based on research conducted with individuals of European ancestry. Whether these results can be generalized to people of other ancestry groups warrants investigation.\nMethods: We will determine the differences in allele frequencies in sweet-related genetic variants and their effects on sweet liking in 426 adults of either African or East Asian ancestry, who have the highest and lowest average added sugars intake, respectively, among ancestry groups in the U.S. We will collect information on participants' sweet-liking phenotype, added sugars intake (sweetness exposure), anthropometric measures, place-of-birth, and for immigrants, duration of time living in the U.S. and age when immigrated. Ancestry-specific polygenic scores of sweet liking will be computed based on the effect sizes of the sweet-related genetic variants on the sweet-liking phenotype for each ancestry group. The predictive validity of the polygenic scores will be tested using individuals of African and East Asian ancestry from the UK Biobank. We will also compare sweet liking between U.S.-born individuals and immigrants within each ancestry group to test whether differences in environmental sweetness exposure during childhood affect sweet liking in adulthood.\nDiscussion: Expanding genetic research on taste to individuals from ancestry groups traditionally underrepresented in such research is consistent with equity goals in sensory and nutrition science. Findings from this study will help in the development of a more personalized nutrition approach for diverse populations.\nTrial registration: This protocol has been preregistered with the Center for Open Science (https://doi.org/10.17605/OSF.IO/WPR9E) and is approved by the City University of New York Human Research Protection Program (IRB#: 2023-0064-Brooklyn).",
                "disciplines": [
                    "3105"
                ]
            }
        }
    },
    "13308115": {
        "title": "West African Mineral Dust: a key in the NExus ClimaTe \u2013 WATer \u2013 Energy \u2013 NETWAT",
        "abstract": "Solar energy plays an increasing role in Africa to meet the Paris Agreement. But, a massive deployment of variable renewable energy creates a new form of vulnerability associated with unsecured supply. Thus, a sustainable energy transition is not only a question of the amount of infrastructure or installed power capacity; it is about empowering the whole energy value-chain, from decision-makers to beneficiaries, to plan the resource and manage the infrastructure in an optimal way. NETWAT will develop solutions to ensure sustainable solar production in West Africa without compromising the sustainability of the water resource. Indeed, the energy sector clearly identified that dust is a key but often \u201cneglected\u201d issue. Dust, by its effect on the solar irradiance and by its deposit on the panels, leads to a reduction in energy output and decreases the efficiency of the solar infrastructure. With mineral dust as the driving force behind our inter and transdisciplinary approach, NETWAT will develop solutions to ensure an optimized photovoltaic (PV) production in West Africa without compromising the sustainability of the water resource management in the region.- NETWAT will improve the understanding of the West African dust cycle and its direct/indirect effects on solar resource and production.- NETWAT will develop an innovative PV production forecasting chain and build reliable and efficient decision-making tools to optimize power grid management and solar production.- Finally, NETWAT will evaluate the water footprint of solar farms and will provide sustainable maintenance plan based on dust dynamics.NETWAT is built on an inter and transdisciplinary consortium gathering two academic partners (IGE and LISA) and one SME (Steadysun). It also benefits from existing long-term African-French partnerships : National Observation Service (SNO) INDAAF, SNO AMMA-Catch, International Joint Research Laboratory NEXUS Climate-Water-Energy-Agriculture in C\u00f4te d'Ivoire and partnerships with the  energy sector in Burkina Faso, C\u00f4te d'Ivoire and in Senegal.",
        "disciplines": [
            "4802"
        ],
        "publications": {
            "10.1016/j.renene.2024.120101": {
                "title": "West African operational daily solar forecast errors and their link with meteorological conditions",
                "abstract": "West Africa is at the forefront of global environmental challenges with its commitment to reduce greenhouse gas emissions and harnessing the potential of renewable energy, especially the promising solar power. This study evaluates Global Horizontal Irradiance (GHI) operational forecast errors for the Zagtouli (Burkina-Faso) and Sococim (Senegal) solar plants, and investigates their links with local meteorological conditions, particularly clouds and dust aerosols. Firstly, the evaluation of aerosol products indicates that CAMS reanalysis is reliable for assessing aerosol optical depth. We then examine the accuracy of three operational GHI forecast products: the Global Forecast System (GFS, NCEP), the Integrated Forecast System (IFS, ECMWF), and SteadyMet (SM, French company Steadysun). The analysis reveals that IFS and SM outperform GFS, SM having a slight advantage due to its probabilistic nature. Closer examination reveals a significant relationship between GHI forecast errors and local meteorological characteristics. These errors are more pronounced during the wet season, primarily attributed to cloud occurrence. Dust events play a secondary influential role, especially during the dry season. Correlation analyses emphasize the forecast errors' major link with cloudiness, while co-occurrences highlight that dust aerosol is a secondary factor in forecast errors for the GHI directly or for cloud representation (aerosol-cloud interaction).",
                "disciplines": []
            }
        }
    },
    "13285831": {
        "title": "Innovative electrical and autonomous vegetation management in utility scale solar parks ( continuation project)",
        "abstract": "Purpose and goal: \nThe solar industry is growing rapidly and parks are covering ever growing areas. Thus, maintenance aspects are becoming increasingly important. The essence of the project lies in developing a competitive solution to manage the vegetation in a large solar park according to the wishes and eligibility requirements of the future customer. Development is focused on creating a electric and fully automated and scalable maintenance system for solar park vegetation. \nMachines are tested and verified in a real environment, where challenges are identified and overcome. \n \nExpected results and effects: \nWe have developed a good understanding of problems and needs that a solar park owner has regarding vegetation management, in relatino to  both technical performance and other values such as biological diversity. The system has undergone major improvement in autonomous operation where the existing planning environment on the software side has been improved to adapt the system for long-term autonomous scalability. The system works stably during continuous autonomous operation and learns to handle situations and obstacles. This applies both to cutting around posts, and under panels. \n \nApproach and implementation: \nThe project has been located at a solar park in Skurup in southern Scania. The solar park in Skurup is about 30 ha and has an installed power of 18MWp and functioned as a demonstration and research facility under 2022-2023. We have worked with a dynamic model where mowing has been initiated when the vegetation has reached a certain height. The height for how far up the vegetation has been released before mowing has been set in relation to the mower\u00b4s sensors and objective based on the development of biological diversity.",
        "disciplines": [
            "3301"
        ],
        "publications": {
            "10.1093/rheumatology/kead301": {
                "title": "Genome-wide investigation of persistence with methotrexate treatment in early rheumatoid arthritis",
                "abstract": "OBJECTIVES: To investigate the influence of genetic factors on persistence with treatment of early RA with MTX monotherapy.\nMETHODS: We conducted a genome-wide association study (GWAS) in a sample of 3902 Swedish early-RA patients initiating MTX in DMARD monotherapy as their first-ever DMARD. The outcome, short- and long-term MTX treatment persistence, was defined as remaining on MTX at 1 and at 3\u2009years, respectively, with no additional DMARDs added. As genetic predictors, we investigated individual SNPs, and then calculated a polygenic risk score (PRS) based on SNPs associated with RA risk. The SNP-based heritability of persistence was estimated overall and by RA serostatus.\nRESULTS: No individual SNP reached genome-wide significance (P\u2009<\u20095 \u00d7 10-8), either for persistence at 1\u2009year or at 3\u2009years. The RA PRS was not significantly associated with MTX treatment persistence at 1\u2009year [relative risk (RR)\u2009=\u20090.98 (0.96-1.01)] or at 3\u2009years [RR\u2009=\u20090.96 (0.93-1.00)]. The heritability of MTX treatment persistence was estimated to be 0.45 (0.15-0.75) at 1\u2009year and 0.14 (0-0.40) at 3\u2009years. The results in seropositive RA were comparable with those in the analysis of RA overall, while heritability estimates and PRS RRs were attenuated towards the null in seronegative RA.\nCONCLUSION: Despite being the largest GWAS on an MTX treatment outcome to date, no genome-wide significant associations were detected. The modest heritability observed, coupled with the broad spread of suggestively associated loci, indicate that genetic influence is of polygenic nature. Nevertheless, MTX monotherapy persistence was lower in patients with a greater genetic disposition, per the PRS, towards RA.",
                "disciplines": [
                    "3202",
                    "3204"
                ]
            }
        }
    },
    "13061591": {
        "title": "The Impact of the Bundled Payment for Care Improvement Advanced on Outcomes for Patients with Sepsis",
        "abstract": "PROJECT SUMMARY Sepsis is a devastating condition resulting from the immune system\u2019s reaction to infection. 1.7 million Americans are hospitalized annually with sepsis, resulting in over 270,000 deaths. Sepsis is more common among older patients, leading to spending among Medicare beneficiaries totaling $41B in 2018. Treatment costs and episode spending also vary widely across hospitals, driven largely by differences in post-acute care. In an attempt to improve care, sepsis was included as one of the 31 inpatient episodes targeted under Medicare\u2019s Bundled Payment for Care Improvement Advanced (BPCI-A) program. BPCI-A is a voluntary program that creates incentives for hospitals to improve patient outcomes and reduce spending across a 90- day post-discharge episode. BPCI-A has the potential to encourage hospitals to more effectively manage patients during the admission to avoid subsequent complications and to discharge patients to lower acuity post-acute settings. At the same time, BPCI-A is not designed primarily to improve quality, and changes in patient outcomes \u2013 positive or negative \u2013 will be closely tied to hospital efforts to reduce spending. Patients with Alzheimer\u2019s disease and related dementias (ADRD) are both more likely to develop sepsis and to have worse outcomes. Patients with ADRD have very high episode spending and are particularly vulnerable to adverse outcomes following discharge, making their treatment for sepsis under BPCI-A critically important to understand. Outside of ADRD, how patient risk and sepsis care pathways influence patient outcomes for sepsis in the context of BPCI-A are not well understood. In this context, we propose the following aims: Aim 1. Evaluate the effects of BPCI-A on outcomes for patients with sepsis. We will link hospital participation in BPCI- A with national Medicare data to test the effects of the program on mortality, readmission, post-acute care, days alive and at home, burdensome transitions, and discharge to hospice. Aim 2. Evaluate the effects of BPCI-A on outcomes for sepsis patients with ADRD. Using validated Medicare claims algorithms to identify patients with ADRD, we will test the impact of BPCI-A on outcomes for patients with ADRD. Aim 3. Understand the relationship between clinical risk, treatment, and post-acute care treatment patterns and outcomes under BPCI-A. Using unique data from the Michigan Sepsis Initiative linked to multi-payer claims data, we will identify the clinical treatment patterns, patient risk factors, and hospital characteristics that predict patient outcomes. We will examine whether hospitals participating in BPCI-A deploy a different set of strategies to manage patients with sepsis. Our proposal is significant because it combines national data with detailed clinical insights to understand the interplay between national policy and nuanced clinical care for patients with sepsis. Our proposal is innovative in its combination of administration and registry data sources coupled with sophisticated quantitative methods to answer a novel question.",
        "disciplines": [
            "4203",
            "4205"
        ],
        "publications": {
            "10.1097/mlr.0000000000002000": {
                "title": "Identifying Sources of Inter-hospital Variation in Episode Spending for Sepsis Care.",
                "abstract": "OBJECTIVE: To evaluate inter-hospital variation in 90-day total episode spending for sepsis, estimate the relative contributions of each component of spending, and identify drivers of spending across the distribution of episode spending on sepsis care.\nDATA SOURCES/STUDY SETTING: Medicare fee-for-service claims for beneficiaries (n=324,694) discharged from acute care hospitals for sepsis, defined by MS-DRG, between October 2014 and September 2018.\nRESEARCH DESIGN: Multiple linear regression with hospital-level fixed effects was used to identify average hospital differences in 90-day episode spending. Separate multiple linear regression and quantile regression models were used to evaluate drivers of spending across the episode spending distribution.\nRESULTS: The mean total episode spending among hospitals in the most expensive quartile was $30,500 compared with $23,150 for the least expensive hospitals (P<0.001). Postacute care spending among the most expensive hospitals was almost double that of least expensive hospitals ($7,045 vs. $3,742), accounting for 51% of the total difference in episode spending between the most expensive and least expensive hospitals. Female patients, patients with more comorbidities, urban hospitals, and BPCI-A-participating hospitals were associated with significantly increased episode spending, with the effect increasing at the right tail of the spending distribution.\nCONCLUSION: Inter-hospital variation in 90-day episode spending on sepsis care is driven primarily by differences in post-acute care spending.",
                "disciplines": [
                    "4203"
                ]
            }
        }
    },
    "13029051": {
        "title": "Processing of fecal samples through the integration of dissolved air flotation and automated diagnosis of intestinal parasites",
        "abstract": "For the advancement in the diagnosis of intestinal parasites in humans, through the Parasitological Examination of Feces (EPF), it is necessary to develop scientific and technological alternatives that can reduce the manual steps of this examination and consequently reduce human interpretation errors and excessive use. of chemical components harmful to man, parasitic structures and the environment. Dissolved Air Flotation (DAF) proves to be a new technical principle with efficient recovery of intestinal parasites and removal of fecal impurities (organic waste) that would benefit laboratory practice with the perspective of automating the processing of feces. With this, this research aims to develop and validate in an intralaboratory way the integration of a new mechanized FAD equipment to the Automated Diagnosis of Intestinal Parasites (DAPI) system. The integration of these devices is named in this study FADDAPI/G1. In the laboratory development phase, 300 fecal samples positive for enteroparasites will be used from a volunteer public at the Municipal Health Laboratory (LMS) in the city of Campinas, SP. These samples will be used in standardization tests with emphasis on FAD, in order to measure the recovery of parasites contained in the floated and non-floated contents in the evaluation of the following parameters: investigation of different surfactants and cationic polymers; adjustment of optimal concentrations of chemical reagents; volume adaptation of the fecal suspension in the flotation tube; and, adequacy of these parameters in the preparation of fecal smears on microscopy slides for the detection of enteroparasites by the FADDAPI/G1 system. The intralaboratory validation of FADDAPI/G1 will occur in comparison with the manual parasitological technique of TF-Test Modified and the DAPI system unified with the TF-Test Modified, with the use of 400 fecal samples collected blindly, in view of the comparison of statistical sensitivity metrics , specificity and Kappa concordance. The results of this study should lead to the creation of an integrated system for the mechanized processing of fecal samples, detection and automated identification through image analysis of intestinal parasites in an unprecedented way.",
        "disciplines": [
            "4019"
        ],
        "publications": {
            "10.1111/tmi.13827": {
                "title": "Detection of intestinal parasites in human faecal samples using dissolved air flotation",
                "abstract": "OBJECTIVE: Ova and parasite (O&P) examination is recommended for the laboratory diagnosis of agents causing parasitic infections; however, this exam requires scientific and technological improvements to enhance its diagnostic validity. Dissolved air flotation (DAF) is an efficient technical principle separating suspended solids in a liquid medium. We aimed to develop and validate a new procedure for intestinal parasite detection with DAF.\nMETHODS: In this study, we collected samples from 500 volunteers, screened them by direct examination, and transferred the material to tubes using the Three Faecal Test (TF-Test) for triplicate DAF tests. We evaluated physical-chemical parameters and DAF prototype components through quantifying parasites recovered from floated and non-floated regions of the flotation column. The DAF operation protocol was validated with the gold standard results.\nRESULTS: The 10% saturated volume proportion and cationic surfactant showed regularity and high parasite recovery (80%). Modifications of the needle device did not influence parasite recovery (p\u00a0>\u20090.05). Sensitivity, specificity, accuracy and kappa agreement obtained with the DAF protocol were 91%, 100%, 93% and substantial (k\u00a0=\u20090.64), respectively.\nCONCLUSION: The DAF principle could be used to process faecal samples in routine laboratory exams, enabling intestinal parasite detection.",
                "disciplines": [
                    "3202"
                ]
            }
        }
    },
    "13056308": {
        "title": "Design and Development of Flexible Metasurfaces for Applications in Biosensing and Telecommunications",
        "abstract": "This proposal aims to support the visit of Dr. Jorge Ricardo Mej\u00eda-Salazar, professor at Inatel in Minas Gerais, to develop research activities at IFSC-USP for a period of ca. 6 weeks. The Doctor. Mej\u00eda-Salazar did postdoctoral work at the IFSC and continued to work collaboratively with us, which has been very fruitful. By way of illustration, Dr. Mej\u00eda-Salazar has published nearly 30 articles in collaboration with IFSC researchers. Since he joined Inatel, this collaboration has been done with virtual meetings. While this has worked very well, we want to extend the topics we are working on together, especially to involve IFSC students and postdoctoral fellows. We believe that your presence at the IFSC in the planned period will help in expanding activities and finalizing the works that are in preparation. For the latter purpose, we want to act as a task force to make the most of Dr. Mej\u00eda-Salazar among us at the IFSC. The activities of the visit will benefit the Thematic Project 2018/22214-6. (AU)",
        "disciplines": [
            "4608"
        ],
        "publications": {
            "10.1063/5.0167167": {
                "title": "Flexible metasurfaces as sub-6 GHz frequency selective surfaces for 5G applications",
                "abstract": "The deployment of fifth-generation mobile network (5G), beyond 5G and sixth-generation mobile network platforms encounters challenges of blockage, interference, and path loss in radio mobile environments. Metasurfaces provide a promising solution to address these limitations. In this paper, we present a methodology for developing ultrathin flexible metasurface-based frequency selective surfaces (FSSs). Our approach combines thermal evaporation for metallic thin films with a macroscopic metasurface mask (something analogous to screen-printing but using thermal evaporation instead of inks). As a proof of concept, we fabricate a sub-6 GHz metasurface-based FSS using gold deposition on a flexible polyethylene terephthalate substrate. Experimental results are validated through numerical full-wave simulations using COMSOL Multiphysics and equivalent-circuit model simulations. The metasurface operates within the primary frequency band utilized in 5G networks (3\u20135 GHz), indicating its potential applicability across a wide range of flexible, conformal, and wearable devices. The fabricated FSS can be installed on surfaces of any shape, such as flat or curved windows, as well as on walls or other external surfaces. This methodology offers practical solutions for wireless communications and enhancing signal transmission in diverse environments.",
                "disciplines": [
                    "4006",
                    "4009"
                ]
            },
            "10.1021/acsami.2c19376": {
                "title": "Magnetoplasmonic Nanoantennas for On-Chip Reconfigurable Optical Wireless Communications",
                "abstract": "On-chip wireless communications require optical nanoantennas with dynamically tunable radiation patterns, which may allow for higher integration with multiple nanoantennas instead of two fixed nanoantennas in existing approaches. In this paper, we introduce a concept to enable active manipulation of radiated beam steering using applied magnetic fields. The proposed system consists of a highly directive Yagi-Uda-like arrangement of magnetoplasmonic nanoribs made of Co<sub>6</sub>Ag<sub>94</sub> and immersed in SiO<sub>2</sub>. Numerical demonstration of the tilting of the radiated beam from the nanoantenna on its plane is provided with full-wave electromagnetic simulations using the finite element method. The tilt direction of the radiated beam can be changed by reversing the magnetization direction, while the conventional plasmonic nanoantenna pattern is recovered by demagnetizing the system. The geometry of the nanoantenna can be tailored to work at optical or infrared wavelengths, but a proof of concept for \u03bb = 700 nm is conducted for taking advantage of the high magneto-optical activity of Co<sub>6</sub>Ag<sub>94</sub>. The design was based on experimental data for materials that can be fabricated via nanolithography, thus permitting magnetically on-chip reconfigurable optical wireless communications.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1021/acsanm.2c05047": {
                "title": "Numerical Simulations of Double-Well Optical Potentials in All-Dielectric Nanostructures for Manipulation of Small Nanoparticles in Aqueous Media",
                "abstract": "The manipulation of molecules placed in close proximity to a liquid is crucial for understanding their interactions, as in the study of antibiotics against bacteria. This can, in principle, be realized with plasmonic optical tweezers, but the heating of metals leads to the denaturing of biomolecules. In this work, we demonstrate that slotted all-dielectric nanodisks made of amorphous silicon (a-Si) exhibit double-well optical potentials, which can be used to stably trap dielectric nanoparticles with radii as small as 15 nm using infrared wavelengths where there is no optical loss (no heating) for a-Si. The latter is important to avoid heating the surrounding environment, which in turn, generates fluid convection currents that would compromise optical trapping. The trapping of one and two nanoparticles (even with different morphologies) in water is demonstrated in numerical results for an all-dielectric nanostructure, which can be obtained with standard materials and nanofabrication methods. The trapping forces are only slightly affected by the morphology of the small dielectric nanoparticles, thus indicating that the trapping approach may be applied to a variety of biomolecules.",
                "disciplines": [
                    "4018"
                ]
            }
        }
    },
    "13827089": {
        "title": "Deciphering the mysteries of sleep:creating a global network of sleep neurobiologists",
        "abstract": "The purpose of this international collaborative research is to build a global network of neurobiologists centered on IIIS and to elucidate the mysteries of sleep. IIIS used cutting-edge technology to tackle the mysteries of sleep, and the many findings obtained became the basis for solving the mysteries of sleep. However, the mysteries have not been completely solved, and the genetic influence of sleep time Big mysteries such as control remain. In order to fully elucidate the mysteries of sleep, it is essential to have the cooperation and support of experts who have different and complementary abilities and techniques than ours. This collaboration will address questions at various levels in four areas of neurobiology: 1. Molecular/cellular neurobiology: Comprehensively identify all molecules involved in the control of sleep/wakefulness, including genes, proteins, and intercellular information transmitters, and assemble each piece of a complex puzzle into a comprehensive picture of sleep. Finalize. 2. Neural circuit/system neurobiology: We unravel each complex network of neural circuits, which are the executive system for sleep/wake control, in terms of neural function and morphology, and make it possible to artificially manipulate sleep. In order to uncover the characteristics and true nature of these neural circuits. 3. Cognitive/behavioral neurobiology: Focusing on our level of consciousness and deepening our understanding of how our brains and bodies need quality sleep in order to keep it in perfect condition and healthy. 4. Chemical neurobiology: Taking on the challenge of developing innovative tools and obtaining technology that enables the manipulation of sleep by dissecting the sleep-wake control mechanism from an unprecedented perspective. Specifically, we will send several young researchers each year to work with world-class collaborators at overseas partners for a period of 2-3 years, to organize a global network of neurobiologists, and to We will focus on supporting the independence building of young researchers who want to innovate their potential. In the first year, we established a system and began preparations.",
        "disciplines": [
            "3201"
        ],
        "publications": {
            "10.1101/2024.05.21.595254": {
                "title": "STGram: Non-Invasive Visualization and Analysis of Circadian Rhythms Through Surface Temperature Monitoring",
                "abstract": "Abstract Circadian rhythms, integral to physiological and behavioral processes, are influenced by environmental cues and developmental stages. This study explores the visualization and analysis of circadian rhythms through non-invasive monitoring of surface body temperature (STGram: Surface Thermo Deviations gram), focusing on the effects of jet lag in international travelers and the developmental progression of circadian rhythms in infants. Using a compact, wearable thermometric device, we collected data from adults experiencing jet lag and a 3-month-old infant over five months. Our analysis identified clear circadian shifts in travelers and illustrated the gradual establishment of circadian rhythms in the infant. These findings underscore the effectiveness of surface body temperature as a marker for circadian rhythm analysis, offering a valuable tool for understanding circadian dynamics and their impact on health. This methodological approach has significant implications for circadian rhythm research, health management, and the study of physiological development.",
                "disciplines": [
                    "3504"
                ]
            },
            "10.1038/s41467-024-47964-4": {
                "title": "Optochemical control of slow-wave sleep in the nucleus accumbens of male mice by a photoactivatable allosteric modulator of adenosine A2A receptors",
                "abstract": "Optochemistry, an emerging pharmacologic approach in which light is used to selectively activate or deactivate molecules, has the potential to alleviate symptoms, cure diseases, and improve quality of life while preventing uncontrolled drug effects. The development of in-vivo applications for optochemistry to render brain cells photoresponsive without relying on genetic engineering has been progressing slowly. The nucleus accumbens (NAc) is a region for the regulation of slow-wave sleep (SWS) through the integration of motivational stimuli. Adenosine emerges as a promising candidate molecule for activating indirect pathway neurons of the NAc expressing adenosine A2A receptors (A2ARs) to induce SWS. Here, we developed a brain-permeable positive allosteric modulator of A2ARs (A2AR PAM) that can be rapidly photoactivated with visible light (\u03bb\u2009>\u2009400\u2009nm) and used it optoallosterically to induce SWS in the NAc of freely behaving male mice by increasing the activity of extracellular adenosine derived from astrocytic and neuronal activity.",
                "disciplines": [
                    "5202",
                    "3214"
                ]
            },
            "10.1093/jb/mvae021": {
                "title": "Morphinan Evolution: The Impact of Advances in Biochemistry and Molecular Biology",
                "abstract": "Morphinan-based opioids, derived from natural alkaloids like morphine, codeine and thebaine, have long been pivotal in managing severe pain. However, their clinical utility is marred by significant side effects and high addiction potential. This review traces the evolution of the morphinan scaffold in light of advancements in biochemistry and molecular biology, which have expanded our understanding of opioid receptor pharmacology. We explore the development of semi-synthetic and synthetic morphinans, their receptor selectivity and the emergence of biased agonism as a strategy to dissociate analgesic properties from undesirable effects. By examining the molecular intricacies of opioid receptors and their signaling pathways, we highlight how receptor-type selectivity and signaling bias have informed the design of novel analgesics. This synthesis of historical and contemporary perspectives provides an overview of the morphinan landscape, underscoring the ongoing efforts to mitigate the problems facing opioids through smarter drug design. We also highlight that most morphinan derivatives show a preference for the G protein pathway, although detailed experimental comparisons are still necessary. This fact underscores the utility of the morphinan skeleton in future opioid drug discovery.",
                "disciplines": [
                    "3214"
                ]
            },
            "10.1016/j.neuron.2024.01.014": {
                "title": "Anterior cingulate cortex projections to the dorsal medial striatum underlie insomnia associated with chronic pain",
                "abstract": "Chronic pain often leads to the development of sleep disturbances. However, the precise neural circuit mechanisms responsible for sleep disorders in chronic pain have remained largely unknown. Here, we present compelling evidence that hyperactivity of pyramidal neurons (PNs) in the anterior cingulate cortex (ACC) drives insomnia in a mouse model of nerve-injury-induced chronic pain. After nerve injury, ACC PNs displayed spontaneous hyperactivity selectively in periods of insomnia. We then show that ACC PNs were both necessary for developing chronic-pain-induced insomnia and sufficient to mimic sleep loss in naive mice. Importantly, combining optogenetics and electrophysiological recordings, we found that the ACC projection to the dorsal medial striatum (DMS) underlies chronic-pain-induced insomnia through enhanced activity and plasticity of ACC-DMS dopamine D1R neuron synapses. Our findings shed light on the pivotal role of ACC PNs in developing chronic-pain-induced sleep disorders.",
                "disciplines": [
                    "3209",
                    "3202"
                ]
            },
            "10.1016/j.isci.2023.107385": {
                "title": "Ventral pallidal glutamatergic neurons regulate wakefulness and emotion through separated projections",
                "abstract": "Insomnia is often comorbid with depression, but the underlying neuronal circuit mechanism remains elusive. Recently, we reported that GABAergic ventral pallidum (VP) neurons control wakefulness associated with motivation. However, whether and how other subtypes of VP neurons regulate arousal and emotion are largely unknown. Here, we report glutamatergic VP (VP<sup>Vglut2</sup>) neurons control wakefulness and depressive-like behaviors. Physiologically, the calcium activity of VP<sup>Vglut2</sup> neurons was increased during both NREM sleep-to-wake transitions and depressive/anxiety-like behaviors in mice. Functionally, activation of VP<sup>Vglut2</sup> neurons was sufficient to increase wakefulness and induce anxiety/depressive-like behaviors, whereas inhibition attenuated both. Dissection of the circuit revealed that separated projections of VP<sup>Vglut2</sup> neurons to the lateral hypothalamus and lateral habenula promote arousal and depressive-like behaviors, respectively. Our results demonstrate a subtype of VP neurons is responsible for wakefulness and emotion through separated projections, and may provide new lines for the intervention of insomnia and depression in patients.",
                "disciplines": [
                    "5202",
                    "3209"
                ]
            },
            "10.1016/j.peptides.2023.171051": {
                "title": "The present and future of synthetic orexin receptor agonists",
                "abstract": "The neuropeptide orexin/hypocretin plays a crucial role in various physiological processes, including the regulation of sleep/wakefulness, appetite, emotion and the reward system. Dysregulation of orexin signaling has been implicated in hypersomnia, especially in narcolepsy, which is a chronic neurological disorder characterized by excessive daytime sleepiness (EDS), sudden loss of muscle tone while awake (cataplexy), sleep paralysis, and hallucinations. Small-molecule orexin receptor agonists have emerged as promising therapeutics for these disorders, and significant progress has been made in this field in the past decade. This review summarizes recent advances in the design and synthesis of orexin receptor agonists, with a focus on peptidic and small-molecule OX2R-selective, dual, and OX1R-selective agonists. The review discusses the key structural features and pharmacological properties of these agonists, as well as their potential therapeutic applications.",
                "disciplines": [
                    "3214"
                ]
            },
            "10.3389/fphar.2023.1138666": {
                "title": "Positive allosteric adenosine A2A receptor modulation suppresses insomnia associated with mania- and schizophrenia-like behaviors in mice",
                "abstract": "<b>Background:</b> Insomnia is associated with psychiatric illnesses such as bipolar disorder or schizophrenia. Treating insomnia improves psychotic symptoms severity, quality of life, and functional outcomes. Patients with psychiatric disorders are often dissatisfied with the available therapeutic options for their insomnia. In contrast, positive allosteric modulation of adenosine A<sub>2A</sub> receptors (A<sub>2A</sub>Rs) leads to slow-wave sleep without cardiovascular side effects in contrast to A<sub>2A</sub>R agonists. <b>Methods:</b> We investigated the hypnotic effects of A<sub>2A</sub>R positive allosteric modulators (PAMs) in mice with mania-like behavior produced by ablating GABAergic neurons in the ventral medial midbrain/pons area and in a mouse model of schizophrenia by knocking out of microtubule-associated protein 6. We also compared the properties of sleep induced by A<sub>2A</sub>R PAMs in mice with mania-like behavior with those induced by DORA-22, a dual orexin receptor antagonist that improves sleep in pre-clinical models, and the benzodiazepine diazepam. <b>Results:</b> A<sub>2A</sub>R PAMs suppress insomnia associated with mania- or schizophrenia-like behaviors in mice. A<sub>2A</sub>R PAM-mediated suppression of insomnia in mice with mania-like behavior was similar to that mediated by DORA-22, and, unlike diazepam, did not result in abnormal sleep. <b>Conclusion:</b> A<sub>2A</sub>R allosteric modulation may represent a new therapeutic avenue for sleep disruption associated with bipolar disorder or psychosis.",
                "disciplines": [
                    "3214"
                ]
            },
            "10.3389/fphar.2023.1098976": {
                "title": "Adenosine and P1 receptors: Key targets in the regulation of sleep, torpor, and hibernation",
                "abstract": "Sleep, torpor, and hibernation are three distinct hypometabolic states. However, they have some similar physiological features, such as decreased core body temperature and slowing heart rate. In addition, the accumulation of adenosine seems to be a common feature before entry into these three states, suggesting that adenosine and its receptors, also known as P1 receptors, may mediate the initiation and maintenance of these states. This review, therefore, summarizes the current research on the roles and possible neurobiological mechanisms of adenosine and P1 receptors in sleep, torpor, and hibernation. Understanding these aspects will give us better prospects in sleep disorders, therapeutic hypothermia, and aerospace medicine.",
                "disciplines": [
                    "3208"
                ]
            }
        }
    },
    "13057629": {
        "title": "Optimizing the Zero Suicide Model for Juvenile Detention",
        "abstract": "PROJECT SUMMARY/ABSTRACT This K23 Career Development Award will prepare the applicant to launch her career as an independent investi- gator with expertise in research at the intersection of implementation and mental health equity research, with a specialization in legal settings that serve youth, consistent with NIMH Strategic Objective 4. The University of Illinois at Chicago (UIC), under the expert mentorship of Drs. Marc Atkins, Jaleel Abdul-Adil, Lisa Saldana, and Greg Brown, is the ideal environment for the applicant\u2019s career development. Faculty conduct extensive imple- mentation research with the goal of promoting youth mental health equity and have strong connections to the Chicago Department of Public Health and the NIH-funded UIC Center for Clinical and Translational Sciences. Training goals include: (a) foundational mental health equity research, (b) advanced implementation research, and (c) specialized training in suicide prevention research and practice. The research component of this appli- cation was developed to complement the training goals and provide opportunities to execute and refine newly developed skills. The research plan addresses the critical need to prevent suicide among youth in juvenile jus- tice settings. Youth in juvenile detention centers experience suicidal ideation at higher rates than their peers, and juvenile detention centers disproportionately serve African American and Black youth, a group experienc- ing an increase in suicide attempts nationally. Aligned with the Zero Suicide model, the applicant will optimize the clinical and implementation elements used within juvenile detention centers (i.e., screening, pathways of care, and brief treatment of suicidality via the Safety Planning Intervention). As the applicant\u2019s goal is to be- come an expert in the implementation of a range of evidence-based practices for legal settings that serve youth, studying suicide prevention, given its large research base of evidence-based practices and its complex regulatory concerns, provides the ideal training platform. In Aim 1, formerly detained young adults (n=35) who identify as Black will be interviewed to understand their lived experiences and identify key barriers to and facili- tators of suicide prevention in juvenile detention. In Aim 2, using data from the applicant\u2019s prior work and Aim 1, the applicant will refine the Zero Suicide clinical elements for detention to ensure they are culturally respon- sive and contextually appropriate and select and operationalize the implementation elements. In Aim 3, the ap- plicant will pilot the feasibility of the Zero Suicide model and R01 method in two local detention centers using a stepped wedge design and a convergent mixed method. The aim is to demonstrate the feasibility of the clinical and implementation elements as well as the recruitment, retention, and data collection procedures. This project will provide the necessary data and skills for the applicant\u2019s future R01 hybrid type 2 effectiveness-implementa- tion trial of the Zero Suicide model for juvenile detention. The timing of this proposed study is critical. Prevent- ing youth suicide is a national priority, and NIMH has pledged to reduce the suicide rate by 20% by 2025 and has a special interest in research on risk and prevention of Black youth suicide (NOT-MH-20-055).",
        "disciplines": [
            "5203"
        ],
        "publications": {
            "10.1186/s43058-023-00521-4": {
                "title": "The application of implementation science methods in correctional health intervention research: a systematic review",
                "abstract": "BackgroundImproving access to high-quality healthcare for individuals in correctional settings is critical to advancing health equity in the United States. Compared to the general population, criminal-legal involved individuals experience higher rates of chronic health conditions and poorer health outcomes. Implementation science frameworks and strategies offer useful tools to integrate health interventions into criminal-legal settings and to improve care. A review of implementation science in criminal-legal settings to date is necessary to advance future applications. This systematic review summarizes research that has harnessed implementation science to promote the uptake of effective health interventions in adult criminal-legal settings.MethodsA systematic review of seven databases (Academic Search Premier, Cumulative Index to Nursing and Allied Health Literature, PsycINFO, Social Work Abstracts, ProQuest Criminal Justice Database, ProQuest Sociological Abstracts, MEDLINE/PubMed) was conducted. Eligible studies used an implementation science framework to assess implementation outcomes, determinants, and/or implementation strategies in adult criminal-legal settings. Qualitative synthesis was used to extract and summarize settings, study designs, sample characteristics, methods, and application of implementation science methods. Implementation strategies were further analyzed using the Pragmatic Implementation Reporting Tool.ResultsTwenty-four studies met inclusion criteria. Studies implemented interventions to address infectious diseases (n=9), substance use (n=6), mental health (n=5), co-occurring substance use and mental health (n=2), or other health conditions (n=2). Studies varied in their operationalization and description of guiding implementation frameworks/taxonomies. Sixteen studies reported implementation determinants and 12 studies measured implementation outcomes, with acceptability (n=5), feasibility (n=3), and reach (n=2) commonly assessed. Six studies tested implementation strategies. Systematic review results were used to generate recommendations for improving implementation success in criminal-legal contexts.ConclusionsThe focus on implementation determinants in correctional health studies reflects the need to tailor implementation efforts to complex organizational and inter-agency contexts. Future studies should investigate policy factors that influence implementation success, design, and test implementation strategies tailored to determinants, and investigate a wider array of implementation outcomes relevant to criminal-legal settings, health interventions relevant to adult and juvenile populations, and health equity outcomes.Trial registrationA study protocol (CRD42020114111) was registered with Prospero.",
                "disciplines": [
                    "4203",
                    "4206"
                ]
            },
            "10.1177/26334895231199467": {
                "title": "Implementing trauma-focused cognitive behavioral therapy in Philadelphia: A 10-year evaluation",
                "abstract": "<b>Background:</b> In 2012, Philadelphia's Department of Behavioral Health and Intellectual disAbility Services (DBHIDS) developed an initiative to implement an evidence-based treatment for posttraumatic stress disorder (PTSD), trauma-focused cognitive behavioral therapy (TF-CBT), across the city's behavioral health system. This report evaluates the initiative's 10-year implementation and effectiveness outcomes. <b>Method:</b> The Exploration, Preparation, Implementation, and Sustainment framework guided our implementation evaluation. The implementation outcomes include adoption, reach, and sustainment; these were obtained during regular evaluation data collection from publicly funded behavioral health agencies participating in the TF-CBT initiative. We analyze effectiveness outcomes (i.e., changes in PTSD symptoms) from a subset of patients receiving TF-CBT, which were collected in 6-month intervals by our research team between 2013 and 2021. <b>Results:</b> From 2012 to 2021, DBHIDS trained 478 clinicians in TF-CBT across 20 behavioral health agencies. During this time, 23,401 youths were screened for potentially traumatic events and PTSD symptoms, and 7,550 youths received TF-CBT. Through the TF-CBT initiative, the city expanded the network of TF-CBT providers from 3 to 20 agencies. DBHIDS sustained this network by maintaining the participation of 16 behavioral health agencies over the course of a decade. The subset of 202 youths who were evaluated to assess TF-CBT effectiveness was drawn from 94 therapists and 20 agencies across Philadelphia. All participating youths completed a baseline assessment, and 151 (75%) completed at least one follow-up assessment. Linear mixed-effects models accounting for observations nested within participants and nested within clinicians found that treatment significantly reduced PTSD symptoms. <b>Conclusion:</b> Between 2012 and 2021, DBHIDS successfully implemented and sustained TF-CBT across the city's behavioral health system. Adoption, reach, and sustainment of TF-CBT were high. Despite the considerable adverse experiences faced by youths seeking treatment in Philadelphia's behavioral health system, TF-CBT was effective. Future directions to improve TF-CBT implementation in the next iteration of the initiative are described.",
                "disciplines": [
                    "5203",
                    "4203",
                    "4409"
                ]
            }
        }
    },
    "13248305": {
        "title": "EPSRC Core Equipment Award 2022",
        "abstract": "The requested equipment will complement existing infrastructure in our Laboratories for Robotics and AI, Sustainability and Photonics Technologies. These Laboratories have been identified as core to the aforementioned strategy and support highly inter-disciplinary research underpinning the work of diverse Research Groups across four Research Institutes (RIs) within the School of Engineering and Physical Sciences (EPS), namely Institutes of; Mechanical Process and Energy Engineering (IMPEE); Photonics and Quantum Sciences (IPAQS); Sensors Signals and Systems (ISSS.",
        "disciplines": [
            "4010"
        ],
        "publications": {
            "10.1002/adom.202303199": {
                "title": "Engineering Waveguide Nonlinear Effective Length via Low Index Thin Films",
                "abstract": "Abstract Novel photonic nanowires are fabricated using low\u2010index materials and tested in the near\u2010infrared spectrum to assess their nonlinear optical properties. In this work, the need to redefine the standard nonlinear figure\u00a0of merit in terms of nonlinear phase shift and optical transmission for a given propagation distance is argued. According to this new metric, the devices largely outperform all established platforms for optical modules with a linear footprint in the range of 50\u2013500 \u00b5m, which is demonstrated to be an outstanding technological gap. For 85 fs pulses, with carrier wavelength at 1480 nm and sub\u2010\u00b5W power levels, a spectral broadening exceeding 80% of the initial bandwidth was\u00a0recorded over a propagation length of just 50 \u00b5m. Leveraging on CMOS\u2010compatible processes and well\u2010established materials such as silicon, silica, and indium tin oxide, the\u00a0devices bring great promise for developing alternative all\u2010optical devices with unparalleled nonlinear performances within the aforementioned\u00a0range.",
                "disciplines": [
                    "5108",
                    "4016",
                    "4018"
                ]
            },
            "10.1002/adom.202301232": {
                "title": "Nonlinear Loss Engineering in Near\u2010Zero\u2010Index Bulk Materials",
                "abstract": "Abstract  Transparent conducting oxides (TCOs) show unprecedented optical nonlinearities in the near infrared wavelength range, where the real part of their linear refractive index approaches zero. More specifically, the Kerr nonlinearities of these materials have sparked widespread attention due to their magnitude and speed. However, due to the absorptive nature of these nonlinear processes, it is of fundamental interest to further investigate the imaginary component of the nonlinear index. The present work studies the nonlinear optical absorption properties of aluminium\u2010doped zinc oxide (AZO) thin films in their near\u2010zero\u2010index (NZI) spectral window. It is found that the imaginary part of the refractive index is reduced under optical excitation such that the field penetration depth more than doubles. An optically induced shift of the NZI bandwidth of \u2248120 nm for a pump intensity of 1.3 TW\u00a0cm \u22122 is also demonstrated. Looking into the optically induced spectral redistribution of the probe signal, local net gain is recorded, which is ascribed to a nonlinear adiabatic energy transfer. The present study adds key information about the fundamental interplay between real and imaginary nonlinear indices in NZI media, while advancing parametric amplification as viable direction for loss compensation. ",
                "disciplines": [
                    "5108"
                ]
            }
        }
    },
    "13046096": {
        "title": "Light-weight portable marine and hydrokinetic energy converter",
        "abstract": "Approved for Public ReleaseEnergy is the lifeblood for the modern Marine Corps, but such dependence also adds pressure, risk, and vu,lnerability to our soldiers, in particular for expeditionary forces. The Ground Renewable Expeditionary Energy Network System (GREEN,S) offers a good solution for sustainable energy in the field, however, also comes with its limitations. The energy source is not 24, hours/day and subjected to weather conditions, thus it is not always dependable. The current GREENS design is heavy and its applica,tion is limited by deployability. However, the modular design opens the door for alternative sources of energy. A lightweight, compa,ct, efficient, and reliable energy source is thus critical. In this proposal, we propose a light-weight, portable, highly efficient,energy conversion modular compatible to GREENS to harvest in-situ energy from the ocean to provide reliable, easy, and cheap renewab,le energy to the Marine Corps. The proposed energy harvesting device can harvest both ocean waves and ocean current energy on a 24/7, basis. The system weighs 50-80 lbs., and can fit into a backpack to be carried around by soldiers on mission. The system can be dep,loyed or retrieved by a single soldier in less than 20 min with ease. Once deployed into the ocean, the system can harvest an averag,e of 300-500 W power continuously on a 24/7 basis without maintenance. The energy per mass will be increased significantly from 1.4,W/lbs. (GREENS 1kW station) to 6-10 W/lbs., 4.3-7.1 times more power per weight. The system is modular and can be scaled up to provi,de more power if needed. The modular design also makes it possible to network with solar energy, wind energy, and diesel engine ener,gy to provide comprehensive and reliable energy to the Marine Corps.The success of this project will significantly reduce the depend,ence on fuel energy and relieve the energy demand pressure faced in modern warfare and decrease the pressure, vulnerability, and ris,ks of the power supply associated logistics. The operation range, endurance, and agility of the Marine Corps can be improved signifi,cantly. The proposed ocean waves and current energy conversion modular could also improve the sustainability and reliability of exis,ting GREENS in the case that solar energy is unavailable, such as at night and rainy day.",
        "disciplines": [
            "4015"
        ],
        "publications": {
            "10.1016/j.energy.2024.130322": {
                "title": "Achieving optimum power extraction of wave energy converters through tunable mechanical components",
                "abstract": "Wave energy converters (WECs) play a significant role in harnessing the vast potential of marine renewable energy. To enhance the power extraction of WECs, it is necessary but challenging to design the parameters of the WECs for the time-varying wave conditions. This research explores the utilization of tunable mechanical components within both the power take-offs (PTO) and wave capturing structures. We first briefly review the tunable mechanisms and then conduct a theoretical analysis of their applications for maximizing power extraction under regular and irregular wave conditions. The study investigates the impact of PTO stiffness and inertance on power extraction through an analytical approach. The results reveal that both parameters exhibit a monotonic effect within specific frequency ranges, and showed the optimum power extraction can be achieved through the tunable mechanical components. Furthermore, the research highlights the importance of designing the frequency tuning limit for two-body WECs to coincide with the desired wave conditions, as it enables all PTO parameters to achieve an optimal power output. Based on the analysis, the paper gives insightful suggestions on the design of PTO and WEC systems, including mass ratio between the two bodies, mooring stiffness, and other relevant parameters. It is found that the tuning through the mechanical component can be significant for the single-body WEC yet less effective for the two-body WEC especially at irregular wave conditions.",
                "disciplines": [
                    "4015"
                ]
            }
        }
    },
    "9852739": {
        "title": "Elucidating the genesis of MAIT cell-mediated immunity",
        "abstract": "T cells develop in the thymus and proceed to survey our body probing molecules that signal if anything is abnormal. A specialised subset of T cells, mucosal associated invariant T (MAIT) cells are crucial in detecting microbial molecules and infection, yet their numbers vary widely between individuals. A key problem is that the factors controlling their development and function are poorly understood. This proposal aims to decode this critical issue in MAIT cell biology, using innovative tools to investigate the molecular basis underpinning their development in the thymus. This work will provide vital, fundamental discoveries into how MAIT cells are produced and regulated, as we ultimately wish to harness MAIT cells to improve human health.",
        "disciplines": [
            "3101",
            "3204"
        ],
        "publications": {
            "10.1126/sciimmunol.abo4365": {
                "title": "A three-stage developmental pathway for human V\u03b39V\u03b42 T cells within the postnatal thymus",
                "abstract": "V\u03b39V\u03b42 T cells are the largest population of \u03b3\u03b4 T cells in adults and can play important roles in providing effective immunity against cancer and infection. Many studies have suggested that peripheral V\u03b39V\u03b42 T cells are derived from the fetal liver and thymus and that the postnatal thymus plays little role in the development of these cells. More recent evidence suggested that these cells may also develop postnatally in the thymus. Here, we used high-dimensional flow cytometry, transcriptomic analysis, functional assays, and precursor-product experiments to define the development pathway of V\u03b39V\u03b42 T cells in the postnatal thymus. We identify three distinct stages of development for V\u03b39V\u03b42 T cells in the postnatal thymus that are defined by the progressive acquisition of functional potential and major changes in the expression of transcription factors, chemokines, and other surface markers. Furthermore, our analysis of donor-matched thymus and blood revealed that the molecular requirements for the development of functional V\u03b39V\u03b42 T cells are delivered predominantly by the postnatal thymus and not in the periphery. Tbet and Eomes, which are required for IFN-\u03b3 and TNF\u03b1 expression, are up-regulated as V\u03b39V\u03b42 T cells mature in the thymus, and mature thymic V\u03b39V\u03b42 T cells rapidly express high levels of these cytokines after stimulation. Similarly, the postnatal thymus programs V\u03b39V\u03b42 T cells to express the cytolytic molecules, perforin, granzyme A, and granzyme K.\u00a0This study provides a greater understanding of how V\u03b39V\u03b42 T cells develop in humans and may lead to opportunities to manipulate these cells to treat human diseases.",
                "disciplines": [
                    "3204"
                ]
            }
        }
    },
    "13527372": {
        "title": "Flawed, Real and Marginalized: Exploring emergent genders in Pakistani online streaming media",
        "abstract": "Pakistan\u2019s society is dominantly a heteropatriarchy in which gender is located at a nexus of religion, ethnicities, and class. Mainstream Pakistani media have played a crucial role in the naturalizing heteropatriarchal gender roles where women are portrayed only as mothers, wives, daughters, and sisters while men are depicted as strong, independent, authoritative, and powerful. These representations leave little space for depiction of alternative gender identities such as LGBTQ+ people. Until recently, the portrayal of transgender people has been unforgiving and biased. Similarly, the LGBTQ+ community has suffered an even worse fate. The politicization and criminalization of LGBTQ+ as deviances on religious grounds have resulted in the complete absence of this community in the national media thereby, ensuring the erasure of their voices and their issues such as being subjected to violent death after coming out. \n\nThis study explores how in Pakistan, an online (OTT) media platform webseries Churails (Witches) subverts patriarchal gender norms and takes up taboo issues (e.g. child marriage, harassment, forced marriage, abuse, transphobia, homosexuality, and society's obsession with whiteness) that have been overlooked and even banned in the mainstream electronic media. Given the way it puts non-conformist women and LGBTQ+ at the centre stage, the series was banned in Pakistan after a backlash over a clip that went viral on social media. The project is divided into into two complementary studies. The first study utilizes Multimodal Critical Discourse Analysis to examine the webseries\u2019 discourse while the second interview-based study analyses how Pakistani men and women have received the series. Such an exploration of genders may lead to bridge different views about gender and foster a discourse that emphasizes \u2018both/and\u2019 or \u2018and/and\u2019 rather than \u2018either/or\u2019 dichotomous categorizations thereby giving voice to groups who have previously not been heard in public.",
        "disciplines": [
            "4405",
            "4804"
        ],
        "publications": {
            "10.1515/sem-2023-0178": {
                "title": "Motorcycles, minarets, and mullahs: a multimodal critical discourse analysis on Pakistan\u2019s journey to rebrand Islam",
                "abstract": "Abstract This study addresses the issue of how religious authority is negotiated and redefined in the age of digital media, focusing on the case of Raja Zia ul Haq, a Pakistani Muslim cleric. Utilizing Multimodal Critical Discourse Analysis, the study posits that Zia ul Haq\u2019s strategic semiotic choices in attire and symbolism serve as calculated maneuvers to navigate complex dialogues of power, identity, and cultural capital. The findings reveal that his appropriation of biker club symbolism disrupts traditional paradigms of Islamic clerical authority in Pakistan. These choices resonate with a younger, digitally savvy audience and function as a form of religious rebranding. The study argues that Zia ul Haq\u2019s semiotic choices challenge monolithic interpretations of Islamic authority, thereby opening new avenues for religious engagement and interpretation. The significance of this work lies in its transnational implications, offering a counter-narrative that challenges prevailing stereotypes about Islamic scholars and suggests new paradigms for understanding religious authority in a globalized world.",
                "disciplines": [
                    "5004"
                ]
            }
        }
    },
    "13062420": {
        "title": "Corneal Examination at cell resolution with optical transmission tomography \u2013 CERES",
        "abstract": "Recently, we paid attention to a physical phenomenon called Gouy phase shift - ? phase change that waves experience, when they pass through an optical focus. We found that this effect can be used to create a new type of optical imaging system that works in transmission and captures optical sections of the sample. We have verified that this method works for ex vivo biological samples. In the current project we want to push this method further and make it suitable for in vivo eye diagnostics, in particular for diagnostics of in vivo human anterior eye (cornea, limbus). One way to achieve the transmission geometry in the eye is by illuminating the posterior segment (fundus) to produce diffusely back-reflected light (well-known red eye effect in conventional photography). This light then acts as a back-illumination source for the cornea. Other transmission configurations to be explored are back-illumination from the iris and epi-illumination through the sclera. Our team has a broad experience of bringing new imaging technologies from the concept to real clinical use. Therefore, the goal of the project extends beyond creating a new in vivo eye imaging device and aims at producing the valuable diagnostic results in clinical patients with a variety of ocular diseases. Particular attention will be given to studying neuropathies and inflammatory eye conditions as well as open-angle glaucoma - major underdiagnosed cause of irreversible blindness.",
        "disciplines": [
            "3212"
        ],
        "publications": {
            "10.1364/boe.506664": {
                "title": "Optical tomography in a single camera frame using fringe-encoded deep-learning full-field OCT.",
                "abstract": "Optical coherence tomography is a valuable tool for in vivo examination thanks to its superior combination of axial resolution, field-of-view and working distance. OCT images are reconstructed from several phases that are obtained by modulation/multiplexing of light wavelength or optical path. This paper shows that only one phase (and one camera frame) is sufficient for en face tomography. The idea is to encode a high-frequency fringe patterns into the selected layer of the sample using low-coherence interferometry. These patterns can then be efficiently extracted with a high-pass filter enhanced via deep learning networks to create the tomographic full-field OCT view. This brings 10-fold improvement in imaging speed, considerably reducing the phase errors and incoherent light artifacts related to in vivo movements. Moreover, this work opens a path for low-cost tomography with slow consumer cameras. Optically, the device resembles the conventional time-domain full-field OCT without incurring additional costs or a field-of-view/resolution reduction. The approach is validated by imaging in vivo cornea in human subjects. Open-source and easy-to-follow codes for data generation/training/inference with U-Net/Pix2Pix networks are provided to be used in a variety of image-to-image translation tasks.",
                "disciplines": [
                    "4003",
                    "3212",
                    "5102"
                ]
            },
            "10.1364/boe.494585": {
                "title": "Comparative analysis of full-field OCT and optical transmission tomography.",
                "abstract": "This work compares two tomographic imaging technologies, time-domain full-field optical coherence tomography (FFOCT) working in reflection and optical transmission tomography (OTT), using a new optical setup that combines both. We show that, due to forward-scattering properties, the axial sectioning and contrast in OTT can be optimized by tuning illumination. The influence of sample scattering and thickness are discussed. We illustrate the comparison of the two methods in static (morphology) and dynamic (metabolic contrast) regimes using cell cultures, tissues and entire organisms emphasizing the advantages of both approaches.",
                "disciplines": [
                    "4006"
                ]
            }
        }
    },
    "13567409": {
        "title": "Media, masses and politics: preliminary studies",
        "abstract": "The project proposes a reflection based on a thorough study of the bibliography relevant to the issues involved in the relationship between media and politics, particularly the production of massive behavior such as we have seen in the current Brazilian presidential elections. To this end, it provides for the reading of classic and contemporary texts on the subject - with particular attention to the changes that the massive use of internet social networks promote in the scenario of democratic politics -, as well as classic works in the field of psychoanalysis, with a view to search for a reflection on the emergence, in a large part of the electorate, of apparently irrational behaviors, disconnected from a basic perception of reality.",
        "disciplines": [
            "4701"
        ],
        "publications": {
            "10.3847/1538-4357/ac4601": {
                "title": "The Importance of Horizontal Poynting Flux in the Solar Photosphere",
                "abstract": "The electromagnetic energy flux in the lower atmosphere of the Sun is a key tool to describe the energy balance of the solar atmosphere. Current investigations on energy flux in the solar atmosphere focus primarily on the vertical electromagnetic flux through the photosphere, ignoring the Poynting flux in other directions and its possible contributions to local heating. Based on a realistic Bifrost simulation of a quiet-Sun (coronal hole) atmosphere, we find that the total electromagnetic energy flux in the photosphere occurs mainly parallel to the photosphere, concentrating in small regions along intergranular lanes. Thereby, it was possible to define a proxy for this energy flux based on only variables that can be promptly retrieved from observations, namely, horizontal velocities of the small-scale magnetic elements and their longitudinal magnetic flux. Our proxy accurately describes the actual Poynting flux distribution in the simulations, with the electromagnetic energy flux reaching 1010 erg cm\u22122 s\u22121. To validate our findings, we extended the analysis to Sunrise/IMaX data. First, we show that Bifrost realistically describes photospheric quiet-Sun regions, as the simulation presents similar distributions for line-of-sight magnetic flux and horizontal velocity field. Second, we found very similar horizontal Poynting flux proxy distributions for the simulated photosphere and observational data. Our results also indicate that the horizontal Poynting flux in the observations is considerably larger than the vertical electromagnetic flux from previous observational estimates. Therefore, our analysis confirms that the electromagnetic energy flux in the photosphere is mainly horizontal and is most intense in localized regions along intergranular lanes.",
                "disciplines": [
                    "5101"
                ]
            }
        }
    },
    "13286187": {
        "title": "Climate-Induced Migration in Africa and Beyond: Big Data and Predictive Analytics",
        "abstract": "Climate change could lead to human resettlements and other (new) forms of mobility. However, the empirical link between various climatic conditions and migration outcomes is highly contested, and, to date, no unified theoretical approach can adequately capture the complexity and contextual dependency of climate-induced migration. To address this gap, CLIMB seeks to develop a holistic approach which will allow us to better understand how climate change may intersect with conflicts, poverty, among other adversities, and operate in tandem in driving human migration.Climate risks are more likely to affect internal mobility, hence, rather than aiming for a global study, CLIMB will collect timely and granular data on specific areas where the climate-migration nexus can be more apparent conceptually and empirically. Senegal is chosen as our first case study, as it is projected to have more extreme weather events and up to one million people could be forced to move by 2050. Moreover, mobile phone data provided by Sonatel (the principal telecom provider of Senegal) offers a unique opportunity to study mobility patterns at a high resolution. CLIMB will also leverage earth observation and social media data, and combine them with survey and official statistical data. Such an approach will allow us to gain more insights about the temporality of climate-induced migration. It will also allow us to better understand how migratory processes are shaped by multi-level factors.",
        "disciplines": [
            "4404"
        ],
        "publications": {
            "10.1371/journal.pone.0284416": {
                "title": "Modelling and predicting forced migration",
                "abstract": "Migration models have evolved significantly during the last decade, most notably the so-called flow Fixed-Effects (FE) gravity models. Such models attempt to infer how human mobility may be driven by changing economy, geopolitics, and the environment among other things. They are also increasingly used for migration projections and forecasts. However, recent research shows that this class of models can neither explain, nor predict the temporal dynamics of human movement. This shortcoming is even more apparent in the context of forced migration, in which the processes and drivers tend to be heterogeneous and complex. In this article, we derived a Flow-Specific Temporal Gravity (FTG) model which, compared to the FE models, is theoretically similar (informed by the random utility framework), but empirically less restrictive. Using EUROSTAT data with climate, economic, and conflict indicators, we trained both models and compared their performances. The results suggest that the predictive power of these models is highly dependent on the length of training data. Specifically, as time-series migration data lengthens, FTG's predictions can be increasingly accurate, whereas the FE model becomes less predictive.",
                "disciplines": [
                    "4403"
                ]
            }
        }
    },
    "10007528": {
        "title": "High-frequency Estimation of Term Structure Models at the Zero Lower Bound",
        "abstract": "This project aims to quantify monetary policy shocks as shifts of the entire term structure of interest rates, when the central bank\u2019s policy rate is constrained at the near-zero level. The proposed method will use a high-dimensional panel of high frequency government bond data. The term structure and resultant policy shocks estimated at intra-day frequencies for major economies including Australia, will be made publicly available. This project expects to deepen our understanding of how monetary policy decisions affect the macroeconomy in a near-zero interest-rate environment. This should provide significant benefits to policymakers for implementing and monitoring monetary policy in achieving desired economic outcomes.",
        "disciplines": [
            "3802",
            "3803"
        ],
        "publications": {
            "10.1080/07350015.2023.2271039": {
                "title": "Tests for Jumps in Yield Spreads",
                "abstract": "This article studies high-frequency econometric methods to test for a jump in the spread of bond yields. We propose a coherent inference procedure that detects a jump in the yield spread only if at least one of the two underlying bonds displays a jump. Ignoring this inherent connection by basing inference only on a univariate jump test applied to the spread tends to overestimate the number of jumps in yield spreads and puts the coherence of test results at risk. We formalize the statistical approach in the context of an intersection union test in multiple testing. We document the relevance of coherent tests and their practicability via simulations and real data examples.",
                "disciplines": [
                    "3801",
                    "3802",
                    "3502"
                ]
            }
        }
    },
    "10007817": {
        "title": "Seeing Dark with Light: Revealing the Milky Way with Stellar Streams",
        "abstract": "This project aims to reveal the dark matter that envelops the Milky Way, deconstructing its mass through observations of cannibalised smaller galaxies. Uniting ground- and space-based observations, this project expects to uncover the detailed size and shape of the Galaxy's dark matter halo through dynamical modelling of dwarf galaxies as they are disrupted by Galactic tidal forces. As well as determining this dominant mass, the expected outcomes of this project include a unique snapshot of the evolution of our Milky Way. Leveraging major international collaborations and producing high-impact scientific results, this project will address the primal question of origins, yielding important societal and cultural benefits.",
        "disciplines": [
            "5101"
        ],
        "publications": {
            "10.1093/mnras/stae385": {
                "title": "3D NLTE Lithium abundances for late-type stars in GALAH DR3",
                "abstract": "Abstract Lithium\u2019s susceptibility to burning in stellar interiors makes it an invaluable tracer for delineating the evolutionary pathways of stars, offering insights into the processes governing their development. Observationally, the complex Li production and depletion mechanisms in stars manifest themselves as Li plateaus, and as Li-enhanced and Li-depleted regions of the HR diagram. The Li-dip represents a narrow range in effective temperature close to the main-sequence turn-off, where stars have slightly super-solar masses and strongly depleted Li. To study the modification of Li through stellar evolution, we measure 3D non-local thermodynamic equilibrium (NLTE) Li abundance for 581\u00a0149 stars released in GALAH DR3. We describe a novel method that fits the observed spectra using a combination of 3D NLTE Li line profiles with blending metal line strength that are optimized on a star-by-star basis. Furthermore, realistic errors are determined by a Monte Carlo nested sampling algorithm which samples the posterior distribution of the fitted spectral parameters. The method is validated by recovering parameters from a synthetic spectrum and comparing to 26 stars in the Hypatia catalogue. We find 228\u00a0613 Li detections, and 352\u00a0536 Li upper limits. Our abundance measurements are generally lower than GALAH DR3, with a mean difference of 0.23 dex. For the first time, we trace the evolution of Li-dip stars beyond the main sequence turn-off and up the subgiant branch. This is the first 3D NLTE analysis of Li applied to a large spectroscopic survey, and opens up a new era of precision analysis of abundances for large surveys.",
                "disciplines": [
                    "5101"
                ]
            },
            "10.1093/mnras/stad2760": {
                "title": "The kinematics, metallicities, and orbits of six recently discovered Galactic star clusters with Magellan/M2FS spectroscopy",
                "abstract": "ABSTRACT We present Magellan/M2FS spectroscopy of four recently discovered Milky Way star clusters (Gran 3/Patchick 125, Gran 4, Garro 01, and LP 866) and two newly discovered open clusters (Gaia 9 and Gaia 10) at low Galactic latitudes. We measure line-of-sight velocities and stellar parameters ([Fe/H], log g, Teff, and [Mg/Fe]) from high-resolution spectroscopy centred on the Mg triplet and identify 20\u201380 members per star cluster. We determine the kinematics and chemical properties of each cluster and measure the systemic proper motion and orbital properties by utilizing Gaia astrometry. We find Gran 3 to be an old, metal-poor (mean metallicity of [Fe/H]\u00a0= \u22121.83) globular cluster located in the Galactic bulge on a retrograde orbit. Gran 4 is an old, metal-poor ([Fe/H]\u00a0= \u22121.84) globular cluster with a halo-like orbit that happens to be passing through the Galactic plane. The orbital properties of Gran 4 are consistent with the proposed LMS-1/Wukong and/or Helmi streams merger events. Garro 01 is metal-rich ([Fe/H]\u00a0= \u22120.30) and on a near-circular orbit in the outer disc but its classification as an open cluster or globular cluster is ambiguous. Gaia 9 and Gaia 10 are among the most distant known open clusters at $R_{\\mathrm{GC}}\\sim 18,~21.2~\\mathrm{\\, kpc}$ and most metal-poor with [Fe/H] \u223c\u22120.50, \u22120.34 for Gaia 9 and Gaia 10, respectively. LP 866 is a nearby, metal-rich open cluster ([Fe/H] = +0.10). The discovery and confirmation of multiple star clusters in the Galactic plane shows the power of Gaia astrometry and the star cluster census remains incomplete.",
                "disciplines": [
                    "5109"
                ]
            }
        }
    },
    "13253639": {
        "title": "Structural and Biochemical Effects of Capsid-targeting Molecules on HIV-1 Capsid Assembly",
        "abstract": "Abstract HIV infection impacts over 37 million individuals, with over 2/3 of these patients receiving antiretroviral therapies (ART). ART is sustained for a patient\u2019s life and can lead to the emergence of drug-resistant HIV-1. To combat drug-resistance, an improved and diverse set of antiretrovirals are needed for clinical use. To this extent, the HIV-1 capsid is an excellent target for antiretroviral therapies as it has numerous, essential roles throughout the HIV-1 replication cycle. Compounds that target the capsid protein (CA), known as capsid effectors (CEs), offer a novel class of HIV-1 antivirals for potential clinical use. One CE with marked success is lenacapavir, developed by Gilead Sciences. Lenacapavir is exceptionally potent, however, early results show treatment with lenacapavir can cause the emergence of antiviral-resistant HIV-1. Our lab has previously reported highly potent antiretrovirals that target the same site as lenacapavir, within the FG-binding pocket. Compounds that bind to the FG-binding pocket of CA mimic a conserved phenylalanine-glycine (FG) dipeptide motif found in many host factors reported to bind CA. Here, I will characterize structural changes to the HIV-1 capsid upon treatment with highly potent CEs that bind the FG-binding pocket and calculate the biochemical parameters of CA\u2022CE interactions for this class of antiretroviral therapeutics. The nature of CA\u2022CE interactions will be assessed in wild-type (WT) and drug-resistant viruses to further our understanding of antiviral resistance. Electron microscopy (EM) will be used to visualize drug-resistant capsid assemblies and discern structural changes relative to WT assemblies (AIM 1). Rates of capsid assembly and changes to thermal stability upon drug-treatment will be calculated using assays designed to probe CA\u2022CA interactions (AIM 2). These aims will study mutations that confer antiviral-resistance and results will be compared to WT CA to identify those with similar phenotypes and therefore higher risks of resistance. Further, CA\u2022CE biochemical parameters of affinity and dissociation rates will be solved by label-free optical detection. This study will further our mechanistic understanding of compounds that bind to the FG-binding pocket of CA. Overall, these results will enable future research to strategically improve antiretrovirals, aiming to combat the HIV-1 epidemic.",
        "disciplines": [
            "3207"
        ],
        "publications": {
            "10.1002/ange.202320045": {
                "title": "A Tag\u2010Free Platform for Synthesis and Screening of Cyclic Peptide Libraries",
                "abstract": "Abstract In the realm of high\u2010throughput screening (HTS), macrocyclic peptide libraries traditionally necessitate decoding tags, essential for both library synthesis and identifying hit peptide sequences post\u2010screening. Our innovation introduces a tag\u2010free technology platform for synthesizing cyclic peptide libraries in solution and facilitates screening against biological targets to identify peptide binders through unconventional intramolecular CyClick and DeClick chemistries (CCDC) discovered through our research. This combination allows for the synthesis of diverse cyclic peptide libraries, the incorporation of various amino acids, and facile linearization and decoding of cyclic peptide binder sequences. Our sensitivity\u2010enhancing derivatization method, utilized in tandem with nano LC\u2010MS/MS, enables the sequencing of peptides even at exceedingly low picomolar concentrations. Employing our technology platform, we have successfully unearthed novel cyclic peptide binders against a monoclonal antibody and the first cyclic peptide binder of HIV capsid protein responsible for viral infections as validated by microscale thermal shift assays (TSA), biolayer interferometry (BLI) and functional assays.",
                "disciplines": [
                    "3405"
                ]
            },
            "10.1002/anie.202320045": {
                "title": "A Tag\u2010Free Platform for Synthesis and Screening of Cyclic Peptide Libraries",
                "abstract": "In the realm of high-throughput screening (HTS), macrocyclic peptide libraries traditionally necessitate decoding tags, essential for both library synthesis and identifying hit peptide sequences post-screening. Our innovation introduces a tag-free technology platform for synthesizing cyclic peptide libraries in solution and facilitates screening against biological targets to identify peptide binders through unconventional intramolecular CyClick and DeClick chemistries (CCDC) discovered through our research. This combination allows for the synthesis of diverse cyclic peptide libraries, the incorporation of various amino acids, and facile linearization and decoding of cyclic peptide binder sequences. Our sensitivity-enhancing derivatization method, utilized in tandem with nano LC-MS/MS, enables the sequencing of peptides even at exceedingly low picomolar concentrations. Employing our technology platform, we have successfully unearthed novel cyclic peptide binders against a monoclonal antibody and the first cyclic peptide binder of HIV capsid protein responsible for viral infections as validated by microscale thermal shift assays (TSA), biolayer interferometry (BLI) and functional assays.",
                "disciplines": [
                    "3405"
                ]
            },
            "10.1016/j.chembiol.2024.02.012": {
                "title": "Identification of clickable HIV-1 capsid-targeting probes for viral replication inhibition",
                "abstract": "Of the targets for HIV-1 therapeutics, the capsid core is a relatively unexploited but alluring drug target due to its indispensable roles throughout virus replication. Because of this, we aimed to identify \"clickable\" covalent modifiers of the HIV-1 capsid protein (CA) for future functionalization. We screened a library of fluorosulfate compounds that can undergo sulfur(VI) fluoride exchange (SuFEx) reactions, and five compounds were identified as hits. These molecules were further characterized for antiviral effects. Several compounds impacted in\u00a0vitro capsid assembly. One compound, BBS-103, covalently bound CA via a SuFEx reaction to Tyr145 and had antiviral activity in cell-based assays by perturbing virus production, but not uncoating. The covalent binding of compounds that target the HIV-1 capsid could aid in the future design of antiretroviral drugs or chemical probes that will help study aspects of HIV-1 replication.",
                "disciplines": [
                    "3404"
                ]
            },
            "10.1101/2023.11.29.569293": {
                "title": "Use of TSAR, Thermal Shift Analysis in R, to identify Folic Acid as a Molecule that Interacts with HIV-1 Capsid",
                "abstract": "Thermal shift assay (TSA) is a versatile biophysical technique for studying protein interactions. Here, we report a free, open-source software tool TSAR (Thermal Shift Analysis in R) to expedite and automate the analysis of thermal shift data derived either from individual experiments or large screens of chemical libraries. The TSAR package incorporates multiple, dynamic workflows to facilitate the analysis of TSA data and returns publication-ready graphics or processed results. Further, the package includes a graphic user interface (GUI) that enables easy use by non-programmers, aiming to simplify TSA analysis while diversifying visualization. To exemplify the utility of TSAR we screened a chemical library of vitamins to identify molecules that interact with the capsid protein (CA) of human immunodeficiency virus type 1 (HIV-1). Our data show that hexameric CA interacts with folic acid <i>in vitro</i>.",
                "disciplines": [
                    "3207"
                ]
            },
            "10.1038/s41467-023-41197-7": {
                "title": "Multidisciplinary studies with mutated HIV-1 capsid proteins reveal structural mechanisms of lattice stabilization",
                "abstract": "HIV-1 capsid (CA) stability is important for viral replication. E45A and P38A mutations enhance and reduce core stability, thus impairing infectivity. Second-site mutations R132T and T216I rescue infectivity. Capsid lattice stability was studied by solving seven crystal structures (in native background), including P38A, P38A/T216I, E45A, E45A/R132T CA, using molecular dynamics simulations of lattices, cryo-electron microscopy of assemblies, time-resolved imaging of uncoating, biophysical and biochemical characterization of assembly and stability. We report pronounced and subtle, short- and long-range rearrangements: (1) A38 destabilized hexamers by loosening interactions between flanking CA protomers in P38A but not P38A/T216I structures. (2) Two E45A structures showed unexpected stabilizing CANTD-CANTD inter-hexamer interactions, variable R18-ring pore sizes, and flipped N-terminal \u03b2-hairpin. (3) Altered conformations of E45Aa \u03b19-helices compared to WT, E45A/R132T, WTPF74, WTNup153, and WTCPSF6 decreased PF74, CPSF6, and Nup153 binding, and was reversed in E45A/R132T. (4) An environmentally sensitive electrostatic repulsion between E45 and D51 affected lattice stability, flexibility, ion and water permeabilities, electrostatics, and recognition of host factors.",
                "disciplines": [
                    "3403"
                ]
            },
            "10.35772/ghm.2023.01065": {
                "title": "Biology of the hepatitis B virus (HBV) core and capsid assembly modulators (CAMs) for chronic hepatitis B (CHB) cure",
                "abstract": "Hepatitis B virus (HBV) is a hepadnavirus, a small DNA virus that infects liver tissue, with some unusual replication steps that share similarities to retroviruses. HBV infection can lead to chronic hepatitis B (CHB), a life-long infection associated with significant risks of liver disease, especially if untreated. HBV is a significant global health problem, with hundreds of millions currently living with CHB. Currently approved strategies to prevent or inhibit HBV are highly effective, however, a cure for CHB has remained elusive. To achieve a cure, elimination of the functionally integrated HBV covalently closed chromosomal DNA (cccDNA) genome is required. The capsid core is an essential component of HBV replication, serving roles when establishing infection and in creating new virions. Over the last two and a half decades, significant efforts have been made to find and characterize antivirals that target the capsid, specifically the HBV core protein (Cp). The antivirals that interfere with the kinetics and morphology of the capsid, termed capsid assembly modulators (CAMs), are extremely potent, and clinical investigations indicate they are well tolerated and highly effective. Several CAMs offer the potential to cure CHB by decreasing the cccDNA pools. Here, we review the biology of the HBV capsid, focused on Cp, and the development of inhibitors that target it.",
                "disciplines": [
                    "3207"
                ]
            },
            "10.3390/v15040896": {
                "title": "Targeting the HIV-1 and HBV Capsids, an EnCore",
                "abstract": "Not many structures are common among all viruses: only nucleic acid and a protein coat [...].",
                "disciplines": [
                    "3107"
                ]
            }
        }
    },
    "13300890": {
        "title": "Developing and applying a world-first alcohol market monitoring system",
        "abstract": "The alcohol market is evolving rapidly, with new products being brought to market and creative marketing strategies being implemented, often targeting younger drinkers. This project will deliver a world-first system of monitoring  marketplace changes and providing timely data to policy makers to enable them to implement effective policy responses. A sustainable system of product monitoring and data reporting will be delivered to assist with alcohol harm-reduction strategies long term.   ",
        "disciplines": [
            "4407"
        ],
        "publications": {
            "10.1111/dar.13836": {
                "title": "The absence of mandatory pregnancy warning labels in online alcohol purchasing contexts",
                "abstract": "INTRODUCTION: As people increasingly migrate to online shopping platforms, hard-won improvements in requirements for consumer information provision at the point of sale are being eroded. An example is the alcohol pregnancy warning label for packaged alcoholic beverages that has been recently introduced in Australia and New Zealand. The aim of the present study was to assess the extent to which the pregnancy warning was visible at the online point of sale when the requirement became mandatory in August 2023.\nMETHODS: Data for alcohol products sold on the websites of the two largest alcohol retailers in Australia were web-scraped from 1 to 3 August 2023. The captured data for 8343 alcoholic beverages were inspected to determine whether the pregnancy warning was visible.\nRESULTS: Virtually no products (0.1%) had the mandatory warning visible on the main sales page, and only 7% enabled visibility of the warning via optional product image rotation functionality.\nDISCUSSION AND CONCLUSIONS: The almost complete absence of the mandatory pregnancy warnings on the main product pages of major alcohol retailers' websites highlights the regulatory problems posed by the emerging shift to online shopping. The very low prevalence of visible pregnancy warnings is likely to be an overestimate of the extent to which consumers would be exposed to warnings due to images being counted as being present regardless of their quality or readability. New regulation is needed to ensure that mandatory information requirements for harmful products are applied to online shopping contexts.",
                "disciplines": []
            }
        }
    },
    "13243034": {
        "title": "MAssively parallel sparse grid PIC algorithms for low TemperatURe plAsmas simulaTIONs \u2013 MATURATION",
        "abstract": "The simulation under real conditions of partially magnetized low temperature plasmas by Lagrangian approaches, though using powerful Particle-In-Cell (PIC) techniques supplemented with efficient high-performance computing methods, requires considerable computing resources for large plasma densities. This is explained by two main limitations. First, stability conditions that constrain the numerical parameters to resolve the small space and time scales. These numerical parameters are the mesh size of the grid used to compute the electric field and the time step between two consecutive computations. Second, PIC methods rely on a sampling of the distribution function by numerical particles whose motion is time integrated in the self-consistent electric field. The PIC algorithm remains close to physics and offers an incomparable efficiency with regard to Eulerian methods, discretizing the distribution function onto a mesh. It is widely and successfully operated for the discretization of kinetic plasma models for more than 40 years. Nonetheless, to spare the computational resources, the number of numerical particles is limited compared to that of the physical particles. Inherent to this \u201ccoarse\u201d sampling, PIC algorithms produce numerical approximations prone to statistical fluctuations that vanish slowly with the mean number of particles per cell. The mesh accessible on typical high performance computing machines may 10^9 cells, which brings the mesh size close to the scale of the physics, but the mean number of numerical particles in each cell shall be limited, to mitigate the memory footprint as well as the computational time. A breakthrough is therefore necessary to reduce the computational resources by orders of magnitude and make possible the use of explicit PIC method for large scale and/or densities for 3D computations. This is the issue addressed within the MATURATION project aiming at introducing a new class of PIC algorithms with an unprecedented computational efficiency, by analyzing and improving, parallelizing and optimizing as well as benchmarking, in the demanding context of partially magnetized low temperature plasmass through 2D large scale and 3D computations, a method recently proposed in the literature, based on a combination of sparse grid techniques and PIC algorithm.",
        "disciplines": [
            "4601"
        ],
        "publications": {
            "10.1063/5.0153862": {
                "title": "Plasma propulsion modeling with particle-based algorithms",
                "abstract": "This Perspective paper deals with an overview of particle-in-cell/Monte Carlo collision models applied to different plasma-propulsion configurations and scenarios, from electrostatic (E\u00d7B and pulsed arc) devices to electromagnetic (RF inductive, helicon, electron cyclotron resonance) thrusters, as well as plasma plumes and their interaction with the satellite. The most important items related to the modeling of plasma\u2013wall interaction are also presented. Finally, the paper reports new progress in the particle-in-cell computational methodology, in particular, regarding accelerating computational techniques for multi-dimensional simulations and plasma chemistry Monte Carlo modules for molecular and alternative propellants.",
                "disciplines": [
                    "5106"
                ]
            }
        }
    },
    "13056334": {
        "title": "Intelligent chargers for electric tourism vehicles using photovoltaic energy with wireless network management",
        "abstract": "In recent years, increased concern for the environment and the consequent restrictions imposed on greenhouse gas emissions and the search for alternative sources of clean renewable energy, has increasingly motivated the use of battery electric vehicles (BEV) as a viable eco-friendly mobility solution. Electric mobility (e-mobility) has been widely discussed for use in urban areas, but it can also be analyzed for applications in tourism. The e-mobility infrastructure for tourism can be made up of different solutions, however, despite not solving problems related to congestion, BEVs for individual transport can be quite attractive because they are a more sustainable solution, with less environmental impact, with greater access capacity to remote areas and for making it easier to develop an energy charging infrastructure using renewable sources of high capillarity and low cost. One of the main technological challenges related to the transition to e-mobility aimed at tourism is the adaptation of the energy distribution infrastructure to accommodate the increased demand resulting from BEV charging. In this way, intelligent two-way charging stations emerge as a crucial element for their success. For an active contribution to reducing greenhouse gas emissions, the energy supplied by charging stations can mostly come from renewable sources, such as solar photovoltaics. Additionally, charging stations can incorporate energy storage systems (ESS) to increase the flexibility and reliability of their operations. Thus, it becomes possible to use the energy from the BEV and ESS to inject energy into the grid and help meet the local energy demand. In this context, this project aims to study new techniques for managing and controlling the operations of an intelligent charging station for tourism BEV using photovoltaic generation with ESS and wireless network communication with the electrical grid operator to coordinate the operations involved. The proposed topology uses a common DC bus, where the station elements are connected by power converters. PV generation and BEV are connected by DC/DC converters and the AC grid is connected to the DC bus by an AC/DC voltage source converter. (AU)",
        "disciplines": [
            "3508"
        ],
        "publications": {
            "10.1109/imoc57131.2023.10379741": {
                "title": "Uplink Performance of Massive LoRaWAN",
                "abstract": "In this paper, the performance of the uplink of a LoRaWAN for massive large-scale applications is presented considering different operation configurations and taking into account the radiopropagation characteristics of the region under study. The resulting developed model allows obtaining valuable information in the design of massive networks.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1109/imoc57131.2023.10379729": {
                "title": "Analysis of LoRa Energy Autonomy Extension Using a Photovoltaic Power Supply System",
                "abstract": "This work describes a methodology for characterizing the consumption of a Low Power Wide Area (LPWA) device based on LoRa (Long Range) technology and the possibility of integrating a Photovoltaic (PV) power supply system to extend its autonomy. The device consumption profiles for Transmission (TX) and Reception (RX) modes were measured, the I-V curves of the PV module were extracted to determine the Maximum Power Point (MPP), and the device autonomy was estimated for different scenarios. The results demonstrated that the autonomy of the LPWA device, both in TX and RX modes, can be extended using the PV power supply system under study through different battery and PV module use strategies.",
                "disciplines": [
                    "4008",
                    "4009"
                ]
            },
            "10.1109/access.2023.3339563": {
                "title": "Analysis of the Optimized Allocation of Wireless and PLC Data Concentrators in Extensive Low-Voltage Networks Considering the Increase in the Residential Electric Vehicles Charging",
                "abstract": "Several countries have recently encouraged the installation of photovoltaic (PV) systems and the adoption of electric vehicles (EVs) in urban areas to reduce dependence on carbon-based energy resources. While integrating PV systems can offer significant benefits to the network, the growing insertion of EV chargers can have a notable impact on the dynamics of low-voltage (LV) distribution networks. Therefore, to effectively leverage the advantages of PV systems and address the challenges related to the insertion of residential EV chargers, distribution companies have begun installing smart data concentrators (SDCs) at strategic points within the LV distribution network. These devices can collect and exchange information with end-users using different communication technologies, but the increased use of EVs can strongly influence the choice of the most suitable communication technologies and system optimization. In this context, this work analyzes the problem of allocating SDCs based on wireless and power line communication (PLC) technologies in extensive LV distribution networks. This analysis shows how the increasing adoption of residential EV chargers can influence the number and location of SDCs, depending on the communication technologies used. The SDCs allocation is formulated as a mixed-integer linear programming (MILP) problem, considering the penetration scenario of residential EV chargers, SDCs installation costs, and signal propagation characteristics of the communication channel as a function of distance. As a case study, SDCs are allocated in a test LV distribution network comprising 15 nodes and 45 end-users within semi-dense and dense urban environments, considering the insertion of residential EV chargers at 5%, 15%, 30%, and 50% levels. The analysis results demonstrate how the number of SDCs to be implemented can vary due to the influence of residential EV chargers. Overall, a 50% insertion of residential EV chargers requires an increase of over 80% in the number of SDCs compared to the initial requirements, and this increase applies specifically to SDCs with PLC technology. The results presented in this work may draw distribution companies\u2019 attention to the importance of selecting the right communication technology as the use of residential EV chargers increases.",
                "disciplines": [
                    "4008",
                    "4009"
                ]
            },
            "10.1109/ojpel.2023.3339014": {
                "title": "Robust Model Predictive Control of a Renewable Energy Converter Under Parametric Uncertainty Conditions",
                "abstract": "The advanced control technique Model predictive control (MPC) is gaining popularity in power electronics for converters with distributed energy resources. It combines closed-loop control and minimizes errors and control effort. As a model-based control technique, MPC's performance can degrade due to plant disturbances, such as parametric errors or large perturbations in grid voltage or load current. Our research used an MPC with modulation on a converter connected to the grid with an inductive filter for integrating renewable energy sources. The margin of robust stability (RS), derived from the singular Value Decomposition (SVD), provides a theoretical investigation of the robustness of the MPC controller tuning in dependency on the cost function weight factors and the time horizons. In the experiments conducted on a 2 kW workbench, it was confirmed that the proposed controller is stable and robust in nominal and under severe parametric uncertainty conditions, addressing the power quality criteria defined in IEEE Std. 519-2014. The experimental results show that the proposed MPC controller tuning outperforms the classical PI current controller in nominal conditions and is more robust to uncertainty in the passive filter of the grid-connected converter.",
                "disciplines": [
                    "4007",
                    "4008",
                    "4009",
                    "4010"
                ]
            }
        }
    },
    "13492403": {
        "title": "Collaborative Research: CISE-MSI: RCBP-RF: CPS, CNS: Emergency Response and Evacuation Training for Active Shooter Events",
        "abstract": "This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2). In recent years, we have witnessed a sharp increase in active shooter events; however, unfortunately, there has been no introduction of new technology or tactics capable of increasing preparedness and training for active shooter events. This project promotes the progress of science and technology development by building interdisciplinary partnerships and research capacity between Bowie State University (BSU) and University of Nevada, Las Vegas (UNLV) for exploratory investigation of active shooter events at Institutes of Higher Education (IHE). The goal of this project is to conduct data collection, preliminary experiments, and a prototype development for the two campuses for improving emergency preparedness for an active shooter event using collaborative immersive virtual reality (VR) environment. This project develops algorithms, implement software and demonstrate proof-of-concept using building systems as a challenge application area. This research involves devising novel conceptual methods for new theoretical and empirical guidance needed to have an environment for human and machine decision making for highly uncertain, complex, time urgent, and dynamically changing missions. The research objectives of this proposal include: 1) Develop an immersive Collaborative Virtual Environment (CVE) using Oculus for course of action, visualization, and situational awareness for active shooter events, 2) Develop a unique immersive graphical user interface (GUI) for communicating between PCs (Player characters) and NPCs (Non-Player Characters) for user interaction, 3) Implementing algorithms for human behavior for NPCs in active shooter events. (e.g. Hostile, Non-Hostile, Selfish, Leader-Following, Panic), 4) Deep learning-based (data-driven) behavioral modeling for realistic NPCs. The successfully implemented project contributes to the state-of-the-art in emergency response training using VR by developing knowledge that could form the basis of public education and awareness programs to help facility occupants, their rescuers and city officials respond appropriately during extreme emergency situation. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3704"
        ],
        "publications": {
            "10.1109/csci58124.2022.00203": {
                "title": "Mobile AR Application for Navigation and Emergency Response",
                "abstract": "Emergency response, navigation, and evacuation are key essentials for effective rescue and safety management. Situational awareness is a key ingredient when fire responders or emergency response personnel responds to an emergency. They have to quickly assess the layout of a building or a campus upon entry. Moreover, the occupants of a building or campus also need situational awareness for navigation and emergency response. We have developed an integrated situational awareness mobile augmented reality (AR) application for smart campus planning, management, and emergency response. Through the visualization of integrated geographic information systems and real-time data analysis, our mobile application provides insights into operational implications and offers information to support effective decision-making. Using existing building features, the authors demonstrate how the mobile AR application provides contextualized 3D visualizations that promote and support spatial knowledge acquisition and cognitive mapping thereby enhancing situational awareness. A limited user study was conducted to test the effectiveness of the proposed mobile AR application using the mobile phone usability questionnaire (MPUQ) framework. The results show that the mobile AR application was relatively easy to use and that it can be considered a useful application for navigation and evacuation.",
                "disciplines": [
                    "4013",
                    "4608"
                ]
            },
            "10.1016/j.ssci.2022.105967": {
                "title": "Effect of trained evacuation leaders on victims\u2019 safety during an active shooter incident",
                "abstract": "Trained evacuation leaders in emergency offer the potential for improved decision making and evacuation. Compared to victims, trained evacuation leaders can make educated assessments of the situation based on their training, knowledge of the facilities, and additional details about the incident, which enables them to guide victims in choosing a safe departure time and evacuation route. Despite a general understanding about the benefits of such leaders in evacuation, mass shooting cases require a separate attention because these cases are more complex with different behavioral decisions, not just running away, with a continuously changing source of the hazard source, the shooter. This study develops a simulation model package and evaluates the effect of trained evaluation leaders on the victim safety during an active shooter incident. The study leverages sophisticated human motion dynamics models and human behaviors supported by past literature in an agent-based model. The study varies several parameters (e.g., occupancy, firing rates and gun range, and victims\u2019 decision of running or hiding) in this simulation to draw generalized conclusions on the leaders\u2019 impact on various scenarios. The results reveal general findings with several interesting points. Overall, increased leaders\u2019 presence contributes to fewer fatalities. Even few trained leaders, compared with none, can considerably improve victim safety. Even if leaders are not uniformly positioned, they still provide substantial benefits for victim\u2019s safety. The leaders\u2019 benefits were consistently found in various parametric studies (e.g., number of leaders, occupancy, leaders\u2019 strategic placement, gun range, and shooting rate) that support the mentioned findings.",
                "disciplines": [
                    "4005"
                ]
            },
            "10.1007/978-3-031-06015-1_8": {
                "title": "Multi-agent Crowd Simulation in an Active Shooter Environment",
                "abstract": "In recent years there has been a sharp increase in active shooter events, but there has been no introduction of new technology or tactics capable of increasing preparedness and training for active shooter events. This has raised a major concern about the lack of tools that would allow robust predictions of realistic human movements and the lack of understanding about the interaction in designated simulation environments. It is impractical to carry out live experiments where thousands of people are evacuated from buildings designed for every possible emergency condition. There has been progress in understanding human movement, human motion synthesis, crowd dynamics, indoor environments, and their relationships with active shooter events, but challenges remain. This paper presents a virtual reality (VR) experimental setup for conducting virtual evacuation drills in response to extreme events and demonstrates the behavior of agents during an active shooter environment. The behavior of agents is implemented using behavior trees in the Unity gaming engine. The VR experimental setup can simulate human behavior during an active shooter event in a campus setting. A presence questionnaire (PQ) was used in the user study to evaluate the effectiveness and engagement of our active shooter environment. The results show that majority of users agreed that the sense of presence was increased when using the emergency response training environment for a building evacuation environment.",
                "disciplines": [
                    "4608"
                ]
            }
        }
    },
    "13242948": {
        "title": "Multimodal Communication for Supervised Transportation \u2013 COMMUTE",
        "abstract": "In the field of transportation, vehicles (ground or air) are becoming more and more autonomous and communicating. The emergence of these new technologies may relegate pilots to a supervisory role, implying less vigilance and less awareness of the environmental context. This degraded state can hinder the effective recovery of the vehicle and lead to dangerous situations. The objective of the COMMUTE project is to develop a genuine non-verbal, multimodal, intuitive and interactive communication system between the driver and his vehicle. For this purpose, multimodal solutions based on a cognitively situated approach will be developed within the framework of an interactive multimodal synthesis platform. Two use cases, presenting a strong safety issue, will constitute the common thread on which theoretical and experimental developments will be based: emergency warning (short time) and continuous regulation (long time).",
        "disciplines": [
            "3509",
            "3304"
        ],
        "publications": {
            "10.1101/2023.01.19.524726": {
                "title": "Minimal impact of proprioceptive loss on implicit sensorimotor adaptation and perceived movement outcome",
                "abstract": "Implicit sensorimotor adaptation keeps our movements well-calibrated amid changes in the body and environment. We have recently postulated that implicit adaptation is driven by a perceptual error: the difference between the desired and perceived movement outcome. According to this perceptual re-alignment model, implicit adaptation ceases when the perceived movement outcome - a multimodal percept determined by a prior belief conveying the intended action, the motor command, and feedback from proprioception and vision - is aligned with the desired movement outcome. Here, we examined the role of proprioception in implicit motor adaptation and perceived movement outcome by examining individuals who lack proprioception. We used a modified visuomotor rotation task designed to isolate implicit adaptation and probe perceived outcome throughout the experiment. Surprisingly, implicit adaptation and perceived outcome were minimally impacted by deafferentation, posing a challenge to the perceptual re-alignment model of implicit adaptation.",
                "disciplines": [
                    "4207"
                ]
            }
        }
    },
    "12983546": {
        "title": "Collaborative Research: Untangling the Changing Nature of El Ni\u00f1o-Southern Oscillation (ENSO)-Driven Terrestrial Impacts",
        "abstract": "El Ni\u00f1o is primarily identified by a large pool of warmer-than-average water in the tropical Pacific Ocean that persists for several months in a row. El Ni\u00f1o, and its cooler-than-average counterpart La Ni\u00f1a, affects global weather and climate by altering atmospheric circulation patterns. El Ni\u00f1o can be predicted several months in advance, and so can provide an early picture of expected weather and climate patterns over North America and other highly populated regions of the world. It is not yet clear how El Ni\u00f1o will change in a future climate, with some studies suggesting it will get stronger, weaker, more or less frequent, or even that El Ni\u00f1o will become more frequent while La Ni\u00f1a diminishes, and so on. Additionally, there is uncertainty about how the future climate, which is expected to be warmer and wetter, will alter El Ni\u00f1o impacts. This study uses a sophisticated computer model simulation of the global atmosphere and ocean to untangle these interactions and understand how different possible changes in El Ni\u00f1o in turn lead to changes in their impacts. For example, if future El Ni\u00f1o events are stronger than current ones, how do temperature and precipitation patterns over North America change in a future climate? The investigators will systematically test several potential scenarios, uncovering the physical mechanisms that cause the changes in impacts. This study also seeks to understand if El Ni\u00f1o impacts may become more predictable, or less predictable, depending on how El Ni\u00f1o changes in the future. The outcomes of this study will contribute to our understanding of how El Ni\u00f1o affects North American weather and climate patterns and what can be expected under climate change. The broader impacts of this work are centered in four areas. Integration of Research and Education: The proposed work will train two graduate students and results will be integrated into classroom materials. Public Outreach: Public outreach will be facilitated through the National Oceanic and Atmospheric Administration\u2019s climate.gov blog about El Ni\u00f1o. Societal Impacts: Under the current climate, El Ni\u00f1o\u2019s impacts are far-reaching and highly impactful. The proposed work will contribute to improved understanding of the uncertainty in seasonal climate forecasts through a greater understanding of variability contingent on El Ni\u00f1o statistics and climate change. Data use beyond the lifetime of this project: The output generated via the proposed experiments will be useful not only for El Ni\u00f1o applications, but also for understanding how other climate variability is modulated by El Ni\u00f1o and future mean state changes. The investigators will share data with interested groups to support such efforts. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3708",
            "3702",
            "3701"
        ],
        "publications": {
            "10.1007/s00382-023-07058-1": {
                "title": "New insights on ENSO teleconnection asymmetry and ENSO forced atmospheric circulation variability over North America",
                "abstract": "El Ni\u00f1o-Southern Oscillation (ENSO)-related sea surface temperature variability in the eastern equatorial Pacific drives an extratropical large-scale atmospheric response. The atmospheric response is a key driver of global climate variability, with the strongest impact occurring during Northern Hemisphere winter. The degree to which atmospheric circulation variability is altered during ENSO events, in comparison with atmospheric circulation variability during ENSO-neutral conditions, is the focus of this study. Two multi-century, CESM1-CAM4 simulations are compared: a fully coupled experiment (CTRL), and a partially decoupled experiment in which ENSO is dynamically suppressed (NoENSO) so that the mean state is not biased towards a particular ENSO phase. We present evidence that the rectification of ENSO and its teleconnections onto the mean state lead to an underestimation of the asymmetry of ENSO teleconnections in this model. Analyses also show that ENSO displaces 500\u00a0hPa geopotential height (Z500) variability away from the central northern U.S. and southern Canada, resulting in less variability during ENSO years than ENSO-neutral years. Additionally, we find that estimating the ENSO-forced change in Z500 variance compared to ENSO-neutral years requires a surprisingly large sample of ENSO-neutral years. The results imply that a substantially longer record\u2013roughly an order of magnitude longer in length\u2013is needed to fully capture the statistics of ENSO\u2019s teleconnected impacts over North America than suggested in previous studies.",
                "disciplines": [
                    "3708",
                    "3702"
                ]
            }
        }
    },
    "10031969": {
        "title": "RESOLVING THE FISHER-FARMER CONUNDRUM IN PREHISTORIC EUROPE USING BIOMOLECULAR APPROACHES (AquaNeo)",
        "abstract": "For most of the modern human evolution, humans were depending on food resources they hunted, gathered and fished. The transition to the Neolithic saw a major change in subsistence, with the introduction of domesticated plants and animals in human diet. Many coastal populations of early farmers turned their back from the sea and were not consuming marine foodstuffs. Little is known about early farmers from inland locations and their use of aquatic resources from rivers and lakes. Together with milk, aquatic resources are the only foodstuff available to farmers that are a source of vitamin D3, crucial for bone health in most of Europe where exposition to UVB are insufficient. Aquatic foods may thus have played a key nutritional role in farmers' diet, particularly in regions where milk was not greatly exploited. However, fishing and trapping skills are very much part of the hunter-gatherer life-ways. Aquatic resource use in farming communities is thus likely to show that these skills were transmitted from residual hunter-gatherer populations to early farmers (cultural hypothesis). Beyond the mere ease-of-access to productive rivers and streams, the use of aquatic resources by early farmers is hypothesised to have been shaped by nutritional necessity and access to cultural skills. \n\nAquatic skeletal remains are very small and fragile, and traditional methods for the detection of consumption of freshwater resources using human bone collagen is extremely challenging. We are targeting pottery sherds to detect the use of freshwater resources at early (inland) farming sites. Indeed lipids (or fats) trapped in pottery pores provide evidence for what was cooked in ceramic vessels. By characterising lipids using state-of-the-art analytical methods, we will be able to detect well-known compounds (or biomarkers) characteristic of aquatic resource processing. We will develop a novel method using a highly sensitive instrument to detect extremely low amounts of such biomarkers in the lipid assemblage of pottery extracts. We will also use the aquatic biomarkers and the carbon isotope signature of ubiquitous compounds found in animal fats (C16:0 and C18:0 fatty acids) to build a mixing model to quantify the amount of freshwater-derived animal fats in each pottery vessel. \n\nThere is very much uncertainty into whether proteins from foodstuffs would survive on archaeological pottery sherds - if so, they would provide very complementary insights to lipids as they are species-specific (while lipids are not). We will test the stability of foodstuff proteins by cooking diverse foodstuffs (including different types of fish) in replica pottery. We will then sample parts of the vessels and bury them in compost under two different conditions for 18 months to mimic archaeological degradation. We will then analyse the sherds using palaeo-proteomics methods to assess whether foodstuff proteins have survived and how well. \n\nWe have >1,500 archaeological lipid extracts and sherds curated in Bristol that were obtained from our European-funded NeoMilk project. We will select extracts and sherds from various farming sites across mainland Europe to investigate aquatic lipid biomarkers and proteins. That will enable us to assess the level and type of freshwater resource use at those sites. This novel data will be extremely valuable to detect sherds that were not used for cooking freshwater resources - they will be used to demonstrate that lipids preserved within can be 14C-dated and be used to build robust chronologies as they are not affected by an \"old-carbon\" effect. \n\nFinally, we will use models to study the link between the use of freshwater resources by early farmers and ecological (accessibility to water bodies), nutritional (milk use, exploitation of hunted game) and cultural (contact with hunter-gatherer populations) parameters. This project will highlight the importance of freshwater ecosystems to human populations in the past, present and future.",
        "disciplines": [
            "4301",
            "4401"
        ],
        "publications": {
            "10.1002/oa.3284": {
                "title": "A photographic atlas for European freshwater and migratory fish remains and key considerations for their analysis",
                "abstract": "Abstract Identification of archeological fish remains requires the use of comparative reference materials, generally in the form of disarticulated fish skeletons. Photographic or illustrative atlases provide an additional resource for the analysis of fish remains. Photographic resources exist for many marine species and for specific geographic regions, whereas freshwater European species have not been covered in great detail. Here, we present a photographic atlas for the bones of freshwater and migratory fish commonly recovered from archeological sites in Central Europe, alongside a discussion of the difficulties and considerations for the analysis of freshwater fish remains. The atlas also highlights the morphological similarity of many species and the interpretive limits of freshwater fish assemblages. The atlas aims to act as an accessible and user\u2010friendly resource, which can be used for basic identification purposes when access to physical collections is not possible, to supplement pre\u2010existing collections, or for training purposes. This paper acts as a platform from which the full atlas can be downloaded.",
                "disciplines": [
                    "4301"
                ]
            }
        }
    },
    "13037509": {
        "title": "Optimizing residential treatment gains for adolescents through tailored behavioral parent training",
        "abstract": "Project Summary Although adolescents (ages 11 to 17) make treatment gains (e.g., reduced internalizing or externalizing behaviors) in psychiatric residential treatment (RT), they experience significant difficulty adapting to the community and often do not sustain treatment gains long term. After RT, 70% of adolescents discharge to their family of origin. However, parents are not provided with the necessary support or behavior management skillset to bridge the gap between RT and home. A new federal mandate will soon require parent training, an evidence-based behavior management intervention, in the RT setting. Parents with adolescents admitted to RT are a difficult-to-reach population, and technology may increase access and uptake of parent training. Parenting Wisely (PW) is a web-based parent training with demonstrated efficacy in increasing effective parenting practices to reduce adolescent behavior problems. We previously found that PW was highly feasible for parents and the skills were perceived as useful. However, parents reported two unmet needs: (1) skill individualization to apply the PW skills and (2) enhanced community to reduce isolation. In collaboration with an advisory board (a partner in the proposed study), we augmented PW with clinician facilitated discussion groups (referred to as PWRT). The discussion groups in PWRT supports program completion and parent engagement, provides a venue to discuss individualizing PW strategies, reduces isolation, and support parents by engaging in conversation about parenting in the RT context. The proposed study aims to: (1) establish feasibility and acceptability of PWRT, (2) evaluate whether PWRT engages target mechanisms (parental self- efficacy, parenting behaviors, social support, family function), and (3) determine the effects of PWRT on adolescent outcomes (internalizing and externalizing behaviors, placement restrictiveness). Sixty parents (30 per condition) will be randomly assigned to PWRT or treatment-as-usual (TAU). Each week for six weeks, parents will complete two PW modules (20 minutes each) and attend one discussion group via Zoom (90- minutes). PWRT will be initiated towards the end of the RT admission and continue post-discharge to bridge the transition from RT to the community. Adolescents (n=60) will not receive intervention; however, we will evaluate the feasibility of adolescent data collection for future studies. Data from parents and adolescents will be collected at baseline, 6-weeks, and 6-months post-baseline to allow for a robust understanding of the longer-term effects of PWRT on treatment gain maintenance. Consistent with PAR-21-211, our team of researchers and community partners is collecting the requisite data for a larger-scale effectiveness trial by testing the feasibility, acceptability, and preliminary effects of PWRT vs. TAU. PWRT is among the first web- based parent training augmented with supportive elements designed to engage parents with adolescents in RT. By providing parents with tailored education and support in PWRT, parents will be equipped with the behavior management skillset to provide structure in the home and ultimately maintain RT treatment gains.",
        "disciplines": [
            "4409"
        ],
        "publications": {
            "10.1136/bmjopen-2023-080603": {
                "title": "Families in transition (FIT) study protocol: feasibility, acceptability and preliminary effects of a group-based parent training in parents of youth in psychiatric residential treatment",
                "abstract": "Although adolescents make treatment gains in psychiatric residential treatment (RT), they experience significant difficulty adapting to the community and often do not sustain treatment gains long term. Their parents are often not provided with the necessary support or behaviour management skillset to bridge the gap between RT and home. Parent training, a gold standard behaviour management strategy, may be beneficial for parents of these youth and web-based parent training programmes may engage this difficult-to-reach population. This study focuses on a hybrid parent training programme that combines Parenting Wisely (PW), a web-based parent training with facilitated discussion groups (Parenting Wisely for Residential Treatment (PWRT)). This study aims to: (1) establish the feasibility and acceptability of PWRT, (2) evaluate whether PWRT engages target mechanisms (parental self-efficacy, parenting behaviours, social support, family function) and (3) determine the effects of PWRT on adolescent outcomes (internalising and externalising behaviours, placement restrictiveness). In this randomised control trial, parents (n=60) will be randomly assigned to PWRT or treatment as usual. Each week for 6 weeks, parents in the PWRT condition will complete two PW modules (20 min each) and attend one discussion group via Zoom (90 min). Adolescents (n=60) will not receive intervention; however, we will evaluate the feasibility of adolescent data collection for future studies. Data from parents and adolescents will be collected at baseline, post intervention (6 weeks post baseline) and 6 months post baseline to allow for a robust understanding of the longer-term effects of PWRT on treatment gain maintenance. The study has been approved by The Ohio State University Institutional Review Board (protocol number 2022B0315). The outcomes of the study will be shared through presentations at both local and national conferences, publications in peer-reviewed journals and disseminated to the families and organisations that helped to facilitate the project. NCT05764369 (V.1, December 2022).",
                "disciplines": []
            }
        }
    },
    "12928770": {
        "title": "RUI: Biochemical Comparison of Type II Polyketide Biosynthetic Enzymes Across Phyla for Expanded Access to Chemical Diversity",
        "abstract": "With the support of the Chemistry of Life Processes Program in the Division of Chemistry, Dr. Louise Charkoudian and her team from Haverford College will investigate how assemblies of bacterial proteins can be leveraged to synthesize molecules that benefit society. Bacteria have evolved the ability to express protein assemblies that catalyze the manufacture of very complicated molecules. If understood at the molecular level, these protein assemblies hold tremendous potential to provide sustainable access to important chemical commodities. This project will engage undergraduate students in the study of the evolution of these assemblies, in identifying the features that confer function and stability upon these assemblies, and in the engineering of new assemblies that have the potential to catalyze the synthesis of novel molecules. The research will provide information about protein assemblies that have never been studied in the laboratory. Tools to facilitate future discovery and engineering efforts will also be developed. The undergraduate students engaged in this research will gain scientific knowledge and learn research skills. They will also learn how to develop professional networks and about different institutions and career paths in a \u201cSymbiotic Professional Development Seminar Series\u201d. This series will also be open to graduate students from research universities. To spark scientific appreciation and foster engagement of the community in discussions of scientific topics, Dr. Charkoudian will develop a \u201cBioArt Greeting Cards\u201d project in which photographs of student-made pieces of biological art are turned into greeting cards. Type II polyketide synthases (PKSs) are powerful biocatalysts in reactions that produce structurally complex and diverse molecules. Progress towards reconstituting type II PKSs in vitro has been stymied by the lack of a robust heterologous expression system for obtaining key type II PKS components. In this project, bioinformatics will be used to create an updated catalogue of type II PKS biosynthetic gene clusters and to identify those ripe for characterization based on phylogeny of origin, inferred evolutionary history, and other sequence patterns. Non-actinomycete bacterial species will be evaluated as a source of type II PKS enzymes that can be expressed in E. coli as stable, active proteins. Specifically, ketosynthase chain length factors (KSCLFs), acyl carrier proteins (ACPs) and phosphopantetheinyl transferases (PPTases) will be characterized to determine the features that influence their stability and function. The compatibility of type II PKS ACPs with PPTases across different PKSs will be explored. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3303"
        ],
        "publications": {
            "10.1101/2023.08.02.551649": {
                "title": "Strategic engineering unlocks in vitro type II polyketide biosynthesis",
                "abstract": "Abstract  Microbial type II polyketides serve as powerful medicinally relevant agents. These molecules are biosynthesized by polyketide synthases (PKSs) comprised of a core ketosynthase-chain length factor (KS-CLF) and phosphopantetheinylated acyl carrier protein ( holo -ACP). While engineering type II PKSs holds potential to unlock sustainable access to diverse bioactive molecules, the inability to obtain cognate type II KS-CLFs and holo -ACPs for in vitro studies represents a longstanding barrier. Herein, we share how the sequence and structural analysis of the Gloeocapsa sp. PCC 7428 ACP allowed us to tune to a requisite weak yet specific interaction with a phosphopantetheinyl transferase to afford the holo -ACP. This, coupled with our ability to heterologously express the cognate KS-CLF in high quantities, unlocked access to polyketide products via in vitro multienzyme assembly. We hope this work inspires future studies of type II PKSs that have previously evaded heterologous expression or have yet to be explored.   Abstract Figure    ",
                "disciplines": [
                    "3106"
                ]
            },
            "10.1099/mgen.0.000965": {
                "title": "An updated catalogue of diverse type II polyketide synthase biosynthetic gene clusters captured from large-scale nucleotide databases",
                "abstract": "Nature serves as a rich source of molecules with immense chemical diversity. Aptly named, these 'natural products' boast a wide variety of environmental, medicinal and industrial applications. Type II polyketides, in particular, confer substantial medicinal benefits, including antibacterial, antifungal, anticancer and anti-inflammatory properties. These molecules are produced by enzyme assemblies known as type II polyketide synthases (PKSs), which use domains such as the ketosynthase chain-length factor and acyl carrier protein to produce polyketides with varying lengths, cyclization patterns and oxidation states. In this work, we use a novel bioinformatic workflow to identify biosynthetic gene clusters (BGCs) that code for the core type II PKS enzymes. This method does not rely on annotation and thus was able to unearth previously 'hidden' type II PKS BGCs. This work led us to identify over 6000 putative type II PKS BGCs spanning a diverse set of microbial phyla, nearly double those found in most recent studies. Notably, many of these newly identified BGCs were found in non-actinobacteria, which are relatively underexplored as sources of type II polyketides. Results from this work lay an important foundation for future bioprospecting and engineering efforts that will enable sustainable access to diverse and structurally complex molecules with medicinally relevant properties.",
                "disciplines": [
                    "3106"
                ]
            }
        }
    },
    "13057327": {
        "title": "Functoriality in the Mod-p Langlands Program",
        "abstract": "Number theory is the branch of mathematics that deals with properties of whole numbers and whole number solutions to polynomial equations, and stands as one of the oldest mathematical disciplines. Representation theory, another equally influential branch of mathematics, quantifies symmetries of geometric objects (such as a square or a hydrogen atom), and has important uses in physics. Though seemingly unrelated, these two areas are intimately linked by the Langlands Program, a vast set of conjectures that allows for the transfer of results and theorems between number theory and representation theory. It is of paramount importance to understand these conjectures, since tools from one discipline can be imported to tackle previously intractable problems in another (the proof of Fermat's Last Theorem being a prime example). This has pushed the Langlands Program to the forefront of current research. The present project seeks to establish instances of a local version of the Langlands Program with mod p coefficients, so that information from representation theory can be transferred into arithmetic data. The setting of the current project lies within the representation theory of p-adic reductive groups (such as GL_2(Q_p)) on mod p vector spaces. Such representations are exceedingly intricate, and one of the main goals is to use derived categories in order to more precisely relate such representations to modules over differential graded Hecke algebras. This will allow for the use of new tools to understand the relationships between Langlands correspondences for varying groups. In addition to this, the PI and his collaborators plan to use known instances of automorphic base change and the global theory of automorphic forms to develop a mod p Langlands correspondence for p-adic unitary groups. This would enrich the known instances of mod p Langlands correspondences by showing that they are compatible with functorial constructions. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4904",
            "4903"
        ],
        "publications": {
            "10.2140/ant.2022.16.2005": {
                "title": "Serre weight conjectures for p-adic unitary groups of rank 2",
                "abstract": "We prove a version of the weight part of Serre\u2019s conjecture for mod p Galois representations attached to automorphic forms on rank 2 unitary groups which are nonsplit at p. More precisely, let F\u2215F+ denote a CM extension of a totally real field such that every place of F+ above p is unramified and inert in F, and let r\u00af:\u2061Gal(F+\u00af/F+)\u2192CU2(\ud835\udd3d\u00afp) be a Galois parameter valued in the C-group of a rank 2 unitary group attached to F\u2215F+. We assume that r\u00af is semisimple and sufficiently generic at all places above p. Using base change techniques and (a strengthened version of) the Taylor\u2013Wiles\u2013Kisin conditions, we prove that the set of Serre weights in which r\u00af is modular agrees with the set of Serre weights predicted by Gee, Herzig and Savitt.",
                "disciplines": [
                    "4903",
                    "4904"
                ]
            }
        }
    },
    "9852821": {
        "title": "Calming the Superfluid Storm: Taming Turbulence in Superfluid Devices",
        "abstract": "Turbulence, the chaotic flow of fluids, occurs in the vast majority of fluid flows in nature. This project aims to develop a new understanding of turbulence in superfluids, a class of quantum fluids which can flow without friction. The significance is that aspects of turbulence are universal, so that discoveries in superfluid turbulence will provide fundamental insights into all forms of turbulence. The expected outcomes are solutions to two outstanding questions \u2013 what are the universal laws of turbulent flow for superfluids, and what new forms of quantum vortex matter are possible? New insights into turbulence will benefit all applications which rely on its understanding, for example in medicine, aviation, and climate modelling.",
        "disciplines": [
            "4012",
            "5108"
        ],
        "publications": {
            "10.1103/physrevlett.132.103402": {
                "title": "Nonequilibrium Transport in a Superfluid Josephson Junction Chain: Is There Negative Differential Conductivity?",
                "abstract": "We consider the far-from-equilibrium quantum transport dynamics in a 1D Josephson junction chain of multimode Bose-Einstein condensates. We develop a theoretical model to examine the experiment of Labouvie et\u00a0al. [Phys. Rev. Lett. 115, 050601 (2015)PRLTAO0031-900710.1103/PhysRevLett.115.050601], wherein the phenomenon of negative differential conductivity (NDC) was reported in the refilling dynamics of an initially depleted site within the chain. We demonstrate that a unitary c-field description can quantitatively reproduce the experimental results over the full range of tunnel couplings, and requires no fitted parameters. With a view toward atomtronic implementations, we further demonstrate that the filling is strongly dependent on spatial phase variations stemming from quantum fluctuations. Our findings suggest that the interpretation of the device in terms of NDC is invalid outside of the weak coupling regime. Within this restricted regime, the device exhibits a hybrid behavior of NDC and the ac Josephson effect. A simplified circuit model of the device will require an approach tailored to atomtronics that incorporates quantum fluctuations.",
                "disciplines": [
                    "5108",
                    "5102",
                    "5104"
                ]
            },
            "10.21468/scipostphys.15.2.068": {
                "title": "Bistability and nonequilibrium condensation in a driven-dissipative Josephson array: A c-field model",
                "abstract": "SciPost Journals Publication Detail SciPost Phys. 15, 068 (2023) Bistability and nonequilibrium condensation in a driven-dissipative Josephson array: A c-field model",
                "disciplines": [
                    "5108"
                ]
            }
        }
    },
    "13527827": {
        "title": "Research infrastructure for the intersections of law and politics",
        "abstract": "LAWPOL pools together political and legal documents and revolutionizes their research. A group led by University of Turku will develop the research infrastructure for the intersections of law and politics based on LAWRADAR (lakitutka.fi) and FINPARL. LAWPOL includes the entire life cycle of legislation. It comprises of policy documents laying the groundwork for legal reform; documents by the legislator, stakeholders, and experts; parliamentary documents; national and international court cases; research literature; and political agendas and manifestos. New research tools expedite and enhance the research of these documents, promoting unprecedentedly broad research on the interrelations between law and politics. LAWPOL is valuable for multiple disciplines, particularly for research on the law-politics interface. The project also improves the general public's access to information \u2013 a fundamental right and cornerstone of democracy.",
        "disciplines": [
            "4807",
            "4804"
        ],
        "publications": {
            "10.1080/02606755.2023.2213550": {
                "title": "Observing political and societal changes in Finnish parliamentary speech data, 1980\u20132010, with topic modelling",
                "abstract": "Parliamentary speech reflects many events, changes and developments in society, as well as shaping them by influencing legislation and public interest. Knowing what topics have been dominant in parliamentary discussions can reveal what has been considered important at the time the speech was given. This knowledge can be achieved computationally with topic modelling, which can identify latent topics in large numbers of texts. Currently, the method is still underused in parliamentary studies and has only previously been used once with Finnish parliamentary speeches. This article aims to create and validate a topic model offering a robust overview of Finnish parliamentary speeches from 1980 to 2010, and to demonstrate the validity of the model by examining peaks in topic occurrences and comparing them to the historical and societal context at the times. The topics \u2018energy\u2019, \u2018employment\u2019 and \u2018democracy\u2019 were selected for closer inspection.",
                "disciplines": [
                    "4303"
                ]
            }
        }
    },
    "13527290": {
        "title": "Digital technologies, risk management solutions and tools for mitigating forest disturbances (MULTIRISK)",
        "abstract": "Climate change induces multiple risks to forests and forestry. Our overarching goal is to provide advanced digital technologies and risk management solutions and tools for mitigating forest disturbances caused by spruce bark beetles and storms. We will develop: 1) advanced geospatial technologies for detecting and monitoring forest disturbances, and 2) efficient solutions and tools for sustainable risk management at different spatial and temporal scales. We will also demonstrate, co-develop, and communicate efficient digital technologies, risk management solutions and tools with key stakeholders in the society, to enhance their utilization potential in practical forestry. Our ambitious research provides a significant renewal in the science-based risk management under a changing operative environment and valuable support for climate change adaptation and mitigation.",
        "disciplines": [
            "3007"
        ],
        "publications": {
            "10.3390/rs15204928": {
                "title": "Comparison of Deep Neural Networks in the Classification of Bark Beetle-Induced Spruce Damage Using UAS Images \u2020",
                "abstract": "The widespread tree mortality caused by the European spruce bark beetle (Ips typographus L.) is a significant concern for Norway spruce-dominated (Picea abies H. Karst) forests in Europe and there is evidence of increases in the affected areas due to climate warming. Effective forest monitoring methods are urgently needed for providing timely data on tree health status for conducting forest management operations that aim to prepare and mitigate the damage caused by the beetle. Unoccupied aircraft systems (UASs) in combination with machine learning image analysis have emerged as a powerful tool for the fast-response monitoring of forest health. This research aims to assess the effectiveness of deep neural networks (DNNs) in identifying bark beetle infestations at the individual tree level from UAS images. The study compares the efficacy of RGB, multispectral (MS), and hyperspectral (HS) imaging, and evaluates various neural network structures for each image type. The findings reveal that MS and HS images perform better than RGB images. A 2D-3D-CNN model trained on HS images proves to be the best for detecting infested trees, with an F1-score of 0.759, while for dead and healthy trees, the F1-scores are 0.880 and 0.928, respectively. The study also demonstrates that the tested classifier networks outperform the state-of-the-art You Only Look Once (YOLO) classifier module, and that an effective analyzer can be implemented by integrating YOLO and the DNN classifier model. The current research provides a foundation for the further exploration of MS and HS imaging in detecting bark beetle disturbances in time, which can play a crucial role in forest management efforts to combat large-scale outbreaks. The study highlights the potential of remote sensing and machine learning in monitoring forest health and mitigating the impacts of biotic stresses. It also offers valuable insights into the effectiveness of DNNs in detecting bark beetle infestations using UAS-based remote sensing technology.",
                "disciplines": [
                    "3709",
                    "4013",
                    "3701"
                ]
            }
        }
    },
    "13488634": {
        "title": "General Stability Theory of Non-Foster and Time-varying Elements",
        "abstract": "The goal of this three-year research effort is to develop a theoretical framework to predict the stability-bandwidth constraints of both non-Foster networks and time-varying networks. If successful, the proposed project will produce a design tool for stability bandwidth optimized non-Foster/ time-varying metamaterials/metasurface systems. In recent years, there has been a clear trend toward using non-Foster and time-varying active elements in artificial electromagnetic structures to increase their versatility. Non-Foster elements are linear electronic circuits that mimic the 'inverse dispersion' of hypothetical negative capacitors and negative inductors, thus violating the well-known Foster's reactance theorem. Their use can lead to broadband antenna matching structures and metamaterial/metasurface-based systems. Unfortunately, it is well known that ensuring stable operation of non-Foster systems is an extremely difficult task. Despite intensive worldwide research efforts, there is still no reliable stability prediction method that ensures an optimal trade-off between operating bandwidth and stability robustness. On the other hand, time-varying reactive elements behave like parametric mixers/transducers. In addition to the well-known applications in parametric amplifiers, time-varying elements have recently been proposed for introducing non-reciprocity, temporal cloaking, and serrodyne frequency conversion in metamaterials/metasurfaces-based devices, just to name a few. Interestingly, studies of these new applications almost completely ignore the issue of stability, even though it is well known that time-varying networks can be unstable. As in the case of non-Foster systems, there is no general theory of the stability of time-varying systems. In this project, it will be shown that non-Foster networks, generalized non-Foster networks (networks containing negative resistors in addition to negative capacitors and negative inductors), and time-varying networks share the same physical background. Based on this, a unified theoretical framework for stability analysis and prediction of non-Foster networks, generalized non-Foster networks, and time-varying networks as well as their arbitrary combination, will be developed. The theory will be based on a rigorous solution of differential equations describing non-Foster/time-varying systems in either the time domain or the Laplace domain as well as associated equivalent circuits. The goal should be a system of equations (or inequalities) that tells the designer in what range of external impedances stable operation is guaranteed for the prescribed bandwidth. The results obtained by developed theory will be compared with numerical and experimental results of representative non-Foster and time-varying systems from the literature. Finally, it will be attempted to use the developed stability theory for the design of novel stability-robust non-Foster/time-varying unit cell for future active metasurfaces.",
        "disciplines": [
            "4009",
            "4006",
            "5103"
        ],
        "publications": {
            "10.1063/5.0203603": {
                "title": "How does the operating bandwidth of non-foster negative capacitor affect its stability properties?",
                "abstract": "The comparative analysis of the stability properties of three generic types of negative non-Foster capacitors (ideal non-dispersive type, low-pass type, and band-pass type) is presented. It is shown that the range of external RC loads that ensure stable operation for a band-pass negative capacitor significantly exceeds the ranges required for both a low-pass negative capacitor and an ideal dispersionless negative capacitor. Furthermore, the rigorous inequality is derived, which connects the operating bandwidth and a range of permissible external loads, thus enabling a straightforward design of practical stable non-Foster systems. Finally, the RF hardware demonstrator (100 kHz\u2013100\u00a0MHz) of the band-pass negative capacitor was fabricated, and all measurement results were found to be in very good agreement with the theoretical predictions.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1103/physrevapplied.21.054027": {
                "title": "Time-varying systems to improve the efficiency of wireless power transfer",
                "abstract": "Conventional wireless-power-transfer (WPT) systems are linear and time invariant, which sets fundamental limitations on their performance, including a trade-off between transfer efficiency and the level of transferred power. In this paper, we introduce and study a possibility of temporal modulation for inductive wireless-power-transfer systems and uncover that this trade-off is avoided as a consequence of varying the inductive coupling strength in time. Our theoretical analysis reveals that under the optimal modulation depth and phase, the time modulation can yield a substantial improvement in the WPT efficiency, while the received power at the load is also improved compared to the static WPT reference system. We experimentally demonstrate the concept with a low-frequency system and observe a threefold improvement in efficiency over the reference static counterpart. This technical capability reconciles the inherent trade-off between the WPT efficiency and transferred power, paving the way for simultaneous advancements in both efficiency and delivered power.",
                "disciplines": [
                    "4007"
                ]
            },
            "10.1109/icecom58258.2023.10367924": {
                "title": "A non-Foster Solution to Broadband Directive Radiation Pattern in Huygens and Magnetoelectric Antennas",
                "abstract": "Classical Huygens source that contains a short dipole and a small loop is very attractive antenna due to its subwavelength size, low profile and unidirectional radiation pattern with a theoretical directivity of 4.77dBi. However, inherent requirement of a 90\u00b0 phase shift between a dipole and loop excitation currents causes a narrow bandwidth with cardiod directive radiation pattern. In this contribution, it is shown that well-known Chu\u2019s equivalent circuits of a short dipole and a small loop provide clear physical picture of the requirements for the 90\u00b0 phase shift. Moreover, the combination of Chu\u2019s equivalent circuits with non-Foster elements leads to broadband cardiod radiation pattern as well as broadband impedance matching. This approach can also be used for construction of a broadband magnetolectric antenna. Proposed idea is tested by circuit-theory simulations, full-wave simulations, and experiments.",
                "disciplines": [
                    "4006",
                    "4008",
                    "4009"
                ]
            },
            "10.1109/icecom58258.2023.10367934": {
                "title": "How to Accurately Predict Instability in non-Foster and Time-varying Circuits?",
                "abstract": "There is a clear trend towards including active components such as non-Foster elements and time-varying elements in electromagnetic systems, especially those based on metamaterials and metasurfaces. These systems, like all active systems, can become unstable under certain circumstances. In this contribution, the advantages and disadvantages of common linear stability prediction methods are compared: port-based methods, transfer-function-based methods, and feedback-theory-based methods. It is shown that the number of methods that can reliably predict physical behavior is very limited, especially for systems based on time-varying elements. Finally, some new ideas of the development of a generalized method, that could be used for systems based on non-Foster elements as well as for systems based on time-varying elements, are discussed.",
                "disciplines": [
                    "4007"
                ]
            },
            "10.1109/icecom58258.2023.10367938": {
                "title": "Dispersion and Stability Properties of Microwave Tunable Negative Inductance in CMOS Technology",
                "abstract": "This paper reports on the analysis of a tunable negative inductor based on a Negative Impedance Inverter (NII) loaded with positive capacitance. The analysis is based on one-pole model of the amplifiers used in the negative impedance inverter. As such, the model introduces the dispersion of the generated negative input inductance and the parasitic input conductance. In addition, the developed model is loaded with an external RL network that mimics a common practical scenario, and a stability analysis is performed. In the last step, a tunable negative inductor was designed in 40-nm CMOS technology to verify the previous analysis. The designed circuit produces a nearly dispersionless inductance of -350 pH to - 85 pH up to 10 GHz with Q > 10 octave bandwidth. The proposed implementation is well suited for MMIC technology as it avoids the use of on-chip inductors unlike designs based on negative impedance converters.",
                "disciplines": [
                    "4008",
                    "4009"
                ]
            },
            "10.1109/icecom58258.2023.10367923": {
                "title": "Stability Analysis of Active Impedance Inverter based on Loss-compensated Passive Structure",
                "abstract": "An active impedance inverter, comprising negative (non-Foster) capacitors have been used recently in tunable bandpass filter designs. Those filters used a negative capacitor based on the well-known Linvill\u2019s topology, while the design based on a loss-compensated passive structure has been proposed very recently. Here, we compare the stability properties of active impedance inverters based on both kinds of negative capacitor, loaded with commonly used complex loads.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1109/metamaterials58257.2023.10289546": {
                "title": "Stability-bandwidth Constraint in Real-world non-Foster Elements",
                "abstract": "Recent experimental studies have shown that there is an inevitable \u201cinverse proportionality\u201d between the operating bandwidth of realistic non-Foster elements (negative capacitors and negative inductors) and a set of admissible external networks that ensure stable operation. This paper explores the application of this phenomenon to the design of novel non-Foster elements with extremely robust stability properties.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.23919/ursigass57860.2023.10265525": {
                "title": "Non-Foster-inspired Time-varying Matching of a Small Transmitting Dipole",
                "abstract": "Broadband matching of a small transmitting dipole is a long-standing problem in the antenna community. It is well known that classical passive resonant matching is inherently constrained by very narrow bandwidth. On the other hand, there are active approaches such as non-Foster-based matching and the recently intensively studied time-varying-based matching. This contribution gives a brief overview of all these approaches and compares their advantages and disadvantages. In addition, a novel approach is proposed that mimics a stable two-element non-Foster-based broadband matching of a short transmitting dipole, using a time-varying approach.",
                "disciplines": [
                    "4006"
                ]
            },
            "10.1109/elmar59410.2023.10253914": {
                "title": "Use of Non-Foster Elements based on Compensated Passive Structure in Tunable Bandpass Filter",
                "abstract": "Recently, a tunable bandpass filter with active impedance inverter comprising non-Foster negative capacitor based on well-known Linvill's design, has been proposed. Here, we extend this idea by using a non-Foster negative capacitor that comprises compensated passive RL structure. It was found that the new filter had properties similar to the one based on originally proposed approach but with better stability and sensitivity properties.",
                "disciplines": [
                    "4006"
                ]
            }
        }
    },
    "13056462": {
        "title": "Development of green composites in the design concept for sustainability from the recycling of protective PE film reinforced with waste PAEK/FC composites",
        "abstract": "The concern with the environment and in accordance with the new environmental guidelines, made the industrial sectors increase the interest and the need to evaluate the viability of mechanical recycling of carbon fiber reinforced polymeric composite (CRFC) waste from the sector automotive industry, since the manufacture of these composites has a high cost and advanced technologies, so approaches that make this recycling possible, viable and attractive to the market are essential. Therefore, this Scientific Initiation project aims to study the feasibility of mechanical recycling of poly (aryl-ether-ketone) (PAEK)/carbon fiber (FC) composite waste in a matrix composed of polyethylene protective film waste (PE) present in prepregs of structural composites in order to reintroduce these residues with high added value in the industrial production chain. In the first stage of this project, the collection, selection and grinding of the PE protective film waste will be carried out, as well as the PAEK/FC composite waste, followed by granulometric separation. Then, the homogenization of the PAEK/FC composite particles in the recycled PE matrix (PErec) will be carried out using a twin-screw extruder and the molding of the standardized test specimens in a mini-injector. At the end of the project, the quality of the recycled composites obtained will be evaluated through mechanical tests (tensile and Izod impact), morphological characterization of the fracture surface by scanning electron microscopy (SEM), electrical (impedance spectroscopy) and electromagnetic characterization seeking properties and new application niches for this material. Thus, through these studies, it will be possible to aim at sustainable development and environmental protection, through the reuse of thermoplastic waste, with high added value and which could be returned to the production process of the automotive sector.",
        "disciplines": [
            "4016",
            "4001"
        ],
        "publications": {
            "10.1002/pen.26771": {
                "title": "Mechanical recycling process: An alternative for a viable disposal of carbon fiber\u2010reinforced thermoplastic waste",
                "abstract": "Abstract    Concern for the environment has increased the interest of the automotive and aerospace industries in evaluating the feasibility of mechanical recycling of waste carbon\u2010fiber\u2010reinforced polymer composites (CFRP) and waste from protective films used during the transport and storage of thermosetting composites, which are removed and discarded during manufacturing. Therefore, this work aimed to develop a recyclable composite from protective film waste by incorporating carbon fiber/poly(aryl ether ketone) (CF/PAEK) composite particles obtained through grinding in knife mills, followed by an analysis of the particle size distribution. Protective film residues (PE res ) were cut to facilitate processing. A mixture of low\u2010density polyethylene and PE res (50/50) was used as the composite matrix, and 5, 10, 15, and 20 wt% CF/PAEK composite particles were added as the reinforcing agents. Then, these recycled composites were prepared by melt mixing using a twin\u2010screw extruder and injection molding to obtain standardized samples. Mechanical, thermal, electrical, and electromagnetic properties were evaluated. It was possible to observe that the increase in the addition of CF/PAEK composite particles contributed to a 290% increase in elastic modulus values and a 9.1% increase in Shore D hardness, electrical conductivity, and attenuation of the electromagnetic wave. Furthermore, satisfactory adhesion between filler and matrix contributed to a good interface and reinforcement of the final material.    Highlights    Mechanical recycling by extrusion of waste from the automotive and aerospace sectors   Grinding of carbon fiber/poly(aryl ether ketone) composite waste to be used as filler   Protective film waste used as matrix   Composites developed with waste with good electrical and electromagnetic properties   The addition of thermoplastic composite residues does not affect thermal and mechanical properties    ",
                "disciplines": [
                    "4016",
                    "4001"
                ]
            }
        }
    },
    "13664651": {
        "title": "Interaction of multispecies Candida streptococcus biofilm on tooth demineralization and oral candidiasis",
        "abstract": "The polymicrobial nature of biofilms associated with oral diseases is increasingly being recognized. These biofilms, through cell-to-cell interactions, cell-extracellular polymeric substances, spatial organization and biochemical and biophysical components, are able to modify their virulence capacity. It has already been demonstrated that the Candida albicans-Streptococcus mutans interaction is capable of increasing the severity of dental caries lesions. Furthermore, the interaction C. albicans-S. gordonni increases tissue invasiveness in oral candidiasis. However, the simultaneous interaction in the process of demineralization of tooth enamel and in oral candidiasis between multispecies biofilms containing C. albicans, S. mutans and S. gordonni has not yet been evaluated. Microbial strains of C. albicans (SC5314), S. mutans (DL1) and S. gordonii will be used to form a multispecies biofilm on saliva-coated hydroxyapatite disks, dental enamel and in an organ-on-chip model of oral keratinocytes . Time-lapse fluorescence microscopy will be used to evaluate the stages of biofilm formation. Multiphoton laser scanning microscopy will be used to evaluate the three-dimensional architecture of the biofilm as well as to verify microbial components and evaluation of proteins related to epithelial integrity (E-cadherin, N-cadherin, Integrin). Non-destructive confocal contrast method, confocal Raman microscopy and Raman spectrometry will be used to evaluate the demineralization capacity of the multispecies biofilm. The analysis and quantification of water- and alkali-soluble polysaccharides will be performed. pH analysis during multispecies biofilm formation and evaluation of gene expression by qRT-PCR of genes related to C. albicans virulence (ALS1, EAP1, PHR1, TUP, ECE1, CRZ1) will be performed. Parametric and non-parametric variance tests will be used for statistical analysis (\u00b1=0.05). (AU)",
        "disciplines": [
            "3203",
            "3107"
        ],
        "publications": {
            "10.1016/j.canep.2023.102451": {
                "title": "Candida species as potential risk factors for oral squamous cell carcinoma: Systematic review and meta-analysis",
                "abstract": "Oral squamous cell carcinoma (OSCC) is considered a multifactorial disease and has been associated with microbial infections, although the association with Candida spp. is still controversial. This systematic review focused on clinical trials which evaluated the relation between oral Candida spp colonization and OSCC. PubMed; Scopus; Embase; Web of Science and Scientific Direct were assessed. Independent reviewers conducted the diagram steps. For data extraction the PRISMA protocol was followed. The quality analysis of case-control studies was performed based on the Newcastle-Ottawa scale. Meta-analysis was performed to evaluate the frequency of Candida spp and the levels of microbial acetaldehyde production (MAP) being odds ratio (OR) the effect-measure applied. Eight and six studies were included in the qualitative analysis and meta-analysis, respectively. It was noted that there was a significantly higher frequency of Candida species (p\u00a0=\u00a00.0003/OR = 9.50) in patients diagnosed with OSCC than healthy patients, especially Candida krusei (p\u00a0=\u00a00.0167/OR=4.62). Candida spp., from oral cancer patients demonstrated significantly greater biofilm, biofilm metabolic activity, phospholipase, proteinase activity and a higher production of MAP (p\u00a0=\u00a00.0111/OR = 2.67). Candida species may have a potential role in OSCC development. Further studies should be conducted to elucidate the mechanism of action of Candida spp and others risk factors in the development of OSCC.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.3390/biomedicines11051344": {
                "title": "Photodynamic Therapy Can Modulate the Nasopharyngeal Carcinoma Microenvironment Infected with the Epstein\u2013Barr Virus: A Systematic Review and Meta-Analysis",
                "abstract": "Nasopharyngeal carcinoma is a malignancy from epithelial cells predominantly associated with the Epstein-Barr virus (EBV) infection, and it is responsible for 140,000 deaths annually. There is a current need to develop new strategies to increase the efficacy of antineoplastic treatment and reduce side effects. Thus, the present study aimed to perform a systematic review and meta-analysis of the ability of photodynamic therapy (PDT) to modulate the tumor microenvironment and PDT efficacy in nasopharyngeal carcinoma treatment. The reviewers conducted all steps in the systematic review. PubMed, Science Direct, Scopus, Scielo, Lilacs, EMBASE, and the Cochrane library databases were searched. The OHAT was used to assess the risk of bias. Meta-analysis was performed with a random-effects model (\u03b1 = 0.05). Nasopharyngeal carcinoma cells treated with PDT showed that IL-8, IL-1\u03b1, IL-1\u03b2, LC3BI, LC3BII, MMP2, and MMP9 levels were significantly higher than in groups that did not receive PDT. NF-\u0138B, miR BART 1-5p, BART 16, and BART 17-5p levels were significantly lower in the PDT group than in the control group. Apoptosis levels and the viability of nasopharyngeal carcinoma cells (&gt;70%) infected with EBV were effective after PDT. This treatment also increased LMP1 levels (0.28-0.50/<i>p</i> &lt; 0.05) compared to the control group. PDT showed promising results for efficacy in killing nasopharyngeal carcinoma cells infected with EBV and modulating the tumor microenvironment. Further preclinical studies should be performed to validate these results.",
                "disciplines": [
                    "3204"
                ]
            },
            "10.3390/pharmaceutics15010181": {
                "title": "In Vitro Evaluation of Photodynamic Activity of Plant Extracts from Senna Species against Microorganisms of Medical and Dental Interest",
                "abstract": "Background: Bacterial resistance requires new treatments for infections. In this context, antimicrobial photodynamic therapy (aPDT) is an effective and promising option. Objectives: Three plant extracts (Senna splendida, Senna alata, and Senna macranthera) were evaluated as photosensitizers for aPDT. Methods: Cutibacterium acnes (ATCC 6919), Streptococcus mutans (ATCC 35668), Staphylococcus aureus (ATCC 25923), Escherichia coli (ATCC 25922), and Candida albicans (ATCC 90028) were evaluated. Reactive oxygen species production was also verified. Oral keratinocytes assessed cytotoxicity. LC-DAD-MS analysis identified the chemical components of the evaluated extracts. Results: Most species cultured in the planktonic phase showed total microbial reduction (>6 log10 CFU/mL/p < 0.0001) for all extracts. C. albicans cultured in biofilm showed total microbial reduction (7.68 log10 CFU/mL/p < 0.0001) for aPDT mediated by all extracts. Extracts from S. macranthera and S. alata produced the highest number of reactive oxygen species (p < 0.0001). The S. alata extract had the highest cell viability. The LC-DAD-MS analysis of active extracts showed one naphthopyrone and seven anthraquinones as potential candidates for photoactive compounds. Conclusion: This study showed that aPDT mediated by Senna spp. was efficient in microbial suspension and biofilm of microorganisms of medical and dental interest.",
                "disciplines": [
                    "3214"
                ]
            }
        }
    },
    "13057841": {
        "title": "A multidimensional approach to assessing six-year trajectories of outcomes of bereaved children, the effects of the FBP to modify trajectories and mediation of effects 15 years later",
        "abstract": "Abstract Parental death is one of the most stressful events of childhood and is associated with increased risk for multiple mental health problems as well as impairments in developmental competencies in childhood and adulthood. This study uses a secondary data analysis of a 15-year longitudinal study of a randomized trial of the Family Bereavement Program (FBP) to characterize the developmental trajectories of problems and competencies of bereaved children over six years; to study the effects of the FBP to reduce problem trajectories; and to study how changing these trajectories account for FBP effects on mental disorder in young adulthood 15 years later. The study builds on a major advance in research to assess individual differences in trajectories of outcomes over time following potentially traumatic events such as bereavement. Multiple studies using this method have concluded that the great majority of children and adults have low levels of problems over time and can be considered to be resilient. The current study questions this conclusion which is based on the assessment of trajectories of single outcomes (a unidimensional approach) and does not consider that different people may experience problems in different ways following adversity. Recent research with bereaved adults adapted a multidimensional approach to assess trajectories across five outcomes and found that few adults (only 8%) had low levels of problems across outcomes. The current study adapt this multidimensional approach to assess trajectories of grief, mental health problems, competencies and risk and protective factors over a six year period for bereaved children in a secondary analysis of data from the longitudinal study of the FBP. This is the first study to apply a multidimensional approach to assess individual trajectories of four domains of outcomes (grief, mental health problems, developmental competencies and risk and protective factors) of children following any major adversity. The findings have significant implications for understanding which bereaved children who could benefit from evidence-based services. The study will apply the multidimensional approach to assess the effects of the FBP on trajectories of problem and competence outcomes as well as targeted risk and protective factors over six years. It will also assess the effects of the FBP to improve the aggregate number of problem trajectories across outcomes. Individuals for whom the FBP reduces one or more problem trajectories can be considered responders to the program. The study will also assess how changing trajectories in problems, competencies or risk and protective factors across six years in childhood and adolescence mediate FBP effects to reduce mental disorder, suicidal ideation/behavior or mental health service use nine years later when participants are young adults. Findings from these analyses have action implications to optimize effective dissemination of components of the FBP that target mediators that are successfully changed by the program and that mediate FBP effects on adult mental health problems.",
        "disciplines": [
            "4403"
        ],
        "publications": {
            "10.1037/fam0001189": {
                "title": "Developmental Pathways of the Family Bereavement Program to Promote Growth 15 Years After Parental Death",
                "abstract": "Although parental death increases the risks of negative developmental outcomes, some individuals report personal growth, an outcome that has received little attention. We tested a developmental cascade model of postloss growth in 244 parentally bereaved youth (ages 8-16 at baseline) from 156 families who participated in a randomized controlled trial of a family-based intervention, the Family Bereavement Program (FBP). Using five waves of data, the present study examined the prospective associations between the quality of parenting immediately following the FBP and postloss growth 6 and 15 years later, and whether these associations were mediated by changes in intra- and interpersonal factors (mediators) during the initial 11 months following the FBP. The mediators were selected based on the theoretical and empirical literature on postloss growth in youth. Results showed that improved quality of parenting immediately following the FBP was associated with increased support-seeking behaviors and higher perceived parental warmth at the 11-month follow-up, both of which were related to postloss growth at the 6-year follow-up and 15-year follow-up. No support was found for the other hypothesized mediators that were tested: internalizing problems, intrusive grief thoughts, and coping efficacy. To promote postloss growth for parentally bereaved youth, bereavement services should target parent-child relationships that help youth feel a sense of parental warmth and acceptance and encourage youth to seek parental support. (PsycInfo Database Record (c) 2024 APA, all rights reserved).",
                "disciplines": [
                    "5203",
                    "5205",
                    "5201"
                ]
            }
        }
    },
    "13559321": {
        "title": "Geographical Indications as Global Knowledge Commons. Reassessing current models of regulation and collective action towards more sustainable social-ecological systems \u2013 GIngKo",
        "abstract": "The aim of the research project GIngKo is to analyze, using the boundary concept of \u201cknowledge commons\u201d as developed by Hess and Ostrom (2007), the potential role of Geographical Indications (GIs) as a lever for action in fostering agro ecological transitions, identify existing limitations and obstacles at different territorial and landscape scales, and assess current strategies (de/re/re-de-re)-territorializing, as well as the logic of specialization/diversification towards more sustainable agri-food systems. Adopting a comparative and inter/transdisciplinary approach, the analysis will especially emphasize: i) the nature and diversity of strategies of agro-ecological transitions adopted by GI\u2019s systems in France, as well as their implications in terms of knowledge codification, collective learning and R&D strategies, ii) the changes in regulatory mechanisms and models of collective action observed in France since a decade ; iii) mirror these evolutions with current trends in other European countries and in other continents worldwide.",
        "disciplines": [
            "4410",
            "4406"
        ],
        "publications": {
            "10.3390/su15129371": {
                "title": "How Can Collective Action Support the Agroecological Transition in Geographical Indication Vineyards? Insights from the Loire Valley Wine Area",
                "abstract": "Few studies have examined the agroecological transition in viticulture, which involves transformation processes, especially at the territorial scale where collective action plays a key role in the dissemination of transition strategies. Collective action in the agroecological transition must be studied in order to encourage and accelerate changes in practices. In this study, collective action is analyzed to understand how governance structures influence the development of collective agroecological transition strategies. Elinor Ostrom\u2019s Institutional Analysis and Development and Social\u2013Ecological Systems analysis frameworks were applied to the Anjou-Saumur wine area in the Loire Valley, where nearly 80% of wine production is under protected designations of origin. Data were collected through seven semi-structured interviews, which were analyzed qualitatively in order to identify the main actors and collective strategies in the agroecological transition. The study showed that the polycentric structure of governance in the protected designations of the origin system enables institutional actors to collectively coordinate their actions. Moreover, collective action is structured in three focal action situations that overlap at the institutional level due to two key actors in the agroecological transition, but also due to tacit rules of the organizational structure for some actors. Action situations dynamically interact with each other across time and geographical scales, helping the agroecological transition process forward by combining top-down and bottom-up strategies. This study provides a novel way of applying the IAD/SES framework as well as a new look at collective action for the agroecological transition at the institutional scale in French viticultural systems under protected designations of origin. This paves the way for interdisciplinary research for the agroecological transition, and might help to select the best strategies to encourage changes of viticultural practices.",
                "disciplines": [
                    "4410"
                ]
            }
        }
    },
    "13285650": {
        "title": "Leap in Swedish freshwater monitoring for water supply risk mitigation",
        "abstract": "Episodes of water shortage during the dry summers of 2018 and 2019 show that climate-related risks to water supply are increasing in southern Sweden. Risk assessment and high-resolution water resources monitoring are needed to quantify current and future water supply risks and aid water supply management. There is, however, a current lack of detailed monitoring of ground- and surface-water resources (GW and SW). Thus, our proposed project aims to: i) conduct a comprehensive analysis of current and future climate-related risks on water supply, ii) develop state-of-the-art techniques for detailed monitoring of SW and GW, and iii) design a decision support system for artificial GW recharge, to inform current and future water supply management in southern Sweden. Risk analysis will reveal areas that display the combination of high climate-risk impacts and vulnerable water supply resources. A geodetic technology called Interferometric synthetic aperture radar (InSAR) and artificial intelligence (AI) will be combined to develop a high-resolution SW and GW monitoring system for unmonitored small lakes and aquifers. The system will use AI algorithms to determine suitable locations for artificial recharge, taking depleting aquifers and excess SW into account. A decision support system will then be designed by integrating water supply risk-related analysis, GW, SW time-series, and suitable locations for aquifer recharge.",
        "disciplines": [
            "3707"
        ],
        "publications": {
            "10.1038/s44221-024-00208-7": {
                "title": "Notable shifts beyond pre-industrial streamflow and soil moisture conditions transgress the planetary boundary for freshwater change",
                "abstract": "Human actions compromise the many life-supporting functions provided by the freshwater cycle. Yet, scientific understanding of anthropogenic freshwater change and its long-term evolution is limited. Here, using a multi-model ensemble of global hydrological models, we estimate how, over a 145-year industrial period (1861\u20132005), streamflow and soil moisture have deviated from pre-industrial baseline conditions (defined by 5th\u201395th percentiles, at 0.5\u00b0 grid level and monthly timestep over 1661\u20131860). Comparing the two periods, we find an increased frequency of local deviations on ~45% of land area, mainly in regions under heavy direct or indirect human pressures. To estimate humanity\u2019s aggregate impact on these two important elements of the freshwater cycle, we present the evolution of deviation occurrence at regional to global scales. Annually, local streamflow and soil moisture deviations now occur on 18.2% and 15.8% of global land area, respectively, which is 8.0 and 4.7 percentage points beyond the ~3 percentage point wide pre-industrial variability envelope. Our results signify a substantial shift from pre-industrial streamflow and soil moisture reference conditions to persistently increasing change. This indicates a transgression of the new planetary boundary for freshwater change, which is defined and quantified using our approach, calling for urgent actions to reduce human disturbance of the freshwater cycle.",
                "disciplines": [
                    "3707"
                ]
            }
        }
    },
    "10007966": {
        "title": "Diet, gut microbiota and the evolution of lifespan and reproduction",
        "abstract": "Nutrition has pronounced effects on lifespan and reproduction across animal species, yet how these effects are mediated is poorly understood. This project aims to determine if the gut microbiota regulates these nutritional effects. This project expects to deliver key insights on the complex interplay between nutrition and the gut microbiota, as well as the potential to manipulate this relationship to extend lifespan and alter reproduction. The expected outcomes of this project include generating new knowledge, building multidisciplinary collaborations and the development of novel experimental approaches. This should provide significant benefits, fore-most in bolstering Australia\u2019s high international standing in evolutionary research.",
        "disciplines": [
            "3107"
        ],
        "publications": {
            "10.1093/evolut/qpae036": {
                "title": "Male song structure predicts offspring recruitment to the breeding population in a migratory bird",
                "abstract": "Bird song is a classic example of a sexually selected trait, but much of the work relating individual song components to fitness has not accounted for song typically being composed of multiple, often-correlated components, necessitating a multivariate approach. We explored the role of sexual selection in shaping the complex male song of house wrens (Troglodytes aedon) by simultaneously relating its multiple components to fitness using multivariate selection analysis, which is widely used in insect and anuran studies but not in birds. The analysis revealed significant variation in the form and strength of selection acting on song across different selection episodes, from nest-site defense to recruitment of offspring to the breeding population. Males that sang more song typically employed in close communication sired more offspring that were subsequently recruited to the breeding population than those that sang more far-communication song. However, this relationship was not consistent across earlier selection episodes, as evidenced by non-linear selection acting on these song components in other contexts. Collectively, our results present a complex picture of multivariate selection on male song structure that would not be evident using univariate approaches and suggest possible trade-offs within and among song components at different points of the breeding season.",
                "disciplines": [
                    "3109",
                    "3103"
                ]
            },
            "10.1093/evolut/qpae024": {
                "title": "The evolution of life span and aging in response to dietary macronutrients in male and female decorated crickets",
                "abstract": "Dietary macronutrients regulate life span and aging, yet little is known about their evolutionary effects. Here, we examine the evolutionary response of these traits in decorated crickets (Gryllodes sigillatus) maintained on diets varying in caloric content and protein-to-carbohydrate ratio. After 37 generations, each population was split: half remained on the evolution diet, and half switched to a standardized diet. Crickets lived longer and aged slower when evolving on high-calorie (both sexes) and carbohydrate-biased (females only) diets and had lower baseline mortality on high-calorie (females only) diets. However, on the standardized diet, crickets lived longer when evolving on high-calorie diets (both sexes), aged slower on high-calorie (females only) and carbohydrate-biased (both sexes) diets, and had lower baseline mortality on high-calorie (males only) and protein-biased (both sexes) diets. Life span was longer, and baseline mortality was lower when provided with the evolution vs. the standardized diet, but the aging rate was comparable. Moreover, life span was longer, aging slower (females only), and baseline mortality was lower (males only) compared to our evolved baseline, suggesting varying degrees of dietary adaptation. Collectively, we show dietary components influence the evolution of life span and aging in different ways and highlight the value of combining experimental evolution with nutritional geometry.",
                "disciplines": [
                    "3103"
                ]
            }
        }
    },
    "13258168": {
        "title": "Old Goa Revelations - new insights on the Viceroys portrait gallery",
        "abstract": "The collection of portraits of the Viceroys of the State of India (1547-1958) is unique in the world for its time scale and size. This remarkable collection of portraits consists of 120 paintings, executed during the period of Portuguese administration, 88 of which in wooden panel and 32 in canvas. With the exception of 3 paintings that are in the National Museum of Ancient Art (MNAA) in Lisbon, the rest are in the Archaeological Museum of Old Goa, under the supervision of the Archaeogical Survey of India (of the Ministry of Culture of the Government of India).\nThe Old Goa Revelations project aims to contribute to the knowledge and appreciation of this unique collection through complementary examination and analysis techniques and multidisciplinary approaches in a collaborative effort of international and inter-institutional teams.\nThe OGR project team was the first team ever to carry out the scientific study of these portraits, and also the first Portuguese team to collaborate with the Archaeological Survey of India (ASI) in 2019, in the study of eight portraits from the Goa collection with support from the Calouste Gulbenkian Foundation. The teams from the two countries worked together to carry out the exams in Goa with non-invasive techniques and to interpret the data obtained from the 8 works analysed. As a result of this first study, several overlapping layers of repaints made from the end of the 16th century to the end of the 19th century were identified with technical and plastic quality inferior to the originals and which condition the correct reading and interpretation of this collection. The success of this initial exploration was the discovery that the original layers are still preserved under more modern repaints corresponding to coeval reproductions of the collection. These primitive compositions display military attire, iconographic elements (such as the coat of arms and military insignia), as well as inscriptions relating to the government of each personality, constituting unique documentary sources about these personalities, as well as to iconography and overseas history. The 8 original portraits from the 16th and 17th centuries, which were not visible to the naked eye, finally, and after over 300 years, could be revealed, through the proposed analytical methodology. This first experience allowed to conclude about the potential of replicating the same method to the remaining cases with integral repaints.\nWhile not considering the removal of layers of modern repaints, and in line with the guidelines of the Indian State, the proposed methodology involves revealing the underlying original layers, integrating the research results in a new museological discourse, in order to return to the cultural community affected to this heritage, the tangible and intangible values of the portraits that were originally made for the Viceroys' Gallery.\nConsistent with previous experience, we propose the continuation of this transdisciplinary and multianalytical approach, in partnership with the ASI scientific team, in the study of 25 selected paintings (from different periods), which allow the collection of additional data about the various layers of intervention and that allow answering specific questions about the historical fortune, formal and material characterization of these works, essential for their understanding.\nAdditionally, it is intended to deepen the knowledge about the materials and techniques of artistic production, overseas iconography and about the various possible conservation and restoration actions, supported by the technical and material characterization of the works. To achieve this objective, we propose the use of different imaging exams, in situ micro and mapping analysis (non-invasive) and their correlation with historical and documentary sources (written in Portuguese).\n\u00a0Assuming a context of common heritage and universal value, we introduce, through this project, an innovative contribution in the fields of interpretation and safeguard, first, by revealing the original portraits, which are not visible to the naked eye, integrating digital and multimedia technologies in the expository discourse and, second, by the adoption of strategies that avoid irreversible and risky restoration operations.\nThese actions will enable new cultural dynamics in that museum and in the Goan community, who are also caretakers of this art gallery.\nFinally, this project constitutes a unique opportunity to strengthen bilateral relations between India and Portugal, favored by the diplomatic efforts of both governments, emphasizing here the role of the Portuguese ambassador to India Carlos Marques and the Indian Minister of State for Foreign Affairs and Culture Meenakshi Lekhi who appointed the Director General of ASI V. Vidyavathi and the person in charge of Conservation and Heritage Janhwij Sharma to directly monitor the OGR project, thus marking a new page in the field of cultural and heritage cooperation.",
        "disciplines": [
            "4302",
            "3601"
        ],
        "publications": {
            "10.3390/micro4010008": {
                "title": "The Decorated Garden Grotto of Condes de Basto Palace in \u00c9vora, Portugal: Microbial Community Characterization and Biocide Tests for Conservation",
                "abstract": "The Eug\u00e9nio de Almeida Foundation\u2019s Casa de Fresco is a historical monument of valuable historic\u2013artistic significance, which currently reveals an assortment of biofilms due to the proliferation of microorganisms in the stone and rocaille elements. The biodeterioration in this area was studied as part of the Conservation and Restoration Project. We effectively characterized the local microbial community using modern high-throughput DNA analysis. Our results suggested the existence of a variety of lichens or lichenized fungi, including genera such as Variospora, Verrucaria, Circinaria, and Caloplaca. Furthermore, we detected several prokaryote microorganisms related to the identification of these lichens. To properly deal with this microbiological issue and avoid fungal recolonization, we evaluated available commercial antimicrobial treatments.",
                "disciplines": [
                    "3107",
                    "4302"
                ]
            },
            "10.3390/molecules28196822": {
                "title": "Rational Design of Cost-Effective 4-Styrylcoumarin Fluorescent Derivatives for Biomolecule Labeling",
                "abstract": "Fluorescent labels are key tools in a wide range of modern scientific applications, such as fluorescence microscopy, flow cytometry, histochemistry, direct and indirect immunochemistry, and fluorescence in situ hybridization (FISH). Small fluorescent labels have important practical advantages as they allow maximizing the fluorescence signal by binding multiple fluorophores to a single biomolecule. At present, the most widely used fluorescent labels available present small Stokes shifts and are too costly to be used in routine applications. In this work we present four new coumarin derivatives, as promising and inexpensive fluorescent labels for biomolecules, obtained through a cost-effective, efficient, and straightforward synthetic strategy. Density functional theory and time-dependent density functional theory calculations of the electronic ground and lowest-lying singlet excited states were carried out in order to gain insights into the observed photophysical properties.",
                "disciplines": [
                    "3406"
                ]
            }
        }
    },
    "10007563": {
        "title": "Planetary Health Histories: Developing Concepts",
        "abstract": "This historical research project aims to explain the conceptual development of the new planetary health, the principal means of assessing impacts of climate change and global environmental degradation on human health. Using a novel combination of history of science and medicine, environmental history, international history and Indigenous studies, this research is expected to show how environmental health and disease ecology have been re-framed and scaled up in the past century to address the effects of global warming. The project will examine critically this intellectual formation, exploring its potential in global health and revealing its blind spots and omissions, especially in relation to Indigenous knowledge and structural inequalities.",
        "disciplines": [
            "5002"
        ],
        "publications": {
            "10.1007/s11673-023-10285-0": {
                "title": "Toward Planetary Health Ethics? Refiguring Bios in Bioethics",
                "abstract": "In responding to perceived crises\u2014such as the COVID-19 pandemic\u2014in routinized ways, contemporary bioethics can make us prisoners of the proximate. Rather, we need bioethics to recognize and engage with complex configurations of global ecosystem degradation and collapse, thereby showing us paths toward co-inhabiting the planet securely and sustainably. Such a planetary health ethics might draw rewardingly on Indigenous knowledge practices or Indigenous philosophical ecologies. It will require ethicists, with other health professionals, to step up and become public advocates for environmental sustainability. The COVID-19 pandemic should be seen as opening a portal to planetary health ethics or ecologized bioethics.",
                "disciplines": [
                    "5001"
                ]
            }
        }
    },
    "13057584": {
        "title": "Integrated microfluidic electrochemical neural probe with monolithic sampling, in-situ calibration, and online detection of neurochemicals for increased long-term performance",
        "abstract": "Project Summary Detection of neurochemical transients within the brain have led to better understanding of how underlying neural circuits function and correlate to behavior, and have contributed to the development of several therapeutic drugs and treatments targeted to a multitude of neurological disorders, neurodegenerative diseases, consequences of stroke, and injury. Fast-scan cyclic voltammetry (FSCV) is one of the most common methods of neurochemical sensing, as it provides 1.) sub- second temporal resolution to capture chemical transmission, diffusion, and uptake events, 2.) physiologically relevant chemical resolution at ~10-100 nM limits of detection, and 3.) sub-micrometer spatial resolution to target specific brain regions of interest by sweeping working electrode voltage and measuring the resultant faradaic current from oxidizing and reducing analytes at their specific redox potentials. However, FSCV selectivity is limited for molecules with similar redox potentials, such as dopamine and ascorbic acid. FSCV also suffers in long-term performance, as implanted electrodes foul due to adsorption of cells, degradatory enzymes, and redox intermediates. This limits FSCV to practical experimental time windows of approximately 90 seconds and functional implant use to just a couple of months. Furthermore, the fast scan rates used in FSCV result in background capacitive currents that are several orders of magnitude higher than the desired signals. This necessitates background subtraction, which results in an inability to detect basal concentrations, limiting traditional FSCV to transient measurements in-vivo. Calibration also cannot be performed in-situ and is traditionally done in a beaker before implantation and after removal of the probe, leading to questionable measurement accuracy requiring confirmation by other methods such as mass spectrometry. The innovation of this proposal is to develop a miniaturized neurochemical sampling probe with integrated electrodes within its microfluidic channels for sensitive, on-line detection while improving long-term sensor performance by leveraging mature silicon microfabrication techniques. The envisioned device can 1.) sense neurochemicals on-line with considerably reduced electrode fouling and drift by physically separating the sampling site and harsh inflammatory response from the detection electrode site, and introducing flow to combat analyte adsorption and increase sensitivity; and 2.) demonstrate in-situ calibration and regeneration of the electrodes through sophisticated microfluidic design, combatting eventual fouling and drift. Aim 1 focuses on electrochemical flow-cell optimization of sensitivity and selectivity with in-vivo validation. Aim 2 focuses on valve-less flow redirection for electrode calibration and regeneration in-situ with demonstration of long-term in-vivo sensing. Successful completion of this project results in an electrochemical neural probe capable of enhanced long-term and sensitive neurochemical detection, validated with in-vivo studies. Slower and more gradual changes in neurochemical composition, such as those mediated by neurohormones, basal concentration measurements, and use in longer-term behavioral studies and applications (such as brain-machine interfaces) are poised to benefit from the success of this proposal.",
        "disciplines": [
            "3401"
        ],
        "publications": {
            "10.1021/acsnano.3c09776": {
                "title": "Highly Localized Chemical Sampling at Subsecond Temporal Resolution Enabled with a Silicon Nanodialysis Platform at Nanoliter per Minute Flows",
                "abstract": "Microdialysis (MD) is a versatile and powerful technique for chemical profiling of biological tissues and is widely used for quantification of neurotransmitters, neuropeptides, metabolites, biomarkers, and drugs in the central nervous system as well as in dermatology, ophthalmology, and pain research. However, MD performance is severely limited by fundamental tradeoffs between chemical sensitivity, spatial resolution, and temporal response. Here, by using wafer-scale silicon microfabrication, we develop and demonstrate a nanodialysis (ND) sampling probe that enables highly localized chemical sampling with 100 \u03bcm spatial resolution and subsecond temporal resolution at high recovery rates. These performance metrics, which are 100-1000\u00d7 superior to existing MD approaches, are enabled by a 100\u00d7 reduction of the microfluidic channel cross-section, a corresponding drastic 100\u00d7 reduction of flow rates to exceedingly slow few nL/min flows, and integration of a nanometer-thin nanoporous membrane with high transport flux into the probe sampling area. Miniaturized ND probes may allow for the minimally invasive and highly localized sampling and chemical profiling in live biological tissues with high spatiotemporal resolution for clinical, biomedical, and pharmaceutical applications.",
                "disciplines": [
                    "3401"
                ]
            },
            "10.1101/2023.09.08.556607": {
                "title": "Highly localized chemical sampling at sub-second temporal resolution enabled with a silicon nanodialysis platform at exceedingly slow flows",
                "abstract": "Microdialysis (MD) is a versatile and powerful technique for chemical profiling of biological tissues and is widely used for quantification of neurotransmitters, neuropeptides, metabolites, biomarkers, and drugs in the central nervous system as well as in dermatology, ophthalmology, and in pain research. However, MD performance is severely limited by fundamental tradeoffs between chemical sensitivity, spatial resolution, and temporal response. Here, by using wafer-scale silicon microfabrication, we develop and demonstrate a nanodialysis (ND) sampling probe that enables highly localized chemical sampling with 100\u03bcm spatial resolution and sub-second temporal resolution at high recovery rates. These performance metrics, which are 100X-1000X superior to existing MD approaches, are enabled by a 100X reduction of the microfluidic channel cross-section, a corresponding drastic 100X reduction of flow rates to exceedingly slow few nL/min flows, and integration of a nanometer-thin nanoporous membrane with high transport flux into the probe sampling area. Miniaturized ND probes may allow for the minimally invasive and highly localized sampling and chemical profiling in live biological tissues with unprecedented spatio-temporal resolution for clinical, biomedical, and pharmaceutical applications.",
                "disciplines": [
                    "3401"
                ]
            },
            "10.1016/j.snb.2023.133733": {
                "title": "Enhancement of faradaic current in an electrochemical cell integrated into silicon microfluidic channels",
                "abstract": "Implantable electrochemical sensors enable fast and sensitive detection of analytes in biological tissue, but are hampered by bio-foulant attack and are unable to be recalibrated in-situ. Herein, an electrochemical sensor integrated into ultra-low flow (nL/min) silicon microfluidic channels for protection from foulants and in-situ calibration is demonstrated. The small footprint (5 \u03bcm radius channel cross-section) of the device allows its integration into implantable sampling probes for monitoring chemical concentrations in biological tissues. The device is designed for fast scan cyclic voltammetry (FSCV) in the thin-layer regime when analyte depletion at the electrode is efficiently compensated by microfluidic flow. A 3X enhancement of faradaic peak currents is observed due to the increased flux of analytes towards the electrodes. Numerical analysis of in-channel analyte concentration confirmed near complete electrolysis in the thin-layer regime below 10 nL/min. The manufacturing approach is highly scalable and reproducible as it utilizes standard silicon microfabrication technologies.",
                "disciplines": [
                    "4012",
                    "3401"
                ]
            }
        }
    },
    "13580107": {
        "title": "An e-SmartPort Platform to support Smart Information Infrastructure for Port Development",
        "abstract": "Since Ever-Given and Covid-19 raised the world aware of global supply chain disruption risk, HK has come to rethink our port\u2019s direction. In the CE\u2019s 2021 Policy Address, HK is set to develop a smart port with wider use of digital technology and good in multimodal logistics. Under the policy, the Transport and Housing Bureau made an MOU with LSCM, supporting LSCM to explore digitization with the port stakeholders through an e-SmartPort Platform.\n\nAs such, LSCM proposes this project to conduct R&D on the topic of e-SmartPort Platform prototype with the port community. LSCM will engage the port community to understand their gap in digitization. Dealing with that, we shall research for blockchain-based data repository with apps developed for port users as well as API for their systems, to facilitate their digitization and data sharing on blockchain. In that, port data schemas will be produced to facilitate sharing and integration with existing 3rd party services platforms. For port process automation, we shall study smart contract on the port blockchain to innovate technologies in methods for automated workflow and interconnection among port users. To support smart port analytics, we shall study the ships\u2019 AIS data to calculate their complex movements, berthing and mooring patterns, and to generate analytics for the efficiency, congestion and trajectory statistics, which enables inter-port connectivity and route re-scheduling analysis. Being smart, ports should spearhead into cybersecurity and ESG issues as well. We propose research to produce a cybersecurity strategy for HK\u2019s smart port development, and the smart contract technology for port users to watch their ESG compliance.\n\nWe shall also conduct 3 pilot trial cases with the port community to illustrate the implementation in different scenarios of cross-boundary trade, cargo transport visibility, and port traffic analytics. With these elements, the project\u2019s goal is to produce an e-SmartPort Platform prototype which helps the port industry to jumpstart HK to a smart port.",
        "disciplines": [
            "3509",
            "4609"
        ],
        "publications": {
            "10.1016/j.ocecoaman.2023.106961": {
                "title": "Aerial visual data-driven approach for berthing capacity estimation in restricted waters",
                "abstract": "Coastal ship berth planning and management necessitate accurate identification of ship position and size, yet this is complicated by the presence of diverse ship types and mixed distribution patterns. Traditional survey-based and position-tracking ship monitoring methods have limitations in reflecting the precise spatial information of coastal ships and their surroundings. This paper introduces a novel aerial visual data-driven methodology to estimate the berthing capacity of sheltered space for stationary ships in geographically dispersed water areas. To measure the berthing capacity, image data from an unmanned aerial vehicle (UAV) survey is collected to reflect the spatial information of all types of ships. A deep learning-based computer vision algorithm is used to automatically detect, identify, and classify ships in sample images. Additionally, we introduce the occupancy factor to empirically quantify the spatial proportional correlation between the ship size and the requisite berthing capacity. A validation test of the proposed method is conducted across all sheltered spaces in Hong Kong, and the UAV survey yields over 7,000 informative images of all types of local ships. The ship identification algorithm achieves an average identification rate of 98.6%, demonstrating higher accuracy and reduced labor and time consumption than observational survey and manual counting methods. Findings indicate that the suggested sheltered space for individual ships is 7.75 times the ship size. The approach provides greater flexibility in estimating berthing capacity for mixed berthing forms in extensive or geographically dispersed water bodies, thereby having the potential to support the design of berths, anchorage areas, and typhoon shelter facilities in coastal regions.",
                "disciplines": []
            },
            "10.1016/j.tre.2023.103169": {
                "title": "Towards sustainable port management: Data-driven global container ports turnover rate assessment",
                "abstract": "Accurate assessment of port turnover rate is essential for port operators and shipping carriers to benchmark and improve their operations. This study proposes a standardized method to estimate the port turnover rate based on satellite data of ocean ships. This method can be generalized to accommodate ports of different geographic and operational characteristics with minimum input and running times. To achieve the research objective, we first construct berth polygon areas for terminals based on Greatmaps (GMap) visual technique. Then, two tailor-made algorithms are proposed to estimate the berthing time of ship in a berthing event. Finally, we assess the port turnover rate with aggregate berthing time at a port and its historical port throughput. Assuming that the turnover rate is unchanged in the short term, we can use the estimated turnover to estimate the monthly throughput of global ports. The findings suggest the average Mean Absolute Percentage Error (MAPE) of our estimation is 3.84%. Standardized and high-frequency port statistics are highly valued by the industry but very costly to access. The proposed method makes high-frequency port turnover rate and throughput available for a wide range of users. The statistics and findings will enhance standardization and transparency of port statistics and promote the sustainable development of port industry.",
                "disciplines": [
                    "3509"
                ]
            }
        }
    },
    "13825883": {
        "title": "Empirical research on customers' online information contact points and channel selection",
        "abstract": "As online information contact points become more diverse, retailers need to design strategies to draw customers into their own channels. In this study, we evaluate how customer heterogeneity in online information contact points can change customer behavior mechanisms, from information search to channel selection at the time of purchase. The originality of this research lies in the fact that it extends the issue of channel selection, which until now has been discussed only within the channels of one's own company and some of its competitors, to the premise that customers interact with various information points. This research can suggest ways to utilize retailers' channel strategies and customer relationship management that integrate online and physical stores in the modern retail environment, which is rapidly moving online due to the impact of the coronavirus.",
        "disciplines": [
            "3503",
            "3506",
            "3504"
        ],
        "publications": {
            "10.1016/j.elerap.2023.101336": {
                "title": "Customer demand concentration in online grocery retailing: Differences between online and physical store shopping baskets",
                "abstract": "The long-tail effect, in which online retailing has a relative advantage in selling less popular products, has been studied extensively with e-commerce growth. However, recent research has raised questions that are more nuanced than originally considered. E-commerce can lead to customer demand concentration under specific conditions such as recommendations of popular products and past-purchase shortcuts. This study explores customer demand concentration in multichannel grocery retailing, a product category that involves low search costs. We use multichannel and multichain purchase panel data, which are representative of a large portion of online supermarkets in Japan. Our analysis shows that, compared with demand in physical stores, demand online is more concentrated on popular products. Furthermore, online shopping experience has a moderating effect, resulting in greater demand concentration among more experienced customers. These results are robust when controlling for available assortments across channels. These findings help retailers to develop inventory and customer relationship management.",
                "disciplines": []
            }
        }
    },
    "13666672": {
        "title": "Ensuring adequate euthanasia in pig production systems",
        "abstract": "Brazil has been consolidating itself as one of the world's largest pork producers, and has great potential to expand its participation in this market. For this, the production chain has been organized in order to meet the demands of the consumer market, which is increasingly looking for a production chain that is attentive to good production practices and animal welfare. A sick animal can remain in unnecessary suffering, in addition to becoming a risk to other pigs as a possible source of infection, resulting in increased costs and labor, in addition to lower performance. Thus, the theme \"Ensuring adequate euthanasia in Brazilian pig production systems\" was selected by the research groups as an object of study due to its economic and social importance. It is of fundamental importance to address this issue in a practical and effective way, respecting the routine of commercial production systems. In addition, it is extremely relevant to provide people involved in the pig production system with adequate training in the correct identification of pigs that require care and treatment, as well as those that need euthanasia, so that they are able not only to perform the euthanasia procedure properly, but also feel comfortable doing it, because they know they will act in the best possible way and ethically, respecting the animal's life. We believe this proposal has the power to achieve that goal and transform the way people see and perform euthanasia. This work will not only improve animal welfare through training and improvement of techniques and decision-making of employees on the farms, but will also allow for the exchange of information and collaboration between three groups of researchers from universities in two different countries, ensuring that animal welfare can be optimized using the most up-to-date scientific information on a global scale and will also contribute to the development of six Sustainable Development Goals recommended by the UN.",
        "disciplines": [
            "3003"
        ],
        "publications": {
            "10.1590/0001-3765202320230351": {
                "title": "Relationship between creep feeding intake and piglet\u2019s performance in the nursery phase",
                "abstract": "The objective of this study was to evaluate the effects of creep feeding during the pre-weaning stage on the performance of piglets at nursery phase, as well as to estimate the economic viability of its application. A total of 125 piglets were exposed to creep feeding and evaluated qualitatively regarding diet intake and quantitatively regarding weight gain. After determining the eaters and non-eaters' piglets, 48 of these animals were evaluated in the nursery phase. Piglets are blocked (initial weigh and sex) and divided into eaters (E, n=24) and non-eaters (NE, n=24). Time to start feed intake, growth performance data and economic viability were analyzed. At pre-weaning phase no weight difference was observed, and only 24.5% of piglets consumed the creep feed after 12 days of exposure. At nursery phase, the E group presented a 250% faster consumption in the first 24 hours of housing, 18.3% greater daily feed intake and 22.0% greater daily gain for whole experimental length, when compared to NE group. The economic evaluation demonstrated a 269% and 225% greater economic profit and return on investment for E. Therefore, the application of creep feeding in pre-weaning improves the piglets' performance during nursery phase and is economically viable.",
                "disciplines": [
                    "3003"
                ]
            },
            "10.1590/s1678-3921.pab2023.v58.03246": {
                "title": "Herbal choline as an alternative to choline chloride in the diet of nursery piglets",
                "abstract": "Abstract The objective of this work was to evaluate the replacement of choline chloride supplementation by herbal choline in the diet of nursery piglets. The experimental design was randomized complete blocks (initial weight and sex) with 80 piglets, in five treatments, with eight replicates. The treatments consisted of: negative control, basal diet supplemented with 300 mg kg-1 choline via choline chloride, basal diet supplemented with 600 mg kg-1 choline via choline chloride, basal diet supplemented with 100 mg kg-1 herbal choline, and basal diet supplemented with 200 mg kg-1 herbal choline. Zootechnical performance data, blood parameters, and economic viability were analyzed. Herbal choline supplementation increases the body weight and daily feed intake of nursery piglets. The supplementation with 100 mg kg-1 herbal choline presents the highest return on investment. Herbal choline can be used as a source of choline supplementation in the diet of nursery piglets to replace choline chloride.\nResumo O objetivo deste trabalho foi avaliar a substitui\u00e7\u00e3o da suplementa\u00e7\u00e3o de cloreto de colina por colina herbal na dieta de leit\u00f5es na creche. O delineamento experimental foi em blocos ao acaso (peso inicial e sexo) com 80 leit\u00f5es, em cinco tratamentos, com oito repeti\u00e7\u00f5es. Os tratamentos consistiram em: controle negativo, dieta basal com suplementa\u00e7\u00e3o de 300 mg kg-1 de colina via cloreto de colina, dieta basal com suplementa\u00e7\u00e3o de 600 mg kg-1 de colina via cloreto de colina, dieta basal com suplementa\u00e7\u00e3o de 100 mg kg-1 de colina herbal e dieta basal com suplementa\u00e7\u00e3o de 200 mg kg-1 de colina herbal. Dados de desempenho zoot\u00e9cnico, par\u00e2metros sangu\u00edneos e viabilidade econ\u00f4mica foram analisados. A suplementa\u00e7\u00e3o de colina herbal aumenta o peso corporal e o consumo di\u00e1rio de ra\u00e7\u00e3o em leit\u00f5es na creche. A suplementa\u00e7\u00e3o com 100 mg kg-1 de colina herbal apresenta o maior retorno sobre o investimento. A colina herbal pode ser utilizada como fonte de suplementa\u00e7\u00e3o de colina na dieta de leit\u00f5es na creche, para substituir o cloreto de colina.",
                "disciplines": [
                    "3003"
                ]
            }
        }
    },
    "13201256": {
        "title": "Quantum internet based on atomic ensembles",
        "abstract": "The recent technological goal to build larger networks for quantum communications, called quantum internet, relies not only on technical advances but on fundamental conceptual developments that took place throughout the last two to three decades. The main development being the recognition of the role quantum entanglement plays in quantum mechanics and, consequently, on our overall descriptionof the natural phenomena around us. The global description of systems purely by quantum mechanics has strong fundamental implications as all processes are coherent and no information is lost. Most of the surprising developments in quantum networks come from this radically coherent perspective, which has been systematically confirmed by the experiments. This global quantum perspective, however, is intrinsically multipartite and complex, requiring the development of new concepts and approaches. The idea of quantum internet takes a central stage in this effort as it provides economic/strategic motivation and more concrete goals to a rather abstract and overly broad scientific problem. This project#s goal is to advance the field of quantum networks by implementing two key ideas: a newclass of multipartite quantum entanglement from an ensemble of two-level atoms, and an atomic memory for ultrabroadband single photons. For the multipartite entanglement, in these first three years we plan to measure first the quadripartite entanglement in light scattered by cold two-level atoms due to excitation by two counter-propagating laser beams. This will require the characterization of bipartite entanglements for the different pairs of modes of the quadripartite state. Such achievement would extend the observationof multipartite entanglement to the simplest and most widely applied system to model light-matter interaction. Important developments could occur in different directions, like observing different types of multipartite entanglement depending on the excitation fields, implementing atomic memories with the atomic external degrees of freedom, and exploring higher order nonlinearities. For the memory of the ultrabroadband photon, we plan to first measure the high absorption of a weak pulse of about 100fs duration in a two-photon sequential transition. For that, we are going to use a high-power amplified control pulse, a spatial light modulator for coherentcontrol, and a heated vapor cell to tune the atomic density. Once we succeed in significantly absorbing this weak pulse, we are going to substitute it by a single photon from a spontaneous parametric-down-conversion source and characterize the collective atomic state generated after it is absorbed by the atomic ensemble. The success here would finally combine atomic memories with the whole field of quantum correlations in spontaneous parametric down-conversion, a workhorse for quantum optics and quantum information. This would have far reaching consequences for quantum information, as, for example, providing a way to connect satellite-based quantum communications with local quantum networks. In practice, the first steps along this line has the potential to create already a new field, with the transduction of quantum information from femtosecond to microseconds timescales and the need to control new types of collective atomic states.",
        "disciplines": [
            "5102",
            "5108"
        ],
        "publications": {
            "10.1038/s41598-024-56540-1": {
                "title": "Gouy phase and quantum interference with cross-Wigner functions for matter-waves",
                "abstract": "The Gouy phase is essential for accurately describing various wave phenomena, ranging from classical electromagnetic waves to matter waves and quantum optics. In this work, we employ phase-space methods based on the cross-Wigner transformation to analyze spatial and temporal interference in the evolution of matter waves characterized initially by a correlated Gaussian wave packet. First, we consider the cross-Wigner of the initial wave function with its free evolution, and second for the evolution through a double-slit arrangement. Different from the wave function which acquires a global Gouy phase, we find that the cross-Wigner acquires a Gouy phase difference due to different evolution times. The results suggest that temporal like-Gouy phase difference is important for an accurate description of temporal interference. Furthermore, we propose a technique based on the Wigner function to reconstruct the cross-Wigner from the spatial intensity interference term in a double-slit experiment with matter waves.",
                "disciplines": [
                    "5108",
                    "5102"
                ]
            },
            "10.1364/ol.494369": {
                "title": "Enhancing nonclassical correlations for light scattered by an ensemble of cold two-level atoms.",
                "abstract": "We report the enhancement of quantum correlations for biphotons generated via spontaneous four-wave mixing in an ensemble of cold two-level atoms. This enhancement is based on the filtering of the Rayleigh linear component of the spectrum of the two emitted photons, favoring the quantum-correlated sidebands reaching the detectors. We provide direct measurements of the unfiltered spectrum presenting its usual triplet structure, with Rayleigh central components accompanied by two peaks symmetrically located at the detuning of the excitation laser with respect to the atomic resonance. The filtering of the central component results in a violation of the Cauchy-Schwarz inequality to (4.8\u00b11.0)\u22701 for a detuning of 60 times the atomic linewidth, representing an enhancement by a factor of four compared with the unfiltered quantum correlations observed at the same conditions.",
                "disciplines": [
                    "5108",
                    "5102"
                ]
            }
        }
    },
    "9852820": {
        "title": "Rewriting moral character and professional virtue",
        "abstract": "This project aims to solve the philosophical problems of whether moral character motivates action and how it does so by developing an innovative account of moral character that draws on two overlooked bodies of research: the psychology of \u2018moral identity\u2019 and the philosophy of narrative self-constitution. The resulting narrative account of moral character claims that moral identities motivate moral action and, therefore, underpin moral character. The project then applies this knowledge to professional ethics, empirically testing the extent to which professional moral identities influence action and creating novel, self-narrative focused strategies to foster professional virtue.",
        "disciplines": [
            "3507",
            "5001"
        ],
        "publications": {
            "10.1017/s0963180124000112": {
                "title": "Assessing Public Reason Approaches to Conscientious Objection in Healthcare.",
                "abstract": "Sometimes healthcare professionals conscientiously refuse to treat patients despite the patient requesting legal, medically indicated treatments within the professionals' remit. Recently, there has been a proliferation of views using the concept of public reason to specify which conscientious refusals of treatment should be accommodated. Four such views are critically assessed, namely, those of Robert Card, Massimo Reichlin, David Scott, and Doug McConnell. This paper argues that McConnell's view has advantages over the other approaches because it combines the requirement that healthcare professionals publicly justify the grounds of their conscientious refusals of treatment with the requirement that those grounds align with minimally decent healthcare. This relatively restrictive approach accommodates conscientious refusals from minimally decent healthcare professionals while still protecting good healthcare, the independence of the healthcare professions, and the fiduciary relationships.",
                "disciplines": [
                    "5001"
                ]
            },
            "10.1136/jme-2023-109568": {
                "title": "UK doctors\u2019 strikes 2023: not only justified but, arguably, supererogatory",
                "abstract": "The 2023 doctors' strikes in the UK have elicited a familiar moral outcry that such strikes are morally wrong. We consider five arguments that might be thought to show doctors' strikes are morally impermissible but show that they all fail. The most we can conclude from such arguments is that doctors' strikes are morally permissible in a narrower range of circumstances than strikes in other sectors.We then outline two independent but compatible justifications for doctors' strikes, one that appeals to doctors' interests in fair pay and working conditions and one that appeals to doctors' duty to protect public health. We also suggest that doctors' strikes can be supererogatory when they aim to correct a government failing in its own duty to protect public health. Finally, we assess the 2023 UK doctors' strikes. We conclude that they are justified and there is a case for considering them supererogatory.",
                "disciplines": [
                    "5003",
                    "5001"
                ]
            },
            "10.1111/japp.12655": {
                "title": "The Balanced View of the Value of Conscience",
                "abstract": "On the mainstream view, consciences are valuable because they promote moral unity. However, conscience, so defined, will systematically prevent moral growth that threatens unity, even when unity has formed around oppressive moral values. This motivates Carolyn McLeod's alternative 'Dynamic View' whereby consciences are valuable to the extent that they are dynamic. Consciences are dynamic when they interact with our best moral judgements to shape or 'retool' the moral values underpinning conscience, sometimes at an initial cost to unity. We modify and extend McLeod's account in two ways: (1) We object to her claim that conscience encourages its own retooling. We argue that the opposite is true - conscience creates a motivational barrier to change that moral judgement must overcome to successfully retool conscience. The task of ensuring dynamism, therefore, falls to moral judgement. (2) However, this motivational barrier enables conscience to play a valuable role that McLeod overlooks - compensating for the limitations of moral judgement. On our Balanced View, the value of conscience depends on it being sufficiently open to being shaped by our best moral judgements but inert enough to compensate for distorted moral judgements and to guide action when under cognitive load.",
                "disciplines": [
                    "5003"
                ]
            }
        }
    },
    "9852731": {
        "title": "Music and speech as a window into the predictive brain",
        "abstract": "Prediction is fundamental to daily life, and yet we know little about how this central process works in the brain. This research program aims to provide in-depth insight into predictive processing by investigating the precise, culturally relevant, and communicative domains of music and speech. The research expects to reveal cognitive and neural correlates of \u201cwhat\u201d will occur and \u201cwhen\u201d it will occur, while exploiting the musician brain as a model for plasticity. Expected outcomes include a multi-dimensional model of prediction and its neural markers that will lay the foundation to investigate impaired predictive processing. This should substantially benefit health and education by providing perspectives for training and rehabilitation.",
        "disciplines": [
            "5202"
        ],
        "publications": {
            "10.1038/s41539-023-00170-1": {
                "title": "Regular rhythmic primes improve sentence repetition in children with developmental language disorder",
                "abstract": "Recently reported links between rhythm and grammar processing have opened new perspectives for using rhythm in clinical interventions for children with developmental language disorder (DLD). Previous research using the rhythmic priming paradigm has shown improved performance on language tasks after regular rhythmic primes compared to control conditions. However, this research has been limited to effects of rhythmic priming on grammaticality judgments. The current study investigated whether regular rhythmic primes could also benefit sentence repetition, a task requiring proficiency in complex syntax\u2014an area of difficultly for children with DLD. Regular rhythmic primes improved sentence repetition performance compared to irregular rhythmic primes in children with DLD and with typical development\u2014an effect that did not occur with a non-linguistic control task. These findings suggest processing overlap for musical rhythm and linguistic syntax, with implications for the use of rhythmic stimulation for treatment of children with DLD in clinical research and practice.",
                "disciplines": [
                    "5204"
                ]
            },
            "10.1016/j.neubiorev.2023.105153": {
                "title": "Can rhythm-mediated reward boost learning, memory, and social connection? Perspectives for future research",
                "abstract": "Studies of rhythm processing and of reward have progressed separately, with little connection between the two. However, consistent links between rhythm and reward are beginning to surface, with research suggesting that synchronization to rhythm is rewarding, and that this rewarding element may in turn also boost this synchronization. The current mini review shows that the combined study of rhythm and reward can be beneficial to better understand their independent and combined roles across two central aspects of cognition: 1) learning and memory, and 2) social connection and interpersonal synchronization; which have so far been studied largely independently. From this basis, it is discussed how connections between rhythm and reward can be applied to learning and memory and social connection across different populations, taking into account individual differences, clinical populations, human development, and animal research. Future research will need to consider the rewarding nature of rhythm, and that rhythm can in turn boost reward, potentially enhancing other cognitive and social processes.",
                "disciplines": []
            }
        }
    },
    "10007884": {
        "title": "Optimisation of piezoelectric metamaterials: Towards robotic stress sensors",
        "abstract": "This project aims to design new piezoelectric material microstructures that can enhance the measurement of complex local stress states within robotic limbs. The project expects to generate new knowledge of the achievable properties of multi-poled piezoelectric materials and develop computational tools for the analysis and structural optimisation of such materials. The designed microstructures may revolutionise piezoelectric sensor technology. Expected outcomes include manufactured proof-of-concept sensors that enable measurement of local stress fields. This should provide significant benefits, such as improved future robot capability and reliability, and research training for next-generation Australian computational mathematicians.",
        "disciplines": [
            "4605",
            "4602",
            "4016"
        ],
        "publications": {
            "10.1007/s00158-023-03663-0": {
                "title": "A Hilbertian projection method for constrained level set-based topology optimisation",
                "abstract": "We present an extension of the projection method proposed by Challis et al. (Int J Solids Struct\u00a045(14\u201315):4130\u20134146, 2008) for constrained level set-based topology optimisation that harnesses the Hilbertian velocity extension-regularisation framework. Our Hilbertian projection method chooses a normal velocity for the level set function as a linear combination of (1) an orthogonal projection operator applied to the extended optimisation objective shape sensitivity and (2) a weighted sum of orthogonal basis functions for the extended constraint shape sensitivities. This combination aims for the best possible first-order improvement of the optimisation objective in addition to first-order improvement of the constraints. Our formulation utilising basis orthogonalisation naturally handles linearly dependent constraint shape sensitivities. Furthermore, use of the Hilbertian extension-regularisation framework ensures that the resulting normal velocity is extended away from the boundary and enriched with additional regularity. Our approach is generally applicable to any topology optimisation problem to be solved in the level set framework. We consider several benchmark constrained microstructure optimisation problems and demonstrate that our method is effective with little-to-no parameter tuning. We also find that our method performs well when compared to a Hilbertian sequential linear programming method.",
                "disciplines": []
            },
            "10.3390/ma16145076": {
                "title": "Optimisation of a Multi-Functional Piezoelectric Component for a Climbing Robot",
                "abstract": "Force sensors on climbing robots give important information to the robot control system, however, off-the-shelf sensors can be both heavy and bulky. We investigate the optimisation of a lightweight integrated force sensor made of piezoelectric material for the multi-limbed climbing robot MAGNETO. We focus on three design objectives for this piezoelectric component. The first is to develop a lightweight component with minimal compliance that can be embedded in the foot of the climbing robot. The second objective is to ensure that the component has sensing capability to replace the off-the-shelf force sensor. Finally, the component should be robust for a range of climbing configurations. To this end, we focus on a compliance minimisation problem with constrained voltage and volume fraction. We present structurally optimised designs that satisfy the three main design criteria and improve upon baseline results from a reference component. Our computational study demonstrates that the optimisation of embedded robotic components with piezoelectric sensing is worthy of future investigation.",
                "disciplines": [
                    "4009"
                ]
            }
        }
    },
    "13242980": {
        "title": "COntrol on Stratified Structures \u2013 COSS",
        "abstract": "The central theme of this project lies in the area of control theory and partial differential equations (in particular Hamilton-Jacobi equations), posed on stratified structures and networks. These equations appear very naturally in several applications like traffic flow modeling, energy management in smart-grids networks or sea-land trajectories with different dynamics. These control problems can be studied within the framework of Hamilton Jacobi equations theory. Recently, significant results have been obtained, leading to a good understanding of the notion of viscosity solutions (in particular the questions of existence and uniqueness) on some specific stratified structures. This base of results will be further developed in different directions. It will first be necessary to complete the analysis for more general problems under weaker hypotheses than the one used so far (nature of the stratification, hypotheses on the Hamiltonians, ...). On the other hand, it is necessary to use the already existing base to advance research in other active areas such as homogenization or mean field games. Moreover, all of the theoretical results will be used to achieve progress in the modeling and numerical resolution of some control problems on stratified domains.More precisely, the aim of this project is to develop the fundamental theory governing optimal control problems, differential games and mean field games in stratified domains and networks, to provide computational methods for their solutions and also to propose a theory of homogenization allowing to pass from microscopic models to macroscopic ones, thereby giving rigorous justifications of the latter.  The main objectives include understanding fundamental questions on the structure of optimal trajectories, in particular when moving from one strata to another, the analysis of the value function and its characterization by adequate Hamilton-Jacobi equations, the feedback control, singular perturbations and homogenization. In the particular case of networks, our aim is also to understand the links with conservation laws with discontinuous fluxes. These tools will allow us to tackle a large class of problems in which the dynamics are discontinuous and may depend on the domain where the trajectory takes place.Our project proposes challenging mathematical and numerical studies for optimal control problems, games and mean-field games, and homogenization on stratified structures. Our approaches are based on nonlinear PDEs theory, non-smooth analysis, and advanced numerical methods. Thanks to the expertise of the team members, and inspired by real-life challenging problems, our project will contribute in advancing the theory and will produce open access academic numerical codes. The project is organized in four major methodological axes: optimal control and optimal trajectories, singular perturbation and homogenization, game theory and mean field games and numerical analysis.",
        "disciplines": [
            "4901"
        ],
        "publications": {
            "10.1007/978-3-031-55260-1_15": {
                "title": "Peculiarities of Space Dependent Conservation Laws: Inverse Design and Asymptotics",
                "abstract": "Recently, results regarding the Inverse Design problem for Conservation Laws and Hamilton-Jacobi equations with x-dependent convex fluxes were obtained in\u00a0Colombo, Perrollaz, and Sylla (2022), Colombo, Perrollaz, and Sylla (2023). More precisely, characterizations of attainable sets and the set of initial data evolving at a prescribed time into a prescribed profile were obtained. Here, we present an explicit example that underlines deep differences between the x-dependent and x-independent cases. Moreover, we add a detailed analysis of the time asymptotic solution of this example, again underlining differences with the x-independent case.",
                "disciplines": [
                    "4901"
                ]
            },
            "10.1007/s11228-024-00719-1": {
                "title": "Forward-Backward Algorithm for Functions with Locally Lipschitz Gradient: Applications to Mean Field Games",
                "abstract": "In this paper, we provide a generalization of the forward-backward splitting algorithm for minimizing the sum of a proper convex lower semicontinuous function and a differentiable convex function whose gradient satisfies a locally Lipschitz-type condition. We prove the convergence of our method and derive a linear convergence rate when the differentiable function is locally strongly convex. We recover classical results in the case when the gradient of the differentiable function is globally Lipschitz continuous and an already known linear convergence rate when the function is globally strongly convex. We apply the algorithm to approximate equilibria of variational mean field game systems with local couplings. Compared with some benchmark algorithms to solve these problems, our numerical tests show similar performances in terms of the number of iterations but an important gain in the required computational time.",
                "disciplines": [
                    "4901",
                    "4903"
                ]
            },
            "10.1007/s00205-023-01948-8": {
                "title": "Microscopic Derivation of a Traffic Flow Model with a Bifurcation",
                "abstract": "The goal of the paper is a rigorous derivation of a macroscopic traffic flow model with a bifurcation or a local perturbation from a microscopic one. The microscopic model is a simple follow-the-leader with random parameters. The random parameters are used as a statistical description of the road taken by a vehicle and its law of motion. The limit model is a deterministic and scalar Hamilton\u2013Jacobi on a network with a flux limiter, the flux-limiter describing how much the bifurcation or the local perturbation slows down the vehicles. The proof of the existence of this flux limiter\u2014the first one in the context of stochastic homogenization\u2014relies on a concentration inequality and on a delicate derivation of a superadditive inequality.",
                "disciplines": [
                    "4901",
                    "4904"
                ]
            },
            "10.1142/s0219199723500657": {
                "title": "Perspective functions with nonlinear scaling",
                "abstract": "The classical perspective of a function is a construction which transforms a convex function into one that is jointly convex with respect to an auxiliary scaling variable. Motivated by applications in several areas of applied analysis, we investigate an extension of this construct in which the scaling variable is replaced by a nonlinear term. Our construction is placed in the general context of locally convex spaces and it generates a lower semicontinuous convex function under broad assumptions on the underlying functions. Various convex-analytical properties are established and closed-form expressions are derived. Several applications are presented.",
                "disciplines": [
                    "4901",
                    "4903"
                ]
            },
            "10.1007/s12220-023-01484-7": {
                "title": "Viscosity Solutions of Hamilton-Jacobi Equations in Proper CAT(0) Spaces",
                "abstract": "In this article, we develop a novel notion of viscosity solutions for first order Hamilton-Jacobi equations in proper CAT(0)$$\\mathrm {CAT(0)}$$ spaces. The notion of viscosity is defined by taking test functions that are locally Lipschitz and can be represented as a difference of two semiconvex functions. Under mild assumptions on the Hamiltonian, we recover the main features of viscosity theory for both the stationary and the time-dependent cases in this setting: the comparison principle and Perron\u2019s method. Finally, we show that this notion of viscosity coincides with the classical one in RN$$\\mathbb {R}^N$$ and we give several examples of Hamilton-Jacobi equations in more general CAT(0)$$\\mathrm {CAT(0)}$$ spaces covered by this setting.",
                "disciplines": [
                    "4901",
                    "4904"
                ]
            },
            "10.1007/s10957-023-02344-8": {
                "title": "Set-Driven Evolution for Multiagent System",
                "abstract": "We consider the deterministic evolution in the Euclidean space of a multiagent system with a large number of agents (possibly infinitely many). At each instant of time, besides from time and its current position, the set of velocities available to each agent is influenced by the set described by the current position of all the other agents. The latter is in turn determined by the overall motion of the crowd of all the agents. The interplay to the microscopical point of view of each single agent, and the macroscopical one of the set-evolution yields a non-trivial dynamical system. This two-level multiagent system can be described either by the evolution of a probability measure\u2014describing the instantaneous density of the crowd\u2014or by the evolution of a set\u2014describing the positions where there is at least one agent. In this paper, we precise the links between the two descriptions, providing also some quantitative estimates on the macroscopical admissible evolutions.",
                "disciplines": [
                    "4901"
                ]
            },
            "10.1007/978-3-031-46359-4_2": {
                "title": "The Mathematical Theory of Hughes\u2019 Model: A Survey of Results",
                "abstract": "We provide an overview of the results on Hughes\u2019 model for pedestrian movements available in the literature. The model consists of a nonlinear conservation law coupled with an eikonal equation. The main difficulty in developing a proper mathematical theory lies in the lack of regularity of the flux in the conservation law, which yields the possibility of non-classical shocks that are generated non-locally by the whole distribution of pedestrians. This is a possible reason behind the availability of existence results only on one-dimensional spatial domains, despite the model having a more natural setting in two spatial dimensions.After the first successful approaches to solving a regularised version of the model, researchers focused on the structure of the Riemann problem, which led to local-in-time existence results for Riemann-type data and paved the way for a WFT (Wave-Front Tracking) approach to the solution semigroup. In parallel, a DPA (Deterministic Particles Approximation) approach was developed in the spirit of follow-the-leader approximation results for scalar conservation laws. Beyond having proved to be powerful analytical tools, the WFT and the DPA approaches also led to interesting numerical results.However, only existence theorems on very specific classes of initial data (essentially ruling out non-classical shocks) have been available until very recently. A proper existence result using a DPA approach was proven not long ago in the case of a linear coupling with the density in the eikonal equation. Shortly after, a similar result was proven via a fixed point approach.We provide a detailed statement of the aforementioned results and sketch the main proofs. We also provide a brief overview of results that are related to Hughes\u2019 model, such as the derivation of a dynamic version of the model via a mean-field game strategy, an alternative optimal control approach, and a localized version of the model. We also present the main numerical results within the WFT and DPA frameworks.",
                "disciplines": [
                    "4904"
                ]
            },
            "10.1007/s10208-023-09629-4": {
                "title": "Approximation of Deterministic Mean Field Games with Control-Affine Dynamics",
                "abstract": "We consider deterministic mean field games where the dynamics of a typical agent is non-linear with respect to the state variable and affine with respect to the control variable. Particular instances of the problem considered here are mean field games with control on the acceleration (see Achdou et al. in NoDEA Nonlinear Differ Equ Appl 27(3):33, 2020; Cannarsa and Mendico in Minimax Theory Appl 5(2):221-250, 2020; Cardaliaguet and Mendico in Nonlinear Anal 203: 112185, 2021). We focus our attention on the approximation of such mean field games by analogous problems in discrete time and finite state space which fall in the framework of (Gomes et al. in J Math Pures Appl (9) 93(3):308-328, 2010). For these approximations, we show the existence and, under an additional monotonicity assumption, uniqueness of solutions. In our main result, we establish the convergence of equilibria of the discrete mean field games problems towards equilibria of the continuous one. Finally, we provide some numerical results for two MFG problems. In the first one, the dynamics of a typical player is nonlinear with respect to the state and, in the second one, a typical player controls its acceleration.",
                "disciplines": [
                    "4901"
                ]
            },
            "10.1007/s00245-023-10029-x": {
                "title": "Semidiscrete Shocks for the Full Velocity Difference Model",
                "abstract": "In this paper, we consider the full velocity difference model for traffic flow and we study the existence and uniqueness of traveling wave solutions. First, using the monotony of the car\u2019s interdistance, we derive necessary conditions for the existence of such solutions. Then, in the framework of viscosity solutions, we construct a traveling wave solution by considering an approximate non-local Hamilton\u2013Jacobi equation on a bounded domain. This traveling wave solution can be interpreted as a phase transition between a congested state and a free-flow one.",
                "disciplines": [
                    "4901"
                ]
            },
            "10.1007/s00028-023-00902-1": {
                "title": "Conservation laws and Hamilton\u2013Jacobi equations with space inhomogeneity",
                "abstract": "Conservation laws with an x-dependent flux and Hamilton\u2013Jacobi equations with an x-dependent Hamiltonian are considered within the same set of assumptions. Uniqueness and stability estimates are obtained only requiring sufficient smoothness of the flux/Hamiltonian. Existence is proved without any convexity assumptions under a mild coercivity hypothesis. The correspondence between the semigroups generated by these equations is fully detailed. With respect to the classical Kru\u017ekov approach to conservation laws, we relax the definition of solution and avoid any restriction on the growth of the flux. A key role is played by the construction of sufficiently many entropy stationary solutions in L\u221e$${{\\textbf{L}}^\\infty }$$ that provide global bounds in time and space.",
                "disciplines": [
                    "4901"
                ]
            },
            "10.1016/j.jde.2023.06.004": {
                "title": "On existence, stability and many-particle approximation of solutions of 1D Hughes' model with linear costs",
                "abstract": "This paper deals with the one-dimensional formulation of Hughes' model for pedestrian flows in the setting of entropy solutions. In this model, the mass conservation equation for the pedestrian density authorizes non-classical shocks at the location of the so-called turning curve. We consider linear (more precisely, affine) cost functions, whose slopes \u03b1 \u2a7e 0 correspond to different crowd behaviours. We prove for the first time an existence result in the framework of entropy solutions, for general data. Differently from the partial existence results available in the literature, our existence result allows for the possible presence of non-classical shocks. The proofs are based on a sharply formulated many-particle approximation scheme, with careful treatment of interactions of particles with the turning curve. First, we rigorously establish the well-posedness of this many-particle scheme. Then we develop a local compactness argument that permits to circumvent the lack of available BV bounds in a vicinity of the turning curve, while proving consistency of the approximation scheme with the entropy formulation. Finally, we illustrate numerically that the model is able to reproduce typical behaviours in case of evacuation. Special attention is devoted to the impact of the parameter \u03b1 on the evacuation time.",
                "disciplines": [
                    "4902"
                ]
            },
            "10.1007/s00030-023-00857-9": {
                "title": "Finite volume approximation and well-posedness of conservation laws with moving interfaces under abstract coupling conditions",
                "abstract": "Scalar conservation law \u2202t\u03c1(t,x)+\u2202x(f(t,x,\u03c1))=0$$\\displaystyle {\\partial _t \\rho (t, x) + \\partial _x({\\textbf{f}}(t, x, \\rho )) = 0}$$ with a flux C1$${\\textbf{C}}^{1}$$ in the state variable \u03c1$$\\rho $$, piecewise C1$${\\textbf{C}}^{1}$$ in the (t,\u00a0x)-plane admits infinitely many consistent notions of solution which differ by the choice of interface coupling. Only the case of the so-called vanishing viscosity solutions received full attention, while different choice of coupling is relevant in modeling situations that appear, e.g., in road traffic and in porous medium applications. In this paper, existence of solutions for a wide set of coupling conditions is established under some restrictions on f$${\\textbf{f}}$$, via a finite volume approximation strategy adapted to slanted interfaces and to the presence of interface crossings. The notion of solution, restated under the form of an adapted entropy formulation which is consistently approximated by the numerical scheme, implies uniqueness and stability of solutions. Numerical simulations are presented to illustrate the reliability of the scheme.",
                "disciplines": [
                    "4901"
                ]
            },
            "10.1007/s11579-023-00333-z": {
                "title": "A mean field model for the interactions between firms on the markets of their inputs",
                "abstract": "We consider an economy made of competing firms which are heterogeneous in their capital and use several inputs for producing goods. Their consumption policy is fixed rationally by maximizing a utility and their capital cannot fall below a given threshold (state constraint). We aim at modeling the interactions between firms on the markets of the different inputs on the long term. The stationary equlibria are described by a system of coupled non-linear differential equations: a Hamilton\u2013Jacobi equation describing the optimal control problem of a single atomistic firm; a continuity equation describing the distribution of the individual state variable (the capital) in the population of firms; the equilibria on the markets of the production factors. We prove the existence of equilibria under suitable assumptions.",
                "disciplines": [
                    "3502"
                ]
            }
        }
    },
    "13245355": {
        "title": "FW-HTF-R: Collaborative Research: Worker-AI Teaming to Enable ADHD Workforce Participation in the Construction Industry of the Future",
        "abstract": "While people with neurodiversity have been marginalized in the construction workplace due to potentially higher risks of injuries, their unique talents could be leveraged using an ecosystem of co-bots driven by artificial intelligence (AI). For humans and machines to become true teammates\u2014and correlatively, for technology to extend occupational opportunities to people with such neurodiversity\u2014intelligent machines must assess, adapt, and respond to both workers and their environment. Such agility requires a reciprocal teaming capability wherein workers can engage their AI counterparts as more than tools, and AI systems can collaborate with workers seamlessly by predicting their behaviors. To extend future occupational opportunities for people with neurodiversity, this project builds an AI-driven learning platform to enable distribution of AI teammates in construction workplaces to support employment opportunities and safety outcomes for construction workers with varying abilities. This study also investigates the intended work scenarios of worker-AI teaming, the unintended consequences of AI-teaming for workers, and the well-being of society. Considering that 4.2% of workers are diagnosed with attention-deficit/hyperactivity disorder (ADHD)\u2014a disorder that is associated with more than 120 million lost workdays in the USA each year, equating to a human capital value of $19.5 billion\u2014this project\u2019s efforts to enable diverse workforce participation in the construction industry will have positive social and economic impacts. Additionally, this project will educate a new generation of leaders in worker-AI teaming and will create partnerships between academia and industry. To lay the necessary foundations for building this human-AI teaming workspace for construction workers with neurodiversity, this proof-of-concept project will translate non\u2010invasive biomechanical and neuro-psychophysiological responses into information a personalized AI-based training systems can assess, model, and leverage to predict workers\u2019 behaviors for improved worker\u2010machine teaming without cultivating technological over-reliance or threats to privacy. In this project, a multidisciplinary team of researchers integrates expertise in civil engineering, computer science, cognitive and behavioral psychology, industrial engineering, and public policy and economics to address fundamental questions regarding the risk taking behavior and cognitive processes of workers with ADHD, barriers to adopting AI and wearable technologies, and the socioeconomic impacts of improved access to construction jobs for ADHD-diagnosed workers, especially in the context of interdependent human-AI partnerships. As this project\u2019s global paradigm moves toward deeper human-machine teaming, the knowledge gained through this project advances the science and technology that influences diverse workforce development, education, and positive work outcomes for workers and society at large. By demonstrating the effectiveness of this AI-driven platform, this project illustrates how human-machine teams can progress on job sites and within communities across all sectors to augment human cognitive capabilities. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3505"
        ],
        "publications": {
            "10.1061/jmenea.meeng-5794": {
                "title": "Application of Automaticity Theory in Construction",
                "abstract": "Automaticity, an essential skill attribute, develops when an activity is performed without requiring attention. Despite its importance, little is known about the implications of automaticity in the construction industry. To address this gap, this study investigated the development of automaticity during a repetitive construction task. Recruiting 28 subjects to participate in a laboratory roofing-installation experiment repeated across four trial days, this study examined traditional metrics of the primary (installation) task\u2019s duration and accuracy as well as nontraditional metrics of a concurrent secondary (memory) task\u2019s score to examine performance measures diagnostically indicative of automaticity. The results revealed that there were significant improvements in the primary task\u2019s mean duration and accuracy and the secondary task\u2019s mean performance score from the experiment\u2019s first trial day to every other day, an indication that, with repeated practice, automaticity-induced performance improves. Because these automatic performance measures provide an index for evaluating feature-based improvements indicative of automaticity, this study argues that such performance measures capture automaticity developing during repetitive construction activities. Given that practitioners are interested in training workers to achieve automaticity to increase their productivity and multitasking skills, the results of this study provide methods for testing training effectiveness and the extent to which workers have developed automaticity.",
                "disciplines": [
                    "3507"
                ]
            },
            "10.1177/21695067231194338": {
                "title": "Examining the Implications of Automaticity Theory in the Construction Industry",
                "abstract": "This study investigated the development of automaticity during repetitive construction activities. Twenty- eight subjects were recruited to participate in a total of 22 trials of simulated roofing installations for one month in a laboratory. The performance metric considered in this research for feature-based diagnosis of automaticity development was the roofing task accuracy. The results revealed that the roofing task accuracy significantly improved with practice as the trial days progressed. Given that practitioners are interested in training workers to achieve automaticity to increase their productivity and multi-tasking skills, the results of this study provide measures to test training effectiveness and the extent to which workers have developed automaticity. Also, by better understanding the model of humans, this study\u2019s results will help improve human-AI teaming as the AI will better understand the cognitive state of its human counterpart and can adapt to him/her more accurately.",
                "disciplines": [
                    "3302"
                ]
            }
        }
    },
    "13243185": {
        "title": "Blue Oxylipins: identification and valorisation of unic bioactive compounds from Microalgae through the collaboration of Research and Industry \u2013 OxyBleu-MARI-2",
        "abstract": "As the first link in the aquatic food chain, microalgae are an important source of biomolecules of interest for nutraceuticals, cosmetics and even health, which are still under-exploited. Among the molecules produced by microalgae, long-chain polyunsaturated fatty acids (PUFA) and their oxidized derivatives present interesting biological activities. However, the full economic valorization of these molecules requires the removal of technological barriers, in particular the selection of suitable species producing compounds of interest (innately and/or under forced conditions) and the \"selected/standardized\" culture that can be transposed to an industrial scale.In order to overcome these obstacles, the OxyBleu-MARI-2 Joint Laboratory proposes to bring together two highly complementary players with unique skills recognized by the academic and industrial worlds. The Synthesis of Bioactive Lipids team of IBMM, University of Montpellier, CNRS, ENSCM is an expert in research on bioactive lipids and more particularly on the total synthesis of oxidized metabolites of various unsaturated fatty acids on the one hand and their quantification, by LC-MS or GC-MS, in various human, animal and plant matrices, on the other hand Microphyt is a \"blue\" biotechnology company leader in the research, development, production and marketing of unique active natural ingredients from microalgae for the food supplement and cosmetic markets. Developed in-house, its unique and patented technologies allow the controlled production, on an industrial scale, of microalgal biomass and associated innovative extracts.The OxyBleu-MARI-2 LabCom will carry out research on the synthesis of extracts containing oxylipin-type PUFA derivatives. The objective of this collaboration is to remove the scientific and technological obstacles to the industrial production in photobioreactors of microalgal biomasses with specific oxylipin profiles. The investigations will focus on the production of the raw material, its extraction using environmentally friendly techniques and the profiling of the extracts obtained, from a chemical and biological point of view. The exploitation of the specificities of the microalgae must pass by (i) a thorough knowledge of the molecules with high added value like the oxylipins, by (ii) the securing of their production and by (iii) the objectivation of their biological activities, These elements will be investigated within the framework of LabCom OxyBleu-MARI-2.",
        "disciplines": [
            "3106"
        ],
        "publications": {
            "10.1038/s41597-024-03034-4": {
                "title": "From MS/MS library implementation to molecular networks: Exploring oxylipin diversity with NEO-MSMS",
                "abstract": "Oxylipins, small polar molecules derived from the peroxidation of polyunsaturated fatty acids (PUFAs), serve as biomarkers for many diseases and play crucial roles in human physiology and inflammation. Despite their significance, many non-enzymatic oxygenated metabolites of PUFAs (NEO-PUFAs) remain poorly reported, resulting in a lack of public datasets of experimental data and limiting their dereplication in further studies. To overcome this limitation, we constructed a high-resolution tandem mass spectrometry (MS/MS) dataset comprising pure NEO-PUFAs (both commercial and self-synthesized) and in vitro free radical-induced oxidation of diverse PUFAs. By employing molecular networking techniques with this dataset and the existent ones in public repositories, we successfully mapped a wide range of NEO-PUFAs, expanding the strategies for annotating oxylipins, and NEO-PUFAs and offering a novel workflow for profiling these molecules in biological samples.",
                "disciplines": [
                    "3205",
                    "3401"
                ]
            }
        }
    },
    "10008045": {
        "title": "Passive biofiltration processes for nitrogen removal from polluted waters",
        "abstract": "Traditional urban wastewater treatment is energy and resource demanding. By combining principles of Water Sensitive Urban Design (WSUD) with advanced pollutant removal processes, we will create necessary knowledge to underpin development of novel sustainable urban water treatment systems. This project aims to understand and utilise Simultaneous Nitrification, Anammox and Denitrification (SNAD) processes within passive plant-soil-based biofilters for cost-effective removal of nitrogen from a range of polluted urban water sources. The project will open a potential for a new technological advancements in urban water management, while simultaneously providing benefits to the environment and community through greening and waterway protection.",
        "disciplines": [
            "4011",
            "4004"
        ],
        "publications": {
            "10.1039/d3ew00347g": {
                "title": "Exploring denitrification and anammox processes in the saturated zone of passively operated vegetated biofiltration systems",
                "abstract": "Vegetated biofiltration systems (VBS) are common nature-based solutions (NBS) for urban water treatment, but their performance in treating nitrogen-rich wastewater is yet to be explored.\n Vegetated biofiltration systems (VBS) are common nature-based solutions (NBS) for urban water treatment, but their performance in treating nitrogen-rich wastewater is yet to be explored. This study investigated the submerged zone (SZ) component of VBS, for its ability to treat nitrogen through traditional denitrification, as well as the anaerobic ammonium oxidation (anammox) process that was rarely studied in NBS. A two-phase column-based experiment was conducted: (1) denitrification phase, to explore the impact of different carbon sources (hardwood chips, softwood chips, walnut shells), retention time and dissolved oxygen (DO) on denitrification; and (2) anammox phase, to identify whether the anammox process could occur in passively operated VBS. The results show that the VBS was able to treat nitrogen rich wastewater (with 80\u2013100 mg L \u22121 total nitrogen \u2013 TN) in both phases (average TN removal rates of 58.0 \u00b1 16.4%). Carbon sources had significant influences on TN and NO 3 \u2013N removal in the denitrification phase ( p < 0.05), with hardwood chips being the most effective (76.3 \u00b1 16.1%, standard conditions). Noticeable improvement was observed when increasing the retention time from 12 h (15.5 \u00b1 4.5% TN removal) to 48 h (81.0 \u00b1 2.9%). DO levels (<0.5 mg L \u22121 to 3 mg L \u22121 ) did not have a significant impact on nitrogen removal in all tested systems. Microbial analysis showed significant differences between hardwood chips/softwood chips and walnut shells. Various types of denitrifying bacteria dominated the microbial community (total relative abundance >10%), with Comamonadaceae_unclassified being the most abundant (average 8.3%) across all media types. A suspected anammox genus SM1A02 was found in the systems, but at very low abundance levels (up to 0.137%), which may indicate the presence of the anammox process in the passively operated VBS. ",
                "disciplines": [
                    "4004",
                    "4011"
                ]
            }
        }
    },
    "13057711": {
        "title": "Federated and transfer learning methods for cross-ancestry and cross-phenotype integration of genomic datasets",
        "abstract": "Abstract This proposal aims to develop advanced data integration methods for improving genetic risk prediction in under-represented non-European populations. Genome-Wide Association Studies (GWAS) have yielded important biological insights into the heritable basis of many complex traits and diseases, and polygenic risk scores (PRS) have shown promising potentials for disease risk stratification. However, since the vast majority of participants in large-scale genomic datasets are from European ancestry (EA) populations, the performance of current PRS is much poorer in non-EA populations than in EA populations, which may exacerbate existing health disparities. Despite some recent inclusive data collection efforts, current risk prediction methods cannot effectively address the heavily unbalanced sample sizes across populations. Robust data integration methods are needed to leverage similarities in genetic architectures across ancestral populations, phenotypic correlations and pleiotropy, and variant functional annotations while accounting for different sources of heterogeneity. Moreover, as various national and institutional biobanks become available, efficient information-sharing strategies with data privacy considerations are needed for combining data across biobanks to improve sample diversity and sample size. This proposal will address these needs by developing a methodological framework with advanced transfer learning (TL) and federated learning (FL) techniques for integrating various sources of data to bridge the gap of risk prediction across populations. Specifically, in Aim 1, we will develop a TL method to integrate ancestrally diverse data based on high-dimensional models with a distance-based regularization to characterize the similarities across populations, and a communication-efficient FL algorithm that jointly fits the TL model across multiple biobanks with only summary-level statistics. In Aim 2, we will develop methods that enable joint analyses of multiple phenotypes in association tests and risk prediction models. We will develop an FL algorithm to combine data from multiple biobanks for cross-phenotype association test, and a TL method with an angle-based regularization to leverage genetic correlations among mixed types of phenotypes in risk prediction. In Aim 3, we will develop knowledge- graph-based TL methods that leverage the shared latent spaces between phenotype-genotype knowledge graphs constructed from different ancestral populations and enable the incorporation of functional annotations. In Aim 4, we will develop open-access statistical software capable of implementing the proposed methods in both offline and cloud computing environments, and apply the proposed methods to the analysis of major depressive disorder and cardiovascular diseases using data from the All of Us program, eMERGE, and the UK biobank.",
        "disciplines": [
            "3105",
            "4202"
        ],
        "publications": {
            "10.1101/2024.05.17.24307550": {
                "title": "Genome-wide association studies in a large Korean cohort identify novel quantitative trait loci for 36 traits and illuminates their genetic architectures",
                "abstract": "Genome-wide association studies (GWAS) have been predominantly conducted in populations of European ancestry, limiting opportunities for biological discovery in diverse populations. We report GWAS findings from 153,950 individuals across 36 quantitative traits in the Korean Cancer Prevention Study-II (KCPS2) Biobank. We discovered 616 novel genetic loci in KCPS2, including an association between thyroid-stimulating hormone and CD36. Meta-analysis with the Korean Genome and Epidemiology Study, Biobank Japan, Taiwan Biobank, and UK Biobank identified 3,524 loci that were not significant in any contributing GWAS. We describe differences in genetic architectures across these East Asian and European samples. We also highlight East Asian specific associations, including a known pleiotropic missense variant in ALDH2, which fine-mapping identified as a likely causal variant for a diverse set of traits. Our findings provide insights into the genetic architecture of complex traits in East Asian populations and highlight how broadening the population diversity of GWAS samples can aid discovery.",
                "disciplines": [
                    "4202",
                    "3105"
                ]
            },
            "10.1101/2024.01.09.24301073": {
                "title": "mixWAS: An efficient distributed algorithm for mixed-outcomes genome-wide association studies",
                "abstract": "Genome-wide association studies (GWAS) have been instrumental in identifying genetic associations for various diseases and traits. However, uncovering genetic underpinnings among traits beyond univariate phenotype associations remains a challenge. Multi-phenotype associations (MPA), or genetic pleiotropy, offer important insights into shared genes and pathways among traits, enhancing our understanding of genetic architectures of complex diseases. GWAS of biobank-linked electronic health record (EHR) data are increasingly being utilized to identify MPA among various traits and diseases. However, methodologies that can efficiently take advantage of distributed EHR to detect MPA are still lacking. Here, we introduce mixWAS, a novel algorithm that efficiently and losslessly integrates multiple EHRs via summary statistics, allowing the detection of MPA among mixed phenotypes while accounting for heterogeneities across EHRs. Simulations demonstrate that mixWAS outperforms the widely used MPA detection method, Phenome-wide association study (PheWAS), across diverse scenarios. Applying mixWAS to data from seven EHRs in the US, we identified 4,534 MPA among blood lipids, BMI, and circulatory diseases. Validation in an independent EHR data from UK confirmed 97.7% of the associations. mixWAS fundamentally improves the detection of MPA and is available as a free, open-source software.",
                "disciplines": [
                    "3105",
                    "4202",
                    "4905"
                ]
            },
            "10.1038/s41598-023-41853-4": {
                "title": "Quantifying and correcting bias due to outcome dependent self-reported weights in longitudinal study of weight loss interventions",
                "abstract": "In response to the escalating global obesity crisis and its associated health and financial burdens, this paper presents a novel methodology for analyzing longitudinal weight loss data and assessing the effectiveness of financial incentives. Drawing from the Keep It Off trial\u2014a three-arm randomized controlled study with 189 participants\u2014we examined the potential impact of financial incentives on weight loss maintenance. Given that some participants choose not to weigh themselves because of small weight change or weight gains, which is a common phenomenon in many weight-loss studies, traditional methods, for example, the Generalized Estimating Equations (GEE) method tends to overestimate the effect size due to the assumption that data are missing completely at random. To address this challenge, we proposed a framework which can identify evidence of missing not at random and conduct bias correction using the estimating equation derived from pairwise composite likelihood. By analyzing the Keep It Off data, we found that the data in this trial are most likely characterized by non-random missingness. Notably, we also found that the enrollment time (i.e., duration time) would be positively associated with the weight loss maintenance after adjusting for the baseline participant characteristics (e.g., age, sex). Moreover, the lottery-based intervention was found to be more effective in weight loss maintenance compared with the direct payment intervention,\u00a0though the difference was non-statistically significant. This framework's significance extends beyond weight loss research, offering a semi-parametric approach to assess missing data mechanisms and robustly explore associations between exposures (e.g., financial incentives) and key outcomes (e.g., weight loss maintenance). In essence, the proposed methodology provides a powerful toolkit for analyzing real-world longitudinal data, particularly in scenarios with data missing not at random, enriching comprehension of intricate dataset dynamics.",
                "disciplines": [
                    "4905"
                ]
            },
            "10.1111/sjos.12685": {
                "title": "Testing the missing at random assumption in generalized linear models in the presence of instrumental variables",
                "abstract": "Practical problems with missing data are common, and many methods have been developed concerning the validity and/or efficiency of statistical procedures. On a central focus, there have been longstanding interests on the mechanism governing data missingness, and correctly deciding the appropriate mechanism is crucially relevant for conducting proper practical investigations. In this paper, we present a new hypothesis testing approach for deciding between the conventional notions of missing at random and missing not at random in generalized linear models in the presence of instrumental variables. The foundational idea is to develop appropriate discrepancy measures between estimators whose properties significantly differ only when missing at random does not hold. We show that our testing approach achieves an objective data-oriented choice between missing at random or not. We demonstrate the feasibility, validity, and efficacy of the new test by theoretical analysis, simulation studies, and a real data analysis.",
                "disciplines": [
                    "4905"
                ]
            },
            "10.1038/s41593-023-01321-8": {
                "title": "Genetic patterning for child psychopathology is distinct from that for adults and implicates fetal cerebellar development",
                "abstract": "Childhood psychiatric symptoms are often diffuse but can coalesce into discrete mental illnesses during late adolescence. We leveraged polygenic scores (PGSs) to parse genomic risk for childhood symptoms and to uncover related neurodevelopmental mechanisms with transcriptomic and neuroimaging data. In independent samples (Adolescent Brain Cognitive Development, Generation R) a narrow cross-disorder neurodevelopmental PGS, reflecting risk for attention deficit hyperactivity disorder, autism, depression and Tourette syndrome, predicted psychiatric symptoms through early adolescence with greater sensitivity than broad cross-disorder PGSs reflecting shared risk across eight psychiatric disorders, the disorder-specific PGS individually or two other narrow cross-disorder (Compulsive, Mood-Psychotic) scores. Neurodevelopmental PGS-associated genes were preferentially expressed in the cerebellum, where their expression peaked prenatally. Further, lower gray matter volumes in cerebellum and functionally coupled cortical regions associated with psychiatric symptoms in mid-childhood. These findings demonstrate that the genetic underpinnings of pediatric psychiatric symptoms differ from those of adult illness, and implicate fetal cerebellar developmental processes that endure through childhood.",
                "disciplines": [
                    "5202"
                ]
            },
            "10.1016/j.jclinepi.2023.02.020": {
                "title": "Origami plot: a novel multivariate data visualization tool that improves radar chart",
                "abstract": "OBJECTIVES: We propose the origami plot, which maintains the original functionality of a radar chart and avoids potential misuse of its connected regions, with newly added features to better assist multicriteria decision-making.\nSTUDY DESIGN AND SETTING: Built upon a radar chart, the origami plot adds additional auxiliary axes and points such that the area of the connected region of all dots is invariant to the ordering of axes. As such, it enables ranking different individuals by the overall performance for multicriteria decision-making while maintaining the intuitive visual appeal of the radar chart. We develop extensions of the origami plot, including the weighted origami plot, which allows reweighting of each attribute to define the overall performance, and the pairwise origami plot, which highlights comparisons between two individuals.\nRESULTS: We illustrate the different versions of origami plots using the hospital compare database developed by the Centers for Medicare & Medicaid Services (CMS). The plot shows individual hospital's performance on mortality, readmission, complication, and infection, as well as patient experience and timely and effective care, as well as their overall performance across these metrics. The weighted origami plot allows weighing the attributes differently when some are more important than others. We illustrate the potential use of the pairwise origami plot in electronic health records (EHR) system to monitor five clinical measures (body mass index [BMI]), fasting glucose level, blood pressure, triglycerides, and low-density lipoprotein ([LDL] cholesterol) of a patient across multiple hospital visits.\nCONCLUSION: The origami plot is a useful visualization tool to assist multicriteria decision making. It improves radar charts by avoiding potential misuse of the connected regions. It has several new features and allows flexible customization.",
                "disciplines": [
                    "4203"
                ]
            },
            "10.1371/journal.pone.0280192": {
                "title": "A privacy-preserving and computation-efficient federated algorithm for generalized linear mixed models to analyze correlated electronic health records data",
                "abstract": "Large collaborative research networks provide opportunities to jointly analyze multicenter electronic health record (EHR) data, which can improve the sample size, diversity of the study population, and generalizability of the results. However, there are challenges to analyzing multicenter EHR data including privacy protection, large-scale computation resource requirements, heterogeneity across sites, and correlated observations. In this paper, we propose a federated algorithm for generalized linear mixed models (Fed-GLMM), which can flexibly model multicenter longitudinal or correlated data while accounting for site-level heterogeneity. Fed-GLMM can be applied to both federated and centralized research networks to enable privacy-preserving data integration and improve computational efficiency. By communicating a limited amount of summary statistics, Fed-GLMM can achieve nearly identical results as the gold-standard method where the GLMM is directly fitted to the pooled dataset. We demonstrate the performance of Fed-GLMM in numerical experiments and an application to longitudinal EHR data from multiple healthcare facilities.",
                "disciplines": [
                    "4604"
                ]
            },
            "10.1016/j.jbi.2022.104243": {
                "title": "COMMUTE: Communication-efficient transfer learning for multi-site risk prediction",
                "abstract": "OBJECTIVES: We propose a communication-efficient transfer learning approach (COMMUTE) that effectively incorporates multi-site healthcare data for training a risk prediction model in a target population of interest, accounting for challenges including population heterogeneity and data sharing constraints across sites.\nMETHODS: We first train population-specific source models locally within each site. Using data from a given target population, COMMUTE learns a calibration term for each source model, which adjusts for potential data heterogeneity through flexible distance-based regularizations. In a centralized setting where multi-site data can be directly pooled, all data are combined to train the target model after calibration. When individual-level data are not shareable in some sites, COMMUTE requests only the locally trained models from these sites, with which, COMMUTE generates heterogeneity-adjusted synthetic data for training the target model. We evaluate COMMUTE via extensive simulation studies and an application to multi-site data from the electronic Medical Records and Genomics (eMERGE) Network to predict extreme obesity.\nRESULTS: Simulation studies show that COMMUTE outperforms methods without adjusting for population heterogeneity and methods trained in a single population over a broad spectrum of settings. Using eMERGE data, COMMUTE achieves an area under the receiver operating characteristic curve (AUC) around 0.80, which outperforms other benchmark methods with AUC ranging from 0.51 to 0.70.\nCONCLUSION: COMMUTE improves the risk prediction in a target population with limited samples and safeguards against negative transfer when some source populations are highly different from the target. In a federated setting, it is highly communication efficient as it only requires each site to share model parameter estimates once, and no iterative communication or higher-order terms are needed.",
                "disciplines": [
                    "4202"
                ]
            },
            "10.1016/j.eclinm.2022.101724": {
                "title": "Long-term kidney function recovery and mortality after COVID-19-associated acute kidney injury: An international multi-centre observational cohort study",
                "abstract": "Background: While acute kidney injury (AKI) is a common complication in COVID-19, data on post-AKI kidney function recovery and the clinical factors associated with poor kidney function recovery is lacking.\nMethods: A retrospective multi-centre observational cohort study comprising 12,891 hospitalized patients aged 18 years or older with a diagnosis of SARS-CoV-2 infection confirmed by polymerase chain reaction from 1 January 2020 to 10 September 2020, and with at least one serum creatinine value 1-365 days prior to admission. Mortality and serum creatinine values were obtained up to 10 September\u00a02021.\nFindings: Advanced age (HR 2.77, 95%CI 2.53-3.04, p\u00a0<\u00a00.0001), severe COVID-19 (HR 2.91, 95%CI 2.03-4.17, p\u00a0<\u00a00.0001), severe AKI (KDIGO stage 3: HR 4.22, 95%CI 3.55-5.00, p\u00a0<\u00a00.0001), and ischemic heart disease (HR 1.26, 95%CI 1.14-1.39, p\u00a0<\u00a00.0001) were associated with worse mortality outcomes. AKI severity (KDIGO stage 3: HR 0.41, 95%CI 0.37-0.46, p\u00a0<\u00a00.0001) was associated with worse kidney function recovery, whereas remdesivir use (HR 1.34, 95%CI 1.17-1.54, p\u00a0<\u00a00.0001) was associated with better kidney function recovery. In a subset of patients without chronic kidney disease, advanced age (HR 1.38, 95%CI 1.20-1.58, p\u00a0<\u00a00.0001), male sex (HR 1.67, 95%CI 1.45-1.93, p\u00a0<\u00a00.0001), severe AKI (KDIGO stage 3: HR 11.68, 95%CI 9.80-13.91, p\u00a0<\u00a00.0001), and hypertension (HR 1.22, 95%CI 1.10-1.36, p\u00a0=\u00a00.0002) were associated with post-AKI kidney function impairment. Furthermore, patients with COVID-19-associated AKI had significant and persistent elevations of baseline serum creatinine 125% or more at 180 days (RR 1.49, 95%CI 1.32-1.67) and 365 days (RR 1.54, 95%CI 1.21-1.96) compared to COVID-19 patients with no AKI.\nInterpretation: COVID-19-associated AKI was associated with higher mortality, and severe COVID-19-associated AKI was associated with worse long-term post-AKI kidney function recovery.\nFunding: Authors are supported by various funders, with full details stated in the acknowledgement section.",
                "disciplines": [
                    "3202"
                ]
            }
        }
    },
    "13043464": {
        "title": "Foreign Electoral Interference: Normative Implications in Light of International Law, Human Rights and Democratic Theory",
        "abstract": "The publication is an updated version of my dissertation accepted in March 2022. It is dedicated to the normative implications of foreign state interference in elections - in a much more comprehensive way than previously available publications. In the first part, relevant backgrounds in the history of ideas, historical aspects and findings from political science are presented. Then the research object is defined and illustrated, with examples of an economic, informational and technical nature. The methodology of the study is also explained. In the second to fourth part, the subject of investigation is examined from three different perspectives of international law. Three relevant norms of international law are each dealt with in a separate chapter: the international ban on intervention, the right of peoples to self-determination and political rights in accordance with Article 25 of the UN Covenant II. Criteria are developed with which permissible examples of foreign state electoral interference can be distinguished from impermissible: Violation of (human rights-compliant ) national electoral laws, disproportionate intensity or manipulation of the electoral process. In the fifth and final part, the insights gained are critically assessed from the perspective of democratic theory. The starting point is the assumption that all human beings, by virtue of their dignity, have a right to real political participation and are capable of critical debate. It shows which examples of foreign state influence on elections - whether legal or illegal - contradict the idea of undistorted representation or the standards of good deliberation. Overall, the study identifies a legality deficit, a legal protection deficit and a legitimacy deficit as possible consequences of foreign state election interference. Finally, some practical approaches are shown as to how democracies can react to foreign influence on elections, whereby not only the state and law should play a role, but also the media, civil society and ultimately all individuals entitled to vote are held accountable. The book also advocates more cooperation and stronger democratic structures at international level. An improvement in the quality of the discourse is to be preferred to confrontational options for action. The conclusion of the dissertation (pp. 200-206), however, is written in such a way that it can function as an independent summary of the book's most important insights.",
        "disciplines": [
            "4408",
            "4807",
            "4803"
        ],
        "publications": {
            "10.38107/037": {
                "title": "Foreign Electoral Interference: Normative Implications in Light of International Law, Human Rights, and Democratic Theory",
                "abstract": "Foreign interference in elections may have attracted increased public attention since 2016, but it is a practice virtually as old as modern electoral democracy itself. This book offers the most comprehensive account of its normative implications yet. It discusses relevant standards of international law, human rights, and democratic theory, thereby casting a net wide enough to address the fundamental value of human dignity as well as the conditions of real political autonomy. Ultimately, the book identifies potential deficits of legality, accountability, and legitimacy ensuing from certain types of foreign electoral interference, and it provides ideas on what can and should be done in response.",
                "disciplines": [
                    "4803",
                    "4807",
                    "4408"
                ]
            }
        }
    },
    "10008036": {
        "title": "Metal Halide Perovskite Spin-Orbit Torque Devices",
        "abstract": "This project aims to demonstrate a new, highly efficient spin-based electronic device by developing a fundamental understanding into the generation and transport of spin in metal halide perovskite based heterostructures. Using an interdisciplinary approach, this project expects to exploit the beneficial spin properties, low cost and scalable production methods of metal halide perovskites. It is expected that this project will deliver new functionality to these emerging materials to enable their application in highly efficient spintronic devices. These outcomes should provide significant benefits to the Australian advanced manufacturing sector by developing new knowledge, advanced technology and training skilled professionals.",
        "disciplines": [
            "3406"
        ],
        "publications": {
            "10.1002/adfm.202314696": {
                "title": "Design Principles of Diketopyrrolopyrrole\u2010Thienopyrrolodione Acceptor1\u2013Acceptor2 Copolymers",
                "abstract": "Abstract  The design principles of acceptor 1 \u2013acceptor 2 copolymers featuring alternating diketopyrrolopyrrole (DPP) and thienopyrrolodione (TPD) moieties are investigated. The investigated series of polymers is obtained by varying the aromatic linker between the two acceptor motifs between thiophene, thiazole, pyridine, and benzene. High electron affinities between 3.96 and 4.42\u00a0eV, facilitated by the synergy of the acceptor motifs are determined with optical gaps between 1.37 and 2.02\u00a0eV. Grazing incidence wide\u2010angle X\u2010ray scattering studies reveal a range of film morphologies after thermal annealing, including face\u2010on, end\u2010on and superstructure edge\u2010on\u2010like crystallites. Conversely, all materials form thin edge\u2010on layers on the polymer\u2013air interface, as demonstrated by multi\u2010elemental near\u2010edge X\u2010ray absorption fine\u2010structure spectroscopy. The benefit of the electron\u2010deficient linkers thiazole and pyridine is evident: In organic field effect transistors, electron mobilities of up to 4.6 \u00d7 10 \u22122 cm 2 V \u22121 s \u22121 are obtained with outstanding on/off current ratios of 5 \u00d7 10 5 , facilitated by the absence of detectable hole transport in these materials. Viability for all\u2010polymer solar cells is assessed in active layer blends with the donor polymer PM6, yielding a maximum average power conversion efficiency of 4.8% and an open circuit voltage above 1\u00a0V. ",
                "disciplines": [
                    "3403",
                    "4016"
                ]
            },
            "10.1063/5.0168129": {
                "title": "Quantum interference effects in a 3D topological insulator with high-temperature bulk-insulating behavior",
                "abstract": "The Bi2Se3-family of 3D topological insulators (3DTI) exhibit insulating bulk states and surface states presenting a Dirac cone. At low temperatures, the conduction channels through the bulk of the material are fully gapped, making 3DTIs perfect systems to study the 2D transport behavior of Dirac fermions. Here, we report a 3DTI Bi1.1Sb0.9STe2 with a reduced level of defects, and thus, high-temperature insulating behavior in its bulk states. The insulator-to-metal transition occurs at \u223c250 K, below which the bulk contributions are negligible. Even at room temperature, the conductivity contribution from the bulk channel is less than 20%. Quantum transport properties of topological surface states are observed in the Bi1.1Sb0.9STe2 nanoflake devices, e.g., high Hall mobility (\u223c1150 cm2/V s at 3 K), strong Shubnikov\u2013de Haas oscillations with \u03c0 Berry phase, weak antilocalization, and electron\u2013electron interaction. Notably, additional oscillation patterns with quasi-periodicity-in-B and field-independent amplitude features are observed. The surface dominant transport behavior up to room temperature suggests that Bi1.1Sb0.9STe2 is a room temperature topological insulator for electronic/spintronic applications.",
                "disciplines": [
                    "3403",
                    "4016"
                ]
            },
            "10.1103/physrevmaterials.7.064202": {
                "title": "Increased phase coherence length in a porous topological insulator",
                "abstract": "The surface area of Bi2Te3 thin films was increased by introducing nanoscale porosity. Temperature dependent resistivity and magnetotransport measurements were conducted both on as-grown and porous samples (23 and 70 nm). The longitudinal resistivity of the porous samples became more metallic, indicating the increased surface area resulted in transport that was more surfacelike. Weak antilocalization was present in all samples, and remarkably the phase coherence length doubled in the porous samples. This increase is likely due to the large Fermi velocity of the Dirac surface states. Our results show that the introduction of nanoporosity does not destroy the topological surface states but rather enhances them, making these nanostructured materials promising for low energy electronics, spintronics and thermoelectrics.",
                "disciplines": [
                    "5104"
                ]
            },
            "10.1038/s41699-023-00404-1": {
                "title": "Abnormal thickness-dependent magneto-transport properties of vdW magnetic semiconductor Cr2Si2Te6",
                "abstract": "Cr2Si2Te6 (CST) is a van der Waals (vdW) ferromagnetic semiconductor. The unique spin model and temperature-dependent magnetic ordering of CST provide opportunities for the next generation of two-dimensional (2D) spintronic devices. Here, abnormal magneto-transport properties are found in CST nanoflakes with variations in thickness. Interestingly, the thickness-dependent magnetoresistance (MR) effect exhibits a nonlinear change as a function of the magnetic field, temperature, and thickness. At a certain temperature below Curie temperature (Tc), a sign reversal of MR ratio from positive to negative can even be detected with thickness reduction. At the temperature range from Tc to 60\u2009K, the Hall effect also presents a transformation from nonlinear behavior in thick layer CST to linear behavior in thin layer CST. These distinctive magneto-transport properties are attributed to the variation of spin correlation with thickness in CST nanoflakes. These findings probe the unique magneto-transport properties of CST and associate it with ferromagnetic correlation, which provides a basis for subsequent spintronics device design based on this material. This work also offers new insights into the relationship between sample thickness, transport properties, and spin correlation of other vdW ferromagnets. It lays a foundation for future vdW magnet-based device fabrication and possible spintronic applications.",
                "disciplines": [
                    "4016",
                    "4009"
                ]
            }
        }
    },
    "10008008": {
        "title": "Analysis and design of midrise built-up cold-formed steel structures",
        "abstract": "The project will develop an analytical and computational basis for designing midrise buildings in cold-formed steel. It will enable solutions with high column capacities and high lateral load resistance to be realised by using built-up sections, thus overcoming the current barrier to constructing buildings up to 10 storeys from cold-formed steel and enabling green, fully recyclable and rapidly constructed buildings to be achieved. Experimental, analytical and computational studies will be undertaken and synthesised into efficient design guidelines for practising engineers, including structural reliability analyses at system level of midrise buildings featuring innovative built-up multi-section columns and integrated shear panels.",
        "disciplines": [
            "4005"
        ],
        "publications": {
            "10.1061/jsendh.steng-12655": {
                "title": "Stiffness Reduction of Cold-Formed Steel Structures Subject to Sectional Buckling and Yielding",
                "abstract": "The paper develops a stiffness reduction factor to be used in geometric nonlinear beam-element type elastic analysis of cold-formed steel structures. The factor accounts for the reduction in flexural and warping torsion rigidities resulting from local and distortional buckling as well as residual stresses, particular to cold-formed steel structures. The purpose of applying the factor is to accurately account for the geometric second order effects when predicting the internal distributions of moments of cold-formed steel structural frames. The stiffness reduction factor arising from local and distortional buckling is first determined followed by the stiffness reduction factor caused by residual stresses. Subsequently, the two effects are combined in a single expression, which is a format suitable for incorporation in the North American specification for cold-formed steel structures, AISI-S100.",
                "disciplines": [
                    "4005"
                ]
            }
        }
    },
    "13243051": {
        "title": "Ionospheric Detection and Imaging of Earthquakes and Tsunamis \u2013 IONO-DIET",
        "abstract": "The Project IONO-DIET aims to develop, for the first time, ionosphere-based methods that will detect earthquakes and tsunamis in near-real-time (NRT), and will determine the earthquake source parameters and/or tsunami wave-heights from the ionosphere in NRT. The latter will be done based on detection of co-seismic and co-tsunamic ionospheric disturbances by GNSS receivers. The ambition of IONO-DIET is to contribute in the improvement of the existing warning systems by rapidly providing the missing piece of information about the seismic source and the tsunami-genesis of an earthquake, or the estimates of the wave heights of tsunamis propagating in open sea. The idea to use ionospheric measurements for tsunami warnings is not new. However, despite several promising seismo-ionospheric results presented recently, the system is not yet there. IONO-DIET aims to become the last step before the ionosphere-based EQ/tsunami risk assessment system becomes a reality.Our approach is based on development of empirical relationships between earthquake & tsunami parameters and their ionospheric signatures. To fully achieve this main goal, it is necessary to address the following specific objectives: 1) to advance in the understanding of the solid Earth/ocean/atmosphere/ionosphere coupling and to respond the fundamental scientific questions; 2) to distinguish NH-driven disturbances from those of other origins. For this purpose, we\u2019ll work on and resolve the biggest challenge in the modern ionospheric sciences - the identification and differentiation of the source of travelling ionospheric disturbances (TIDs); 3) to develop a few novel methodologies that satisfy the NRT requirements by being precise and rapid.     To perform the Project\u2019s Tasks, besides the permanent staff in both institutes, we plan to recruit 1PhD Student, 2 PostDocs and 1 Engineer. The recruitment charges and the workload will be divided equally between France and Brazil.",
        "disciplines": [
            "3706"
        ],
        "publications": {
            "10.1186/s40623-023-01940-2": {
                "title": "Ionospheric response to the 2020 Samos earthquake and tsunami",
                "abstract": "On 30 October 2020 at 11:51 UT, a magnitude 7.0 earthquake occurred in the Dodecanese sea (37.84\u00b0N, 26.81\u00b0E, 10\u00a0km depth) and generated a tsunami with an observed run-up of more than 1\u00a0m on the Turkish coasts. Both the earthquake and the tsunami produced acoustic and gravity waves that propagated upward, triggering co-seismic and co-tsunamic ionospheric disturbances. This paper presents a multi-instrumental study of the ionospheric impact of the earthquake and related tsunami based on ionosonde data, ground-based Global Navigation Satellite Systems (GNSS) data and data from DORIS beacons received by Jason3 in the Mediterranean region. Our study focuses on the Total Electron Content to describe the propagation of co-seismic and co-tsunami ionospheric disturbances (CSID, CTID), possibly related to gravity waves triggered by the earthquake and tsunami. We use simultaneous vertical ionosonde soundings to study the interactions between the upper and lower atmosphere, highlighting the detection of acoustic waves generated by the seismic Rayleigh waves reaching the ionosonde locations and propagating vertically up to the ionosphere. The results of this study provide a detailed picture of the Lithosphere-Atmosphere\u2013Ionosphere coupling in the scarcely investigated Mediterranean region and for a relatively weak earthquake.Graphical abstract",
                "disciplines": [
                    "3706"
                ]
            },
            "10.1029/2022ja031231": {
                "title": "Rapid Detection of Co\u2010Seismic Ionospheric Disturbances Associated With the 2015 Illapel, the 2014 Iquique and the 2011 Sanriku\u2010Oki Earthquakes",
                "abstract": "Abstract Co\u2010seismic Ionospheric disturbances (CID, or \u201cionoquakes\u201d) are disturbances in the electron density or total electron content (TEC) of the ionosphere, produced by the ground motion due to earthquakes. Usually, ionoquakes are detected in the near\u2010epicentral region within 8\u201310\u00a0min after an earthquake onset time. In this work, we present a new methodology that allows to estimate the CID arrival time based on determining the CID peak time in TEC measurements with respect to the peak time of seismic waves registered by the nearest seismic station. Our methodology also allows to understand the altitude of GNSS detection that otherwise remains ambiguous. We apply the newly developed techniques to detect CID signatures associated with three large earthquakes: the 2015 Illapel, the 2014 Iquique, and the 2011 Sanriku\u2010Oki. We show that for these events, the CID arrive 250\u2013430\u00a0s after the time of the seismic wave peak, or 350\u2013700\u00a0s after the earthquake onset time. Our analysis show that the first CID are detected at the altitudes of 150\u2013180\u00a0km (the Sanriku earthquake) and of 200\u2013300\u00a0km (the Illapel and the Iquique earthquakes). The disturbances represent high\u2010frequency acoustic oscillations that propagate with a horizontal speed faster than 0.75\u00a0km/s.\nKey Points    A new methodology to rapidly estimate the time and the altitude of detection of co\u2010seismic ionospheric disturbances (CID)   The methodology uses data from near\u2010epicenter seismic stations to calculate the seismic peak time as an alternative to the earthquake onset   First report on detection of CID as soon as 400\u00a0s after the earthquake onset and 250\u2013430\u00a0s after the seismic peak time   ",
                "disciplines": [
                    "3706"
                ]
            },
            "10.1029/2023ja031663": {
                "title": "The 6 February 2023 T\u00fcrkiye Earthquake Sequence as Detected in the Ionosphere",
                "abstract": "Abstract On 6 February 2023, a series of large earthquakes struck Turkey and Northern Syria. The main earthquake of Mw 7.8 occurred at 01:17:34 UTC and was followed by the three notable (Mw\u00a0>\u00a05.5) aftershocks within the next 18\u00a0min. Then, \u223c9\u00a0hr later, the biggest aftershock with magnitude Mw 7.5 and a Mw 6.0 earthquake occurred to the north\u2010east from the first main earthquake. In this work, we use data of ground\u2010based Global Navigation Satellite Systems (GNSS) receivers in Turkey, Israel and Cyprus to analyze the ionospheric response to this series of earthquakes. We separate these events in two groups: the first sequence of earthquakes (at 01\u201302 UTC) and the second sequence (at 10\u201311 UTC). For the first sequence, we observe a clear N\u2010shaped total electron content (TEC) response after the Mw 7.8 mainshock earthquake and Mw 6.7 aftershock, and a smaller TEC disturbance that is, most likely, caused by the Mw 5.6 earthquake. The latter is now the smallest earthquake detected by using ionospheric GNSS data. The co\u2010seismic ionospheric disturbances (CSID) propagated from the epicentral area in the south\u2010west direction with velocities of about 750\u2013830\u00a0m/s. For the second sequence, we observed the response to the Mw 7.5 aftershock earthquake and the Mw 6.0 aftershock. The CSID propagated both to the south\u2010west and the north\u2010west to the epicentral area, with velocities of about 950\u20131,100\u00a0m/s.\nKey Points    By using Global Navigation Satellite Systems data, we analyze ionospheric total electron content (TEC) response to the Turkey earthquake sequences of 6 February 2023   We detect strong ionospheric response to two Mw7.5+ earthquakes and weaker signatures after three smaller aftershocks with Mw\u00a0<\u00a06.7   The TEC response was the largest\u00a0on the south\u2010west from the epicentral areas for all earthquakes   ",
                "disciplines": [
                    "3706"
                ]
            },
            "10.1029/2022gl101465": {
                "title": "Ocean\u2010Ionosphere Disturbances Due To the 15 January 2022 Hunga\u2010Tonga Hunga\u2010Ha'apai Eruption",
                "abstract": "Abstract We investigate the oceanic and ionospheric response in New Caledonia\u2010New Zealand and Chile\u2010Argentina to the 15 January 2022 Hunga\u2010Tonga volcanic eruption. For the first time, we highlight a reversed response in the oceans and in the ionosphere in terms of the amplitudes. The sea\u2010surface fluctuations due to the passage of the atmospheric Lamb wave (i.e., air\u2010sea wave) were not remarkable while the related ionospheric perturbation was considerable. Reversely, the eruption\u2010induced tsunami (\u201cregular\u201d tsunami) caused major variations in sea\u2010surface heights (\u223c1\u00a0m near the volcano and \u223c2\u00a0m along the Chilean coastline), whereas the associated ionospheric perturbation was quite small. The observed large\u2010amplitude ionospheric response due to Lamb waves propagation is difficult to explain, and the coupling between the Lamb wave and the ionosphere is not well\u2010understood yet. For the first time, we estimate the delay between the Lamb waves and their signatures in the ionosphere to be \u223c12\u201320\u00a0min.\nPlain Language Summary The eruption of Hunga\u2010Tonga volcano produced a variety of atmospheric and tsunami waves recorded all over the world. We study the impacts of the eruption together on the oceans and in the ionosphere in New Caledonia\u2010New Zealand (near the volcano) and Chile\u2010Argentina (far from the volcano). At the sea surface, we observe two phenomena causing sea\u2010height variations. The first is a small tsunami (air\u2010sea wave) created by the Lamb wave: the high\u2010pressure atmospheric wave triggered by the eruption. The second is the tsunami induced by the eruption itself. Spectacularly, at 300\u00a0km altitude, in the ionosphere, we observe perturbations in the electron content caused by the Lamb wave and by the regular tsunami. We are the first to report on the reversed amplitude of the two phenomena in the oceans and in the ionosphere. The sea\u2010surface perturbation caused by the Lamb wave was not significant, while ionospheric perturbation was considerable. In contrast, the regular tsunami wave produced major variations. For the first time, we estimate the time delay between the Lamb wave and its signature in the ionosphere.\nKey Points    Joint study of oceanic and ionospheric response in New Caledonia\u2010New Zealand and Chile\u2010Argentina to the 15 January 2022 volcanic eruption   Near\u2010surface propagating Lamb wave caused a small tsunami in the ocean (air\u2010sea wave) and unusually strong disturbances in the ionosphere   Inversely, the eruption\u2010generated tsunami showed significant wave heights in the ocean and much smaller response in the ionosphere   ",
                "disciplines": [
                    "3708",
                    "4015",
                    "3705",
                    "3706"
                ]
            }
        }
    },
    "13057794": {
        "title": "Supplement for Role of Environmental Weathering and Gastrointestinal Digestion on the Bioavailability and Toxicity of Microplastic and Cadmium Mixtures",
        "abstract": "Project Summary of Diversity Supplement In this supplement, the postdoctoral fellow candidate Dr. Justin Scott will carry out a project with the overall goal of understanding the sorption of organic compounds onto weathered MPs and nanoplastics (NPs), and MPs and NPs bioaccumulation and toxicity in fish (RTgutGC) and human (Caco2) intestinal cell lines. This will allow us to better understand their transformation and fate after ingestion and determine exposure risk and potential adverse effects. Justin will complement his toxicological training by learning advanced spectroscopy and environmental chemistry methodologies under the supervision of Dr. Jorge Gonzalez Estrella. Through the incorporation of analytical techniques such as dynamic light scattering (DLS), zeta potential, Fourier transform infrared (FTIR), scanning electron microscopy (SEM), and pyrolysis gas chromatography mass spectrophotometry (py-GC-MS) we will gain a better understanding of MP and NPs reactivity and adverse effects. Importantly, the reactivity of specific weathered (i.e., UV aged and oxidized) MPs/NPs types (i.e., polyethylene, polyvinyl chloride, and polypropylene) with specific organic chemical mixtures (i.e., lindane, dichlorodiphenyldichloroethylene (DDE), and azoxystrobin) will be determined. In addition, the adverse effect of MPs/NPs alone or in co-exposure with organics will be evaluated using a physiologically relevant exposure system which includes in vitro digestion and intestinal cells lines. We hypothesize that environmental weathering of MPs and NPs will increase sorption of organic chemical mixtures onto them, which will increase the contaminant uptake by the intestinal epithelium. Moreover, gastrointestinal and digestive processes will allow desorption of chemicals from MPs and NPs and an increase in bioaccumulation and cytotoxicity. Aim .1 Evaluate the reactivity of weathered MP and NP with organic chemical mixtures in exposure media; Aim 2: Evaluate the Fate of organic chemical mixtures and MPs/NPs in the exposure system; and Aim 3: Evaluate the role of gastrointestinal digestion processes on MPs/NPs reactivity with organic chemicals and effect in intestinal cells.",
        "disciplines": [
            "4105",
            "4102",
            "3206"
        ],
        "publications": {
            "10.21203/rs.3.rs-4345687/v1": {
                "title": "Bioaccumulation of Microplastics in Decedent Human Brains Assessed by Pyrolysis Gas Chromatography-Mass Spectrometry",
                "abstract": "Rising global concentrations of environmental micro- and nanoplastics (MNPs) drive concerns for human exposure and health outcomes. Applying pyrolysis gas chromatography-mass spectrometry (Py-GC/MS) methods to isolate and quantify MNPs from human samples, we compared MNP accumulation in kidneys, livers, and brains. Autopsy samples from the Office of the Medical Investigator in Albuquerque, NM, collected in 2016 and in 2024, were digested for Py-GC/MS analysis of 12 polymers. Brains exhibited higher concentrations of MNPs than liver or kidney samples. All organs exhibited significant increases from 2016 to 2024. Polyethylene was the predominant polymer; the relative proportion of polyethylene MNPs was greater in brain samples than in liver or kidney. Transmission electron microscopy verified the nanoscale nature of isolated particles, which largely appeared to be aged, shard-like plastics remnants across a wide range of sizes. Results demonstrate that MNPs are selectively accumulated into the human brain and concentrations are rising over time.",
                "disciplines": [
                    "4105"
                ]
            },
            "10.1093/toxsci/kfae021": {
                "title": "Quantitation and identification of microplastics accumulation in human placental specimens using pyrolysis gas chromatography mass spectrometry",
                "abstract": "The exponential increase in global plastic usage has led to the emergence of nano- and microplastic (NMP) pollution as a pressing environmental issue due to its implications for human and other mammalian health. We have developed methodologies to extract solid materials from human tissue samples by saponification and ultracentrifugation, allowing for highly specific and quantitative analysis of plastics by pyrolysis-gas chromatography and mass spectrometry (Py-GC-MS). As a benchmark, placenta tissue samples were analyzed using fluorescence microscopy and automated particle count, which demonstrated the presence of >1-micron particles and fibers, but not nano-sized plastic particles. Analyses of the samples (n\u2009=\u200910) using attenuated total reflectance-Fourier transform infrared spectroscopy indicated presence of rayon, polystyrene, polyethylene, and unclassified plastic particles. By contrast, among 62 placenta samples, Py-GC-MS revealed that microplastics were present in all participants' placentae, with concentrations ranging widely from 6.5 to 685\u2009\u00b5g NMPs per gram of placental tissue, averaging 126.8\u2009\u00b1\u2009147.5\u2009\u00b5g/g (mean\u00b1SD). Polyethylene was the most prevalent polymer, accounting for 54% of total NMPs and consistently found in nearly all samples (mean 68.8\u2009\u00b1\u200993.2\u2009\u00b5g/g placenta). Polyvinyl chloride and nylon each represented approximately 10% of the NMPs by weight, with the remaining 26% of the composition represented by 9 other polymers. Together, these data demonstrate advancements in the unbiased quantitative resolution of Py-GC-MS applied to the identification and quantification of NMP species at the maternal-fetal interface. This method, paired with clinical metadata, will be pivotal to evaluating potential impacts of NMPs on adverse pregnancy outcomes.",
                "disciplines": [
                    "3214"
                ]
            }
        }
    },
    "13741096": {
        "title": "Blocking Neuroimmune Communication as a Treatment for Endometriosis-Associated Pain",
        "abstract": "PUBLIC ABSTRACT\n\nEndometriosis is an inflammatory disease that affects up to 10% of women in reproductive age with annual health care costs approaching $70 billion in the U.S. alone. Debilitating pain causes affected women to lose, on average, 11 hours of work weekly, primarily as a result of reduced effectiveness during working time, while for the U.S. Army, chronic pain leads to roughly 20,000 days of lost duty time per year. This is also extended to U.S. Army dependents, as more than 75% of U.S. Army dependents who had undergone laparoscopy or laparotomy because of pelvic pain were diagnosed with endometriosis. Moreover, this debilitating chronic pelvic pain also contributes to depressive symptoms and anxiety symptoms that, ultimately, might lead to decreased work, social engagement, and relationships with colleagues and family in endometriosis patients. Current treatments for pain in women with endometriosis are limited to the use of non-steroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen, hormonal agents such as birth control pills, and surgical removal of the lesions. However, patients often do not respond or experience limited benefit from hormonal therapies, NSAIDs present several side effects and should be used with cautious by patients with other comorbidities, and even after surgery, disease and pain recurrence are very common. Therefore, new medical therapies and targets that provide long-term benefits, including pain relief, are still urgently needed. \n\n \n\nThe perception of pain is transmitted by specialized nerve cells called \u201cnociceptors.\u201d Recent studies demonstrate that nociceptors not only can sense pain but also release \u201cneuropeptides\u201d such as calcitonin gene-related peptide (CGRP) to orchestrate inflammation and the activity of immune cells. This process is called \u201cneuroimmune communication.\u201d To produce its effect, CGRP acts on the receptor activity modifying protein 1 (RAMP1). Macrophage is a type of immune cell that is responsible for the engulfment and destruction of target cells and microorganisms. They are the main cells in the peritoneal cavity (abdominal space), and during endometriosis, macrophages change their activity to promote the growth and support of endometriosis lesions. We did preliminary experiments and found that mice without a specific type of nociceptor (TRPV1+ nociceptors) show less pain and grow smaller endometriotic lesions. In corroboration, we also did preliminary experiments with a U.S. Food and Drug Administration (FDA)-approved drug that blocks RAMP1 called rimegepant. Rimegepant-treated animals showed less pain, fewer lesions, and the remaining lesions were smaller when compared to the non-treated animals. This indicates that blocking CGRP/RAMP1 signaling might not only relieve pain but also actively eliminate lesions and reduce the growth of remaining endometriotic lesions. Ultimately, this indicates that CGRP or RAMP1 targeting drugs can provide long-term benefit for patients. In this project, to confirm the efficacy of this type of drug, we will test three additional FDA-approved drugs that target either CGRP or RAMP1, namely ubrogepant (small molecule RAMP1 antagonist, but structurally distinct from rimegepant), fremanezumab (monoclonal antibody against CGRP), and erenumab (monoclonal antibody against RAMP1). We hypothesize that neuropeptide CGRP release by nociceptors is the main driver of endometriosis-associated pain and lesion growth/establishment. Therefore, silencing the communication of nociceptors to macrophages by blocking CGRP/RAMP1 signaling can treat endometriosis pain. \n\n \n\nMost work on endometriosis therapeutics targets either endocrine hormones and/or their receptors. This multidisciplinary project is conceptually innovative because it combines approaches from three disciplines (neuroscience, immunology, and pharmacology) to validate CGRP/RAMP1 as a non-opioid and non-hormonal therapy for endometriosis-associated pain. Combining different techniques (e.g., chemogenetic activation of lesion-restricted nociceptors, cell culture) with the use of FDA-approved drugs that block CGRP/RAMP1 signaling, we aim to address two biologically significant and clinically relevant questions about endometriosis: \n\na) Does the communication between nociceptor neurons (through the release of CGRP) to macrophages contribute to lesion growth and implantation in vivo? \n\nb) Can CGRP/RAMP1 blocking strategies be used to treat endometriosis? \n\n \n\nBy answering question \u201ca,\u201d we will demonstrate that CGRP release activates RAMP1 receptor in macrophages and changes their phenotype to promote lesion growth and implantation. We will also leverage state-of-the-art techniques, such as single cell RNA sequencing, to identify macrophage populations that are responsible for endometriosis lesion growth vs. endometriosis lesion resolution upon nociceptor neuron activation and inhibition, respectively. By answering question \u201cb,\u201d we will demonstrate that blocking nociceptor to macrophage communication through CGRP/RAMP1 signaling with rimegepant, ubrogepant, fremanezumab, and erenumab could be a significant and innovative non-hormonal and non-opioid approach for endometriosis treatment. \n\n \n\nThis proposal responds to the Fiscal Year 2022 Peer Reviewed Medical Research Program Endometriosis Topic Area. Specifically, we address the following areas of encouragement in endometriosis research designated by the Department of Defense: (1) improve understanding of long-term complications and comorbidities of associated diseases and conditions, and (2) develop and test novel treatments for associated diseases and conditions. Overall, this project aims to reduce the negative effects of chronic pain among a substantial proportion of active-duty military members, Veterans, and their families who are burdened by the consequences of endometriosis.",
        "disciplines": [
            "3215",
            "3202"
        ],
        "publications": {
            "10.1101/2023.08.28.555101": {
                "title": "Nociceptor to macrophage communication through CGRP/RAMP1 signaling drives endometriosis-associated pain and lesion growth",
                "abstract": "Abstract  Endometriosis is a debilitating and painful gynecological inflammatory disease affecting approximately 15% of women. Current treatments are ineffective for a significant fraction of patients, underscoring the need for new medical therapies with long-term benefits. Given the genetic correlation between migraines and endometriosis, we sought evidence for the role of CGRP-mediated neuroimmune communication in endometriosis. We found that mouse and human endometriosis lesions contained CGRP and RAMP1. In mice, nociceptor ablation reduced pain, monocyte recruitment, and lesion size, suggesting that nociceptors support endometriosis lesions. In vitro, CGRP-treated macrophages showed impaired efferocytosis and supported endometrial cell growth in a RAMP1-dependent manner. Treatment with FDA-approved drugs that block CGRP-RAMP1 signaling reduced evoked and spontaneous pain, and lesion size. Since the lack of drug efficacy at reducing ongoing pain drives most endometriosis therapy failure, our data demonstrating effectiveness of non-hormonal and non-opioid CGRP/RAMP1 blocking therapies may lead to clinical benefit for endometriosis patients. ",
                "disciplines": [
                    "3209",
                    "3202"
                ]
            }
        }
    },
    "9852715": {
        "title": "Topological phases of matter for quantum computation",
        "abstract": "A global effort is underway to build quantum computers at scale. There are promising approaches based on quantum phases of matter with exotic topological properties that are harnessed to protect fragile quantum information. This project aims to take advantage of recent breakthroughs in three dimensional topological phases to discover new materials and design better components for quantum computers. This addresses the significant question of what the analogue of a transistor will be in a full scale quantum computer. Benefits include classification of three dimensional topological phases and the discovery of better routes to scalable quantum computing, potentially causing a fundamental shift in the direction of this global research effort.",
        "disciplines": [
            "4009",
            "5104"
        ],
        "publications": {
            "10.1103/physrevb.109.205125": {
                "title": "Boundaries and defects in the cubic code",
                "abstract": "Haah's cubic code is the prototypical type-II fracton topological order. It instantiates the no stringlike operator property that underlies the favorable scaling of its code distance and logical energy barrier. Previously, the cubic code was only explored in translation-invariant systems on infinite and periodic lattices. In these settings, the code distance scales superlinearly with the linear system size, while the number of logical qubits within the degenerate ground space exhibits a complicated functional dependence that undergoes large fluctuations within a linear envelope. Here, we extend the cubic code to systems with open boundary conditions and crystal lattice defects. We characterize the condensation of topological excitations in the vicinity of these boundaries and defects, finding that their inclusion can introduce local stringlike operators and enhance the mobility of otherwise fractonic excitations. Despite this, we use these boundaries and defects to define new encodings where the number of logical qubits scales linearly without fluctuations, and the code distance scales superlinearly, with the linear system size. These include a subsystem encoding with open boundary conditions and a subspace encoding using lattice defects.",
                "disciplines": []
            }
        }
    },
    "10007803": {
        "title": "Shape4D: Modelling the Spatiotemporal Deformation Patterns in 3D Shapes",
        "abstract": "This research will develop new mathematical methods and algorithms that will enable the use of population-level longitudinal studies to model the spatial and temporal deformation patterns in 3D biological objects. Using novel geometric and deep learning techniques, it will create new methods that will allow the characterization of how the 3D shape of objects deforms with ageing, disease progression and interaction with their environment, and the simulation of spatiotemporal deformations in anatomical organs. Benefits include a better understanding of growth processes, predictive models of how degenerative diseases progress and a computational framework that will assist in designing proper mitigation and intervention strategies.",
        "disciplines": [
            "4607"
        ],
        "publications": {
            "10.1111/cgf.14942": {
                "title": "Structure learning for 3D Point Cloud Generation from Single RGB Images",
                "abstract": "Abstract 3D point clouds can represent complex 3D objects of arbitrary topologies and with fine\u2010grained details. They are, however, hard to regress from images using convolutional neural networks, making tasks such as 3D reconstruction from monocular RGB images challenging. In fact, unlike images and volumetric grids, point clouds are unstructured and thus lack proper parameterization, which makes them difficult to process using convolutional operations. Existing point\u2010based 3D reconstruction methods that tried to address this problem rely on complex end\u2010to\u2010end architectures with high computational costs. Instead, we propose in this paper a novel mechanism that decouples the 3D reconstruction problem from the structure (or parameterization) learning task, making the 3D reconstruction of objects of arbitrary topologies tractable and thus easier to learn. We achieve this using a novel Teacher\u2010Student network where the Teacher learns to structure the point clouds. The Student then harnesses the knowledge learned by the Teacher to efficiently regress accurate 3D point clouds. We train the Teacher network using 3D ground\u2010truth supervision and the Student network using the Teacher's annotations. Finally, we employ a novel refinement network to overcome the upper\u2010bound performance that is set by the Teacher network. Our extensive experiments on ShapeNet and Pix3D benchmarks, and on in\u2010the\u2010wild images demonstrate that the proposed approach outperforms previous methods in terms of reconstruction accuracy and visual quality.",
                "disciplines": [
                    "4607",
                    "4611"
                ]
            },
            "10.1109/tpami.2022.3163720": {
                "title": "4D Atlas: Statistical Analysis of the Spatiotemporal Variability in Longitudinal 3D Shape Data",
                "abstract": "We propose a novel framework to learn the spatiotemporal variability in longitudinal 3D shape data sets, which contain observations of objects that evolve and deform over time. This problem is challenging since surfaces come with arbitrary parameterizations and thus, they need to be spatially registered. Also, different deforming objects, hereinafter referred to as 4D surfaces, evolve at different speeds and thus they need to be temporally aligned. We solve this spatiotemporal registration problem using a Riemannian approach. We treat a 3D surface as a point in a shape space equipped with an elastic Riemannian metric that measures the amount of bending and stretching that the surfaces undergo. A 4D surface can then be seen as a trajectory in this space. With this formulation, the statistical analysis of 4D surfaces can be cast as the problem of analyzing trajectories embedded in a nonlinear Riemannian manifold. However, performing the spatiotemporal registration, and subsequently computing statistics, on such nonlinear spaces is not straightforward as they rely on complex nonlinear optimizations. Our core contribution is the mapping of the surfaces to the space of Square-Root Normal Fields (SRNF) where the [Formula: see text] metric is equivalent to the partial elastic metric in the space of surfaces. Thus, by solving the spatial registration in the SRNF space, the problem of analyzing 4D surfaces becomes the problem of analyzing trajectories embedded in the SRNF space, which has a euclidean structure. In this paper, we develop the building blocks that enable such analysis. These include: (1) the spatiotemporal registration of arbitrarily parameterized 4D surfaces even in the presence of large elastic deformations and large variations in their execution rates; (2) the computation of geodesics between 4D surfaces; (3) the computation of statistical summaries, such as means and modes of variation, of collections of 4D surfaces; and (4) the synthesis of random 4D surfaces. We demonstrate the performance of the proposed framework using 4D facial surfaces and 4D human body shapes.",
                "disciplines": [
                    "4607"
                ]
            }
        }
    },
    "13308152": {
        "title": "Machine Translation for Open Science \u2013 MaTOS",
        "abstract": "The MaTOS (Machine Translation for Open Science) project aims to develop new methods for the machine translation (MT) of complete scientific documents, as well as automatic metrics to evaluate the quality of these translations. Our main application target is the translation of scientific articles between French and English, where linguistic resources can be exploited to obtain more reliable translations, both for publication purposes and for gisting and text mining. However, efforts to improve MT of complete documents are hampered by the inability of existing automatic metrics to detect weaknesses in the systems and to identify the best ways to remedy them. The MaTOS project aims to address both of these issues.This project is part of a movement to automate the processing of scientific articles; MT is no exception to this trend, particularly in the biomedical field. Applications are numerous: text mining, bibliometric analysis, automatic detection of plagiarism and articles reporting falsified conclusions, etc. We wish to take advantage of the results of these works, but also to contribute to it in many ways: (a) by developing new open resources for specialised MT; (b) by improving, through the study of terminological variations, the description of textual coherence markers for scientific articles; (c) by studying new methods of multilingual processing for these documents; (d) by proposing metrics dedicated to the measurement of progress for this type of task. The final result will allow, through improved translation, the circulation and dissemination of scientific knowledge.",
        "disciplines": [
            "4605",
            "4704"
        ],
        "publications": {
            "10.1016/j.csl.2024.101623": {
                "title": "Translating scientific abstracts in the bio-medical domain with structure-aware models",
                "abstract": "Machine Translation (MT) technologies have improved in many ways and generate usable outputs for a growing number of domains and language pairs. Yet, most sentence based MT systems struggle with contextual dependencies, processing small chunks of texts, typically sentences, in isolation from their textual context. This is likely to cause systematic errors or inconsistencies when processing long documents. While various attempts are made to handle extended contexts in translation, the relevance of these contextual cues, especially those related to the structural organization, and the extent to which they affect translation quality remains an under explored area. In this work, we explore ways to take these structural aspects into account, by integrating document structure as an extra conditioning context. Our experiments on biomedical abstracts, which are usually structured in a rigid way, suggest that this type of structural information can be useful for MT and document structure prediction. We also present in detail the impact of structural information on MT output and assess the degree to which structural information can be learned from the data.",
                "disciplines": [
                    "4605"
                ]
            }
        }
    },
    "9206232": {
        "title": "Synthesis and photophysical properties of luminescent coordination polymer glasses",
        "abstract": "In this study, we aimed to study the optical properties of the coordination polymer glass state and to form a novel photofunctional metal complex glass. By imparting high luminescence properties in the glass state of coordination polymers composed of metals and organic substances, it is expected that a new group of functional substances having both the glass state with excellent transparency and moldability and the luminescence functionality of metal complex molecules will be obtained. Will be done. In the first six months, the characteristics of the light emission characteristics of the glassy coordination polymer were investigated. Therefore, by doping the existing glassy coordination polymer, which is predicted to have wide ultraviolet-visible light transmission, with a metal complex dye, its characteristics were investigated by analyzing its emission characteristics. As a result, it was found that the glass state of the coordination polymer composed of zinc, imidazole and phosphoric acid shows high transparency in a wide wavelength region of 350-800 nm. This glass state can be made into a transparent glass state of 1 cm square in a quartz cell by the melt quench method. In order to investigate the effect on the luminescence characteristics inside, luminescent metal complex molecules such as ruthenium polypyridyl were introduced into the coordination polymer glass, and PMMA and other organic polymers that have been reported so far have been introduced. It showed a higher quantum yield and excitation lifetime than glass. This is considered to be the result of the high polarity of the coordination polymer consisting of metal and anion, and it is considered that it works favorably in promoting the excited state and the luminescence process. In order to form a glass state with a novel luminescent metal complex, which is considered to be a future development, it is necessary to handle various metal species and organic ligands and conduct research on photofunctionality. Therefore, this research project will be temporarily suspended in order to carry out research in a research group of an overseas institution that is very good at them.",
        "disciplines": [
            "3402",
            "3403"
        ],
        "publications": {
            "10.1039/d0sc01737j": {
                "title": "Coordination polymer glass from a protic ionic liquid: proton conductivity and mechanical properties as an electrolyte",
                "abstract": "High proton conducting electrolytes with mechanical moldability are a key material for energy devices. We propose an approach for creating a coordination polymer (CP) glass from a protic ionic liquid for a solid-state anhydrous proton conductor. A protic ionic liquid (dema)(H<sub>2</sub>PO<sub>4</sub>), with components which also act as bridging ligands, was applied to construct a CP glass (dema)<sub>0.35</sub>[Zn(H<sub>2</sub>PO<sub>4</sub>)<sub>2.35</sub>(H<sub>3</sub>PO<sub>4</sub>)<sub>0.65</sub>]. The structural analysis revealed that large Zn-H<sub>2</sub>PO<sub>4</sub> <sup>-</sup>/H<sub>3</sub>PO<sub>4</sub> coordination networks formed in the CP glass. The network formation results in enhancement of the properties of proton conductivity and viscoelasticity. High anhydrous proton conductivity (<i>\u03c3</i> = 13.3 mS cm<sup>-1</sup> at 120 \u00b0C) and a high transport number of the proton (0.94) were achieved by the coordination networks. A fuel cell with this CP glass membrane exhibits a high open-circuit voltage and power density (0.15 W cm<sup>-2</sup>) under dry conditions at 120 \u00b0C due to the conducting properties and mechanical properties of the CP glass.",
                "disciplines": []
            }
        }
    },
    "9852654": {
        "title": "Child victims: Providing protection from re-victimisation and offending",
        "abstract": "This project aims to improve understanding of the impact of child abuse, neglect and exposure to domestic violence on young people\u2019s future experiences of re-victimisation and offending. It expects to generate new evidence about the maltreatment experiences that increase risk of youth re-victimisation and offending, potential causal mechanisms and factors that might aggravate or buffer children from these harmful effects. Expected outcomes include increased knowledge to inform effective policy and interventions aimed at identifying at-risk children and meeting young people\u2019s needs related to adverse legal outcomes. This should help improve public safety, reduce the economic impact of maltreatment and support vulnerable children to thrive.",
        "disciplines": [
            "4402",
            "4805"
        ],
        "publications": {
            "10.1186/s12889-023-17570-y": {
                "title": "Police-reported family violence victimisation or perpetration and mental health-related emergency department presentations: an Australian data-linkage study",
                "abstract": "BackgroundFamily violence is a leading social determinant of mental ill-health but its link to mental health-related emergency department presentations is poorly understood. Existing research has largely used retrospective designs with a focus on victimisation, typically among women. We examined whether police-reported family violence victimisation and perpetration were prospectively associated with mental health emergency department presentations in women and men. We also identified family violence risk and vulnerability characteristics associated with such presentations.MethodsDemographics, prior police involvement, and individual and relationship vulnerabilities were provided by Victoria Police for 1520 affected family members (i.e., primary victims) and 1470 respondents (i.e., persons alleged to have perpetrated family violence) from family violence reports in 2016\u201317. Emergency mental health presentations 22\u201330\u00a0months post-family-violence report were determined through linkage with the Victorian Emergency Minimum Dataset and compared to statewide presentations.ResultsEmergency mental health presentations during follow-up were identified in 14.3% of the family violence sample, with 1.9% presenting for self-harm. Mental health presentation rates per 1,000 people were markedly higher among affected family members and respondents of both sexes and all ages than in the general population, except for male affected family members aged 45\u2009+\u2009. Adjusting for age and sex, the mental health presentation rate was 6 and 11 times higher among affected family members and respondents, respectively, than in the general population. Individual vulnerabilities were more closely related to risk of emergency mental health presentations than relationship characteristics.ConclusionsPolice-recorded family violence is associated with increased mental health-related emergency department presentations over the short-to-medium term. Strengthened cross-sector collaboration is needed to identify, address, and refer individuals with overlapping family violence and mental health needs and to improve victims\u2019 and perpetrators\u2019 access to community mental health and related services. This should help prevent individuals from reaching a crisis point in their mental health.",
                "disciplines": [
                    "4202",
                    "4203",
                    "4206"
                ]
            },
            "10.1080/13218719.2023.2243303": {
                "title": "Expanding treatment pathways for sexually abusive behaviour in young people: an examination of Therapeutic Treatment Orders",
                "abstract": "Young people who engage in sexually abusive behaviour account for a substantial number of sexual offences worldwide. Despite this, a limited body of work has explored the optimal pathways into treatment for these young people. This is an important question to explore given the iatrogenic effects of receiving treatment following incarceration and burgeoning legislative frameworks focusing on the diversion of youth who sexually offend. In Victoria, Australia, Therapeutic Treatment Orders were introduced to mandate young people with sexually abusive behaviours to community-based treatment without undergoing formal criminal justice processes. It is possible this unique treatment pathway helps overcome several limitations associated with traditional pathways. This article reviews existing research on pathways to treatment for young people who engage in sexually abusive behaviour before detailing Therapeutic Treatment Orders, and the role they may play in unionising criminal justice and diversion treatment frameworks. Considerations for future research are also explored.",
                "disciplines": [
                    "4805",
                    "4402"
                ]
            },
            "10.5694/mja2.52089": {
                "title": "Sexual abuse during childhood and all\u2010cause mortality into middle adulthood: an Australian cohort study",
                "abstract": "OBJECTIVE: To compare mortality from all causes, internal causes (eg, cancers, circulatory and respiratory system diseases), and external causes (eg, suicide, accidents, assault) among people who were sexually abused during childhood with mortality for the general population.\nDESIGN: Historical cohort study.\nSETTING, PARTICIPANTS: 2759 people (2201 women, 79.8%) who had experienced medically assessed contact sexual abuse in Victoria while aged 16 years or younger during 1964-1995, as recorded in Victorian Institute of Forensic Medicine records.\nMAIN OUTCOME MEASURES: Mortality rate, based on linked National Death Index data (1980-2020), by five-year age group; sex- and age-standardised mortality ratios; comparison of rates with age- and sex-adjusted rates for the general Victorian population (incident rate ratio [IRR]).\nRESULTS: We included 115 deaths of people under 50 years of age in our analysis (4.2% of people sexually abused as children; 79 women, 36 men); 56 deaths were attributed to external, 56 to internal causes (cause of death information missing in three cases). In each age group from 15-19 years, the mortality rates for people sexually abused as children were higher than for the general population; age- and sex-standardised all-cause mortality ratios were highest for people aged 25-29 years (men: 16.5; 95% confidence interval [CI], 11.0-22.0; women: 19.2; 95% CI, 14.3-24.2). The age- and sex-adjusted mortality rate for people sexually abused as children was higher than in the general population for all-cause (IRR, 8.25; 95% CI, 5.92-11.5), internal cause (IRR, 5.92; 95% CI, 3.89-9.01), and external cause deaths (IRR, 12.6; 95% CI, 9.61-16.6); the differences in external cause mortality were greater for people who had experienced penetrative (IRR, 14.9; 95% CI, 10.9-20.5) than for those who had experienced non-penetrative sexual abuse as children (IRR, 8.92; 95% CI, 5.35-14.9).\nCONCLUSIONS: Sexual abuse during childhood is associated with higher mortality rates into mid-adulthood. Preventing child sexual abuse and intervening early to reduce the damage it inflicts is not only essential for the welfare of the child, but could also help reduce avoidable deaths later in life.",
                "disciplines": [
                    "4206"
                ]
            },
            "10.1177/00938548231170799": {
                "title": "Assessing Risk of Family Violence by Young People: Identifying Recidivism Base Rates and the Validity of the VP-SAFvR for Youth",
                "abstract": "Police-reported incidents of youth family violence have been increasing in frequency yet limited research exists about how best to risk assess this cohort. The present study examined the validity of the Victoria Police Screening Assessment for Family Violence Risk (VP-SAFvR) for Australian youth aged 10 to 24 years ( n = 4,999) reported to police for using family violence. The 6-month base rate of family violence recidivism was 24.24% for same-dyad recidivism and 35.31% for any-dyad recidivism. The VP-SAFvR demonstrated moderate discriminative validity (area under the curve [AUC] = .65) for the total sample and comparable discriminative validity across age (AUCs = .64-.67), gender (AUCs = .63-.65), and relationship (i.e., child-to-parent abuse, sibling abuse, intimate partner abuse; AUCs = .62-.65). Predictive validity was adequate at a threshold score of four for 10- to 24-year olds and most subgroups. Results demonstrate the utility of a structured risk triage tool for youth family violence.",
                "disciplines": [
                    "4402",
                    "5201"
                ]
            }
        }
    },
    "13827079": {
        "title": "International Strategic Research Alliance for Sustainable Socio-Economic Recovery from the COVID-19 Pandemic in Japan and Asia",
        "abstract": "In the \u201cJapan\u2019s socio-economic recovery and sustainability\u201d group,TSRBased on the large-scale corporate data that is continuously collected by and health surveys (JSTAR\uff09\u300d\u3001\u300cJapan Gerontological Evaluation Research Organization (JAGES\uff09We constructed a specific research plan, collected and analyzed various micro data such as the Iwanuma City Survey. In the \u201cSocio-economic recovery and sustainability in Asia and emerging countries around the world\u201d group,ADBhas been building this system since before the pandemic in collaboration with central banks and finance ministries of Asian countries.Asia Small and Medium-Size Enterprise (SME) Monitor\u30c7\u30fcWe analyzed the database. In addition, the Asian Development Bank (ADB\uff09Based on cooperation withAlibaba\uff08Ele.me), IndonesiaGoJekWe conducted an impact evaluation of the coronavirus using large-scale business data. Regarding recovery and sustainability of life and society,ADBWe have started collaboration with Asian population dynamics and aging comparative research. In addition, in preparation for building a national database in Bhutan, the Japan International Cooperation Agency (Japan International Cooperation Agency)JICA)We collaborated with In the \"Social implementation of reconstruction policies based on the economic theory of market design\" group,ADBWe collaborated with the National University of Singapore to analyze the effectiveness of food distribution during the lockdown in the Philippines in March 2020, and collaborated with the National University of Singapore to design public housing.EMPMpromoted. While building a secretariat system, we are also developing human resources at the Center for Policy Evaluation Research and Education, Graduate School of Economics, the University of Tokyo.CREPE\uff09Under this position, we conducted searches for specially appointed assistant professors and specially appointed researchers, and also began hiring student research assistants. Led by the \"Socioeconomic Recovery and Sustainability in Asia and the World's Emerging Countries\" group, we have begun designing the \"Advanced Program for the Development of Highly Skilled Human Resources.\"",
        "disciplines": [
            "3507"
        ],
        "publications": {
            "10.1007/s11150-024-09710-z": {
                "title": "The time trend and life-cycle profiles of consumption",
                "abstract": "This paper analyzes the time trend of household consumption in Japan between 1981 and 2020, using microdata from the Family Income and Expenditure Survey (FIES). We examine how the trends in the levels, shares, and growth of consumption vary across categories of consumption, items, and age groups, and assess changes in consumption inequality over time. Our analysis shows that consumption inequality mildly increased, driven primarily by the trend of service consumption and a shift in the age distribution. Additionally, we estimate the life-cycle profiles of consumption and find that the age component of total consumption follows a standard hump-shaped pattern, but varies significantly across goods and service categories and item groups. Finally, using the estimated age profiles of different consumption items, we project how aggregate consumption and its composition may evolve as Japan\u2019s population ages in the coming decades.",
                "disciplines": [
                    "3802"
                ]
            },
            "10.1016/j.jbankfin.2023.107047": {
                "title": "The effect of bank recapitalization policy on credit allocation, investment, and productivity: Evidence from a banking crisis in Japan",
                "abstract": "This paper examines the ramifications of government capital injections into financially distressed banks during the 1997 Japanese banking crisis. Using a dataset merging firm-level financial statements and bank balance sheets, we explore whether the capital injections primarily benefited high-productivity firms or were misallocated to struggling \u201czombie\u201d firms. The results suggest that post-injection banks increased lending to high-productivity non-zombie and low-productivity zombie firms. The former aligns with conventional theories prioritizing high-productivity firms for investment and productivity enhancement; the latter suggests credit misallocation toward struggling firms mainly for debt servicing. There is no evidence that these injections promoted investments among firms. The results indicate that zombie firms reduced investments, particularly in infrastructure. High-productivity non-zombie firms did not exhibit a significant investment boost despite receiving more loans but displayed positive labor and total factor productivity growth, potentially driven by sales growth and increased advertisement expenses rather than employment and wage adjustments.",
                "disciplines": [
                    "3501",
                    "3502",
                    "3507"
                ]
            },
            "10.1016/j.euroecorev.2023.104632": {
                "title": "On the stability of preferences: Experimental evidence from two disasters",
                "abstract": "We investigate the impacts of two disasters in Japan and the Philippines on preferences using the convex time budget experiments and multiple price list experiments with monetary rewards. By exploiting natural experiments which are combined with lab-in-the-field experiments, we aim to investigate whether and how long preferences are affected by extreme events. We find evidence supporting preference instability caused by exposure to natural hazards: in both our study sites, disaster exposure seems to make individuals more present-biased even though they differ in socioeconomic conditions and disaster types. The estimated impacts are persistent over the short and long time intervals in both disaster-affected areas and are robust to the method of measuring preferences.",
                "disciplines": [
                    "3801"
                ]
            },
            "10.1038/s41598-023-30724-7": {
                "title": "Building social capital with elders\u2019 leadership through a community hub \u201cIbasho\u201d in the Philippines and Nepal",
                "abstract": "We quantitatively study the Ibasho project\u2014a unique, innovative community-based project that involves co-creating a building as a social hub. Ibasho\u2019s decision-making undertakes a bottom-up approach, differentiating itself from the conventional top-down decision-making process. Using sui generis data, we find that Ibasho projects in the Philippines and Nepal contributed to enhancing social capital among elders in both cases. Yet there are differences between the two communities. In the Philippines, participation in Ibasho increased the number of a participant\u2019s friends, or \u201cstrong ties,\u201d indicating that it is on the intensive margin of human relationships. In contrast, joining Nepal\u2019s Ibasho broadened weak ties rather than strong ones. This contrast may stem from the difference in pre-existing social and built infrastructures in the two communities, which were strengthened through the building-human interactions.",
                "disciplines": [
                    "3507"
                ]
            },
            "10.1038/s41598-023-29536-6": {
                "title": "Heterogenous effects of the Great East Japan earthquake on prosociality of people depending on their age",
                "abstract": "This study investigates the instability of prosociality in the real world by looking at the age-specific non-linear relationship between disaster exposure and prosocial behavior. We employed unique microdata from two communities in Japan that were hit by the Great East Japan Earthquake and Tsunami disaster in 2011. Exploiting exogenous variations in disaster exposure, we find age-specific heterogeneous effects of disaster exposure on prosocial behavior captured by the behavior of sending New Year\u2019s cards as well as attitudinal survey questions. Among the older groups, disaster damages undermine prosociality, whereas the younger groups show reinforced prosocial behaviors. These findings can be explained consistently by combining two possible determinants of prosocial behavior: pure or impure altruism and self-enforcements in repeated interactions at workplaces. Age information can help disentangle these two elements at least partially.",
                "disciplines": [
                    "3801"
                ]
            },
            "10.1111/obes.12545": {
                "title": "Haste Makes No Waste: Positive Peer Effects of Classroom Speed Competition on Learning",
                "abstract": "Abstract This study investigates the effects of speed competition in classrooms on young pupils' learning outcomes. To examine how faster peers' speed affects slower pupils' speed and learning, we employ students' daily progress data in a self\u2010learning programme at BRAC primary schools in Bangladesh. The programme's unique setting allows us to address the reflection problem reasonably well. While speed competition could generate negative consequences, our results show overall positive peer effects on problem\u2010solving time and scores. The effects are stronger among peers with similar abilities, without negatively affecting others. Our results show efficiency gains from non\u2010market competition in education and learning.",
                "disciplines": [
                    "3801"
                ]
            },
            "10.1016/j.jebo.2022.11.027": {
                "title": "Adverse selection and moral hazard in corporate insurance markets: Evidence from the 2011 Thailand floods",
                "abstract": "This paper is the first empirical study on adverse selection and moral hazard in the corporate disaster insurance market. By constructing and examining a unique plant-level panel dataset on the 2011 Thailand floods, we overcome the general lack of data that has previously prevented a systematic study on the issue. By exploiting unexpected, large losses caused by a severe disaster, we find evidence of adverse selection for both property and business interruption insurance. Moral hazard, measured by impacts on recovery efforts, is also found for both types of insurance, albeit more salient effects for business interruption insurance.",
                "disciplines": [
                    "3801",
                    "3802",
                    "3507"
                ]
            }
        }
    },
    "10007820": {
        "title": "Why do neutrophils swarm? This project aims to combine novel immunology, microscopy and computational approaches to investigate how immune cells called neutrophils cooperate to protect the host against microbes",
        "abstract": "Neutrophils are rapidly recruited to sites of inflammation and then utilise a type of highly coordinated collective behaviour termed swarming. However, the role of neutrophil swarms in fighting off infection is poorly understood. The project is poised to generate new knowledge on the importance of immune cell cooperation by developing in silico models of the immune response. The project will provide benefit through enhanced understanding of fundamental principles of immunity and develop new computational tools to model complex immune function in silico.",
        "disciplines": [
            "3204"
        ],
        "publications": {
            "10.3389/fimmu.2023.1060258": {
                "title": "Skin immunity in wound healing and cancer",
                "abstract": "The skin is the body's largest organ. It serves as a barrier to pathogen entry and the first site of immune defense. In the event of a skin injury, a cascade of events including inflammation, new tissue formation and tissue remodeling contributes to wound repair. Skin-resident and recruited immune cells work together with non-immune cells to clear invading pathogens and debris, and guide the regeneration of damaged host tissues. Disruption to the wound repair process can lead to chronic inflammation and non-healing wounds. This, in turn, can promote skin tumorigenesis. Tumors appropriate the wound healing response as a way of enhancing their survival and growth. Here we review the role of resident and skin-infiltrating immune cells in wound repair and discuss their functions in regulating both inflammation and development of skin cancers.",
                "disciplines": [
                    "3204"
                ]
            }
        }
    },
    "10007690": {
        "title": "Impacts of changing water ownership and reforms on Australian water markets",
        "abstract": "Water markets play a critical role in helping Australia\u2019s food bowl survive periods of severe drought. This project aims to evaluate how the Murray-Darling Basin water markets performed, in terms of the impact of water ownership, and investigate how water reforms have affected rural communities over the past two decades. Expected outcomes include a clearer understanding on how different water ownership structures impact price and price volatility of water, market power, economic welfare of water traders, and what social and economic impacts water reforms in the past decades have in the Basin. The findings will provide critical evidence for evaluating future water reforms, building resilient rural communities and safeguarding food security.",
        "disciplines": [
            "3801"
        ],
        "publications": {
            "10.1016/j.jhydrol.2024.130983": {
                "title": "The Australian public\u2019s preferences for further environmental and cultural water recovery options in the Murray-Darling Basin",
                "abstract": "The Murray-Darling Basin (MDB) Plan in Australia legislated in 2012 represents the largest recovery of water, from consumptive use to environmental use in the world \u2013 with the aim of restoring rivers and ecosystems back to health. To date, although billions of dollars have been spent, the Plan\u2019s water recovery targets have not been achieved and will not meet their original target dates for full recovery, with governments needing to continue to make difficult water policy choices and trade-offs. This study explores a survey of Australian public preferences for five different water reallocation options in the MDB (and methods to be used for recovery) and identifies individual characteristics associated with various policy options. Almost a quarter of those surveyed did not support further water recovery; 17\u00a0% favoured recovering water to current goals only; 22\u00a0% favoured recovering environmental water beyond current goals; while 38\u00a0% favoured recovering both environmental and cultural water beyond current goals. For those wanting further recovery, a third preferred using irrigation infrastructure subsidies as the main method, while the majority favoured buying water directly back from irrigators (either through voluntary buyback or compulsory acquisition). Trust levels, location, age, climate change perception and gender all played a part in influencing respondent preferences for various water recovery options.",
                "disciplines": [
                    "3801"
                ]
            }
        }
    },
    "13219624": {
        "title": "Dissecting sugar-induced modulation of gut-brain circuits",
        "abstract": "Sugary beverages are a major contributor to the diabetes and obesity epidemics, but the mechanisms underlying this connection remain poorly understood. Rapid communication between the gut and the brain about recently consumed nutrients is critical for maintaining energy and glucose balance. However, despite its clear link to metabolic disease, very little is known about how a high-sugar diet alters the dynamics of this communication. Specifically, it is unknown how chronically over-consuming sugar versus fat changes neural responses to food intake and satiation signals in ways that might promote the development of obesity and diabetes. Understanding how diet changes neural dynamics is critical for developing novel approaches to prevent and treat these diseases. Neuromodulatory therapies that harness the ability of the nervous system to control appetite and blood glucose hold tremendous promise in this arena, and not knowing which neural populations to target and how to modulate them remain a major barrier to their implementation. This project seeks to change that. The Beutler lab will monitor the activity of several neural populations critical for normal feeding and glucose balance in mice before and after a high-sugar diet. They will also use cutting-edge genetic tools to manipulate genetically defined groups of neurons and determine whether this rescues the adverse behavioral and metabolic effects of a high-sugar diet. These experiments will enhance understanding of how nutrition impacts brain function, determine how this goes awry during the development of obesity and diabetes, and identify neural targets for preventing and treating these diseases.\n\t\u00a0Excessive sugar intake is clearly linked with the development of diabetes and obesity, but the mechanisms underlying this association is incompletely understood. This project aims to determine how excessive sugar intake disrupts gut-brain communication and alters neural responses to nutrients in ways that promote the development of these metabolic diseases. It will additionally address whether manipulating the activity of neural populations disrupted by sugar overconsumption can counteract the adverse metabolic effects of a high sugar diet. By dissecting in unprecedented detail how diet composition alters the function of the neural circuits that regulate body weight and blood glucose, this work will reveal novel approaches to treat and prevent diabetes and obesity.\n\tI want to understand how what we eat alters the activity of brain centers that control appetite and blood glucose at single-cell resolution, and how certain diets can promote the development of diabetes and obesity by disrupting neural activity. In the future, my lab will harness this knowledge to develop and test novel neural circuit-based therapies in rodent models of these diseases. Our ultimate goal is to see our discoveries translated into the clinic.\n\tAs a clinical endocrinologist, I treat patients with diabetes and obesity every week. It is an exciting time in this field with rapidly improving treatment options finally available to patients. But there is much we still do not understand about the development and progression of these diseases, and unraveling these mechanisms has the potential to transform therapy and even lead to a cure for them. This is what motivates my research program. The ADA Pathway to Stop Diabetes Award will transform my research efforts, enabling my lab to invest in the most cutting-edge neuroscience tools in order to understand how diet promotes metabolic disease by altering neural activity. The goal of this work is to identify and test novel approaches to treat diabetes and obesity.\n\tAdvances in technology have enabled the generation of incredibly large and complex neuroscience datasets. This includes the type of single cell resolution neural recording data we will collect as part of this project. A major challenge for the future will be to understand what these data are telling us and how to translate this understanding into treatments for diseases that affect brain function, including diabetes and obesity. This will require collaboration across the fields of neuroscience, endocrinology, computer science, and engineering. As a physician-scientist it is my goal to lead interdisciplinary groups to pioneer circuit-based therapies for metabolic diseases.",
        "disciplines": [
            "3210"
        ],
        "publications": {
            "10.1101/2024.03.18.585583": {
                "title": "Incretin hormones and pharmacomimetics rapidly inhibit AgRP neuron activity to suppress appetite",
                "abstract": "Analogs of the incretin hormones glucagon-like peptide-1 (GLP-1) and glucose-dependent insulinotropic peptide (GIP) have become mainstays of obesity and diabetes management. However, both the physiologic role of incretin hormones in the control of appetite and the pharmacologic mechanisms by which incretin-mimetic drugs suppress caloric intake remain incompletely understood. Hunger-promoting AgRP-expressing neurons are an important hypothalamic population that regulates food intake. Therefore, we set out to determine how incretins analogs affect their activity <i>in vivo</i>. Using fiber photometry, we observed that both GIP receptor (GIPR) and GLP-1 receptor (GLP-1R) agonism acutely inhibit AgRP neuron activity in fasted mice and reduce the response of AgRP neurons to food. Moreover, optogenetic stimulation of AgRP neurons partially attenuated incretin-induced feeding suppression, suggesting that AgRP neuron inhibition is necessary for the full appetite-suppressing effects of incretin-based therapeutics. Finally, we found that GIP but not GLP-1 is necessary for nutrient-mediated AgRP neuron inhibition, representing a novel physiologic role for GIP in maintaining energy balance. Taken together, these findings reveal neural mechanisms underlying the efficacy of incretin-mimetic obesity therapies. Understanding these drugs' mechanisms of action is crucial for the development of next-generation obesity pharmacotherapies with an improved therapeutic profile.",
                "disciplines": [
                    "3214"
                ]
            },
            "10.1016/j.celrep.2024.113675": {
                "title": "Sucrose overconsumption impairs AgRP neuron dynamics and promotes palatable food intake",
                "abstract": "Rapid gut-brain communication is critical to maintain energy balance and is disrupted in diet-induced obesity. In particular, the role of carbohydrate overconsumption in the regulation of interoceptive circuits in\u00a0vivo requires further investigation. Here, we report that an obesogenic high-sucrose diet (HSD) selectively blunts silencing of hunger-promoting agouti-related protein (AgRP) neurons following intragastric delivery of glucose, whereas we previously showed that overconsumption of a high-fat diet (HFD) selectively attenuates lipid-induced neural silencing. By contrast, both HSD and HFD reversibly dampen rapid AgRP neuron inhibition following chow presentation and promote intake of more palatable foods. Our findings reveal that excess sugar and fat pathologically modulate feeding circuit activity in both macronutrient-dependent and -independent ways and thus may additively exacerbate obesity.",
                "disciplines": [
                    "3101"
                ]
            }
        }
    },
    "13017437": {
        "title": "HIGH efficiency LIGHT emission by inelastic tunneling \u2013 HighLights",
        "abstract": "This project aims at demonstrating high efficiency light sources based on inelastic tunneling through a tunnel junction and explore their potential for short range optical communications. Optical links are considered to be a promising venue for on-chip or chip-to-chip communication in order to reduce power consumption. In this context, light emission by inelastic tunneling effect (LEIT) has attractive features: i) ultrafast emission,  ii) small footprint. Unfortunately, the efficiency is very low due to the dominant elastic current tunneling in light emitting metal-insulator-metal tunnel junctions. We aim at improving the efficiency by four orders of magnitude by reducing elastic tunneling while enhancing light emission using plasmonic resonators. We will combine the well-established knowledge of electronic transport in tunnel junctions with the nanophotonics know-how (microcavities, plasmonic resonators) to achieve a breakthrough in the efficiency of LEIT.",
        "disciplines": [
            "4018"
        ],
        "publications": {
            "10.1103/physrevx.14.021017": {
                "title": "Unified Treatment of Light Emission by Inelastic Tunneling: Interaction of Electrons and Photons beyond the Gap",
                "abstract": "A direct current through a metal-insulator-metal tunneling junction emits light when surface-plasmon polaritons (SPPs) are excited. Two distinct processes are believed to coexist in this light emission mediated by surface plasmons: inelastic tunneling, where electrons excite SPPs in the insulator gap, and hot-electron radiative decay, which occurs in the electrodes after elastic tunneling. Previous theoretical approaches to study light emission by inelastic tunneling have relied on Bardeen\u2019s approximation where the electronic wave functions are considered only in the barrier of the junction. In this work, we introduce an extension to models of inelastic tunneling by incorporating the full quantum device solution of the Schr\u00f6dinger equation, which can also account for processes in the metallic electrodes. The extension unveils the existence of long-range correlations of the current density across the barrier and enables us to establish the equivalence between two models widely used in the past: (i) a calculation of the inelastic transition rate between two states across the barrier based on Fermi\u2019s golden rule and (ii) a calculation of the power transferred to plasmons by current fluctuations. Importantly, the new model accounts for processes that take place in the metallic electrodes and that could not be described within Bardeen\u2019s approximation. Hence, it is no longer necessary to invoke a hot-electron mechanism to obtain a dependence on the geometry of metallic electrodes. The new framework enables to discuss the role of surface plasmons localized in different metal-insulator interfaces and to include possible nonlocal effects at the interfaces.",
                "disciplines": [
                    "5104"
                ]
            }
        }
    },
    "13016819": {
        "title": "Evolution of the Cambrian and Ordovician Biodiversification Onset Over Space and Time \u2013 ECO-BOOST",
        "abstract": "The early Palaeozoic biodiversification is the most significant radiation of marine ecosystems of Earth\u2019s History, with two major pulses documented from diversity datasets: the 'Cambrian Explosion\u2019 and the 'Great Ordovician Biodiversification Event\u2019. However, in recent years, it became obvious that these two \u2018events\u2019 were more intensively studied in a few locations, creating a gap of data, and thus a bias, in biodiversity databases. Moreover, recent investigations documented that exceptionally preserved fossils typical of the 'Cambrian Explosion\u2019 were still present in the Ordovician. We hypothesize that global \u2018explosions\u2019 of diversity never occurred. Our main objective is to plot all data of the marine fossil record on new palaeogeographical maps in combination with climatological/geographical and macro-ecological modelling to allow data/model comparisons and biodiversity reconstructions. We will document that very complex, long-term evolutionary processes took place over space and time, starting in the late Precambrian and lasting throughout most of the early Palaeozoic. This will allow us to obtain, for the first time, spatial and temporal views illustrating the biodiversity changes in the earliest marine ecosystems, including the identification and location of diversity \u2018hotspots.\u2019 It will also allow us to determine the timing of establishment of the first Latitudinal Diversity Gradient (LDG) and its evolution through time. The modelling approach will produce testable palaeoclimatological, palaeoecological and biogeographical predictions, providing spatio-temporal models of biodiversity patterns for the Cambrian and Ordovician. Our project thus proposes to combine empirical and modelling approaches, with new tools that have never been applied to early Palaeozoic marine ecosystems.",
        "disciplines": [
            "3104",
            "3705",
            "3103",
            "3709"
        ],
        "publications": {
            "10.1038/s41559-024-02331-w": {
                "title": "The Cabri\u00e8res Biota (France) provides insights into Ordovician polar ecosystems",
                "abstract": "Early Palaeozoic sites with soft-tissue preservation are predominantly found in Cambrian rocks and tend to capture past tropical and temperate ecosystems. In this study, we describe the diversity and preservation of the Cabri\u00e8res Biota, a newly discovered Early Ordovician Lagerst\u00e4tte from Montagne Noire, southern France. The Cabri\u00e8res Biota showcases a diverse polar assemblage of both biomineralized and soft-bodied organisms predominantly preserved in iron oxides. Echinoderms are extremely scarce, while sponges and algae are abundantly represented. Non-biomineralized arthropod fragments are also preserved, along with faunal elements reminiscent of Cambrian Burgess Shale-type ecosystems, such as armoured lobopodians. The taxonomic diversity observed in the Cabri\u00e8res Biota mixes Early Ordovician Lagerst\u00e4tten taxa with Cambrian forms. By potentially being the closest Lagerst\u00e4tte to the South Pole, the Cabri\u00e8res Biota probably served as a biotic refuge amid the high-water temperatures of the Early Ordovician, and shows comparable ecological structuring to modern polar communities.",
                "disciplines": [
                    "3103",
                    "3104"
                ]
            },
            "10.1016/j.gloplacha.2024.104354": {
                "title": "The dynamic ocean redox evolution during the late Cambrian SPICE: Evidence from the I/Ca proxy",
                "abstract": "The late Cambrian Steptoean positive carbon isotope excursion (SPICE) is a distinct chemostratigraphic feature of the Paleozoic, marked by a 4\u20135\u2030 shift in carbonate \u03b413C that has been recognized across the globe during the Paibian Stage. The SPICE may be related to enhanced burial of organic matter and pyrite during the expansion of marine euxinia, which as a source of O2 also results in a pulse of atmospheric oxygen. However, geochemical proxies have not clearly illustrated how the ocean redox evolved with atmospheric oxygen changes during the SPICE. This study presents new carbonate I/Ca data, a redox proxy for the upper ocean, from three basins. I/Ca values are low at Great Basin and South China from early into the peak of SPICE, indicating generally anoxic conditions in shallow waters. The overall increasing trend in I/Ca through the peak and recovery phase of the SPICE roughly correlates with the previously modeled rise in atmospheric oxygen. Spatially, the Georgina Basin (Mt. Whelan) might have recorded a relatively more oxic upper ocean compared to the Great Basin and South China. Earth system model simulations also demonstrate the importance of paleogeographic and oceanographic settings on local redox conditions, highlighting the redox heterogeneity during the SPICE.",
                "disciplines": [
                    "3709",
                    "3702",
                    "3705"
                ]
            },
            "10.1038/s41467-023-41685-w": {
                "title": "Impact of global climate cooling on Ordovician marine biodiversity",
                "abstract": "Global cooling has been proposed as a driver of the Great Ordovician Biodiversification Event, the largest radiation of Phanerozoic marine animal Life. Yet, mechanistic understanding of the underlying pathways is lacking and other possible causes are debated. Here we couple a global climate model with a macroecological model to reconstruct global biodiversity patterns during the Ordovician. In our simulations, an inverted latitudinal biodiversity gradient characterizes the late Cambrian and Early Ordovician when climate was much warmer than today. During the Mid-Late Ordovician, climate cooling simultaneously permits the development of a modern latitudinal biodiversity gradient and an increase in global biodiversity. This increase is a consequence of the ecophysiological limitations to marine Life and is robust to uncertainties in both proxy-derived temperature reconstructions and organism physiology. First-order model-data agreement suggests that the most conspicuous rise in biodiversity over Earth\u2019s history \u2013 the Great Ordovician Biodiversification Event \u2013 was primarily driven by global cooling.",
                "disciplines": [
                    "3709",
                    "3103",
                    "3104",
                    "3705"
                ]
            },
            "10.1126/sciadv.adg7679": {
                "title": "Why the Early Paleozoic was intrinsically prone to marine extinction",
                "abstract": "The geological record of marine animal biodiversity reflects the interplay between changing rates of speciation versus extinction. Compared to mass extinctions, background extinctions have received little attention. To disentangle the different contributions of global climate state, continental configuration, and atmospheric oxygen concentration (<i>p</i>O<sub>2</sub>) to variations in background extinction rates, we drive an animal physiological model with the environmental outputs from an Earth system model across intervals spanning the past 541 million years. We find that climate and continental configuration combined to make extinction susceptibility an order of magnitude higher during the Early Paleozoic than during the rest of the Phanerozoic, consistent with extinction rates derived from paleontological databases. The high extinction susceptibility arises in the model from the limited geographical range of marine organisms. It stands even when assuming present-day <i>p</i>O<sub>2</sub>, suggesting that increasing oxygenation through the Paleozoic is not necessary to explain why extinction rates apparently declined with time.",
                "disciplines": [
                    "3103",
                    "3104",
                    "3705"
                ]
            },
            "10.1144/sp532-2022-1": {
                "title": "The Ordovician ocean circulation: a modern synthesis based on data and models",
                "abstract": "Abstract\n                  Surface currents constitute an efficient transport agent for (larvae of) marine faunas, while the circulation of water masses in the ocean interior drives nutrient redistribution, ventilates the ocean and contributes to shaping surface biological productivity and the benthic redox landscape. Therefore, a robust understanding of ocean circulation, both shallow and deep, and of its response to climate change, is required to interpret palaeobiogeographic signals, biological productivity patterns and biodiversity trends. This is especially critical during periods of dynamic biological change, such as the Ordovician. Yet, oceanic circulation patterns leave no direct evidence in the geological record and can therefore be reconstructed solely based on indirect indicators, such as the distribution of faunas and geochemical proxies. General circulation models offer independent, physically robust insights onto the coupling between climate change and ocean circulation. Integrated approaches based on the assimilation of geological data in numerical models thus constitute a promising way forward. We here provide a literature review and updated synthesis of the current understanding of the Ordovician ocean circulation, based on data and models.",
                "disciplines": [
                    "3708",
                    "3709"
                ]
            }
        }
    },
    "13061348": {
        "title": "Cortico-amydala circuit dysfunction underlying avoidance behaviors and aversive facial expressions to social touch in mouse models of autism",
        "abstract": "PROJECT ABSTRACT Autism spectrum disorders (ASD) are neurodevelopmental disorders characterized by deficits in social interaction, repetitive behaviors and atypical sensory processing. The change in quality of life in ASD individuals is primarily attributed to social deficits, which can be associated with (or even triggered by) atypical processing of sensory information. In particular, social touch deficits in ASD may explain this association given the strong relationship between social interaction deficits and tactile hypersensitivity in ASD. Early tactile hyperresponsivity predicts future social impairments in ASD children and the absence of touch prevents ASD children from forming social relationships as adults. ASD individuals also lack representations of affective social touch in somatosensory brain regions. In mouse models of ASD, tactile sensitivity and social touch interactions also appear to be linked. Still, several important questions about social touch remain unresolved. First, it is not known when social touch behavioral deficits first emerge in ASD. These deficits may emerge early on in development when sensory hypersensitivity first develops or later in adolescence when social experiences become more frequent. Second, little is known about how social touch and maladaptive behaviors to social touch are represented in the brain of ASD individuals. Relevant brain areas may include the primary somatosensory cortex (S1), which encodes social touch and shows impaired adaptation to innocuous tactile stimuli in ASD mouse models, and the basolateral amygdala (BLA), which is important for encoding aversive stimuli and salient social information. To investigate social touch deficits in mouse models of autism, I have designed a novel head-fixed behavioral assay during which behavioral responses to social touch can be measured. This assay allows me to spatially and temporally control social touch interactions between mice so that I can assess the behavioral responses to both voluntary (whisker-whisker contact) and forced (snout-snout contact) social touch in a test mouse as it interacts with a stranger mouse. My preliminary data already shows that both the Fragile X Syndrome and maternal immune activation mouse models of autism animals display increased avoidance behaviors and aversive facial expressions (AFEs) to both voluntary and forced social touch compared to their controls in adulthood. Furthermore, these maladaptive behaviors are more prominent during social touch than object touch. For this proposal, I will utilize this novel behavioral assay and in vivo silicon probe electrophysiology recordings (Neuropixels) to 1. investigate when avoidance behaviors and AFEs to social touch emerge during development (postnatal and juvenile ages) in ASD mice and 2. determine how social touch and the maladaptive behavioral responses it triggers in ASD are represented as neural dynamics in S1 and BLA. This proposal is significant because it will provide the first characterization of behavioral manifestations of social touch deficits across development and investigate the neural circuit disruptions underlying these deficits in mouse models of ASD.",
        "disciplines": [
            "5202",
            "5204"
        ],
        "publications": {
            "10.1523/jneurosci.0226-23.2023": {
                "title": "A Novel Head-Fixed Assay for Social Touch in Mice Uncovers Aversive Responses in Two Autism Models.",
                "abstract": "Social touch, an important aspect of social interaction and communication, is essential to kinship across animal species. How animals experience and respond to social touch has not been thoroughly investigated, in part because of the lack of appropriate assays. Previous studies that examined social touch in freely moving rodents lacked the necessary temporal and spatial control over individual touch interactions. We designed a novel head-fixed assay for social touch in mice, in which the experimenter has complete control to elicit highly stereotyped bouts of social touch between two animals. The user determines the number, duration, context, and type of social touch interactions, while monitoring an array of complex behavioral responses with high resolution cameras. We focused on social touch to the face because of its high translational relevance to humans. We validated this assay in two different models of autism spectrum disorder (ASD), the <i>Fmr1</i> knock-out (KO) model of Fragile X syndrome (FXS) and maternal immune activation (MIA) mice. We observed higher rates of avoidance running, hyperarousal, and aversive facial expressions (AFEs) to social touch than to object touch, in both ASD models compared with controls. <i>Fmr1</i> KO mice showed more AFEs to mice of the same sex but whether they were stranger or familiar mice mattered less. Because this new social touch assay for head-fixed mice can be used to record neural activity during repeated bouts of social touch it could be used to uncover underlying circuit differences.<b>SIGNIFICANCE STATEMENT</b> Social touch is important for communication in animals and humans. However, it has not been extensively studied and current assays to measure animals' responses to social touch have limitations. We present a novel head-fixed assay to quantify how mice respond to social facial touch with another mouse. We validated this assay in autism mouse models since autistic individuals exhibit differences in social interaction and touch sensitivity. We find that mouse models of autism exhibit more avoidance, hyperarousal, and aversive facial expressions (AFEs) to social touch compared with controls. Thus, this novel assay can be used to investigate behavioral responses to social touch and the underlying brain mechanisms in rodent models of neurodevelopmental conditions, and to evaluate therapeutic responses in preclinical studies.",
                "disciplines": [
                    "3209"
                ]
            },
            "10.1101/2023.01.11.523491": {
                "title": "A novel head-fixed assay for social touch in mice uncovers aversive responses in two autism models",
                "abstract": "Social touch, an important aspect of social interaction and communication, is essential to kinship across animal species. How animals experience and respond to social touch has not been thoroughly investigated, in part due to the lack of appropriate assays. Previous studies that examined social touch in freely moving rodents lacked the necessary temporal and spatial control over individual touch interactions. We designed a novel head-fixed assay for social touch in mice, in which the experimenter has complete control to elicit highly stereotyped bouts of social touch between two animals. The user determines the number, duration, context, and type of social touch interactions, while monitoring with high frame rate cameras an array of complex behavioral responses. We focused on social touch to the face because of their high translational relevance to humans. We validated this assay in two different models of autism spectrum disorder (ASD), the <i>Fmr1</i> knockout model of Fragile X Syndrome and maternal immune activation mice. We observed increased avoidance, hyperarousal, and more aversive facial expressions to social touch, but not to object touch, in both ASD models compared to controls. Because this new social touch assay for head-fixed mice can be used to record neural activity during repeated bouts of social touch it should be of interest to neuroscientists interested in uncovering the underlying circuits.",
                "disciplines": [
                    "5202"
                ]
            }
        }
    },
    "13017503": {
        "title": "Physical approaches of erosion by water flows: roles of transport and reactions in mass-transfers \u2013 PhysErosion",
        "abstract": "Erosion is defined as the loss of mass of a solid phase under the action of a flow in a fluid. Two physical mechanisms are distinguished. Chemical erosion occurs, when the molecules and minerals forming the solid are dissolved into the liquid. Mechanical erosion acts when the flow is fast enough to transport grains extracted from the solid. These phenomena explain, for example, the weathering and corrosion of building materials. Erosion is also essential in geomorphology, describing at different scales the formation of landscapes under the action of wind, rainfalls and rivers. The transport of grains in the river beds thus corresponds to a process of mechanical erosion, while the dissolution of soluble rocks such as salt or limestone by water forming a cave network is a matter of chemical erosion. In general, chemical weathering and mechanical transport are combined. In this project, we propose to study from a physical point of view the different mechanisms of erosion by water flows by associating several complementary areas of expertise. The dynamics and forms of erosion will be studied experimentally in different hydrodynamic configurations, at IPGP (Olivier Devauchelle) for granular transport and at MSC (Michael Berhanu) for fast dissolving materials, then the combination of chemical and mechanical erosion. The reactive mechanisms at the interfaces will be physically characterized at ILM (Jean Colombani). Finally, these experimental inputs will be used to propose at ISTO (Cyprien Soulaine) a general model involving several space and time scales that will be integrated in cutting-edge multi-scale simulators for hydro-geochemical processes. It will thus be possible to offer long-term predictions of the evolution of landscapes under the action of erosion phenomena.",
        "disciplines": [
            "3705"
        ],
        "publications": {
            "10.1073/pnas.2309379120": {
                "title": "Emergence of tip singularities in dissolution patterns",
                "abstract": "Chemical erosion, one of the two major erosion processes along with mechanical erosion, occurs when a soluble rock-like salt, gypsum, or limestone is dissolved in contact with a water flow. The coupling between the geometry of the rocks, the mass transfer, and the flow leads to the formation of remarkable patterns, like scallop patterns in caves. We emphasize the common presence of very sharp shapes and spikes, despite the diversity of hydrodynamic conditions and the nature of the soluble materials. We explain the generic emergence of such spikes in dissolution processes by a geometrical approach. Singularities at the interface emerge as a consequence of the erosion directed in the normal direction, when the surface displays curvature variations, like those associated with a dissolution pattern. First, we demonstrate the presence of singular structures in natural interfaces shaped by dissolution. Then, we propose simple surface evolution models of increasing complexity demonstrating the emergence of spikes and allowing us to explain at long term by coarsening the formation of cellular structures. Finally, we perform a dissolution pattern experiment driven by solutal convection, and we report the emergence of a cellular pattern following well the model predictions. Although the precise prediction of dissolution shapes necessitates performing a complete hydrodynamic study, we show that the characteristic spikes which are reported ultimately for dissolution shapes are explained generically by geometrical arguments due to the surface evolution. These findings can be applied to other ablation patterns, reported for example in melting ice.",
                "disciplines": [
                    "3705"
                ]
            },
            "10.1073/pnas.2301947120": {
                "title": "Dissolution-driven propulsion of floating solids",
                "abstract": "We show that unconstrained asymmetric dissolving solids floating in a fluid can move rectilinearly as a result of attached density currents which occur along their inclined surfaces. Solids in the form of boats composed of centimeter-scale sugar and salt slabs attached to a buoy are observed to move rapidly in water with speeds up to 5 mm/s determined by the inclination angle and orientation of the dissolving surfaces. While symmetric boats drift slowly, asymmetric boats are observed to accelerate rapidly along a line before reaching a terminal velocity when their drag matches the thrust generated by dissolution. By visualizing the flow around the body, we show that the boat velocity is always directed opposite to the horizontal component of the density current. We derive the thrust acting on the body from its measured kinematics and show that the propulsion mechanism is consistent with the unbalanced momentum generated by the attached density current. We obtain an analytical formula for the body speed depending on geometry and material properties and show that it captures the observed trends reasonably. Our analysis shows that the gravity current sets the scale of the body speed consistent with our observations, and we estimate that speeds can grow slowly as the cube root of the length of the inclined dissolving surface. The dynamics of dissolving solids demonstrated here applies equally well to solids undergoing phase change and may enhance the drift of melting icebergs, besides unraveling a primal strategy by which to achieve locomotion in active matter.",
                "disciplines": [
                    "5109"
                ]
            }
        }
    },
    "13300702": {
        "title": "Accelerating messenger RNA (mRNA) therapeutics by cracking the epitranscriptomic code",
        "abstract": "The remarkable efficacy of SARS-CoV-2 vaccines based on messenger RNA (mRNA) has highlighted the extraordinary potential of mRNA technologies and has secured the promise of mRNA as a therapeutic modality for multiple diseases. This research project builds on a recent breakthrough from my research that enables an unprecedented characterisation of the chemical composition of individual mRNA molecules to uphold this promise and accelerate mRNA exploration and design for therapeutic development.",
        "disciplines": [
            "3404"
        ],
        "publications": {
            "10.1038/s41467-024-48673-8": {
                "title": "Biochemical-free enrichment or depletion of RNA classes in real-time during direct RNA sequencing with RISER",
                "abstract": "The heterogeneous composition of cellular transcriptomes poses a major challenge for detecting weakly expressed RNA classes, as they can be obscured by abundant RNAs. Although biochemical protocols can enrich or deplete specified RNAs, they are time-consuming, expensive and can compromise RNA integrity. Here we introduce RISER, a biochemical-free technology for the real-time enrichment or depletion of RNA classes. RISER performs selective rejection of molecules during direct RNA sequencing by identifying RNA classes directly from nanopore signals with deep learning and communicating with the sequencing hardware in real time. By targeting the dominant messenger and mitochondrial RNA classes for depletion, RISER reduces their respective read counts by more than 85%, resulting in an increase in sequencing depth of 47% on average for long non-coding RNAs. We also apply RISER for the depletion of globin mRNA in whole blood, achieving a decrease in globin reads by more than 90% as well as an increase in non-globin reads by 16% on average. Furthermore, using a GPU or a CPU, RISER is faster than GPU-accelerated basecalling and mapping. RISER\u2019s modular and retrainable software and intuitive command-line interface allow easy adaptation to other RNA classes. RISER is available at https://github.com/comprna/riser.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1038/s41467-024-47953-7": {
                "title": "Prediction of m6A and m5C at single-molecule resolution reveals a transcriptome-wide co-occurrence of RNA modifications",
                "abstract": "The epitranscriptome embodies many new and largely unexplored functions of RNA. A significant roadblock hindering progress in epitranscriptomics is the identification of more than one modification in individual transcript molecules. We address this with CHEUI (CH3 (methylation) Estimation Using Ionic current). CHEUI predicts N6-methyladenosine (m6A) and 5-methylcytosine (m5C) in individual molecules from the same sample, the stoichiometry at transcript reference sites, and differential methylation between any two conditions. CHEUI processes observed and expected nanopore direct RNA sequencing signals to achieve high single-molecule, transcript-site, and stoichiometry accuracies in multiple tests using synthetic RNA standards and cell line data. CHEUI\u2019s capability to identify two modification types in the same sample reveals a co-occurrence of m6A and m5C in individual mRNAs in cell line and tissue transcriptomes. CHEUI provides new avenues to discover and study the function of the epitranscriptome.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            },
            "10.1016/j.fsigen.2024.103048": {
                "title": "Profiling age and body fluid DNA methylation markers using nanopore adaptive sampling",
                "abstract": "DNA methylation plays essential roles in regulating physiological processes, from tissue and organ development to gene expression and aging processes and has emerged as a widely used biomarker for the identification of body fluids and age prediction. Currently, methylation markers are targeted independently at specific CpG sites as part of a multiplexed assay rather than through a unified assay. Methylation detection is also dependent on divergent methodologies, ranging from enzyme digestion and affinity enrichment to bisulfite treatment, alongside various technologies for high-throughput profiling, including microarray and sequencing. In this pilot study, we test the simultaneous identification of age-associated and body fluid-specific methylation markers using a single technology, nanopore adaptive sampling. This innovative approach enables the profiling of multiple CpG marker sites across entire gene regions from a single sample without the need for specialized DNA preparation or additional biochemical treatments. Our study demonstrates that adaptive sampling achieves sufficient coverage in regions of interest to accurately determine the methylation status, shows a robust consistency with whole-genome bisulfite sequencing data, and corroborates known CpG markers of age and body fluids. Our work also resulted in the identification of new sites strongly correlated with age, suggesting new possible age methylation markers. This study lays the groundwork for the systematic development of nanopore-based methodologies in both age prediction and body fluid identification, highlighting the feasibility and potential of nanopore adaptive sampling while acknowledging the need for further validation and expansion in future research.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            },
            "10.1093/bib/bbad163": {
                "title": "Concepts and methods for transcriptome-wide prediction of chemical messenger RNA modifications with machine learning",
                "abstract": "The expanding field of epitranscriptomics might rival the epigenome in the diversity of biological processes impacted. In recent years, the development of new high-throughput experimental and computational techniques has been a key driving force in discovering the properties of RNA modifications. Machine learning applications, such as for classification, clustering or de novo identification, have been critical in these advances. Nonetheless, various challenges remain before the full potential of machine learning for epitranscriptomics can be leveraged. In this review, we provide a comprehensive survey of machine learning methods to detect RNA modifications using diverse input data sources. We describe strategies to train and test machine learning methods and to encode and interpret features that are relevant for epitranscriptomics. Finally, we identify some of the current challenges and open questions about RNA modification analysis, including the ambiguity in predicting RNA modifications in transcript isoforms or in single nucleotides, or the lack of complete ground truth sets to test RNA modifications. We believe this review will inspire and benefit the rapidly developing field of epitranscriptomics in addressing the current limitations through the effective use of machine learning.",
                "disciplines": [
                    "3102"
                ]
            }
        }
    },
    "13552996": {
        "title": "Investigating the synaptic trafficking of endogenous AMPARs",
        "abstract": "Project Summary Changes to synaptic architecture underlie the cellular basis for learning and memory and impaired synaptic function and plasticity are observed in numerous brain diseases and disorders including epilepsy, autism, and schizophrenia. The synthesis and precise delivery of AMPA-type glutamate receptors (AMPARs) to the postsynaptic membrane is a critical mechanism for proper basal synaptic function and plasticity. How new receptors are delivered to specific synapses and how receptor trafficking is influenced by neural activity remain important questions. A major limitation for addressing these questions is the current reliance on non- physiological, overexpressed receptors to study neuronal synaptic protein trafficking pathways. To overcome this hurdle, I have developed and validated a new toolkit that allows me to label endogenous AMPARs and control their trafficking. I propose to leverage these new tools to investigate where, when, and how new AMPARs are delivered to specific synapses under basal conditions and following diverse forms of synaptic plasticity.",
        "disciplines": [
            "3209",
            "3214",
            "5202"
        ],
        "publications": {
            "10.1101/2023.12.12.570420": {
                "title": "miRNA-mediated control of gephyrin synthesis drives sustained inhibitory synaptic plasticity",
                "abstract": "Activity-dependent protein synthesis is crucial for many long-lasting forms of synaptic plasticity. However, our understanding of the translational mechanisms controlling inhibitory synapses is limited. One distinct form of inhibitory long-term potentiation (iLTP) enhances postsynaptic clusters of GABA<sub>A</sub>Rs and the primary inhibitory scaffold, gephyrin, to promote sustained synaptic strengthening. While we previously found that persistent iLTP requires mRNA translation, the precise mechanisms controlling gephyrin translation during this process remain unknown. Here, we identify miR153 as a novel regulator of <i>Gphn</i> mRNA translation which controls gephyrin protein levels and synaptic clustering, ultimately impacting GABAergic synaptic structure and function. We find that iLTP induction downregulates miR153, reversing its translational suppression of <i>Gphn</i> mRNA and allowing for increased <i>de novo</i> gephyrin protein synthesis and synaptic clustering during iLTP. Finally, we find that reduced miR153 expression during iLTP is driven by an excitation-transcription coupling pathway involving calcineurin, NFAT and HDACs, which also controls the miRNA-dependent upregulation of GABA<sub>A</sub>Rs. Overall, this work delineates a miRNA-dependent post-transcriptional mechanism that controls the expression of the key synaptic scaffold, gephyrin, and may converge with parallel miRNA pathways to coordinate gene upregulation to maintain inhibitory synaptic plasticity.",
                "disciplines": [
                    "3101",
                    "3209"
                ]
            },
            "10.1016/j.celrep.2023.113331": {
                "title": "Acute reorganization of postsynaptic GABAA receptors reveals the functional impact of molecular nanoarchitecture at inhibitory synapses",
                "abstract": "Neurotransmitter receptors partition into nanometer-scale subdomains within the postsynaptic membrane that are precisely aligned with presynaptic neurotransmitter release sites. While spatial coordination between pre- and postsynaptic elements is observed at both excitatory and inhibitory synapses, the functional significance of this molecular architecture has been challenging to evaluate experimentally. Here we utilized an optogenetic clustering approach to acutely alter the nanoscale organization of the postsynaptic inhibitory scaffold gephyrin while monitoring synaptic function. Gephyrin clustering rapidly enlarged postsynaptic area, laterally displacing GABA<sub>A</sub> receptors from their normally precise apposition with presynaptic active zones. Receptor displacement was accompanied by decreased synaptic GABA<sub>A</sub> receptor currents even though presynaptic release probability and the overall abundance and function of synaptic GABA<sub>A</sub> receptors remained unperturbed. Thus, acutely repositioning neurotransmitter receptors within the postsynaptic membrane profoundly influences synaptic efficacy, establishing the functional importance of precision pre-/postsynaptic molecular coordination at inhibitory synapses.",
                "disciplines": [
                    "3101"
                ]
            }
        }
    },
    "13242935": {
        "title": "Scattering amplitudes and non-Perturbative unitARity : a new way To the S-mAtrix \u2013 SPARTA",
        "abstract": "Scattering experiments are the most elaborate way to analyse the laws of nature. In quantum field theory, the S-matrix encompasses all scattering processes, and describes physical phenomena as varied as collision experiments, gravitational waves, the strong nuclear force, string theoretic and quantum gravitational effects such as black hole production in high-energy scattering.There are two approaches to compute the S-matrix: perturbative and non-perturbative. The first has progressed a lot, propelled by the modern colliders\u2019 needs, but captures only restricted physical regimes. Interestingly, it gave rise to new concepts, such as the double-copy construction of gravity, whose origin is elusive. The non-perturbative approach aims to compute the S-matrix directly, by combining the powerful principles it must obey: unitarity, causality, and crossing. Its main bottlenecks are our lack of control on multi-particle processes, and the non-linear nature of unitarity. These constraints are so stringent that today we still have not obtained a single fully consistent S-matrix.This project aims to fill this gap. It will (1) provide the first fully consistent S-matrices and produce the most accurate up-to-date pion S-matrix model, (2) produce models of unitary quantum-gravity scattering with high-energy black hole production. Even more ambitiously, for (1) and (2), the team will explore the space of all such consistent S-matrices. Finally, (3) SPARTA will investigate the non-perturbative nature of double-copy and explore its role as a new S-matrix principle.SPARTA will reach these goals thanks to an original approach to non-perturbative unitarity, \"scattering-from-production\", which tackles the bottlenecks of the non-perturbative approach, while making use of modern perturbation theory, and using powerful numerical tools. By this unique approach, SPARTA will lay the foundations of a grand programme, at the interface of scattering amplitudes and non-perturbative S-matrix.",
        "disciplines": [
            "5107",
            "4902",
            "5106"
        ],
        "publications": {
            "10.1103/physrevd.108.105013": {
                "title": "Cluster alphabets from generalized worldsheets: A geometric approach to finite types",
                "abstract": "We provide a systematic derivation of cluster alphabets of finite types. The construction is based on a geometric realization of the generalized worldsheets by gluing and folding a pair of polygons. The cross ratios of the worldsheet z variables are evolved using the Y-system equations. By a new gauge choice, we obtain a simpler set of cluster alphabets than the known ones.",
                "disciplines": [
                    "4904"
                ]
            },
            "10.1007/jhep11(2023)005": {
                "title": "Scattering amplitudes from dispersive iterations of unitarity",
                "abstract": "We present and numerically implement a computational method to construct relativistic scattering amplitudes that obey analyticity, crossing, elastic and inelastic unitarity in three and four spacetime dimensions. The algorithm is based on the Mandelstam representation of the amplitude and iterations of unitarity. The input for the iterative procedure is given by the multi-particle double spectral density, the S-wave inelasticity, and the value of the amplitude at the crossing-symmetric point. The output, obtained at the fixed point of the iteration of unitarity, is a nonperturbative scattering amplitude. The amplitudes we obtain exhibit interesting features, such as non-zero particle production, intricate high-energy and near the two-particle threshold behavior. Scattering amplitudes obtained by initializing the iteration process with zero (or small) multi-particle input end up close to saturating the S-matrix bounds derived by other methods. There is a version of the iterative algorithm that is directly related to Feynman diagrams: it effectively re-sums infinitely many two-particle reducible planar Feynman graphs in the \u03d54 theory, which remarkably produces a unitary nonperturbative scattering amplitude function. Finally, we discuss how the algorithm can be further refined by including multi-particle unitarity.",
                "disciplines": [
                    "4902",
                    "5107"
                ]
            }
        }
    },
    "13057889": {
        "title": "Development of targeted microbiome therapeutics and dietary interventions for potent intestinal barrier promotion to minimize GI-ARS",
        "abstract": "ABSTRACT Exposure to total body irradiation (TBI) produced by nuclear accidents, premeditated nuclear, or terrorist attack causes gastrointestinal (GI) acute radiation syndrome (GI-ARS), a state of severe intestinal mucosal barrier damage, loss of tissue integrity, and translocation of the luminal content. Measures to counteract the effect of such detrimental exposure are critical for the survival and well-being of those impacted. The gastrointestinal microbiome (bacteria and metabolites) plays a crucial role in the maintenance of tissue homeostasis. Multiple studies have implicated specific microbiome clades as responsible for promoting intestinal barrier function and consequent resistance against infections and inflammatory conditions. The central hypothesis of this project is that targeted microbiome supplementation with specific subsets of intestinal bacteria or probiotics engineered to produce barrier function-promoting metabolites and their enhancement via precise dietary intervention actively improves barrier homeostasis in the intestinal epithelium, creating an environment that reduces GI-ARS. In Aim 1, we will develop novel live biotherapeutic products that minimize GI-ARS by promoting barrier function through the potent induction of functional epithelial surface P-glycoprotein expression. Additionally, we will uncover the broader distribution of this receptor system within clinical, metagenomic samples. In Aim 2, we will develop a novel genetically engineered strain of the probiotic E. coli Nissle 1917 that minimizes GI-ARS by promoting barrier function through the potent constitutive production of succinate. Lastly, in Aim 3 we will evaluate the effect of prebiotics-enriched diets in promoting GI-ARS limitation by barrier-enhancing intestinal bacteria. Cumulatively, this work will generate novel microbiome therapeutic agents that, by specifically targeting intestinal barrier function, minimize GI-ARS and increase survival after total body irradiation.",
        "disciplines": [
            "3205"
        ],
        "publications": {
            "10.1101/2024.01.29.574039": {
                "title": "Microbiota encoded fatty-acid metabolism expands tuft cells to protect tissues homeostasis during Clostridioides difficile infection in the large intestine",
                "abstract": "Metabolic byproducts of the intestinal microbiota are crucial in maintaining host immune tone and shaping inter-species ecological dynamics. Among these metabolites, succinate is a driver of tuft cell (TC) differentiation and consequent type 2 immunity-dependent protection against invading parasites in the small intestine. Succinate is also a growth enhancer of the nosocomial pathogen <i>Clostridioides difficile</i> in the large intestine. To date, no research has shown the role of succinate in modulating TC dynamics in the large intestine, or the relevance of this immune pathway to <i>C. difficile</i> pathophysiology. Here we reveal the existence of a three-way circuit between commensal microbes, <i>C. difficile</i> and host epithelial cells which centers around succinate. Through selective microbiota depletion experiments we demonstrate higher levels of type 2 cytokines leading to expansion of TCs in the colon. We then demonstrate the causal role of the microbiome in modulating colonic TC abundance and subsequent type 2 cytokine induction using rational supplementation experiments with fecal transplants and microbial consortia of succinate-producing bacteria. We show that administration of a succinate-deficient <i>Bacteroides thetaiotaomicron</i> knockout (\u0394frd) significantly reduces the enhanced type 2 immunity in mono-colonized mice. Finally, we demonstrate that mice prophylactically administered with the consortium of succinate-producing bacteria show reduced <i>C. difficile</i>-induced morbidity and mortality compared to mice administered with heat-killed bacteria or the vehicle. This effect is reduced in a partial tuft cell knockout mouse, <i>Pou2f3</i><sup>+/-</sup>, and nullified in the tuft cell knockout mouse, <i>Pou2f3</i><sup>-/-</sup>, confirming that the observed protection occurs <i>via</i> the TC pathway. Succinate is an intermediary metabolite of the production of short-chain fatty acids, and its concentration often increases during dysbiosis. The first barrier to enteric pathogens alike is the intestinal epithelial barrier, and host maintenance and strengthening of barrier integrity is vital to homeostasis. Considering our data, we propose that activation of TC by the microbiota-produced succinate in the colon is a mechanism evolved by the host to counterbalance microbiome-derived cues that facilitate invasion by intestinal pathogens.",
                "disciplines": [
                    "3107"
                ]
            },
            "10.1126/scitranslmed.adi9711": {
                "title": "Commensal antimicrobial resistance mediates microbiome resilience to antibiotic disruption",
                "abstract": "Despite their therapeutic benefits, antibiotics exert collateral damage on the microbiome and promote antimicrobial resistance. However, the mechanisms governing microbiome recovery from antibiotics are poorly understood. Treatment of <i>Mycobacterium tuberculosis</i>, the world's most common infection, represents the longest antimicrobial exposure in humans. Here, we investigate gut microbiome dynamics over 20 months of multidrug-resistant tuberculosis (TB) and 6 months of drug-sensitive TB treatment in humans. We find that gut microbiome dynamics and TB clearance are shared predictive cofactors of the resolution of TB-driven inflammation. The initial severe taxonomic and functional microbiome disruption, pathobiont domination, and enhancement of antibiotic resistance that initially accompanied long-term antibiotics were countered by later recovery of commensals. This resilience was driven by the competing evolution of antimicrobial resistance mutations in pathobionts and commensals, with commensal strains with resistance mutations reestablishing dominance. Fecal-microbiota transplantation of the antibiotic-resistant commensal microbiome in mice recapitulated resistance to further antibiotic disruption. These findings demonstrate that antimicrobial resistance mutations in commensals can have paradoxically beneficial effects by promoting microbiome resilience to antimicrobials and identify microbiome dynamics as a predictor of disease resolution in antibiotic therapy of a chronic infection.",
                "disciplines": [
                    "3207"
                ]
            }
        }
    },
    "13242798": {
        "title": "How DNA Damage Response contributes to Liver Metabolic Disorders \u2013 DNAFAT",
        "abstract": "Non-Alcoholic Fatty Liver Disease (NAFLD) is a major public health concern. Alarmingly, steatosis (NAFL) progresses pejoratively to Non-Alcoholic Steatohepatitis (NASH), which is considered as a growing worldwide epidemic threat, due to the absence of treatment. DNA-FAT consortium identified for the first time how DNA Damage Response triggers the cGAS-STING pathway in hepatocytes linking DNA lesions, metabolism and immunosurveillance. The goal of DNA-FAT project is now to determine how DNA Damage Response contributes to Liver Metabolic Disorders. Our project involves efficient teamwork, sharing unique tools, techniques and scientific expertise and will be dedicated to: Obj. 1: - Monitor the outcome of DNA lesions accumulation in fatty hepatocytes during NAFLD. Obj. 2: - Decipher the role of DDR genes in metabolic reprogramming during NAFLD, Obj. 3: - Unravel the role of STING/cGAS pathway in the inflammatory response during NAFLD. Obj. 4: - Perform a translational analysis in human NAFLD. DNA-FAT project should represent an important step towards that will allow the identification of novel therapeutic candidates to prevent the NAFLD progression.",
        "disciplines": [
            "3102"
        ],
        "publications": {
            "10.3390/cancers15143723": {
                "title": "NAFLD-Related HCC: Focus on the Latest Relevant Preclinical Models",
                "abstract": "Hepatocellular carcinoma (HCC) is the most common type of primary liver cancer and one of the deadliest cancers worldwide. Despite extensive research, the biological mechanisms underlying HCC's development and progression remain only partially understood. Chronic overeating and/or sedentary-lifestyle-associated obesity, which promote Non-Alcoholic Fatty Liver Disease (NAFLD), have recently emerged as worrying risk factors for HCC. NAFLD is characterized by excessive hepatocellular lipid accumulation (steatosis) and affects one quarter of the world's population. Steatosis progresses in the more severe inflammatory form, Non-Alcoholic Steatohepatitis (NASH), potentially leading to HCC. The incidence of NASH is expected to increase by up to 56% over the next 10 years. Better diagnoses and the establishment of effective treatments for NAFLD and HCC will require improvements in our understanding of the fundamental mechanisms of the disease's development. This review describes the pathogenesis of NAFLD and the mechanisms underlying the transition from NAFL/NASH to HCC. We also discuss a selection of appropriate preclinical models of NAFLD for research, from cellular models such as liver-on-a-chip models to in vivo models, focusing particularly on mouse models of dietary NAFLD-HCC.",
                "disciplines": [
                    "3211"
                ]
            }
        }
    },
    "10007857": {
        "title": "A new platform technology for gene therapy",
        "abstract": "The project aims to make a landmark contribution to biological science by enabling programmed delivery of therapeutic payloads from biocompatible materials. It will employ a novel synthetic biology approach to form two distinct peptide-enabled molecular architectures in a single system. This is expected to deliver a platform technology that will allow successful programmed delivery of viral vectors. The project is likely to deliver significant societal benefit as a fundamental scientific platform, improving Australia's capacity and impact in the agriculture and the healthcare sectors. The platform technology has the potential to increase the quality of life for patients and their carers, while also produce fitter, healthier livestock.",
        "disciplines": [
            "3206"
        ],
        "publications": {
            "10.1021/acsnano.3c11337": {
                "title": "Neuronal Replenishment via Hydrogel-Rationed Delivery of Reprogramming Factors",
                "abstract": "The central nervous system's limited capacity for regeneration often leads to permanent neuronal loss following injury. Reprogramming resident reactive astrocytes into induced neurons at the site of injury is a promising strategy for neural repair, but challenges persist in stabilizing and accurately targeting viral vectors for transgene expression. In this study, we employed a bioinspired self-assembling peptide (SAP) hydrogel for the precise and controlled release of a hybrid adeno-associated virus (AAV) vector, AAVDJ, carrying the NeuroD1 neural reprogramming transgene. This method effectively mitigates the issues of high viral dosage at the target site, off-target delivery, and immunogenic reactions, enhancing the vector's targeting and reprogramming efficiency. <i>In vitro</i>, this vector successfully induced neuron formation, as confirmed by morphological, histochemical, and electrophysiological analyses. <i>In vivo</i>, SAP-mediated delivery of AAVDJ-NeuroD1 facilitated the trans-differentiation of reactive host astrocytes into induced neurons, concurrently reducing glial scarring. Our findings introduce a safe and effective method for treating central nervous system injuries, marking a significant advancement in regenerative neuroscience.",
                "disciplines": [
                    "4003",
                    "3206",
                    "3209"
                ]
            },
            "10.1038/s41467-023-36133-8": {
                "title": "Hydrogel oxygen reservoirs increase functional integration of neural stem cell grafts by meeting metabolic demands",
                "abstract": "Injectable biomimetic hydrogels have great potential for use in regenerative medicine as cellular delivery vectors. However, they can suffer from issues relating to hypoxia, including poor cell survival, differentiation, and functional integration owing to the lack of an established vascular network. Here we engineer a hybrid myoglobin:peptide hydrogel that can concomitantly deliver stem cells and oxygen to the brain to support engraftment until vascularisation can occur naturally. We show that this hybrid hydrogel can modulate cell fate specification within progenitor cell grafts, resulting in a significant increase in neuronal differentiation. We find that the addition of myoglobin to the hydrogel results in more extensive innervation within the host tissue from the grafted cells, which is essential for neuronal replacement strategies to ensure functional synaptic connectivity. This approach could result in greater functional integration of stem cell-derived grafts for the treatment of neural injuries and diseases affecting the central and peripheral nervous systems.",
                "disciplines": [
                    "3206",
                    "4003"
                ]
            }
        }
    },
    "13057672": {
        "title": "Biomimetic approaches for enthesis tissue engineering",
        "abstract": "ABSTRACT Rotator cuff tears are prevalent, particularly in the elderly population, and typically require surgical repair to regain shoulder function. Unfortunately, successful repair remains a major clinical challenge, with high post- operative failure rates. At the root of these failures is poor healing at the repaired tendon-to-bone interface, which does not regenerate the native tendon enthesis attachment structures. Specifically, the healthy tendon enthesis consists of a transitional tissue with spatial gradations in composition (e.g., mineral content) and cell phenotype (e.g., tenocytes, chondrocytes, and osteoblasts), which provides a strong and tough attachment to transfer muscle load from tendon to bone. To address the critical clinical need to improve outcomes after tendon-to-bone repair, this project brings together a multidisciplinary research team to develop, validate, and translate a novel class of biomimetic scaffolds for enhancing healing. The team is led by Dr. Thomopoulos (MPI, an expert in tendon-to-bone development, pathology, and repair) from Orthopedics and Biomedical Engineering at Columbia University and Dr. Xia (MPI, an expert in materials science and nanotechnology) from Biomedical Engineering at Georgia Tech. Key compositional and structural features of the natural tendon-to-bone attachment will be directly fabricated in Aim 1 or generated by stem cells provided with the appropriate cues in Aim 2. The first (acellular) approach has the benefit of high throughput and off-the-shelf availability whereas the second (cellular) approach has the advantage of a responsive extracellular matrix generating component. Funnel-shaped microchannels will be laser drilled through the depth of the scaffolds to encourage cell migration and extracellular matrix deposition, and thus alleviate the concern that the interposed scaffold will be a barrier to healing between the tendon and bone. These two designs will be independently fabricated and evaluated in vitro and then tested in a clinically relevant animal model of rotator cuff injury and repair in Aim 3. Reducing the failure rates of rotator cuff surgical repairs will have a major impact on a large population of patients. The proposed clinically relevant translational studies have the potential to directly impact the treatment of rotator cuff injuries. Furthermore, the results will be broadly applicable to connective tissue-to-bone repair in other locations (e.g., ACL reconstruction, meniscal repair).",
        "disciplines": [
            "4003"
        ],
        "publications": {
            "10.1016/j.cobme.2024.100547": {
                "title": "Achieving tendon enthesis regeneration across length scales",
                "abstract": "Surgical reattachment of tendon to bone is a clinical challenge, with unacceptably high retear rates in the early period after repair. A primary reason for these repeated tears is that the multiscale toughening mechanisms found at the healthy tendon enthesis are not regenerated during tendon-to-bone healing. The need for technologies to improve these outcomes is pressing, and the tissue engineering community has responded with many advances that hold promise for eventually regenerating the multiscale tissue interface that transfers loads between the two dissimilar materials, tendon, and bone. This review provides an assessment of the state of these approaches, with the aim of identifying a critical agenda for future progress.",
                "disciplines": [
                    "4003"
                ]
            },
            "10.1002/ange.202319567": {
                "title": "Putting Hybrid Nanomaterials to Work for Biomedical Applications",
                "abstract": "Abstract Hybrid nanomaterials have found use in many biomedical applications. This article provides a comprehensive review of the principles, techniques, and recent advancements in the design and fabrication of hybrid nanomaterials for biomedicine. We begin with an introduction to the general concept of material hybridization, followed by a discussion of how this approach leads to materials with additional functionality and enhanced performance. We then highlight hybrid nanomaterials in the forms of nanostructures, nanocomposites, metal\u2013organic frameworks, and biohybrids, including their fabrication methods. We also showcase the use of hybrid nanomaterials to advance biomedical engineering in the context of nanomedicine, regenerative medicine, diagnostics, theranostics, and biomanufacturing. Finally, we offer perspectives on challenges and opportunities.",
                "disciplines": [
                    "3206",
                    "4018"
                ]
            },
            "10.1002/anie.202319567": {
                "title": "Putting Hybrid Nanomaterials to Work for Biomedical Applications",
                "abstract": "Hybrid nanomaterials have found use in many biomedical applications. This article provides a comprehensive review of the principles, techniques, and recent advancements in the design and fabrication of hybrid nanomaterials for biomedicine. We begin with an introduction to the general concept of material hybridization, followed by a discussion of how this approach leads to materials with additional functionality and enhanced performance. We then highlight hybrid nanomaterials in the forms of nanostructures, nanocomposites, metal-organic frameworks, and biohybrids, including their fabrication methods. We also showcase the use of hybrid nanomaterials to advance biomedical engineering in the context of nanomedicine, regenerative medicine, diagnostics, theranostics, and biomanufacturing. Finally, we offer perspectives on challenges and opportunities.",
                "disciplines": []
            }
        }
    },
    "13056454": {
        "title": "Development and validation of predictive models based on a portable spectrometer and NIR hyperspectral imaging and machine learning to predict the composition of black soldier fly larvae (Hermetia illucens)",
        "abstract": "With the current population growth, the food industry is looking for sustainable sources of food. Edible insects are seen as a sustainable source of protein and fat, which can help fill the world's food deficit. In this group, the larva of the black soldier fly (Hermetia illucens) has aroused great interest for being able to quickly transform (~14 days) organic waste into high quality protein, as well as fat, chitin and minerals. The insect production industry is growing in the world, including Brazil. Therefore, it is necessary to develop methodologies for analyzing the quality of larvae and larval meal quickly and efficiently. Near-infrared spectroscopy (NIRS) allows the development of a non-destructive, fast analysis methodology with minimal sample preparation. Portable NIR spectrometers have emerged as a way to perform in situ measurements due to their ergonomic design, ease of transporting them and their relatively low cost. On the other hand, hyperspectral NIR images simultaneously provide spectral (chemical) and spatial (physical) information of the entire region of interest without the need for contact with the sample. For these reasons, they can be an alternative to traditional methods, allowing better quality control of black soldier fly larvae. Thus, this project aims at the development and validation of predictive models based on portable NIR spectrometers or hyperspectral images and machine learning for the prediction of the chemical composition of black soldier fly larvae, more specifically fat content, protein content and fatty acid profile. .",
        "disciplines": [
            "3001"
        ],
        "publications": {
            "10.1016/j.jfca.2023.105901": {
                "title": "Detection of adulteration of Alpaca (Vicugna pacos) meat using a portable NIR spectrometer and NIR-hyperspectral imaging",
                "abstract": "Alpaca meat has high protein content; good tenderness and low intramuscular fat content, being more expensive than meat from other animals (e.g., beef). Hence, alpaca meat may face adulteration, which demands chemical analytical methods to be identified. In this study, chemical-free methods, e.g., portable NIR spectrometer and NIR-HSI were employed to detect adulteration of alpaca meat with pork, chicken, and beef (0 \u2013 50% w/w). Spectral analysis revealed significant differences in the spectra of pure alpaca meat samples using NIR-HSI. Principal Component Analysis (PCA) grouped samples into pure and non-pure alpaca meat using both devices as sources of spectra. Next, we developed and validated one-class Data Driven Soft Independent Class Analogy (DD-SIMCA) models to authenticate pure alpaca meat. DD-SIMCA models using spectra acquired by both devices achieved 100% sensitivity and 100% specificity for external set of samples. Besides, Partial Least Squares Regression (PLSR) based on NIR-HSI outperformed the portable NIR spectrometer to predict the concentration of adulterant in alpaca meat. In conclusion, both devices supported by chemometric approaches can be implemented as screening methods to detect adulteration in alpaca meat.",
                "disciplines": [
                    "3003"
                ]
            },
            "10.1016/j.foodcont.2023.109969": {
                "title": "Prediction of protein and lipid content in black soldier fly (Hermetia illucens L.) larvae flour using portable NIR spectrometers and chemometrics",
                "abstract": "Black soldier fly (BSF) larvae meet circular economy requirements by transforming waste into high-quality protein and lipids. Because of the rapid larva development to the mature stage (14 days - 2 months), the insect production industry seeks rapid analytical methods. We evaluated the performance of two portable NIR spectrometers (1: 900\u20131700\u00a0nm; 2: 1350\u20132562\u00a0nm), coupled to Partial Least Square Regression (PLSR) and Support Vector Machine Regression (SVMR) to predict protein and lipid content (%) in BSF larvae flour. The spectra dataset was explored by Principal Component Analysis (PCA). PLSR and SVMR performed similarly in predicting protein content for both spectrometers according to Residual Prediction Deviation (RPD >2.5) and Root Mean Square Error of Prediction (RMSEP\u00a0=\u00a01.9%). SVMR turned out to yield a better prediction performance for the lipidic content (RMSEP\u00a0=\u00a03.51%; RPD\u00a0=\u00a04.32) respect to PLSR. Moreover, spectrometer 2, working at a higher wavelength range, showed better performance than spectrometer 1. In addition, a variable selection step was performed, where interval PLS (iPLS) and genetic algorithm (GA) improved PLSR models. In conclusion, a portable NIR spectrometer coupled with chemometrics could support rapid analytical measurements in the insect industry.",
                "disciplines": [
                    "4004",
                    "3006"
                ]
            }
        }
    },
    "13057249": {
        "title": "EAGER: Measuring the Impact and Diffusion of Open Source Software Innovation on Contributor and Project Networks",
        "abstract": "Open-Source Software (OSS) is developed, maintained, and extended through the contribution of independent developers as well as individuals and groups from universities, government research institutions, businesses, and nonprofits. Many OSS projects are developed in free repositories, and the information embedded in these repositories - including the code, contributors, and development activity - is publicly available. However, the extent and impacts of OSS on the economy and innovation are currently unknown, and the creation and use of OSS highlight an aspect of technology diffusion and flow not captured in science and technology indicators. The goals of this project are to discover, collect, and use publicly available non-survey data sources on OSS and to test the feasibility of developing methods to measure the impact and diffusion of OSS innovation. The project will evaluate OSS through development of rigorous, repeatable, and scalable methods and metrics. The outputs of this effort \u2014 unique data sets, code, and the resulting analyses of the interactions among contributors and projects \u2014 advance our nascent knowledge about OSS, including the patterns and dynamics of collaborations, influential actors, prevailing topics, and diffusion. Developed measures will complement existing indicators on peer-reviewed publications and patents. Our framework could apply to other aspects of open science, such as shared data available in public repositories. To address our core questions, we propose (i) to characterize the OSS ecosystem by analyzing available information on OSS projects (creation and use), and developers (institutions, sectors, and countries); (ii) to represent the interactions using networks of contributors (through collaborations between developers) and networks of OSS projects (through reuses across projects and shared contributors) and to analyze their structural features; (iii) to develop methods to measure the impact of projects and developers using network-based and OSS-based measures (e.g., downloads); (iv) to study the diffusion of OSS innovation within and across institutions, sectors and countries; and (v) to bring forward a unique and novel data product combining various data sources on OSS. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4610",
            "4612"
        ],
        "publications": {
            "10.1016/j.respol.2024.104954": {
                "title": "From GitHub to GDP: A framework for measuring open source software innovation",
                "abstract": "Open source software (OSS) is software that anyone can review, modify, and distribute freely, usually with only minor restrictions such as giving credit to the creator of the work. The use of OSS is growing rapidly, due to its value in increasing firm and economy-wide productivity. Despite its widespread use, there is no standardized methodology for measuring the scope and impact of this fundamental intangible asset. This study presents a framework to measure the value of OSS using data collected from GitHub, the largest platform in the world with over 100 million developers. The data include over 7.6 million repositories where software is developed, stored, and managed. We collect information about contributors and development activity such as code changes and license detail. By adopting a cost estimation model from software engineering, we develop a methodology to generate estimates of investment in OSS that are consistent with the U.S. national accounting methods used for measuring software investment. We generate annual estimates of current and inflation-adjusted investment as well as the net stock of OSS for the 2009\u20132019 period. Our estimates show that the U.S. investment in 2019 was $37.8 billion with a current-cost net stock of $74.3 billion.",
                "disciplines": [
                    "3502"
                ]
            }
        }
    },
    "13016892": {
        "title": "Identifying the causes and consequences of the Diversity of Individual Trajectories of life histories in age-structured populations \u2013 DivInT",
        "abstract": "While the analysis of biodiversity has become a major topic of ecology and evolution, the diversity observed in life history trait trajectories at the individual level remains poorly understood. DivInT aims at filling this knowledge gap by (1) integrating existing data on individual trajectories of life history traits in contrasted populations of vertebrates, (2) performing standardized analyses of these trajectories within and among populations both within and across traits, (3) measuring the diversity of observed individual trajectories of phenotypic traits and fitness components, (4) identifying factors that shape the diversity of individual trajectories and quantifying their impact on population growth rate, and (5) quantifying the relative contribution of chance, constraint, and adaptation in shaping individual trajectories within and across populations. DivInT will thus provide new insight on how individual heterogeneity shapes population dynamics and life history evolution.",
        "disciplines": [
            "3104",
            "3103"
        ],
        "publications": {
            "10.1371/journal.pbio.3002513": {
                "title": "A unified framework for evolutionary genetic and physiological theories of aging",
                "abstract": "Why and how we age are 2 intertwined questions that have fascinated scientists for many decades. However, attempts to answer these questions remain compartmentalized, preventing a comprehensive understanding of the aging process. We argue that the current lack of knowledge about the evolution of aging mechanisms is due to a lack of clarity regarding evolutionary theories of aging that explicitly involve physiological processes: the disposable soma theory (DST) and the developmental theory of aging (DTA). In this Essay, we propose a new hierarchical model linking genes to vital rates, enabling us to critically reevaluate the DST and DTA in terms of their relationship to evolutionary genetic theories of aging (mutation accumulation (MA) and antagonistic pleiotropy (AP)). We also demonstrate how these 2 theories can be incorporated in a unified hierarchical framework. The new framework will help to generate testable hypotheses of how the hallmarks of aging are shaped by natural selection.",
                "disciplines": []
            }
        }
    },
    "10007782": {
        "title": "Formal Verification of Quantum Logic Circuits",
        "abstract": "The project aims to develop comprehensive theory and effective techniques for formal modelling, equivalence checking, and model checking of quantum circuits. The research is timely as the rapid growth of quantum computing hardware makes it an urgent task to develop verification techniques for quantum hardware design and quantum compilers. The successful development of the algorithms and software tools proposed in this project will significantly advance the knowledge on formal verification of quantum circuits and help Australian quantum start-ups build and maintain an internationally leading position in the rapidly emerging quantum electronic design automation (EDA) industry.",
        "disciplines": [
            "4009",
            "4612"
        ],
        "publications": {
            "10.1109/qce57702.2023.00111": {
                "title": "Decision Diagrams for Symbolic Verification of Quantum Circuits",
                "abstract": "With the rapid development of quantum computing, automatic verification of quantum circuits becomes more and more important. While several decision diagrams (DDs) have been introduced in quantum circuit simulation and verification, none of them supports symbolic computation. Algorithmic manipulations of symbolic objects, however, have been identified as crucial, if not indispensable, for several verification tasks. This paper proposes the first decision-diagram approach for operating symbolic objects and verifying quantum circuits with symbolic terms. As a notable example, our symbolic tensor decision diagrams (symbolic TDD) could verify the functionality of the 160-qubit quantum Fourier transform circuit within three minutes. Moreover, as demonstrated on Bernstein-Vazirani algorithm, Grover's algorithm, and the bit-flip error correction code, the symbolic TDD enables efficient verification of quantum circuits with user-supplied oracles and/or classical controls.",
                "disciplines": [
                    "5108",
                    "4009",
                    "4612"
                ]
            },
            "10.1109/iccad57390.2023.10323863": {
                "title": "Single-Qubit Gates Matter for Optimising Quantum Circuit Depth in Qubit Mapping",
                "abstract": "Quantum circuit transformation (QCT, a.k.a. qubit mapping) is a critical step in quantum circuit compilation. Typically, QCT is achieved by finding an appropriate initial mapping and using SWAP gates to route the qubits such that all connectivity constraints are satisfied. The objective of QCT can be to minimise circuit size or depth. Most existing QCT algorithms prioritise minimising circuit size, potentially overlooking the impact of single-qubit gates on circuit depth. In this paper, we first point out that a single SWAP gate insertion can double the circuit depth, and then propose a simple and effective method that takes into account the impact of single-qubit gates on circuit depth. Our method can be combined with many existing QCT algorithms to optimise circuit depth. The Qiskit SABRE algorithm has been widely accepted as the state-of-the-art algorithm for optimising both circuit size and depth. We demonstrate the effectiveness of our method by embedding it in SABRE, showing that it can reduce circuit depth by up to 50% and 27% on average on, for instance, Google Sycamore and 117 real quantum circuits from MQTBench.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1016/j.ic.2023.105077": {
                "title": "Abstract interpretation, Hoare logic, and incorrectness logic for quantum programs",
                "abstract": " interpretation, Hoare logic, and incorrectness (or reverse Hoare) logic are powerful techniques for static analysis of computer programs. They have all been successfully extended to the quantum setting, but developed largely in parallel. This paper explores the relationship between these techniques in the context of verifying quantum while-programs, where the abstract domain and the set of assertions for quantum states are well-structured. We show that any complete quantum abstract interpretation induces a quantum Hoare logic and a quantum incorrectness logic, both being sound and relatively complete. Moreover, the induced logic systems operate in a forward manner, making them more suitable for certain applications. Conversely, any sound and relatively complete quantum Hoare logic or incorrectness logic induces a complete quantum abstract interpretation. As an application, we show the non-existence of any sound and relatively complete quantum Hoare logic or incorrectness logic if tuples of local subspaces are taken as assertions.",
                "disciplines": []
            },
            "10.1145/3582016.3582039": {
                "title": "Verification of Nondeterministic Quantum Programs",
                "abstract": "Nondeterministic choice is a useful program construct that provides a way to describe the behaviour of a program without specifying the details of possible implementations. It supports the stepwise refinement of programs, a method that has proven useful in software development. Nondeterminism has also been introduced in quantum programming, and termination of nondeterministic quantum programs has been extensively analysed. In this paper, we go beyond termination analysis to investigate the verification of nondeterministic quantum programs where properties are given by sets of hermitian operators on the associated Hilbert space. Hoare-type logic systems for partial and total correctness are proposed which turn out to be both sound and relatively complete with respect to their corresponding semantic correctness. To show the utility of these proof systems, we analyse some quantum algorithms such as quantum error correction scheme, Deutsch algorithm, and a nondeterministic quantum walk. Finally, a proof assistant prototype is implemented to aid in the automated reasoning of nondeterministic quantum programs.",
                "disciplines": [
                    "4613",
                    "4009",
                    "4602",
                    "4612"
                ]
            },
            "10.1109/tcad.2022.3179223": {
                "title": "Supervised Learning Enhanced Quantum Circuit Transformation",
                "abstract": "A quantum circuit transformation (QCT) is required when executing a quantum program in a real quantum processing unit (QPU). By inserting auxiliary SWAP gates, a QCT algorithm transforms a quantum circuit to one that satisfies the connectivity constraint imposed by the QPU. Due to the nonnegligible gate error and the limited qubit coherence time of the QPU, QCT algorithms that minimize gate number or circuit depth or maximize the fidelity of output circuits are in urgent need. Unfortunately, finding optimized transformations often involve exhaustive searches, which are extremely time consuming and not practical for most circuits. In this article, we propose a framework that uses a policy artificial neural network (ANN) trained by supervised learning on shallow circuits to help existing QCT algorithms select the most promising SWAP gate. ANNs can be trained offline in a distributed way and the trained ANN can be easily incorporated into QCT algorithms to enable them to search deeper without bringing too much overhead in time complexity. Exemplary embeddings of the trained ANNs into target QCT algorithms demonstrate that the transformation performance can be consistently improved on QPUs with various connectivity structures and random or realistic quantum circuits.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1145/3517145": {
                "title": "Verification of Distributed Quantum Programs",
                "abstract": "Distributed quantum systems and especially the Quantum Internet have the ever-increasing potential to fully demonstrate the power of quantum computation. This is particularly true given that developing a general-purpose quantum computer is much more difficult than connecting many small quantum devices. One major challenge of implementing distributed quantum systems is programming them and verifying their correctness. In this paper, we propose a CSP-like distributed programming language to facilitate the specification and verification of such systems. After presenting its operational and denotational semantics, we develop a Hoare-style logic for distributed quantum programs and establish its soundness and (relative) completeness with respect to both partial and total correctness. The effectiveness of the logic is demonstrated by its applications in the verification of quantum teleportation and local implementation of non-local CNOT gates, two important algorithms widely used in distributed quantum systems.",
                "disciplines": [
                    "4613",
                    "4612"
                ]
            },
            "10.1016/j.tcs.2022.02.017": {
                "title": "Formal semantics of a classical-quantum language",
                "abstract": "We investigate the formal semantics of a simple imperative language that has both classical and quantum constructs. More specifically, we provide an operational semantics, a denotational semantics and two Hoare-style proof systems: an abstract one and a concrete one. The two proof systems are satisfaction-based, as inspired by the program logics of Barthe et al. for probabilistic programs. The abstract proof system turns out to be sound and relatively complete, while the concrete one is sound only.",
                "disciplines": [
                    "4904"
                ]
            },
            "10.1145/3514355": {
                "title": "A Tensor Network based Decision Diagram for Representation of Quantum Circuits",
                "abstract": "Tensor networks have been successfully applied in simulation of quantum physical systems for decades. Recently, they have also been employed in classical simulation of quantum computing, in particular, random quantum circuits. This article proposes a decision diagram style data structure, called Tensor Decision Diagram (TDD), for more principled and convenient applications of tensor networks. This new data structure provides a compact and canonical representation for quantum circuits. By exploiting circuit partition, the TDD of a quantum circuit can be computed efficiently. Furthermore, we show that the operations of tensor networks essential in their applications (e.g., addition and contraction) can also be implemented efficiently in TDDs. A proof-of-concept implementation of TDDs is presented and its efficiency is evaluated on a set of benchmark quantum circuits. It is expected that TDDs will play an important role in various design automation tasks related to quantum circuits, including but not limited to equivalence checking, error detection, synthesis, simulation, and verification.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1145/3514239": {
                "title": "Quantum Circuit Transformation: A Monte Carlo Tree Search Framework",
                "abstract": " In the noisy intermediate-scale quantum era, quantum processing units suffer from, among others, highly limited connectivity between physical qubits. To make a quantum circuit effectively executable, a circuit transformation process is necessary to transform it, with overhead cost the smaller the better, into a functionally equivalent one so that the connectivity constraints imposed by the quantum processing unit are satisfied. Although several algorithms have been proposed for this goal, the overhead costs are often very high, which degenerates the fidelity of the obtained circuits sharply. One major reason for this lies in that, due to the high branching factor and vast search space, almost all of these algorithms only search very shallowly, and thus, very often, only (at most) locally optimal solutions can be reached. In this article, we propose a Monte Carlo Tree Search (MCTS) framework to tackle the circuit transformation problem, which enables the search process to go much deeper. The general framework supports implementations aiming to reduce either the size or depth of the output circuit through introducing SWAP or remote CNOT gates. The algorithms, called MCTS-Size and MCTS-Depth , are polynomial in all relevant parameters. Empirical results on extensive realistic circuits and IBM Q Tokyo show that the MCTS-based algorithms can reduce the size (respectively, depth) overhead by, on average, 66% (respectively, 84%) when compared with t  \\( \\left| {\\mathrm{ket}} \\right\\rangle \\)  , an industrial-level compiler. ",
                "disciplines": [
                    "4009"
                ]
            }
        }
    },
    "13057720": {
        "title": "Sex-related differences in cardiac mitochondrial response to inflammation",
        "abstract": "Cardiac damage occurs following sepsis, trauma, and ischemia. Acute inflammation triggered by these injuries impairs mitochondria, a key determinant for the severity of cardiac damage. While sex dimorphism impacts consequences of these injuries, no information is available regarding sex-specific mitochondrial responses to acute inflammation. We have observed that TNFa acutely depresses cardiac function and female hearts are resistant to TNFa-induced cardiac dysfunction. We have also found sex differences in mitochondrial performance in cardiomyocytes exposed to TNFa or LPS. Thus, we reason that sex-specific mitochondrial responses to inflammation is the underlying mechanism for sex disparities in cardiac damage. Mitochondrial connexin-43 (Cx43) and caveolin-3 (Cav3, a structural protein essential for caveolae formation) are involved in mitochondrial protection in the ischemic heart. To date, neither mitochondrial (mito)Cx43 nor mitoCav3 has been studied for sex-dependent mitochondrial resilience to inflammation. Our recent study has suggested that mitoCx43 and its smaller isoform, Gja1-20k, play a role in sex-related mitochondrial responses and estrogen-mediated cardiac protection following acute ischemia/reperfusion. Our preliminary work has further indicated: 1) better cardiac function is associated with higher levels of mitoCx43 phosphorylation (p-Cx43), mitoGja1-20k and mitoCav3 in female hearts than in male hearts following TNFa or LPS challenge; 2) female cardiomyocytes have better mitochondrial performance than male ones upon TNFa or LPS exposure; 3) knockdown of Cx43 or Cav3 impairs mitochondrial function in myoblasts subjected to TNFa or LPS; 4) 17b-estradiol (E2) treatment improves mitochondrial function with increased p-Cx43 and mitoGja1-20k; ablation of cardiac Cx43 abolishes E2-elicited mitochondrial protection in cardiomyocytes exposed to TNFa; and 5) E2 enhances Cx43 and Cav3 binding to estrogen receptor (ER)a and promotes Cx43-Cav3 interaction in cardiac mitochondria. We hypothesize that female heart mitochondria are resistant to acute inflammation-induced damage via ER(s) activation-increased mitochondrial Gja1-20k, p-Cx43 and Cx43-Cav3 interaction in comparison to the male ones. In this proposed study, we will employ LPS- or cecal ligation puncture (CLP)-induced sepsis models to explore the role of mitoCx43 and mitoCav3 in regulating sex-specific cardiac mitochondrial protection. We will determine the roles of Cx43 (Aim 1), Cav3 and their interaction (Aim 2) in maintaining cardiac mitochondrial health and in sex differences of mitochondrial resilience upon acute inflammation; and assess the therapeutic potential of Gja1- 20k-loaded exosomes in LPS- or CLP-induced septic cardiomyopathy (Aim 3). We expect that novel approach using engineered exosomes to specifically deliver Gja1-20k to cardiomyocytes will improve mitochondrial preservation and cardiac function in septic cardiomyopathy. Completion of the proposed study will bring novel insights about sex-specific differential mitochondrial responses to acute inflammation and offer the basis of developing novel approaches in treating acute inflammation-caused cardiomyopathy in both sexes.",
        "disciplines": [
            "3208"
        ],
        "publications": {
            "10.1038/s41598-024-51799-w": {
                "title": "Importance of Per2 in cardiac mitochondrial protection during stress",
                "abstract": "During myocardial injury, inflammatory mediators and oxidative stress significantly increase to impair cardiac mitochondria. Emerging evidence has highlighted interplays between circadian protein\u2014period 2 (Per2) and mitochondrial metabolism. However, besides circadian rhythm regulation, the direct role of Per2 in mitochondrial performance particularly following acute stress, remains unknown. In this study, we aim to determine the importance of Per2 protein\u2019s regulatory role in mitochondrial function following exposure to inflammatory cytokine TNF\u03b1 and oxidative stressor H2O2 in human cardiomyocytes. Global warm ischemia (37\u00a0\u00b0C) significantly impaired complex I activity with concurrently reduced mitochondrial Per2 in adult mouse hearts. TNF\u03b1 or H2O2 decreased Per2 protein levels and damaged mitochondrial respiratory function in adult mouse cardiomyocytes. Next, mitochondrial membrane potential (\u0394\u03c8$$\\Delta \\psi$$M) using JC-1 fluorescence probe and mitochondrial respiration capacity via Seahorse Cell Mito Stress Test were then detected in Per2 or control siRNA transfected AC16 Human Cardiomyocytes (HCM) that were subjected to 2\u00a0h-treatment of TNF\u03b1 (100\u00a0ng/ml) or H2O2 (100\u00a0\u03bcM). After 4\u00a0h-treatment, cell death was also measured using Annexin V and propidium iodide apoptosis kit through flow cytometry. We found that knockdown of Per2 enhanced TNF\u03b1-induced cell death and TNF\u03b1- or H2O2-disrupted \u0394\u03c8$$\\Delta \\psi$$M, as well as TNF\u03b1- or H2O2-impaired mitochondrial respiration function. In conclusion, Per2 knockdown increases likelihood of cell death and mitochondrial dysfunction in human cardiomyocytes exposed to either TNF\u03b1 or H2O2, supporting the protective role of Per2 in HCM during stress with a focus on mitochondrial function.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.3390/cells12242815": {
                "title": "Mesenchymal Stem Cell-Derived Exosomal microRNAs in Cardiac Regeneration",
                "abstract": "Mesenchymal stem cell (MSC)-based therapy is one of the most promising modalities for cardiac repair. Accumulated evidence suggests that the therapeutic value of MSCs is mainly attributable to exosomes. MSC-derived exosomes (MSC-Exos) replicate the beneficial effects of MSCs by regulating various cellular responses and signaling pathways implicated in cardiac regeneration and repair. miRNAs constitute an important fraction of exosome content and are key contributors to the biological function of MSC-Exo. MSC-Exo carrying specific miRNAs provides anti-apoptotic, anti-inflammatory, anti-fibrotic, and angiogenic effects within the infarcted heart. Studying exosomal miRNAs will provide an important insight into the molecular mechanisms of MSC-Exo in cardiac regeneration and repair. This significant information can help optimize cell-free treatment and overcome the challenges associated with MSC-Exo therapeutic application. In this review, we summarize the characteristics and the potential mechanisms of MSC-derived exosomal miRNAs in cardiac repair and regeneration.",
                "disciplines": [
                    "3206"
                ]
            }
        }
    },
    "13043499": {
        "title": "The Application of UN Charter Chapter XI to Military Occupations",
        "abstract": "This book argues that Chapter XI should apply to all situations of occupation, regardless of their stated purpose. When a foreign State stays in a territory by force, the foreign State becomes the occupant and occupation law applies. It shall be shown that occupation law presents an economic incentive to remain in foreign territory or even to invade it in the first place. The problem with this is, that during occupation, there is no peace. But peace is the stated purpose of the Charter of the United Nations. The prohibition of the use of force in the Charter is powerless against occupation law and its incentive to occupy. Therefore, the Charter must offer a remedy against the incentive to occupy. In other words, it must provide an alternative to traditional occupation law. An alternative that applies despite the deficiencies of the collective security system.The United Nations have applied Chapter XI of the Charter with the aim to end colonialism. It will be argued that Chapter XI applies not only to historic colonies but to all occupations and that historic colonies themselves were in fact occupied territories at the time they were taken under the aegis of Chapter XI. Therefore, the purpose of Chapter XI is not fulfilled at a historical point in time, but instead continues as long as there will be military occupations. A contemporary interpretation shall reveal that Chapter XI subjects the occupant to extensive economic obligations. These obligations shall render it economically unattractive to stay in foreign territory by force. Chapter XI can put the Charter in a position to reach its purpose of peace by dissolving existing, and preventing future occupations.",
        "disciplines": [
            "4801"
        ],
        "publications": {
            "10.5771/9783748935544": {
                "title": "The Application of UN Charter Chapter XI to Military Occupations",
                "abstract": "<p>This book argues that Chapter XI of the UN Charter should be applied to military occupations. The book operates in two parts. First, it describes the status quo of the law of military occupation and the economic incentive that this status quo holds for the occupant. Second, it shows by way of a contemporary interpretation, how Chapter XI should be applied and what it would mean for the economic rights of the inhabitants. It will be argued that the application of Chapter XI would make it economically unattractive for an occupant to stay in the foreign territory, while leaving his right to self-defense intact.</p> <p>This book is of interest to scholars and practitioners who are seeking new avenues for the laws of military occupation.</p>",
                "disciplines": [
                    "4807"
                ]
            }
        }
    },
    "13042856": {
        "title": "Network-based credit risk models in P2P lending markets",
        "abstract": "P2P (peer-to-peer) lending today consists of the lending of money to individuals and businesses through online services without bank intermediation (Thakor, 2020). P2P platforms offer a secure cyberspace (Niu et al., 2020) where borrowers are linked to investors who engage (usually) in a buyout auction, where the bidding process ends when the loan has been fully funded (Xia et al., 2017). Bank lending is backed by deposits, uninsured debt and equity; thus, banks have skin in the game, unlike P2P lending platforms, where loans are funded by investors directly, i.e., through investors\u2019 equity. Higher interest rates and diversification potential incentivize lenders, represented by individuals and recently also by banks, hedge funds, venture capital firms and private equity firms (Giudici et al. 2019a), to participate in P2P lending. Traditional banks receive loan repayments that are used to pay out depositors, subordinated debt holders and potentially shareholders, while P2P platforms receive fees from loan origination (paid by the borrower) and transaction fees. Administration of lending tends to be cheaper for P2P platforms, which provide an online marketplace and initial risk classification, while banks are subject to much tighter regulation and thus have higher costs (Thakor, 2020). However, banks have much richer data at their disposal (e.g., through long-term relational banking), which makes their task of identifying potential nonperforming loans easier. One would therefore expect P2P platforms to attract borrowers who would otherwise not be eligible for bank loans. This effect is amplified during recessions, as reduced access to bank credit directs riskier borrowers towards the P2P markets. This phenomenon has been observed empirically, as several studies have found that after the 2008 recession, the growth of P2P markets accelerated (e.g., Jin and Zhu, 2015). Similar growth is likely to unfold during and after the current worldwide economic crisis induced by the COVID-19 pandemic.Given the nature of P2P markets, they are characterized as immature industries with loose regulation, greater information asymmetry and increased credit risk, which all lead to higher default rates. This leaves the door open to considerable risks. To mitigate adverse selection and moral hazard problems, one needs to build trust. In traditional bank-lending markets, trust is constructed via relational banking, using collateral, certified accounts, risk monitoring, the presence of a board of directors, tighter regulation, etc. (Emekter, 2015). Voluntary implementation of these mechanisms would incur significant costs and thus marginalize the competitive edge of P2P lending markets. Several recent studies have found that the failure of P2P platforms in China is related to general market conditions (bond yields), ownership, information disclosure, and popularity, while political ties were found to also play an important role (e.g., Gao et al., 2021, He and Li, 2021). A hands-on approach to establishing trust between investors and P2P markets is to use accurate credit risk models. The main objective of the proposed research project is to design a state-of-the art and interpretable credit risk models for P2P lending markets.",
        "disciplines": [
            "3502",
            "3801",
            "3501"
        ],
        "publications": {
            "10.1016/j.eswa.2024.124100": {
                "title": "Leveraging network topology for credit risk assessment in P2P lending: A comparative study under the lens of machine learning",
                "abstract": "Peer-to-Peer (P2P) lending markets have witnessed remarkable growth, revolutionizing the way borrowers and lenders interact. Despite the increasing popularity of P2P lending, it poses significant challenges related to credit risk assessment and default prediction with meaningful implications for financial stability. Traditional credit risk models have been widely employed in the field of P2P lending; however, they may not be capable to capture latent factor information inherent to a loan network based on similarity distances. Thus, in this study we propose an enhanced two-step modeling approach for Machine Learning (ML) that utilizes insights from network analysis and subsequently combines derived network centrality metrics with traditional credit risk factors to improve the prediction accuracy in the credit default prediction process. Through a comparative analysis of three classical ML models with varying degrees of complexity, namely Elastic Net (EN), Random Forest (RF), and Multi-Layer Perceptron (MLP), we showcase novel evidence that the systematic inclusion of network topology features in the credit scoring process can significantly improve the prediction accuracy of the scoring models. Additional robustness tests via the inclusion of randomly shuffled centrality metrics in the analysis, and a further comparison of the graph-based models against a pertinent state-of-the-art credit scoring model in form of XGBoost, further confirm our results. The insights from this study bear valuable conclusions for P2P lending platforms to further improve their scoring systems with graph-enhanced metrics, thereby reducing default risk and facilitating greater access to credit.",
                "disciplines": [
                    "3502"
                ]
            },
            "10.1016/j.frl.2024.105308": {
                "title": "Network centrality and credit risk: A comprehensive analysis of peer-to-peer lending dynamics",
                "abstract": "This letter analyzes credit risk assessment in the Peer-to-Peer (P2P) lending domain by leveraging a comprehensive dataset from Bondora, a leading European P2P platform. Through combining traditional credit features with network topological features, namely the degree centrality, we showcase the crucial role of a borrower\u2019s position and connectivity within the P2P network in determining loan default probabilities. Our findings are bolstered by robustness checks using shuffled centrality features, which further underscore the significance of integrating both financial and network attributes in credit risk evaluation. Our results shed new light on credit risk determinants in P2P lending and benefit investors in capturing inherent information from P2P loan networks.",
                "disciplines": [
                    "3502"
                ]
            },
            "10.12688/openreseurope.16436.1": {
                "title": "Unraveling market mysteries: a comprehensive review of financial anomalies and puzzles",
                "abstract": "This comprehensive literature review consolidates various market anomalies and puzzles, providing an aggregated perspective to understand these complex dynamics that challenge the traditional Efficient Market Hypothesis. We examined numerous academic works to reveal insights into long-term return irregularities, earnings management influence on equity offerings, and information uncertainty\u2019s impact on stock returns. The review delves into unique phenomena like persistent mutual fund performance, the day-of-the-week returns, the January effect, weather-induced mood shifts on the market, and the dynamics of multiple anomalies. International asset pricing and weekend anomalies were also discussed, with a particular focus on cryptocurrency efficiency. Incorporating behavioral finance perspectives, we explored social transmission bias, emotional finance, biased beliefs, investor optimism, sentiment, and global market inefficiencies. The influence of unique events and seasonal factors, such as the Super Bowl, daylight saving time, and the Halloween effect, were also analyzed. The review concludes by highlighting the evolving landscape of market anomalies, discussing ma- chine learning approaches to anomaly research, investor behavior challenges, and the disappearing anomalies in country and industry returns. It sets the groundwork for holistic comprehension of market anomalies, suggesting future research directions such as exploring new data sources, comprehensive theoretical modeling, and the role of technology, market regulations, and environmental changes on market anomalies.",
                "disciplines": [
                    "3502",
                    "3801"
                ]
            },
            "10.12688/openreseurope.16278.1": {
                "title": "Navigating the Environmental, Social, and Governance (ESG) landscape: constructing a robust and reliable scoring engine - insights into Data Source Selection, Indicator Determination, Weighting and Aggregation Techniques, and Validation Processes for Comprehensive ESG Scoring Systems",
                "abstract": "This white paper explores the construction of a reliable Environmental, Social, and Governance (ESG) scoring engine, with a focus on the importance of data sources and quality, selection of ESG indicators, weighting and aggregation methodologies, and the necessary validation and benchmarking procedures. The current challenges in ESG scoring and the importance of a robust ESG scoring system are addressed, citing its increasing relevance to stakeholders. Furthermore, different data types, namely self-reported data, third-party data, and alternative data, are critically evaluated for their respective merits and limitations. The paper further elucidates the complexities and implications involved in the choice of ESG indicators, illustrating the trade-offs between standardized and customized approaches. Various weighting methodologies including equal weighting, factor weighting, and multi-criteria decision analysis are dissected. The paper culminates in outlining processes for validating the ESG scoring engine, emphasizing the correlation with financial performance, and conducting robustness and sensitivity analyses. Practical examples through case studies exemplify the implementation of the discussed techniques. The white paper aims to provide insights and guidelines for practitioners, academics, and policy makers in designing and implementing robust ESG scoring systems.",
                "disciplines": [
                    "3507"
                ]
            },
            "10.12688/openreseurope.15386.1": {
                "title": "Digital Finance: Reaching New Frontiers",
                "abstract": "Digital Finance must become the center of academic research in finance if the European financial industry is to remain competitive in the future. We argue that the new interdisciplinary field of Digital Finance should be prioritized based on the strategic priorities of the European Union, the needs of the finance industry, and the academic research gaps. Digital Finance as an interdisciplinary field will contribute to the strategic priorities of the European Union, such as financing for growth and jobs, financial stability and supervision, financial education, financing for small and medium-sized enterprises, and combating exclusion and inequality in access to credit.",
                "disciplines": [
                    "3502"
                ]
            }
        }
    },
    "13242837": {
        "title": "Removing off-flavor components from pea seeds by genetic means \u2013 PIVERT",
        "abstract": "Plant-based proteins have recently attracted particular interest due to their health benefits and sustainable origin compared to their animal counterparts. In this context, the use of pulses as ingredients for the production of protein-rich foodstuffs is increasing. The PIVERT project is centred on Pea (Pisum sativum L.), the leading grain legume crop in France, that produces seeds rich in high nutritional value proteins even in the absence of nitrogen fertilizers. However, pea-derived ingredients are still under-exploited in the food industry, one main factor being the beany off-flavour imparted that leads to low consumer acceptability. Methoxypyrazines, and volatile organic compounds (VOCs) such as hexanal, arising from the enzymatic oxidation of lipids by lipoxygenases, are two off-note components described as beany, grassy and hay-like, and rated as unpleasant flavours by consumers. In this project we propose to exploit plant genetics to address the pea seed flavour problem. PIVERT aims to identify pea lines or ecotypes with reduced or modified contents of methoxypyrazines and lipoxygenase-derived VOCs, and with improved organoleptic properties. We will use a targeted approach based on screening pea TILLING populations for key genes in the biosynthesis of these off-flavour components. In parallel, we will exploit the natural genetic diversity available for pea in an untargeted approach. A large collection of pea ecotypes will be screened by GC-MS to reveal novel and contrasted seed VOC emission profiles. The profiles will be analysed by genome wide-association study using existing genotyping data to identify loci involved in VOC profile determination. Both strategies will feed into descriptive quantitative sensory evaluations of these novel pea lines and ecotypes. This will represent a first step in the development of pea varieties better adapted to the food and ingredient industry.",
        "disciplines": [
            "3004"
        ],
        "publications": {
            "10.3390/foods12244484": {
                "title": "Unlocking Flavor Potential Using Microbial \u03b2-Glucosidases in Food Processing",
                "abstract": "Aroma is among of the most important criteria that indicate the quality of food and beverage products. Aroma compounds can be found as free molecules or glycosides. Notably, a significant portion of aroma precursors accumulates in numerous food products as nonvolatile and flavorless glycoconjugates, termed glycosidic aroma precursors. When subjected to enzymatic hydrolysis, these seemingly inert, nonvolatile glycosides undergo transformation into fragrant volatiles or volatiles that can generate odor-active compounds during food processing. In this context, microbial \u03b2-glucosidases play a pivotal role in enhancing or compromising the development of flavors during food and beverage processing. \u03b2-glucosidases derived from bacteria and yeast can be utilized to modulate the concentration of particular aroma and taste compounds, such as bitterness, which can be decreased through hydrolysis by glycosidases. Furthermore, oral microbiota can influence flavor perception by releasing volatile compounds that can enhance or alter the perception of food products. In this review, considering the glycosidic flavor precursors present in diverse food and beverage products, we underscore the significance of glycosidases with various origins. Subsequently, we delve into emerging insights regarding the release of aroma within the human oral cavity due to the activity of oral microbial glycosidases.",
                "disciplines": [
                    "3006"
                ]
            }
        }
    },
    "13528059": {
        "title": "Visual Peacetech: Digital Visual Images as Security-Building Tools",
        "abstract": "This is research about visual peace technology (peacetech), the way digital technologies and artistic innovation can be designed to support peace efforts. Peacetech as an industry is so nascent, that no academic research has been published to fill the notion with precise peace-centered content. This research aims to accomplish this by exploring technology at the intersection with artistic image-design as part of peace efforts. More specifically, this research explores 1) digital visuality of peace and security in war-affected communities, 2) virtual reality design for user-experience-peacework and 3) augmented reality image-making as a guerilla peacebuilding strategy. This research of technologies in peacework is ever more important in the times of full-scale war against Ukraine, its hi-tech grassroots-driven defense, and the implications that the war against such technologically-advanced society as Ukraine has for peacebuilding. This means that after the war ends - Ukraine wins, defending and building up (digital) peace will require more and more technological prowess and strategic use of technologies for peace. This research is a preparatory step for such strategic use of peacetech. The research effort also includes theoretical advancement of (visual) peace technology and practical tool-development (the digital media products the researcher/artist creates as part of research experiments) for digital peacebuilders seeking to employ visual peace technology already now.",
        "disciplines": [
            "3605"
        ],
        "publications": {
            "10.1057/s42984-024-00090-3": {
                "title": "Unfuturing peace: augmented reality image design for Guerilla peacebuilding",
                "abstract": "This project explores the potential of image-making in augmented reality (AR) technologies as means of designing sustaining quality peace futures\u2014unfuturing peace, focusing on Ukraine\u2019s heroic defense against Russia\u2019s 2022\u20132024 full-scale war of aggression as a case study. Employing the methodology of compositional interpretation and the conceptual tool \u201cfutures images,\u201d the project theoretically and practically differentiates between defuturing and unfuturing as peace design processes in developing an essay of originally designed marker-based Augmented Reality Posters in Support of Ukraine as demos of sustaining quality peace arrangements. The posters reference the topics of (physical) integrity of Ukrainian symbols, global food security and the security of the LGBTQI+ community in Ukraine. The technological artistic process/outcomes of this AR image-making experiment and their relation to power layouts in peacebuilding form the bases for theorizing how AR-supported futures design in war-affected communities\u2014unfuturing peace\u2014could facilitate \u201cguerrilla peacebuilding.\u201d In outlining theoretical and practical premises of guerilla peacebuilding, the project intersects Augmented Reality Posters in Support of Ukraine with explorations of guerilla warfare and counterinsurgency efforts leading to the 2016 Havana Peace Agreements in Colombia as well as mobile technologies/power in guerrilla approaches to democratic development.",
                "disciplines": [
                    "3605"
                ]
            }
        }
    },
    "13016970": {
        "title": "Synthesis of electron-deficient conjugated nanorings by host-guest templates \u2013 stargate",
        "abstract": "The aim of this project is to provide access to electron-deficient conjugated nanorings (i. e. macrocycles of diameters ? 2 nm) and explore their physico-chemical properties. Large electron-rich conjugated nanorings (i. e. based on carbazole, phenylene or porphyrin) are singular structures possessing exceptional properties such as unusual fluorescence, quantum coherence, or large ring anti-aromaticity. These unique properties are of great interest for molecular electronics, or smart fluorescent compounds. However, cationic, conjugated, electron-poor nanorings have been overlooked. In fact, such compounds have to date never been described. The integration of electron-deficient structures in conjugated nanorings is expected to afford a new class of compounds with unprecedented properties. In this context, viologen building-blocks (i. e. containing 4,4\u2019-bipyridiniums units) seem perfectly suited due to their electron-deficient nature and structural tunability. However, organizing viologens into nanorings is not trivial. In this project, we propose a straightforward strategy to access water-soluble electron-poor nanorings by using an original host-guest template approach featuring viologens, cucurbituril macrocycles and star-shape oligomers that represent an access gate to electron-deficient nanorings. We plan to investigate in detail the physico-chemical properties of this new class of compounds characterized by (i) their cationic nature, (ii) their interlocked structure and (iii) their water-solubility.",
        "disciplines": [
            "3403",
            "3405"
        ],
        "publications": {
            "10.1002/anie.202315985": {
                "title": "Internal Dynamics and Modular Peripheral Binding in Stimuli\u2010Responsive 3 : 2 Host:Guest Complexes",
                "abstract": "Now that the chemistry of 1\u2009:\u20091 host:guest complexes is well-established, it is surprising to note that higher stoichiometry (oligomeric) complexes, especially those with excess host, remain largely unexplored. Yet, proteins tend to oligomerize, affording new functions for cell machinery. Here, we show that cucurbit[n]uril (CB[n]) macrocycles combined with symmetric, linear di-viologens form unusual 3\u2009:\u20092 host:guest complexes exhibiting remarkable dynamic properties, host self-sorting, and external ring-translocation. These results highlight the structural tunability of cucurbit[8]uril (CB[8]) based 3\u2009:\u20092 host:guest complexes in water and their responsiveness toward several stimuli (chemicals, pH, redox).",
                "disciplines": [
                    "3403",
                    "3405"
                ]
            },
            "10.1002/ange.202315985": {
                "title": "Internal Dynamics and Modular Peripheral Binding in Stimuli\u2010Responsive 3 : 2 Host:Guest Complexes",
                "abstract": "Abstract  Now that the chemistry of 1 : 1 host:guest complexes is well\u2010established, it is surprising to note that higher stoichiometry (oligomeric) complexes, especially those with excess host, remain largely unexplored. Yet, proteins tend to oligomerize, affording new functions for cell machinery. Here, we show that cucurbit[ n ]uril (CB[ n ]) macrocycles combined with symmetric, linear di\u2010viologens form unusual 3 : 2 host:guest complexes exhibiting remarkable dynamic properties, host self\u2010sorting, and external ring\u2010translocation. These results highlight the structural tunability of cucurbit[8]uril (CB[8]) based 3 : 2 host:guest complexes in water and their responsiveness toward several stimuli (chemicals, pH, redox). ",
                "disciplines": [
                    "3403",
                    "3405"
                ]
            }
        }
    },
    "13057892": {
        "title": "The University of Iowa Stroke Preclinical Assessment Network to Support Translational Studies for Acute Cerebroprotection",
        "abstract": "Project Summary The University of Iowa (UIowa) is poised to advance the field of cerebroprotection in patients with acute ischemic stroke by remaining as a site for the NIH Stroke Preclinical Assessment Network (SPAN)\u2019s translational research infrastructure to efficiently conduct rigorous and innovative comparative studies of cerebroprotection in the context of reperfusion. UIowa-SPAN has consistently followed a rigorous, clinical trial-like approach to avoid the methodological mistakes of past cerebroprotection research. Specifically, we use randomization, blinded intervention, independent outcome adjudications, and intention-to-treat analyses to interpret and report our animal studies. We also address the effect of sex and comorbidities to increase the translational value of our research. UIowa-SPAN brings together a team of basic and translational scientists that integrates technical expertise with logistics. This has resulted in the top performance during the first iteration of SPAN, consistently leading the enrollment efficiency of the network while producing the highest quality data based on the metrics. We aim to maintain or exceed this performance if selected as a site in the new iteration of the network. Notably, the goals of UIowa-SPAN are aligned with those of UIowa\u2019s regional coordinating center for StrokeNet, a NIH clinical trial network with the mission of identifying and testing promising stroke therapies. We are also proposing innovations to multiple aspects of the SPAN, including minimizing overall data variability, technical improvements in the embolic clot rodent model, and improvements to the internal validity of the current outcome measures, using artificial intelligence to interpret corner tests and alternative computation methods for the grid walk test. Our goal is to rigorously and efficiently identify which cerebroprotective interventions are likely to succeed in clinical trials in order to improve the outcomes of the 800,000 Americans who suffer a stroke and are currently treated with reperfusion strategies that have limited effectiveness.",
        "disciplines": [
            "5201"
        ],
        "publications": {
            "10.1161/atvbaha.123.319821": {
                "title": "Platelet Metabolic Profiling Reveals Glycolytic and 1-Carbon Metabolites Are Essential for GP VI\u2013Stimulated Human Platelets\u2014Brief Report",
                "abstract": "BACKGROUND: Evolving evidence suggests that besides signaling pathways, platelet activation involves a complex interplay between metabolic pathways to support thrombus growth. Selective targeting of metabolic checkpoints may inhibit platelet activation and provide a novel antiplatelet strategy. We, therefore, examined global metabolic changes that occur during the transition of human platelets from resting to an activated state to identify metabolites and associated pathways that contribute to platelet activation.\nMETHODS: We performed metabolic profiling of resting and convulxin-stimulated human platelet samples. The differential levels, pathway analysis, and PCA (principal component analysis) were performed using Metaboanalyst. Metascape was used for metabolite network construction.\nRESULTS: Of the 401 metabolites identified, 202 metabolites were significantly upregulated, and 2 metabolites were downregulated in activated platelets. Of all the metabolites, lipids scored highly and constituted \u224850% of the identification. During activation, aerobic glycolysis supports energy demand and provides glycolytic intermediates required by metabolic pathways. Consistent with this, an important category of metabolites was carbohydrates, particularly the glycolysis intermediates that were significantly upregulated compared with resting platelets. We found that lysophospholipids such as 1-palmitoyl-GPA (glycero-3-phosphatidic acid), 1-stearoyl-GPS (glycero-3-phosphoserine), 1-palmitoyl-GPI (glycerophosphoinositol), 1-stearoyl-GPI, and 1-oleoyl-GPI were upregulated in activated platelets. We speculated that platelet activation could be linked to 1-carbon metabolism, a set of biochemical pathways that involve the transfer and use of 1-carbon units from amino acids, for cellular processes, including nucleotide and lysophospholipid synthesis. In alignment, based on pathway enrichment and network-based prioritization, the metabolites from amino acid metabolism, including serine, glutamate, and branched-chain amino acid pathway were upregulated in activated platelets, which might be supplemented by the high levels of glycolytic intermediates.\nCONCLUSIONS: Metabolic analysis of resting and activated platelets revealed that glycolysis and 1-carbon metabolism are necessary to support platelet activation.",
                "disciplines": [
                    "3205"
                ]
            },
            "10.1093/cvr/cvad149": {
                "title": "Metabolic targeting of platelets to combat thrombosis: dawn of a new paradigm?",
                "abstract": "Current antithrombotic therapies used in clinical settings target either the coagulation pathways or platelet activation receptors (P2Y12 or GPIIb/IIIa), as well as the cyclooxygenase (COX) enzyme through aspirin. However, they are associated with bleeding risk and are not suitable for long-term use. Thus, novel strategies which provide broad protection against platelet activation with minimal bleeding risks are required. Regardless of the nature of agonist stimulation, platelet activation is an energy-intensive and ATP-driven process characterized by metabolic switching toward a high rate of aerobic glycolysis, relative to oxidative phosphorylation (OXPHOS). Consequently, there has been considerable interest in recent years in investigating whether targeting metabolic pathways in platelets, especially aerobic glycolysis and OXPHOS, can modulate their activation, thereby preventing thrombosis. This review briefly discusses the choices of metabolic substrates available to platelets that drive their metabolic flexibility. We have comprehensively elucidated the relevance of aerobic glycolysis in facilitating platelet activation and the underlying molecular mechanisms that trigger this switch from OXPHOS. We have provided a detailed account of the antiplatelet effects of targeting vital metabolic checkpoints such as pyruvate dehydrogenase kinases (PDKs) and pyruvate kinase M2 (PKM2) that preferentially drive the pyruvate flux to aerobic glycolysis. Furthermore, we discuss the role of fatty acids and glutamine oxidation in mitochondria and their subsequent role in driving OXPHOS and platelet activation. While the approach of targeting metabolic regulatory mechanisms in platelets to prevent their activation is still in a nascent stage, accumulating evidence highlights its beneficial effects as a potentially novel antithrombotic strategy.",
                "disciplines": [
                    "3201"
                ]
            },
            "10.1161/strokeaha.123.042714": {
                "title": "Targeting Neutrophil \u03b19 Improves Functional Outcomes After Stroke in Mice With Obesity-Induced Hyperglycemia",
                "abstract": "BACKGROUND: Obesity-induced hyperglycemia is a significant risk factor for stroke. Integrin \u03b19\u03b21 is expressed on neutrophils and stabilizes adhesion to the endothelium via ligands, including Fn-EDA (fibronectin containing extra domain A) and tenascin C. Although myeloid deletion of \u03b19 reduces susceptibility to ischemic stroke, it is unclear whether this is mediated by neutrophil-derived \u03b19. We determined the role of neutrophil-specific \u03b19 in stroke outcomes in a mice model with obesity-induced hyperglycemia.\nMETHODS: \u03b19<sup>Neu-KO</sup> (\u03b19<sup>fl/fl</sup>MRP8Cre<sup>+</sup>) and littermate control \u03b19<sup>WT</sup> (\u03b19<sup>fl/fl</sup>MRP8Cre<sup>-</sup>) mice were fed on a 60% high-fat diet for 20 weeks to induce obesity-induced hyperglycemia. Functional outcomes were evaluated up to 28 days after stroke onset in mice of both sexes using a transient (30 minutes) middle cerebral artery ischemia. Infarct volume (magnetic resonance imaging) and postreperfusion thrombo-inflammation (thrombi, fibrin, neutrophil, phospho-nuclear factor kappa B [p-NF\u03baB], TNF [tumor necrosis factor]-\u03b1, and IL [interleukin]-1\u03b2 levels, markers of neutrophil extracellular traps) were measured post 6 or 48 hours of reperfusion. In addition, functional outcomes (modified Neurological Severity Score, rota-rod, corner, and wire-hanging test) were measured for up to 4 weeks.\nRESULTS: Stroke upregulated neutrophil \u03b19 expression more in obese mice (<i>P</i>&lt;0.05 versus lean mice). Irrespective of sex, deletion of neutrophil \u03b19 improved functional outcomes up to 4 weeks, concomitant with reduced infarct, improved cerebral blood flow, decreased postreperfusion thrombo-inflammation, and neutrophil extracellular traps formation (NETosis) (<i>P</i>&lt;0.05 versus \u03b19<sup>WT</sup> obese mice). Obese \u03b19<sup>Neu-KO</sup> mice were less susceptible to thrombosis in FeCl<sub>3</sub> injury-induced carotid thrombosis model. Mechanistically, we found that \u03b19/cellular fibronectin axis contributes to NETosis via ERK (extracellular signal-regulated kinase) and PAD4 (peptidyl arginine deiminase 4), and neutrophil \u03b19 worsens stroke outcomes via cellular fibronectin-EDA but not tenascin C. Obese wild-type mice infused with anti-integrin \u03b19 exhibited improved functional outcomes up to 4 weeks (<i>P</i>&lt;0.05 versus vehicle).\nCONCLUSIONS: Genetic ablation of neutrophil-specific \u03b19 or pharmacological inhibition improves long-term functional outcomes after stroke in mice with obesity-induced hyperglycemia, most likely by limiting thrombo-inflammation.",
                "disciplines": [
                    "3208"
                ]
            },
            "10.1016/j.jtha.2023.04.002": {
                "title": "Mitochondrial calcium uniporter b deletion inhibits platelet function and reduces susceptibility to arterial thrombosis",
                "abstract": "BACKGROUND: Mitochondrial calcium uniporter b (MCUb) is a negative regulator of the mitochondrial calcium uniporter (MCU) and is known to limit mitochondrial calcium ion (Ca<sup>2+</sup>) uptake. The role of MCUb in platelet function remains unclear.\nOBJECTIVES: Utilizing MCUb<sup>-/-</sup> mice, we examined the role of MCUb in regulating platelet function and thrombosis.\nMETHODS: Platelet activation was evaluated in agonist-induced standardized in\u00a0vitro assays. Susceptibility to arterial thrombosis was evaluated in FeCl<sub>3</sub> injury-induced carotid artery and laser injury-induced mesenteric artery thrombosis models. The glycolytic proton efflux rate and oxygen consumption rate were measured to evaluate aerobic glycolysis.\nRESULTS: Upon stimulation, MCUb<sup>-/-</sup> platelets exhibited reduced cytoplasmic Ca<sup>2+</sup> responses concomitant with increased mitochondrial Ca<sup>2+</sup> uptake. MCUb<sup>-/-</sup> platelets displayed reduced agonist-induced platelet aggregation and spreading on fibrinogen and decreased \u03b1 and dense-granule secretion and clot retraction. MCUb<sup>-/-</sup> mice were less susceptible to arterial thrombosis in FeCl<sub>3</sub> injury-induced carotid and laser injury-induced mesenteric thrombosis models with unaltered tail bleeding time. In adoptive transfer experiments, thrombocytopenic hIL-4R\u03b1/GPIb\u03b1-transgenic mice transfused with MCUb<sup>-/-</sup> platelets were less susceptible to FeCl<sub>3</sub> injury-induced carotid thrombosis compared with hIL-4R\u03b1/GPIb\u03b1-Tg mice transfused with wild type platelets, suggesting a platelet-specific role of MCUb in thrombosis. MCUb<sup>-/-</sup> stimulated platelets exhibited reduced glucose uptake, decreased glycolytic rate, and lowered pyruvate dehydrogenase phosphorylation, suggesting that mitochondrial Ca<sup>2+</sup> mediates bioenergetic changes in platelets.\nCONCLUSION: Our findings suggest that mitochondrial Ca<sup>2+</sup> signaling and glucose oxidation are functionally linked in activated platelets and reveal a novel role of MCUb in platelet activation and arterial thrombosis.",
                "disciplines": [
                    "3208"
                ]
            },
            "10.1182/bloodadvances.2023010100": {
                "title": "Mitochondrial pyruvate dehydrogenase kinases contribute to platelet function and thrombosis in mice by regulating aerobic glycolysis",
                "abstract": "Resting platelets rely on oxidative phosphorylation (OXPHOS) and aerobic glycolysis (conversion of glucose to lactate in the presence of oxygen) for their energy requirements. In contrast, platelet activation exhibits an increased rate of aerobic glycolysis relative to OXPHOS. Mitochondrial enzymes pyruvate dehydrogenase kinases (PDKs) phosphorylate the pyruvate dehydrogenase (PDH) complex to inhibit its activity, thereby diverting the pyruvate flux from OXPHOS to aerobic glycolysis upon platelet activation. Of 4 PDK isoforms, PDK2 and PDK4 (PDK2/4) are predominantly associated with metabolic diseases. Herein, we report that the combined deletion of PDK2/4 inhibits agonist-induced platelet functions, including aggregation, integrin \u03b1IIb\u03b23 activation, degranulation, spreading, and clot retraction. In addition, collagen-mediated PLC\u03b32 phosphorylation and calcium mobilization were significantly reduced in PDK2/4-/- platelets, suggesting impaired GPVI signaling. The PDK2/4-/- mice were less susceptible to FeCl3-induced carotid and laser-induced mesenteric artery thrombosis without any effect on hemostasis. In adoptive transfer experiments, thrombocytopenic hIL-4R\u03b1/GPIb\u03b1-transgenic mice transfused with PDK2/4-/- platelets exhibited less susceptibility to FeCl3 injury-induced carotid thrombosis compared with hIL-4R\u03b1/GPIb\u03b1-Tg mice transfused with WT platelets, suggesting a platelet-specific role of PDK2/4 in thrombosis. Mechanistically, the inhibitory effects of PDK2/4 deletion on platelet function were associated with reduced PDH phosphorylation and glycoPER in activated platelets, suggesting that PDK2/4 regulates aerobic glycolysis. Finally, using PDK2 or PDK4 single KO mice, we identified that PDK4 plays a more prominent role in regulating platelet secretion and thrombosis compared with PDK2. This study identifies the fundamental role of PDK2/4 in regulating platelet functions and identifies the PDK/PDH axis as a potentially novel antithrombotic target.",
                "disciplines": [
                    "3208"
                ]
            }
        }
    },
    "13249245": {
        "title": "Computational Biomedicine at the Exascale",
        "abstract": "Abstracts are not currently available in GtR for all funded research. This is normally because the abstract was not required at the time of proposal submission, but may be because it included sensitive information such as personal details.",
        "disciplines": [
            "4806"
        ],
        "publications": {
            "10.3389/fphar.2024.1379236": {
                "title": "Effects of ranolazine on the arrhythmic substrate in hypertrophic cardiomyopathy",
                "abstract": "<b>Introduction:</b> Hypertrophic cardiomyopathy (HCM) is a leading cause of lethal arrhythmias in the young. Although the arrhythmic substrate has been hypothesised to be amenable to late Na<sup>+</sup> block with ranolazine, the specific mechanisms are not fully understood. Therefore, this study aimed to investigate the substrate mechanisms of safety and antiarrhythmic efficacy of ranolazine in HCM. <b>Methods:</b> Computational models of human tissue and ventricles were used to simulate the electrophysiological behaviour of diseased HCM myocardium for variable degrees of repolarisation impairment, validated against <i>in vitro</i> and clinical recordings. S1-S2 pacing protocols were used to quantify arrhythmic risk in scenarios of (i) untreated HCM-remodelled myocardium and (ii) myocardium treated with 3\u00b5M, 6\u00b5M and 10\u00b5M ranolazine, for variable repolarisation heterogeneity sizes and pacing rates. ECGs were derived from biventricular simulations to identify ECG biomarkers linked to antiarrhythmic effects. <b>Results:</b> 10\u00b5M ranolazine given to models manifesting ventricular tachycardia (VT) at baseline led to a 40% reduction in number of VT episodes on pooled analysis of &gt;40,000 re-entry inducibility simulations. Antiarrhythmic efficacy and safety were dependent on the degree of repolarisation impairment, with optimal benefit in models with maximum JT<sub>c</sub> interval &lt;370\u00a0ms. Ranolazine increased risk of VT only in models with severe-extreme repolarisation impairment. <b>Conclusion:</b> Ranolazine efficacy and safety may be critically dependent upon the degree of repolarisation impairment in HCM. For moderate repolarisation impairment, reductions in refractoriness heterogeneity by ranolazine may prevent conduction blocks and re-entry. With severe-extreme disease substrates, reductions of the refractory period can increase re-entry sustainability.",
                "disciplines": [
                    "3214"
                ]
            }
        }
    },
    "12942586": {
        "title": "Diffusiophoretic Bioaugmentation: Boosting the Bacterial Motility in Soil Matrix by Chemical Gradients for Enhanced Bioremediation",
        "abstract": "When a toxic chemical spill occurs, the chemicals often leak into the soil, making it difficult to remove because the chemicals can easily seep deep underground. To clean up the spill, chemical-degrading bacteria can be injected into the contaminated soil. One of the major challenges of this approach is delivering the bacteria directly to the contaminated site. If the chemicals are deep in the soil, the injected bacteria must sense and swim towards the contaminants which can be a slow process. The goal of this project is to speed up the movement of the bacteria toward the contaminated site by injecting the bacteria into the ground with additional non-toxic chemicals that can enhance their motion by creating chemical gradients. Successful completion of this project will benefit society by developing environmental remediation strategies to mitigate ecological and human health impacts of toxic pollutants. Additional benefits to society will be accomplished through student education and training including the mentoring of a graduate student at the University at Buffalo. Toxic chemical spills require processes to degrade the chemicals to avoid environmental and human health impacts. Successful bioremediation of chemical spills requires directing decomposer bacteria to the target soil micropores that are deep in the subsurface where contaminants are likely to persist. The small bacteria can passively advect across permeable regions of the subsurface via pore flow. However, impervious micropores, which are prevalent in the soil matrix, can only be accessed by active motility or Brownian motion. These areas often tend to hold a significant amount of contaminants since they cannot be easily swept away by the pore flow, thus limiting the remediation efficacy. Therefore, there is a critical need to develop an effective way to disperse bacteria to hard-to reach spaces. The main objective of this proposal is to achieve enhanced bioremediation by introducing chemical heterogeneity in the soil. The central hypothesis is that the chemical gradients created within the soil matrix during bioremediation can accelerate the bacterial transport not only by chemotaxis, the movement by intracellular transduction of an organism in response to chemical stimulus, but also by diffusiophoresis, the directed migration of colloidal particles along chemical gradients due to the physicochemical interactions between the surrounding chemicals and the particle surface. When the chemical and cell surface conditions are met, diffusiophoresis can enhance the transport of bacteria by orders of magnitude compared to Brownian motion regardless of the bacteria type. This investigation will include experimental characterization of the interplay between chemotaxis and diffusiophoresis in microfluidic systems and laboratory-scale bioremediation demonstration in the soil matrix. This research aims to elucidate the fundamental aspects of bacterial diffusiophoresis and demonstrate an effective, low-cost strategy to enhance bioremediation . Further societal benefits include introducing undergraduate engineering students to microbial engineering through a hands-on course that will be developed to include various aspects from cell culture and microfluidic fabrication to laboratory-scale bioremediation as well as mentoring of a graduate student. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4105",
            "4106"
        ],
        "publications": {
            "10.1101/2023.07.03.547532": {
                "title": "Diffusiophoresis promotes phase separation and transport of biomolecular condensates",
                "abstract": "The internal microenvironment of a living cell is heterogeneous and comprises a multitude of organelles with distinct biochemistry. Amongst them are biomolecular condensates, which are membrane-less, phase-separated compartments enriched in system-specific proteins and nucleic acids. The heterogeneity of the cell engenders the presence of multiple spatiotemporal gradients in chemistry, charge, concentration, temperature, and pressure. Such thermodynamic gradients can lead to non-equilibrium driving forces for the formation and transport of biomolecular condensates. Here, we report how ion gradients impact the transport processes of biomolecular condensates on the mesoscale and biomolecules on the microscale. Utilizing a microfluidic platform, we demonstrate that the presence of ion concentration gradients can accelerate the transport of biomolecules, including nucleic acids and proteins, via diffusiophoresis. This hydrodynamic transport process allows localized enrichment of biomolecules, thereby promoting the location-specific formation of biomolecular condensates via phase separation. The ion gradients further impart active motility of condensates, allowing them to exhibit enhanced diffusion along the gradient. Coupled with a reentrant phase behavior, the gradient-induced active motility leads to a dynamical redistribution of condensates that ultimately extends their lifetime. Together, our results demonstrate diffusiophoresis as a non-equilibrium thermodynamic force that governs the formation and transport of biomolecular condensates.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1103/physreve.107.l052602": {
                "title": "Shape- and orientation-dependent diffusiophoresis of colloidal ellipsoids",
                "abstract": "We present the diffusiophoresis of ellipsoidal particles induced by ionic solute gradients. Contrary to the common expectation that diffusiophoresis is shape independent, here we show experimentally that this assumption breaks down when the thin Debye layer approximation is relaxed. By tracking the translation and rotation of various ellipsoids, we find that the phoretic mobility of ellipsoids is sensitive to the eccentricity and the orientation of the ellipsoid relative to the imposed solute gradient, and can further lead to nonmonotonic behavior under strong confinement. We show that such a shape- and orientation-dependent diffusiophoresis of colloidal ellipsoids can be easily captured by modifying theories for spheres.",
                "disciplines": []
            },
            "10.1063/5.0133871": {
                "title": "Directed colloidal assembly and banding via DC electrokinetics",
                "abstract": "Manipulating the transport and assembly of colloidal particles to form segregated bands or ordered supracolloidal structures plays an important role in many aspects of science and technology, from understanding the origin of life to synthesizing new materials for next-generation manufacturing, electronics, and therapeutics. One commonly used method to direct colloidal transport and assembly is the application of electric fields, either AC or DC, due to its feasibility. However, as colloidal segregation and assembly both require active redistribution of colloidal particles across multiple length scales, it is not apparent at first sight how a DC electric field, either externally applied or internally induced, can lead to colloidal structuring. In this Perspective, we briefly review and highlight recent advances and standing challenges in colloidal transport and assembly enabled by DC electrokinetics.",
                "disciplines": [
                    "4012"
                ]
            }
        }
    },
    "13057105": {
        "title": "I-Corps: Software application for predicting consumer food acceptability based on appearances under different illumination conditions",
        "abstract": "The broader impact/commercial potential of this I-Corps project is the development of a software application to predict consumer acceptability under different illumination conditions. The proposed technology is focused on consumer acceptability prediction related to food appearance, evaluating how external illumination may affect a deep learning-based image understanding model. Consumers may benefit from the proposed technology by having a more accurate understanding of the products they purchase and a reduced risk. In addition, the proposed technology may be used to recommend the correct illumination levels, which may help reduce food waste. With proper illumination recommendations, retailers may find an increase in purchases and a significant cost-savings as there may be a reduction in product returns. This I-Corps project is based on the development of an illumination estimation deep learning model that may be used to predict food acceptability. Illumination estimation is a fundamental prerequisite for many computer vision applications. Unnatural illumination may influence human perceptions of essential characteristics of goods, e.g., food products in retail stores under different lighting conditions. When food products are placed under different lighting conditions, consumers feel differently in response to the products, which may further affect purchase decisions. The goal is to develop an illumination human acceptability prediction model, which may be transferred to general industrial manufacturing and inspection applications. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3503"
        ],
        "publications": {
            "10.1109/icnwc57852.2023.10127328": {
                "title": "Sensory predictive analysis of freshness of food products under different lighting conditions",
                "abstract": "Recently, the efforts to use machine vision and artificial intelligence to evaluate the characteristics of food products has increased significantly. This is largely because, these technologies put up considerable advances in areas where the humans fail. We develop a sensory panel to study the effects of lighting conditions viz., light temperature and lighting power on the freshness of a food product. Panelists evaluated the product in terms of purchase intent (line scale from 0 to 100), overall liking (line scale from 0 to 100), and freshness (line scale from 0 to 100). Later, using machine learning models, predictive analytics is conducted to analyze the correlation among the light conditions and panliests\u2019 gradings.",
                "disciplines": [
                    "3006"
                ]
            }
        }
    },
    "13530419": {
        "title": "DSFAS: Big Data-enabled Real-time Learning and Decision Making for Field-based High Throughput Plant Phenotyping",
        "abstract": "Contemporary agriculture faces several new challenges imposed by environmental factors such as scarcity of arable land and climate change. Accelerated crop improvements and significant advancements in understanding of the plant's response to stresses are needed to meet the global food demand and to cope with the predicted dramatic changes in climate conditions and to ensure environmental sustainability. Repeated and quick measurement of crop phenotypic parameters is a major bottleneck in plant breeding programs and for closing the gap between genomics data and phenotype, and high-throughput phenotyping (HTP) technologies have been proposed to address this issue. Automated data collection for HTP and detailed data management and processing have recently proven their benefits in obtaining phenotypic information. However, in existing platforms, data collected from the field are stored locally and later transferred and processed offline. To tap the full potentials of phenotyping, multi-scale variety (plot/plant/field), heterogeneous and large volume data should be collected by various static and mobile sensors (e.g., robotic devices) connected through Internet of Things (IoT) technology. Although large datasets can be useful for phenotyping, they raise several challenges, e.g., combining data from various sensors/sources, provenance, contextualization, data management, storage, extracting features and visualization, which overall make it a big data problem. It is then critical to develop a new platform to collect data, handle real-time streams, analyze and manage such large datasets for HTP applications, which this research intends to do. The proposed research is important to the general public because it will: (1) satisfy and enhance human food and fiber needs by improving crop yield through the efficient use of HTP technology; and (2) sustain the economic viability of farm operations. The efficient and high performance IoT-enabled, big data cyber-physical system of this research suits agriculture and food industry needs.To meet such unprecedented needs, aiming at improving crop quality and yield, this project offers a compelling research plan tobuild an autonomous platform utilizing smart sensors and robotic devices connected through IoT technology, as well as a suite of new analytical tools to collect, manage and analyze large datasets in order to study the morphological, physiological and pathological traits without causing damage to the plants. This data can be potentially used in combination with environmental and genotypic data to make breeding decisions, to uncover relationships between genotypes and phenotypes and for automated monitoring of plant health status to reduce qualitative and quantitative losses during crop production. The ultimate goals of the project will be in: (1) facilitating real-time decision making for an improved field-based plants phenotyping; and (2) developing open-source data analytic platforms to improve affordability, penetration and adoption of AI technologies among the stakeholders, and most importantly farmers (resulting in societal benefits). If those goals are met, the general impact would be to inspire how the intersection of big data analytics and IoT-enabled databases can transform farm operations and farm management, as well as HTP. It will also open up new avenues to utilize novel (and emerging) data-driven approaches in agricultural processes. Another significant impact of this project is the capability it will create to share curated and labeled phenotypic data with the scientific community.",
        "disciplines": [
            "4605",
            "3008"
        ],
        "publications": {
            "10.1016/j.atech.2023.100265": {
                "title": "Development and deployment of a big data pipeline for field-based high-throughput cotton phenotyping data",
                "abstract": "In this study, we propose a big data pipeline for cotton bloom detection using a Lambda architecture, which enables real-time and batch processing of data. Our proposed approach leverages Azure resources such as Data Factory, Event Grids, Rest APIs, and Databricks. This work is the first to develop and demonstrate the implementation of such a pipeline for plant phenotyping through Azure's cloud computing service. The proposed pipeline consists of data preprocessing, object detection using a YOLOv5 neural network model trained through Azure AutoML, and visualization of object detection bounding boxes on output images. The trained model achieves a mean Average Precision (mAP) score of 0.96, demonstrating its high performance for cotton bloom classification. We evaluate our Lambda architecture pipeline using 9,000 images yielding an optimized runtime of 34 minutes. The results illustrate the scalability of the proposed pipeline as a solution for deep learning object detection, with the potential for further expansion through additional Azure processing cores. This work advances the scientific research field by providing a new method for cotton bloom detection on a large dataset and demonstrates the potential of utilizing cloud computing resources, specifically Azure, for efficient and accurate big data processing in precision agriculture.",
                "disciplines": [
                    "4605"
                ]
            }
        }
    },
    "12966066": {
        "title": "Feasibility of Implementing Acupuncture into a Federally Qualified Health Center to Alleviate  Multiple Symptoms Among Breast Cancer Survivors Receiving Endocrine therapy",
        "abstract": "PROJECT SUMMARY Nearly 94% of breast cancer survivors experience one or more symptoms during or after endocrine therapy. Joint pain, hot flashes, sleep disturbance, fatigue, depression, and anxiety are the most common concurrent symptoms, some of which can persist for 5 to 10 years. These symptoms negatively affect adherence to treatment and compromise people\u2019s functional status, quality of life, and work functioning. Acupuncture is a single therapy with few side effects that holistically addresses multiple symptoms. The effect of acupuncture on multiple symptoms among breast cancer survivors receiving endocrine therapy has not been investigated. Further, implementation-focused acupuncture research focuses on privately insured clinic settings and ignores social determinants of health. There is an urgent need to remove barriers and ensure equal access to this evidence-based treatment among breast cancer survivors with limited access to acupuncture. Federally qualified health centers (FQHC) provide care to people who experience significant barriers to health care access. To date, limited data exist about the use of acupuncture among cancer survivors attending FQHCs. This research study has 2 aims: (1) to test the feasibility and acceptability of implementing acupuncture within an FQHC oncology clinic as a way to manage multiple symptoms (pain, hot flashes, fatigue, sleep disturbance, depression, anxiety) among breast cancer survivors receiving endocrine therapy, and (2) to use a mixed methods approach to identify barriers and facilitators associated with the implementation of acupuncture within an FQHC. The long-term goal is to facilitate the widespread implementation, dissemination, and sustained utilization of acupuncture for symptom management among medically underserved breast cancer survivors receiving endocrine therapy in FQHCs nationwide, and ultimately to promote broader insurance coverage for acupuncture. The proposed research is significant because of its potential to ensure equal access acupuncture, an evidence-based intervention. Results will provide the foundation for a larger multi-site hybrid effectiveness-implementation trial of integrating acupuncture into services provided at FQHCs for breast cancer survivors.",
        "disciplines": [
            "4203",
            "4208",
            "4205"
        ],
        "publications": {
            "10.1016/j.cct.2023.107387": {
                "title": "Feasibility of implementing acupuncture in medically underserved breast cancer survivors (FAB): A protocol",
                "abstract": "Nearly 94% of breast cancer survivors experience one or more symptoms or side effects during or after endocrine therapy. Joint pain, hot flashes, sleep disturbance, fatigue, depression, and anxiety are the most common concurrent symptoms, some of which can persist for 5 to 10\u00a0years. Acupuncture is a holistic modality that addresses multiple symptoms and side effects in a single therapy. Acupuncture has not yet been investigated for its effectiveness in treating the multiple symptoms experienced by breast cancer survivors receiving endocrine therapy. Medically underserved breast cancer survivors typically have limited access to acupuncture. The barriers limiting access to acupuncture need to be removed to enable equal access to breast cancer survivors for this evidence-based treatment. Thus, we developed a randomized controlled trial with a 5-week acupuncture intervention versus usual care for medically underserved breast cancer survivors. Mixed methods (semi-structured interviews, surveys, study notes) will be used to obtain in-depth understanding of barriers and facilitators for eventual implementation of the acupuncture intervention. This study will facilitate the widespread implementation, dissemination, and sustained utilization of acupuncture for symptom management among medically underserved breast cancer survivors receiving endocrine therapy.",
                "disciplines": [
                    "4203",
                    "4205",
                    "4208"
                ]
            },
            "10.1155/2023/2397564": {
                "title": "Understanding the Autonomic Nervous System: A How-To Guide for Designing Engaging Pathophysiology and Pharmacology Courses for Nursing Students",
                "abstract": "Aim. The objective of this article is to describe our innovative competency-based approach to teaching nursing students about the autonomic nervous system (ANS). Background. Nurse educators require resources about pedagogical approaches related to ANS instruction. Design and Methods. We implemented an approach based on Kolb\u2019s Experiential Learning Theory, which was piloted in several nursing courses that spanned undergraduate and graduate levels of education. Results. We organized content according to three core ANS concepts: receptors and ligands; neurotransmission; and ANS divisions and reflexes. After students demonstrated mastery of these concepts, we introduced active-learning exercises, such as case studies, interactive games, concept mapping, and simulation-based education. This approach layered clinically-relevant information upon the core concepts. We leveraged student feedback by adding historical, social science, and literary examples into lectures because students reported how this approach made the material engaging. Conclusion. Our approach guides students toward a conceptual understanding of the ANS to support critical thinking and enhance nursing skills, such as interpreting physiologic signals, titrating vasoactive medications, and recognizing ANS disorders.",
                "disciplines": [
                    "4204",
                    "4205"
                ]
            }
        }
    },
    "10007746": {
        "title": "Extinction, Survival, Resurgence: Indigenous and colonial histories",
        "abstract": "This project aims to investigate the histories of Indigenous communities deemed extinct by Europeans in the wake of settler colonisation but who maintain they have survived with renewed cultures. With a focus on Tasmania and Newfoundland, Canada, the project examines archival material alongside the lived experiences of Indigenous communities to advance understandings of extinction and survival at a time of rapid environmental change. Outcomes include enhanced capacity to build collaborations with international first nation communities, institutions and researchers. New digital tools making historical materials accessible to Indigenous Australians and cultural institutions will significantly benefit cultural and language renewal.",
        "disciplines": [
            "4702"
        ],
        "publications": {
            "10.1007/s10502-024-09441-1": {
                "title": "Beyond access: (re)designing archival guides for changing landscapes",
                "abstract": "In 2013, the authors of this article and their colleague Gavan McCarthy published Stories in Stone: an annotated history and guide to the collections of Ernest Westlake (1855\u20131922). The guide provided contextual information and digital access to the entire paper archives relating to the three large stone collections formed by Westlake during his lifetime: French and English geological specimens housed in the Oxford University Museum of Natural History from 1924, and a collection of Tasmanian Aboriginal stone tools stored in the Pitt Rivers Museum since 1923. The Tasmanian collections, formed by Westlake from 1908 to 1910, are highly significant to the Palawa (or Pakana or Tasmanian Aboriginal) community because they include objects made by ancestors, and words spoken by ancestors to Westlake and recorded in his field notebooks. Stories in Stone was created to improve access to Westlake\u2019s Tasmanian collections for the Palawa community with whom author Rebe Taylor had worked closely since 1999. Nonetheless, the structural and technical design of Stories in Stone was not Palawa-led. It was driven by Australian and international archiving standards; by stipulations set out by the collecting institutions; and by the stories of collecting and subsequent scholarship on the collections. In 2023, Stories in Stone is offline, and the authors are planning a relaunch. This time they aim to reach beyond their original aim of providing archival access to the Palawa community, and work with Palawa community to co-design how that access is delivered. This consultative work will be done at the University of Tasmania, where Palawa advisors and other Indigenous scholars have been integral to developing international Indigenous data sovereignty principals. This article precedes those formal discussions and thus offers a timely reflection on the original aims and design of Stories in Stone as well as an extensive analysis of broader changes in the management and dissemination of First Nations collections and culture. Such changes include: international human rights frameworks; movements supporting data and archival sovereignty; co-designed archival technologies; and increased focus on archives as process not merely product. These developments will lay the foundations for the next version of Stories in Stone, which aims to go beyond access, scholarship, and standards by helping to facilitate First Nations\u2019 aspirations for dignity, sovereignty, and self-determination.",
                "disciplines": [
                    "4302",
                    "4610"
                ]
            }
        }
    },
    "13530364": {
        "title": "Optimizing rangeland decision making by unraveling geographic variation in the timing of forage sensitivity to weather",
        "abstract": "More variable and extreme weather patterns, such as droughts rivaling that of the dustbowl, are a prominent feature of climate change projections and pose a fundamental challenge to rain-fed rangeland production systems. Ranchers have the potential to mitigate the uncertainty posed by increasing climatic variability through pro-active decision making that can have profound economic implications, but this relies upon knowledge of when to implement such decisions. And while a growing body of research has shown that forage production is sensitive to weather variation during relatively narrow periods during the growing season, we lack an understanding of how this timing of forage sensitivity to weather varies at the spatial scales in which decision making occurs, from the landscape, county, and state all the way to the scale of the ecoregion. The goal of this proposal is to improve our understanding of rangeland responses to weather variability by focusing onwhenprecipitation most affects forage production among different ranges in the western United States. Understanding this timing will provide about critical decision dates: the dates during the growing season by which ranchers should initiate drought mitgation strategies should be initated if drought conditions have emerged.",
        "disciplines": [
            "3701"
        ],
        "publications": {
            "10.1111/gcb.16637": {
                "title": "Timing and magnitude of drought impacts on carbon uptake across a grassland biome",
                "abstract": "Although drought is known to negatively impact grassland functioning, the timing and magnitude of these impacts within a growing season remain unresolved. Previous small-scale assessments indicate grasslands may only respond to drought during narrow periods within a year; however, large-scale assessments are now needed to uncover the general patterns and determinants of this timing. We combined remote sensing datasets of gross primary productivity and weather to assess the timing and magnitude of grassland responses to drought at 5\u00a0km<sup>2</sup> temporal resolution across two expansive ecoregions of the western US Great Plains biome: the C<sub>4</sub> -dominated shortgrass steppe and the C<sub>3</sub> -dominated northern mixed prairies. Across over 700,000 pixel-year combinations covering more than 600,000\u2009km<sup>2</sup> , we studied how the driest years between 2003-2020 altered the daily and bi-weekly dynamics of grassland carbon (C) uptake. Reductions to C uptake intensified into the early summer during drought and peaked in mid- and late June in both ecoregions. Stimulation of spring C uptake during drought was small and insufficient to compensate for losses during summer. Thus, total grassland C uptake was consistently reduced by drought across both ecoregions; however, reductions were twice as large across the more southern and warmer shortgrass steppe. Across the biome, increased summer vapor pressure deficit (VPD) was strongly linked to peak reductions in vegetation greenness during drought. Rising VPD will likely exacerbate reductions in C uptake during drought across the western US Great Plains, with these reductions greatest during the warmest months and in the warmest locations. High spatiotemporal resolution analyses of grassland response to drought over large areas provide both generalizable insights and new opportunities for basic and applied ecosystem science in these water-limited ecoregions amid climate change.",
                "disciplines": [
                    "3103"
                ]
            }
        }
    },
    "13789260": {
        "title": "Three-dimensional (3D) dosimetry based on optically stimulated luminescence - towards high-resolution proton radiotherapy",
        "abstract": "Approximately 40% of all Polish cancer patients receive radiotherapy (RT) as part of their treatment. The goal of RT is to deliver the necessary dose of radiation to the cancerous lesion being treated, with minimal damage to healthy tissue and surrounding organs, all with the goal of optimizing therapeutic effects and reducing side effects. To meet the criteria for effective and safe RT, increasingly modern radiotherapeutic techniques are used. Since 2011, the Institute of Nuclear Physics of the Polish Academy of Sciences (IFJ PAN) has been conducting the first proton radiotherapy in Poland, one of the most advanced and precise RT techniques using ionizing radiation, in this case proton particles. The unique nature of the interaction of protons with matter, which transfer their energy/dose mainly at the end of the path in the patient's body, in the area of the so-called Bragg peak, allows for the precise delivery of high doses of radiation to the treated tumor lesion using complex three-dimensional (3D) treatment plans to best reflect the shape of the treated tumor lesion. Therefore, in the process of preparing therapy, it is necessary to use appropriate measurement techniques, the so-called dosimetric systems that facilitate the preparation and verification of therapeutic treatment plans. However, there are currently no dedicated solutions for 3D dosimetry used clinically, and the basic dosimetric tool is an ionization chamber. Other dosimetric tools are also used in the measurements, e.g. luminescence detectors, but in both cases the information obtained about the dose is point-based, i.e. one-dimensional. Therefore, there is a need to develop innovative measurement techniques enabling dose measurement in 3D. One of the new and promising techniques developed at IFJ PAN uses prototype dosimeters in the form of flat and flexible silicone foils with a phosphor embedded inside, i.e. a material that accumulates energy under the influence of ionizing radiation, and then, as a result of light stimulation, and the so-called optically stimulated luminescence (OSL), it is possible to measure the absorbed dose. Using a properly designed optical imaging system and a highly sensitive CCD camera, this technology enables mapping of the actual dose distribution in 3D. The newly developed system has so far been tested during the verification of the spatial dose distribution for an eyeball tumor at the Eye Radiotherapy Laboratory of the IFJ PAN. The results obtained showed the great potential of the system. However, for the technology to be fully used when verifying complex treatment plans, its further development is necessary. Therefore, the main goal of the project is to initiate a comprehensive research program concerning, firstly, the examination of the dosimetric properties of prototype films based on the combination of a phosphor in a silicone matrix, and secondly, the optimization of the 3D optical system for use in clinical conditions for proton radiotherapy. Material properties tests include, among others: the influence of the concentration of dopants activating the luminescence process in a given phosphor, the stability of the obtained signal, signal loss after reading, sensitivity to radiation, detector efficiency and many others. However, in the second case, the 3D reading system should be reconstructed in terms of the use of foil of the appropriate size (min. 10x10 mm2), spatial resolution, field of view and the method of data acquisition and processing. The current project will allow the development of a new formula of a very promising and innovative spatial dosimetry system, which in the future may overcome the problems occurring in previous attempts to perform 3D dosimetry. Therefore, the most important achievement of the project will be: *The ability to record radiation dose in 3D based on the OSL technique, with high spatial resolution and precision, taking into account other important and basic dosimetric properties. *3D optical imaging system consisting of a light source (e.g. laser diodes/LEDs) and an optical detection system (emission filters combined with an EMCCD camera) *The dosimeter is reusable (enables multiple reading and scanning procedures) and the signal can be removed by stimulation intense light field. * The dosimeter enables a quick and easy reading procedure (no computational algorithms). Additionally, the dose can be stored for a longer period of time. * The dosimeter can be made in various forms, including: round/square foils/sheets. By using a foil stack, it is possible to recreate the actual dose distribution in 3D, which allows for the simulation of treated shapes and their deformations (e.g. a realistic organ/tumor phantom). * The dosimeter is resistant to environmental conditions (e.g. water, magnetic field) and ensures easy transport and operation. * The dosimeter system is evaluated for verification in the area of proton therapy and optimized for simultaneous measurement of dose and other important physical parameters, e.g. linear energy transfer (LET) values.",
        "disciplines": [
            "5105",
            "3211"
        ],
        "publications": {
            "10.3390/ma16051978": {
                "title": "Optically Stimulated Luminescent Response of the LiMgPO4 Silicone Foils to Protons and Its Dependence on Proton Energy",
                "abstract": "Modern radiotherapy (RT) techniques, such as proton therapy, require more and more sophisticated dosimetry methods and materials. One of the newly developed technologies is based on flexible sheets made of a polymer, with the embedded optically stimulated luminescence (OSL) material in the form of powder (LiMgPO<sub>4</sub>, LMP) and a self-developed optical imaging setup. The detector properties were evaluated to study its potential application in the proton treatment plan verification for eyeball cancer. The data showed a well-known effect of lower luminescent efficiency of the LMP material response to proton energy. The efficiency parameter depends on a given material and radiation quality parameters. Therefore, the detailed knowledge of material efficiency is crucial in establishing a calibration method for detectors exposed to mixed radiation fields. Thus, in the present study, the prototype of the LMP-based silicone foil material was tested with monoenergetic uniform proton beams of various initial kinetic energies constituting the so-called spread-out Bragg peak (SOBP). The irradiation geometry was also modelled using the Monte Carlo particle transport codes. Several beam quality parameters, including dose and the kinetic energy spectrum, were scored. Finally, the obtained results were used to correct the relative luminescence efficiency response of the LMP foils for monoenergetic and spread-out proton beams.",
                "disciplines": []
            }
        }
    },
    "13061483": {
        "title": "Host and parasite determinants of Leishmania Viannia persistence in naturally infected human populations",
        "abstract": "Project Summary The natural history of human dermal leishmaniasis caused by Leishmania Viannia species provides unequivocal evidence of long-term persistence of parasites in asymptomatically as well as symptomatically infected individuals. Persistent infection can remain asymptomatic, or can be clinically manifested through the development of mucosal or cutaneous leishmaniasis (ML and CL) following either asymptomatic infections, or as recurrent disease long after resolution of primary lesions. Molecular evidence of persistent parasites in the conjunctiva, nasal and oropharyngeal mucosal tissues, skin and blood monocytes has been documented in as many as 40% of infected individuals in endemic areas of L. Viannia transmission, however, the role of the host immune response and parasite subpopulations in promoting and sustaining Leishmania persistence in humans remains unknown. It is also well established that immune tolerance is an underlying factor of latent infection and tissue protection in infections by other protozoa such as Plasmodium and Toxoplasma. Similar host mechanisms of immune tolerance likely contribute to Leishmania persistence in the absence of signs and symptoms, since disruption of the immune homeostasis by immunosuppression or local trauma have been identified as contributing factors in recurrent CL. We hypothesize that Leishmania-host interactions eliciting strong, yet regulated innate immune responses drive the establishment of local environments of immune tolerance (metabolic and immunological), that favor Leishmania persistence in humans. In this project we will characterize the transcriptomes, metabolomes and immunophenotypes of host tissues and cells associated with persistent infection. We will genotype the corresponding Leishmania populations, and will assess the participation of immunological tolerance in human tissues where Leishmania persistence has been detected: nasal mucosa, skin and monocytes. More specifically, we will 1) Identify the molecular signature of Leishmania persistence in a cohort of patients with prior history of CL, 2) Characterize the genotype and phenotype of persister Leishmania sub-populations as they modulate human host cells, and 3) Expand an ex vivo 3D cell culture system to model the metabolic and immunological microenvironment of Leishmania persistence. This project will provide critical knowledge on the metabolic and immunological microenvironments of human tissues permissive for Leishmania persistence, define the signatures and biomarkers of persistence, and advance ex vivo models of persistent Leishmania infection.",
        "disciplines": [
            "3207",
            "3009",
            "3202",
            "3204"
        ],
        "publications": {
            "10.21203/rs.3.rs-4271873/v1": {
                "title": "Innate biosignature of treatment failure in human cutaneous leishmaniasis",
                "abstract": "The quality and magnitude of the immune and inflammatory responses determine the clinical outcome of <i>Leishmania</i> infection, and contribute to the efficacy of antileishmanial treatments. However, the precise immune mechanisms involved in healing or in chronic immunopathology of human cutaneous leishmaniasis (CL) are not completely understood. Through sequential transcriptomic profiling of blood monocytes (Mo), neutrophils (N\u03c6), and eosinophils (E\u03c6) over the course of systemic treatment with meglumine antimoniate, we discovered that a heightened and sustained Type I interferon (IFN) response signature is a hallmark of treatment failure (TF) in CL patients. The transcriptomes of pre-treatment, mid-treatment and end-of-treatment samples were interrogated to identify predictive and prognostic biomarkers of TF. A composite score derived from the expression of 9 differentially expressed genes (common between Mo, N\u03c6 and E\u03c6) was predictive of TF in this patient cohort for biomarker discovery. Similarly, machine learning models constructed using data from pre-treatment as well as post-treatment samples, accurately classified treatment outcome between cure and TF. Results from this study instigate the evaluation of Type-I IFN responses as new immunological targets for host-directed therapies for treatment of CL, and highlight the feasibility of using transcriptional signatures as predictive biomarkers of outcome for therapeutic decision making.",
                "disciplines": [
                    "3204"
                ]
            }
        }
    },
    "13061530": {
        "title": "Preclinical development of the novel inhibitor of apoptosis proteins S2/IAPinh for cancer therapy",
        "abstract": "Scientific abstract Epithelial ovarian cancer (EOC) and pancreatic ductal adenocarcinoma (PDAC) are two of the most devastating human malignancies in desperate need for improved treatment concepts. Treatment resistance in cancer therapy frequently includes, among others, reduced drug uptake, increased drug efflux, improved adaptation to chemotherapy-induced stress/DNA damage and inhibition of apoptosis. An example of such a resistance mechanism is the X-linked inhibitor of apoptosis proteins (XIAP), a potent negative regulator of caspases and promoter of cancer cell survival in both ovarian and pancreatic cancer. Inhibition of XIAP has been studied to increase apoptosis and to overcome drug resistance in vitro and in preclinical mouse models. Second mitochondria-derived activator of caspases (SMAC) is an endogenous inhibitor of both XIAP and cellular IAP (cIAP) by reactivating caspase activity (XIAP blockade) and cIAP degradation, leading to cancer cell death. These findings have initiated the development of synthetic small molecule mimics of endogenous SMAC, which have been studied in a wide variety of human malignancies either as single agents but also in combination with systemic chemotherapy as a means to further improve patient outcomes. The foundation of our work with respect to small molecule drug development is based on sigma-2 ligands (S2) that facilitate fast and selective uptake into the cancer cells due to ~10-fold higher abundancy of the corresponding sigma-2 receptor (S2R) compared to normal host cells. By generating chemical conjugates between S2 and a variety of small molecule drug cargos, we are now capable of delivering therapeutic payloads more efficiently and selectively than their non-targeted counterparts to the tumors (targeted therapy). LCL161 is a clinically explored IAP inhibitor (IAPinh) that induces target activation but failed to demonstrate objective responses in patients. In this grant, we propose to study an innovative experimental cancer therapeutic by chemically linking IAPinh (LCL161) to S2 ligand SW43, resulting in S2/IAPinh for tumor- selective drug delivery and therapy. We hypothesize that S2/IAPinh can be combined with systemic, low-dose chemotherapy to result in synergistic treatment regimens that lead to tumor eradication while systemic toxicities are reduced to a minimum. The overall goal of our current study is to find effective therapies for ovarian and pancreatic cancer. The proposed aims maximize the chance that a novel drug candidate, S2/IAPinh, will be effective clinically. This is envisioned either as single-agent, low-dose S2/IAPinh therapy in the context of a TNF-\u03b1 gene signature in patient tumors or as combination regimens with clinically approved pathway enhancers, such as Nab-paclitaxel (Abraxane) (ovarian cancer) and Gemcitabine/Nab-paclitaxel (pancreatic cancer) but also statin-based inhibitors of cholesterol de novo synthesis. Our new findings represent an exciting innovative opportunity to enhance the activity profile of S2/IAPinh employing novel drug combinations for the benefit of cancer patients.",
        "disciplines": [
            "3211",
            "3101"
        ],
        "publications": {
            "10.1038/s41419-024-06693-8": {
                "title": "Cytotoxic sigma-2 ligands trigger cancer cell death via cholesterol-induced-ER-stress",
                "abstract": "Sigma-2-ligands (S2L) are characterized by high binding affinities to their cognate sigma-2 receptor, overexpressed in rapidly proliferating tumor cells. As such, S2L were developed as imaging probes (ISO1) or as cancer therapeutics, alone (SV119 [C6], SW43 [C10]) and as delivery vehicles for cytotoxic drug cargoes (C6-Erastin, C10-SMAC). However, the exact mechanism of S2L-induced cytotoxicity remains to be fully elucidated. A series of high-affinity S2L were evaluated regarding their cytotoxicity profiles across cancer cell lines. While C6 and C10 displayed distinct cytotoxicities, C0 and ISO1 were essentially non-toxic. Confocal microscopy and lipidomics analysis in cellular and mouse models revealed that C10 induced increases in intralysosomal free cholesterol and in cholesterol esters, suggestive of unaltered intracellular cholesterol trafficking. Cytotoxicity was caused by cholesterol excess, a phenomenon that contrasts the effects of NPC1 inhibition. RNA-sequencing revealed gene clusters involved in cholesterol homeostasis and ER stress response exclusively by cytotoxic S2L. ER stress markers were confirmed by qPCR and their targeted modulation inhibited or enhanced cytotoxicity of C10 in a predicted manner. Moreover, C10 increased sterol regulatory element-binding protein 2 (SREBP2) and low-density lipoprotein receptor (LDLR), both found to be pro-survival factors activated by ER stress. Furthermore, inhibition of downstream processes of the adaptive response to S2L with simvastatin resulted in synergistic treatment outcomes in combination with C10. Of note, the S2L conjugates retained the ER stress response of the parental ligands, indicative of cholesterol homeostasis being involved in the overall cytotoxicity of the drug conjugates. Based on these findings, we conclude that S2L-mediated cell death is due to free cholesterol accumulation that leads to ER stress. Consequently, the cytotoxic profiles of S2L drug conjugates are proposed to be enhanced via concurrent ER stress inducers or simvastatin, strategies that could be instrumental on the path toward tumor eradication.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1038/s41598-024-56928-z": {
                "title": "The novel drug candidate S2/IAPinh improves survival in models of pancreatic and ovarian cancer",
                "abstract": "Cancer selective apoptosis remains a therapeutic challenge and off-target toxicity has limited enthusiasm for this target clinically. Sigma-2 ligands (S2) have been shown to enhance the cancer selectivity of small molecule drug candidates by improving internalization. Here, we report the synthesis of a novel drug conjugate, which was created by linking a clinically underperforming SMAC mimetic (second mitochondria-derived activator of caspases; LCL161), an inhibitor (antagonist) of inhibitor of apoptosis proteins (IAPinh) with the sigma-2 ligand SW43, resulting in the new chemical entity S2/IAPinh. Drug potency was assessed via cell viability assays across several pancreatic and ovarian cancer cell lines in comparison with the individual components (S2 and IAPinh) as well as their equimolar mixtures (S2\u2009+\u2009IAPinh) both in vitro and in preclinical models of pancreatic and ovarian cancer. Mechanistic studies of S2/IAPinh-mediated cell death were investigated in vitro and in vivo using syngeneic and xenograft mouse models of murine pancreatic and human ovarian cancer, respectively. S2/IAPinh demonstrated markedly improved pharmacological activity in cancer cell lines and primary organoid cultures when compared to the controls. In vivo testing demonstrated a marked reduction in tumor growth rates and increased survival rates when compared to the respective control groups. The predicted mechanism of action of S2/IAPinh was confirmed through assessment of apoptosis pathways and demonstrated strong target degradation (cellular inhibitor of apoptosis proteins-1 [cIAP-1]) and activation of caspases 3 and 8. Taken together, S2/IAPinh demonstrated efficacy in models of pancreatic and ovarian cancer, two challenging malignancies in need of novel treatment concepts. Our data support an in-depth investigation into utilizing S2/IAPinh for the treatment of cancer.",
                "disciplines": [
                    "3101",
                    "3404",
                    "3211"
                ]
            }
        }
    },
    "9205580": {
        "title": "Reconstructing ancient atmospheric composition using temperature dependence of sulfur isotope fractionation",
        "abstract": "In 2021, photochemical experiments were carried out systematically from room temperature to -45\u00b0C, and isotopic fractionation coefficients for SO2 photodissociation reactions at low temperature and low pressure were obtained for the first time. The results showed a clear temperature dependence, and the values of \u03b434S, \u039433S, and \u039436S increased at lower temperatures under the condition of a constant SO2 partial pressure (at -45\u00b0C, they were about four times higher than at room temperature). On the other hand, the \u039433S/\u03b434S and \u039436S/\u039433S ratios were almost independent of temperature (\u039433S/\u03b434S ~ +0.12, \u039436S/\u039433S ~ -3.1). The tendency of the fractionation coefficient to increase at lower temperatures qualitatively agrees with the prediction based on the temperature dependence of the SO2 absorption spectrum. That is, when the temperature decreases, the absorption cross-section at the wavelength of the absorption peak increases, and 32SO2, which has the highest isotope abundance, absorbs ultraviolet rays, and only 32SO2 slows down the photodissociation reaction, resulting in isotope anomaly (self-shielding effect). ) worked effectively and the fractionation coefficient may have increased. Comparing the experimental results with the Archean sulfur isotope ratios, it is not possible to approach the \u039433S/\u03b434S ratio (~+0.9) even if the temperature is lowered. It was found that the sulfur isotope ratio could not be perfectly reproduced. On the other hand, the \u03b434S and \u039433S values observed from sulfuric acid aerosols over the past 2,600 years are attributed to oxidation of SO2 by OH radicals (SO2 + OH \u2192 HSO3, HSO3 + O2 \u2192 SO3 + HO2, SO3 + H2O \u2192 H2SO4) and SO2 light. Dissociation-mediated sulfate formation (SO2 + h\u03bd \u2192 SO + O, SO + O2 + M \u2192 SO3 + M, SO3 + H2O \u2192 H2SO4) is likely to be explained by a mixed model of two sulfate formation pathways. rice field. I wrote a paper summarizing the above contents and submitted it to an international journal.",
        "disciplines": [
            "3703"
        ],
        "publications": {
            "10.1016/j.chemgeo.2024.122157": {
                "title": "An analysis of \u039436S/\u039433S dependence on definitions of sulfur mass-independent fractionation",
                "abstract": "Mass-independent fractionation of stable sulfur isotopes (MIF-S) is believed to be a unique tracer of modern stratospheric eruptions as well as the Archean Earth's reducing atmosphere. The \u039436S/\u039433S ratio has been suggested as a strong constraint to the photochemical origin(s) of MIF-S data, because the variation of \u039436S/\u039433S ratio is commonly thought insignificant when mass-independent fractionated sulfur species (i.e., non-zero \u039433S or \u039436S values) are mixed with mass-dependent fractionated sulfur species (i.e., \u039433S\u202f=\u202f\u039436S\u202f=\u202f0\u2030). Given the assumption that mixing makes a straight line in \u039433S versus \u039436S space, mixing would spread \u039433S and \u039436S values of geological or atmospheric samples along a line starting from the initial composition of 0 and the original \u039436S/\u039433S slope could be preserved. The \u039436S/\u039433S ratio, however, does not always remain constant during mixing, for the equations that define \u039433S and \u039436S, which by definition represent deviations from mass-dependent behavior, are not linear. Several different definitions (linear, exponential, and logarithmic expressions) have been widely applied for \u039433S and \u039436S, which make the \u039436S/\u039433S ratio a definition-dependent value. Given that each definition has advantages and disadvantages, attention should be paid to the robustness of the \u039436S/\u039433S ratio they predict. To examine the robustness of \u039436S/\u039433S ratio, we performed numerical and analytical analyses of its definition dependence and the behavior during two-component mixing. Our results suggest that the calculated \u039433S and \u039436S derived from different definitions vary with absolute values of \u03b434S (|\u03b434S|): at larger |\u03b434S|, the deviations become more prominent, and when |\u03b434S| is larger than ~34\u2030, the discrepancy of \u039436S values determined by different definitions is over 1\u2030, which leads to significant definition-dependent variation in \u039436S/\u039433S at identical \u03b433S, \u03b434S, and \u03b436S values. This definition-dependence of \u039436S/\u039433S is negligible for most natural samples that show small 34S/32S fractionation. However, particular attention should be paid when dealing with processes that yield not only significant MIF-S but also large 34S isotopic fractionations, such as SO2 photolysis and elemental sulfur polymerization. Among the tested expressions, the linear definitions are the most convenient to model two-component mixing when the \u03b434S difference between the end members is large, because \u039433S and \u039436S values of the mixture can strictly fall on the linear arrays in \u039433S versus \u039436S spaces. By applying the linear expression, the \u039436S-\u039433S distributions observed in the modern stratospheric records can be reproduced by SO2 photolysis experiments. This agreement has been previously overlooked because the laboratory-produced \u039436S/\u039433S ratios by exponential and logarithm definitions did not match the values for the modern stratospheric records.",
                "disciplines": [
                    "3705"
                ]
            },
            "10.1016/j.chemgeo.2022.121064": {
                "title": "Sulfur mass-independent fractionation during SO2 photolysis in low-temperature/pressure atmospheres",
                "abstract": "Mass-independent fractionation of sulfur isotopes (MIF-S) has been observed in Archean sedimentary rocks and modern stratospheric sulfate aerosol (SSA). Photolysis of SO2 is known to cause significant MIF-S and could be related to the observed MIF-S. However, previous experiments with SO2 photolysis at room temperature, or at low temperatures and atmospheric pressure, did not quantitatively explain quadruple sulfur isotopic compositions (\u03b434S, \u039433S, and \u039436S values) of the Archean sedimentary rocks and the modern SSA. Here we describe sulfur isotopic fractionation during SO2 photolysis including isotopic self-shielding at low temperatures (down to 228\u00a0K) and low pressures (from 5.9 to 9.8\u00a0kPa) where pressure broadening of SO2 becomes negligible. Results indicate that magnitudes of sulfur isotopic fractionation factors (34\u03b5, 33E, and 36E values, where 33E\u00a0=\u00a033\u03b5 \u2013 1000\u00a0\u00d7\u00a0[(1\u00a0+\u00a034\u03b5/1000)0.515\u00a0\u2212\u00a01] and 36E\u00a0=\u00a036\u03b5\u00a0\u2212\u00a01000\u00a0\u00d7\u00a0[(1\u00a0+\u00a036\u03b5/1000)1.90\u00a0\u2212\u00a01]) increase with decreasing temperature, with values at 228\u00a0K being about four times those at 296\u00a0K (34\u03b5 of up to +344\u2030). Meanwhile, 33E/34\u03b5 and 36E/33E ratios are roughly independent of temperature over the temperature range (by approximately +0.1 and\u00a0\u2212\u00a03.1, respectively), although the 33E/34\u03b5 ratios slightly increase with decreasing temperature, ranging from ~\u00a0+\u00a00.08 to ~\u00a0+\u00a00.13. A two-component mixing model involving SO2 oxidation by OH and SO2 photolysis in the stratosphere reproduces \u03b434S and \u039433S values of modern SSA when the contribution ratio of SO2 photolysis to SO3 production is ~20%. The contribution ratio of ~20% is consistent with a previous estimation by Whitehill et al. (2015). However, \u039433S/\u03b434S ratios at low temperatures are far from those of Archean sedimentary rocks, calling for an additional mechanism (or mechanisms) to explain Archean MIF-S.",
                "disciplines": [
                    "3703",
                    "3705"
                ]
            },
            "10.2343/geochemj.gj22004": {
                "title": "Absorption spectra measurements at ~1 cm\u20131 spectral resolution of 32S, 33S, 34S, and 36S sulfur dioxide for the 206\u2013220 nm region and applications to modeling of the isotopic self-shielding",
                "abstract": "The sulfur isotope fractionation that occurs during SO2 photolysis is key to explaining the isotope signatures stored in ancient sedimentary rocks and understanding the atmospheric compositions of the early Earth and early Mars. Here, we report the photoabsorption cross-sections of 32SO2, 33SO2, 34SO2, and 36SO2 measured from 206 to 220 nm at 296 K. The wavelength resolution was set to 1 cm\u20131, 25 times higher than that of previous SO2 isotopologue absorption spectra measurements. The precision of ~10% is in agreement with previously reported SO2 absorption spectra. In comparison with previously reported high-resolution spectra of natural abundance, SO2 measurements demonstrate smaller cross-sectional magnitudes at absorption peaks and an offset wavelength by ~0.016 nm. Using the newly recorded isotopologue spectra, we calculated the sulfur isotope fractionation for self-shielding during SO2 photolysis. The calculated 34S fractionation (34\u03b5) roughly reproduces the observed relationship between 34\u03b5 and the SO2 column density in previous photolysis experiments. Thus, the cross-section is useful for predicting 34S/32S isotope fractionation in an optically thick SO2 atmosphere. In contrast, for mass-independent fractionation (MIF-S, i.e., non-zero \u039433S), the measured spectra predicted a weakly negative \u039433S/\u03b434S slope of about \u20130.1. The small \u039433S/\u03b434S slope is consistent with the slopes of SO2 photolysis experiments under high-pressure atmospheres (i.e., the pressure broadened absorption line width will be comparable to the spectral resolution). Therefore, MIF-S during photolysis experiments was linked to spectroscopic measurements for the first time. We conclude that reasonable precision and high-resolution spectroscopic measurements are key to explaining the origin of MIF-S at column densities below 1018 cm\u20132. However, MIF-S production in chamber experiments or atmospheric conditions may require understanding pressure or temperature effects, such as linewidth broadening on the UV-absorption spectra, and how these effects manifest themselves on isotopologues.",
                "disciplines": [
                    "3703",
                    "3705"
                ]
            }
        }
    },
    "13028974": {
        "title": "Synthesis, Characterization and Performance Evaluation of Heterojunctions of Metallic Oxides based on TiO2 with Potential Applications in Photocatalytic Systems",
        "abstract": "Heterogeneous photocatalysis is an oxidative process and a potential candidate for mitigating problems associated with environmental pollution. In recent years, the synthesis and photocatalytic properties of several semiconductors have been described in the literature. Many factors influence the efficiency of these materials, such as surface, structural, morphological and electronic properties. Obtaining heterojunctions between oxides is considered an effective way to increase the photocatalytic efficiency compared to individual oxides, improving absorption in the visible region, reducing the recombination of photogenerated charges and promoting the generation of surface active species. In this context, this project aims to synthesize TiO2-based heterojunctions modified with ruthenium oxide (RuO2) or graphene oxide (rGO), seeking to understand the chemical and physical interfacial interactions of these heterojunctions and their performance regarding the photodegradation of a pharmaceutical contaminant model (acetaminophen) in aqueous medium. For this purpose, TiO2/RuO2 and TiO2/rGO heterojunctions will be studied in the form of powder and thin films immobilized on soda-lime glass substrates (microspheres and slides). The materials obtained will be characterized and their photocatalytic activity will be studied preliminarily in aqueous suspension and later in microstructured flat plate photochemical reactors in continuous operation, irradiated by simulated sunlight and LEDs.",
        "disciplines": [
            "3406",
            "4004",
            "4103",
            "4018"
        ],
        "publications": {
            "10.1016/j.jwpe.2023.104395": {
                "title": "A novel hybrid continuous-flow wastewater treatment for lamotrigine degradation by combining enzymatic and photo-oxidative reactions",
                "abstract": "In response to the increasing occurrence of lamotrigine (LMG) in wastewater, low removal efficiency of conventional treatments, and the need for advanced and innovative approaches, our work aimed to develop and optimize a hybrid enzymatic-photo-oxidative treatment. The coupling of immobilized homemade peroxidase and UVC/H2O2 was first studied in batch mode. The hybrid reactions resulted in 100\u00a0% removal and a first-order specific reaction rate of 0.142\u00a0min\u22121 at 80\u00a0mg\u00a0L\u22121 of H2O2. Subsequently, our research focused on treatment optimization in a flat-plate reactor operated in continuous flow. Response surface methodology revealed that maintaining a UVC dose of 3240\u00a0mJ\u00a0cm\u22122 allows >90\u00a0% removal across a wide range of H2O2 concentrations. The experiment with LMG-spiked effluent confirmed the effectiveness of the proposed treatment for removing the antiepileptic from a real matrix. The proposed degradation pathway shows that the system can oxidize lamotrigine by sequential reactions with additional dechlorination steps not yet reported. Furthermore, only the hybrid reactions showed environmental safety, as confirmed by cytotoxicity studies. Notably, our study evaluated, for the first time, the coupling of enzymatic and photo-oxidative reactions in a single reactor operated in continuous-flow mode. The operational flexibility suggests its potential application for wastewater treatment facilities.",
                "disciplines": [
                    "4004",
                    "4011"
                ]
            },
            "10.1016/j.jece.2023.111107": {
                "title": "Microplastics as hazardous pollutants: Occurrence, effects, removal and mitigation by using plastic waste as adsorbents and supports for photocatalysts",
                "abstract": "Most sectors in our society use plastic-based materials from different polymer sources due to their different properties and wide range of applications. Combined with population growth, this has caused a vertiginous increase in plastic waste. In the last eight decades, plastic production has resulted in over 8.3 billion metric tons, and unfortunately, around 80% of these plastics have been discarded into the environment, causing harmful effects. The lack of management and control of plastic waste results in the presence of microplastics (MPs) in the environment. This affects food chains and causes problems for biodiversity, the environment and human health. In this review, the classification, environmental occurrence, hazardous effects and management of MPs in wastewater treatment plants are discussed in detail. Other issues associated with the presence of MPs are also addressed; for example, the role played by MPs as vehicles for a range of hazardous chemical contaminants, such as pharmaceuticals, hormones and pesticides, \u201caccidentally\u201d contaminating aquatic organisms that feed on these materials. This review also highlights the technologies that have had satisfactory results in recent years in the removal and/or degradation of MPs, such as heterogeneous photocatalysis, adsorption, and electrochemical processes. We also point out that, in order to mitigate the problem, plastic waste can be transformed into high value-added products, such as adsorbents (adsorption capacity: 0.2\u20131753\u00a0mg\u00a0g-1) and/or supports for photocatalytic materials used in heterogeneous photocatalysis for the degradation of organic contaminants, a subject that is still little discussed in the literature. Finally, during the review, the challenges of this line of investigation are also presented. These insights will offer possibilities and strategies for the development of multifunctional materials based on plastic waste, applied in processes such as adsorption and heterogeneous photocatalysis, as well as for understanding the importance of monitoring MPs in aqueous media, due to the various problems associated with their presence as waste, as vehicles for emerging contaminants, and as possible releasers of organic contaminants arising from additives or their photoinduced weathering.",
                "disciplines": [
                    "3406",
                    "4004",
                    "4011"
                ]
            }
        }
    },
    "12915307": {
        "title": "Just turn up: informal sport and participatory social life in the superdiverse city",
        "abstract": "The project explores the extent and ways in which participation in informal sport in urban public spaces contribute to social interaction and urban inclusion. In cities characterised by high levels of superdiverse migrant settlement and social inequality the project will examine whether and how informal sport animates public spaces, is socially connective and has health and wellbeing implications. The experience of the Covid-19 crisis has sharpened awareness of the need for accessible outdoor spaces for physical activities and for social life. This project will focus on how informal sport uses and redefines urban space as a means of exploring what makes for the 'good city' (Amin 2006)\n\nInformal sport, defined here as peer organised, non-club or fee-based sport, within which players often participate by 'just turning up', is increasingly popular and involves socially and ethnically diverse groups which tend to be under-represented in club-based sport (Sport England 2020). While some types of informal sport are familiar ('jumpers for goal posts' football, street cricket) others are relatively new (volleyball, parkrun and urban walking groups) reflecting the vitality of this mode of social participation. There are indications that social media and migrant settlement contribute to this vitality and the expansion of informal sport (Wise et al 2018)\n\nInformal sport typically takes place in everyday public spaces and the project looks outside the walls of the gym and club to focus on sport activities in parks and facilities on housing estates or 'reused' spaces such as residential streets and alleyways. As cities become more unequal and heterogeneous there has been an increased policy emphasis on sport and health initiatives that promote inclusion, wellbeing and the health of urban populations through accessible outdoor activities within local neighbourhoods (Public Health England 2017; Sport England 2020). \n\nHowever, public space is not available in the same way or to the same extent in different parts of cities. And the 'unspoken rules' of informal sport can still exclude some even as they include others. This is an active process in which outdoor spaces may be appropriated by otherwise excluded groups and sport-related activities may provide them with ways of inhabiting and claiming a right to the city (Aquino et al 2021). Nevertheless, this right may still be contested. In this context the research examines the growth and in/exclusionary, on and offline dynamics of informal sports participation and the social, spatial and wellbeing outcomes that it generates. \n\nLocating itself in two comparative case study cities, (Sheffield and London), the project uses a mix of qualitative methods combining social mapping, interviews, participant observation and digital ethnography. The project is organised around four Work Packages (WP) which focus on: the geographies and types of informal sport activities (WP1); the social media environments which support and enhance informal sport (WP2); the practices, interactions and experiences of those taking part in different types of informal sport (WP 3) and the perspectives of sport, cohesion, urban design and health policy actors on the wellbeing and in/exclusionary role of informal sport (WP4). The project will generate academic outputs to make interdisciplinary contributions on sport, health, inclusion, superdiversity and urban space. It will use creative and policy-based approaches with community and organisational partners to develop impact focused resources and activities aimed at collaboratively engaging wider non-academic publics.",
        "disciplines": [
            "4410",
            "4406",
            "3504"
        ],
        "publications": {
            "10.1080/02614367.2022.2162109": {
                "title": "Informal sport and leisure, urban space and social inequalities: Editors\u2019 Introduction",
                "abstract": "While informal sport may appear to be a poor relation of formal sport, participation in informal sport is now more popular than organised club sport. The special issue provides an opportunity to showcase international leisure studies research which variously explores the meaning and implications of informal sport as a growing form of collective leisure activity and the wider social affordances \u2013 and strains \u2013 of collective leisure practices. The Editors\u2019 Introduction focuses on the ways in which informal sport and leisure depend on sometimes hard-won public (parks, city squares, designed leisure spaces) and reused incidental urban space (e.g. post-industrial areas). It sets out the ways in which informal sport and leisure involves marginalised and precarious urban populations, gives rise to co-ethnic and ethnically diverse identifications, secures senses of belonging and citizenship, is gender and age ex/inclusive and is attractive to policy actors. It outlines how the articles collected in the special issue address what are still under-examined aspects of the informal sport phenomenon.",
                "disciplines": [
                    "3504",
                    "4406",
                    "4410"
                ]
            }
        }
    },
    "10007658": {
        "title": "Physical Layer Security for Wireless Machine-Type Communications",
        "abstract": "This project aims to provide new understanding and design guidelines to secure wireless communications among low-cost resource-constrained devices. This is achieved by advancing the fundamental theory of an emerging security paradigm named physical layer security. Expected outcomes of this project include a communication-theoretic framework to characterise the secrecy performance of communications over wireless networks, followed by novel signal processing and transmission designs. The research outcomes should provide innovative solutions to safeguard commercial and industry Internet of Things networks, benefiting Australia's digital transformation.",
        "disciplines": [
            "4006",
            "4613"
        ],
        "publications": {
            "10.1109/twc.2024.3400601": {
                "title": "Performance Analysis of Finite Blocklength Transmissions Over Wiretap Fading Channels: An Average Information Leakage Perspective",
                "abstract": "Physical-layer security (PLS) is a promising technique to complement more traditional means of communication security in beyond-5G wireless networks. However, studies of PLS are often based on ideal assumptions such as infinite coding blocklengths or perfect knowledge of the wiretap link\u2019s channel state information (CSI). In this work, we study the performance of finite blocklength (FBL) transmissions using a new secrecy metric \u2014 the average information leakage (AIL). We evaluate the exact and approximate AIL with Gaussian signaling and arbitrary fading channels, assuming that the eavesdropper\u2019s instantaneous CSI is unknown. We then conduct case studies that use artificial noise (AN) beamforming to analyze the AIL in both Rayleigh and Rician fading channels. The accuracy of the analytical expressions is verified through extensive simulations, and various insights regarding the impact of key system parameters on the AIL are obtained. Particularly, our results reveal that allowing a small level of AIL can potentially lead to significant reliability enhancements. To improve the system performance, we formulate and solve an average secrecy throughput (AST) optimization problem via both non-adaptive and adaptive design strategies. Our findings highlight the significance of blocklength design and AN power allocation, as well as the impact of their trade-off on the AST.",
                "disciplines": [
                    "4613",
                    "4006"
                ]
            },
            "10.1109/globecom54140.2023.10437972": {
                "title": "Secure Short-Packet Transmission with Aerial Relaying: Blocklength and Trajectory Co-Design",
                "abstract": "In this paper, we propose a secure short-packet communication (SPC) system involving an unmanned aerial vehicle (UAV)-aided relay in the presence of a terrestrial passive eavesdropper. The considered system, which is applicable to various next-generation Internet-of-Things (IoT) networks, exploits a UAV as a mobile relay, facilitating the reliable and secure exchange of intermittent short packets between a pair of remote IoT devices with strict latency. Our objective is to improve the overall secrecy throughput performance of the system by carefully designing key parameters such as the coding blocklengths and the UAV trajectory. However, this inherently poses a challenging optimization problem that is difficult to solve optimally. To address the issue, we propose a low-complexity algorithm inspired by the block successive convex approximation approach, where we divide the original problem into two subproblems and solve them alternately until convergence. Numerical results demonstrate that the proposed design achieves significant performance improvements relative to other benchmarks, and offer valuable insights into determining appropriate coding blocklengths and UAV trajectory.",
                "disciplines": [
                    "4613",
                    "4006"
                ]
            },
            "10.1109/twc.2023.3344802": {
                "title": "Secure Short-Packet Communications via UAV-Enabled Mobile Relaying: Joint Resource Optimization and 3D Trajectory Design",
                "abstract": "Short-packet communication (SPC) and unmanned aerial vehicles (UAVs) are anticipated to play crucial roles in the development of 5G-and-beyond wireless networks and the Internet of Things (IoT). In this paper, we propose a secure SPC system, where a UAV serves as a mobile decode-and-forward (DF) relay, periodically receiving and relaying small data packets from a remote IoT device to its receiver in two hops with strict latency requirements, in the presence of an eavesdropper. This system requires careful optimization of important design parameters, such as the coding blocklengths of both hops, transmit powers, and the UAV\u2019s trajectory. While the overall optimization problem is nonconvex, we tackle it by applying a block successive convex approximation (BSCA) approach to divide the original problem into three subproblems and solve them separately. Then, an overall iterative algorithm is proposed to obtain the final design with guaranteed convergence. Our proposed low-complexity algorithm incorporates robust trajectory design and resource management to optimize the effective average secrecy throughput of the communication system over the course of the UAV-relay\u2019s mission. Simulation results demonstrate significant performance improvements compared to various benchmark schemes and provide useful design insights on the coding blocklengths and transmit powers along the trajectory of the UAV.",
                "disciplines": [
                    "4613",
                    "4006"
                ]
            },
            "10.1109/tifs.2023.3268443": {
                "title": "Secrecy Performance Evaluation of Scalable Cell-Free Massive MIMO Systems: A Stochastic Geometry Approach",
                "abstract": "This paper presents the first performance analysis of physical layer downlink secure transmissions in a scalable cell-free massive MIMO (SCF-mMIMO) system. A stochastic geometry approach is used to model the locations of the access points (APs), user equipments (UEs), and eavesdroppers (Eves) as independent homogeneous Poisson point processes (HPPPs). In addition to applying maximum ratio transmission (MRT) to send the confidential messages, null-space artificial noise is also injected for secrecy enhancement. We analytically characterize the secrecy performance in terms of both the outage-based secrecy transmission rate (STR) and the ergodic secrecy rate (ESR), appropriate for slow quasi-static fading channels and fast block-fading channels, respectively. By utilizing moment matching and Gil-Pelaez inversion theorem, we are able to obtain mathematically tractable approximations for the performance metrics. These approximations are shown to have high accuracy as compared to simulation results. Our numerical results reveal useful design insights that cannot be inferred from existing studies. These insights answer important questions such as whether it is best to deploy as many APs each with fewer antennas and to what extent the artificial noise insertion is beneficial.",
                "disciplines": [
                    "4613",
                    "4006"
                ]
            }
        }
    },
    "12880288": {
        "title": "Generation of electron cyclotron radiation with helical wavefront and its application",
        "abstract": "In 2017, it was theoretically shown that high-order harmonic radiation from electrons with circular orbits exhibits vorticity, that is, it has a helical wavefront. Since electron cyclotron motion (ECM) is a type of circular motion, electron cyclotron radiation (ECE) also has a helical wavefront. Although phenomena including ECEs are ubiquitous in nature, ECEs with helical wavefronts have not been observed to date. Therefore, in this research, we set the academic question of whether it is possible to experimentally observe and apply ECE with a helical wavefront.",
        "disciplines": [
            "5110"
        ],
        "publications": {
            "10.1093/ptep/ptae021": {
                "title": "Enhanced Classical Radiation Damping of Electronic Cyclotron Motion in the Vicinity of the Van Hove Singularity in a Waveguide",
                "abstract": "Abstract We study the damping process of electron cyclotron motion and the resulting emission in a waveguide using the classical Friedrichs model without relying on perturbation analysis such as Fermi\u2019s golden rule. A Van Hove singularity appears at the lower bound (or cutoff frequency) of the dispersion associated with each of the electromagnetic field modes in the waveguide. In the vicinity of the Van Hove singularity, we found that not only is the decay process associated with the resonance pole enhanced (amplification factor \u223c104) but the branch-point effect is also comparably enhanced. As a result, the timescale on which most of the decay occurs is dramatically shortened. Further, this suggests that the non-Markovian branch-point effect should be experimentally observable in the vicinity of the Van Hove singularity. Our treatment yields a physically acceptable solution without the problematic runaway solution that is well known to appear in the traditional treatment of classical radiation damping based on the Abraham\u2013Lorentz equation.",
                "disciplines": [
                    "5108"
                ]
            }
        }
    },
    "9852656": {
        "title": "Harnessing dynamic materials to produce better heterogeneous catalysts",
        "abstract": "This project aims to investigate an emerging class of catalysts featuring dynamic reaction sites using innovative computational chemistry methods. The capability of traditional materials has reached a performance status quo for many catalytic reactions. Dynamic materials may unlock a new dimension in catalyst design; however, their influence on reactivity is unclear, and the combination of materials and dynamics represents an immense parameter space. This project expects to provide a comprehensive framework for understanding dynamic catalytic processes. Expected outcomes of this project include the identification of specific materials and dynamics that achieve extraordinary efficiency for the benefit of sustainable chemical production.",
        "disciplines": [
            "3403"
        ],
        "publications": {
            "10.1021/accountsmr.4c00071": {
                "title": "Challenges and Opportunities of Molecular Simulations for Negative Gas Adsorption",
                "abstract": "Negative gas adsorption (NGA) is a particularly eye-catching phenomenon, involving the spontaneous desorption of gas upon pressure increase during adsorption in a flexible nanoporous material. The material undergoes a structural transition from an \u201copen-pore\u201d phase to a contracted \u201cclosed-pore\u201d phase upon gas adsorption, leading to macroscopic gas desorption visible to the naked eye. It was initially evidenced experimentally in 2016 for the adsorption of methane and n-butane in the DUT-49 metal\u2013organic framework (DUT = Dresden University of Technology) and later demonstrated to be a general phenomenon, occurring for different gases and in a variety of materials with the same topology. NGA materials belong to the category of metamaterials, displaying behavior that is not found (or rarely observed) in \u201cnatural\u201d or simple materials. The negative adsorption transition takes place outside of thermodynamic equilibrium, and its characterization requires the use of many complementary experimental techniques (adsorption measurements, in situ X-ray diffraction, EXAFS, NMR, etc.), as well as molecular simulation techniques. In order to obtain a full and consistent picture of the NGA phenomenon, it is indeed necessary to combine computational modeling with a variety of methods, at different scales, in order to understand the microscopic behavior of the host framework and guest molecules to the macroscopic experimental results. At the smallest scale, density functional theory calculations have been used to understand the energetics and structure of the NGA materials, as well as the micromechanical properties of their organic linkers: the buckling of these linkers explains the large metastability of the open-pore phase and gives rise to the NGA transition. At a larger scale, classical grand canonical Monte Carlo simulations in the \u201crigid host\u201d structures can predict the adsorption capacity of different phases, elucidating the driving force behind the structural transition. To explicitly couple the flexibility of the framework and the adsorption of guest molecules, molecular dynamics simulations (relying on a classical force field for the flexible metal\u2013organic framework) can be coupled with free energy methods to investigate the thermodynamics of NGA, obtaining free energy profiles that determine the relative stability of different phases with varying amounts of adsorbed gas. Finally, mesoscopic-scale modeling methods are required in order to understand the phenomenon at a scale larger than one unit cell and explain experimental findings about the influence of crystal size effects on the NGA transition. This Account summarizes the computational approaches that have been used so far to better understand negative gas adsorption and highlights open questions and perspectives in this field of research.",
                "disciplines": [
                    "3403"
                ]
            },
            "10.26434/chemrxiv-2024-hvxml": {
                "title": "Challenges and opportunities of molecular simulations for negative gas adsorption",
                "abstract": "Negative gas adsorption (NGA) is a particularly eye-catching phenomenon, involving the spontaneous desorption of gas upon pressure increase during adsorption in a flexible nanoporous material. The material undergoes a structural transition from an \u201copen pore\u201d phase to a contracted \u201cclosed pore\u201d phase upon gas adsorption, leading to macroscopic gas desorption visible to the naked eye. It was initially evidenced experimentally in 2016 for the adsorption of methane and n-butane in the DUT-49 metal\u2013organic framework (DUT = Dresden University of Technology), and later demonstrated to be a general phenomenon, occurring for different gases and in a variety of materials with the same topology. NGA materials belong to the category of metamaterials, displaying behavior that is not found (or rarely observed) in \u201cnatural\u201d or simple materials. The negative adsorption transition takes place outside of thermodynamic equilibrium, and its characterization requires the use of many complementary experimental techniques (adsorption measurements, in situ X-ray diffraction, EXAFS, NMR, etc.), as well as molecular simulation techniques. In order to obtain a full and consistent picture of the NGA phenomenon, it is indeed necessary to combine computational modelling with a variety of methods, at different scales, in order to understand the microscopic behavior of the host framework and guest molecules to the macroscopic experimental results. At the smallest scale, density functional theory (DFT) calculations have been used to understand the energetics and structure of the NGA materials, as well as the micromechanical properties of their organic linkers: the buckling of these linkers explains the large metastability of the open-pore phase, and gives rise to the NGA transition. At a larger scale, classical grand canonical Monte Carlo (GCMC) simulations in the \u201crigid host\u201d structures can predict the adsorption capacity of different phases, elucidating the driving force behind the structural transition. To explicitly couple the flexibility of the framework and the adsorption of guest molecules, molecular dynamics simulations (relying on a classical force field for the flexible MOF) can be coupled with free energy methods to investigate the thermodynamics of NGA, obtaining free energy profiles that determine the relative stability of different phases with varying amounts of adsorbed gas. Finally, mesoscopic-scale modeling methods are required in order to understand the phenomenon at a scale larger than one unit cell, and explain experimental findings about the influence of crystal size effects on the NGA transition. This Account summarizes the computational approaches that have been used so far to better understand negative gas adsorption, and highlight open questions and perspectives in this field of research.",
                "disciplines": [
                    "3403"
                ]
            },
            "10.1039/d4nr01024h": {
                "title": "The use of collective variables and enhanced sampling in the simulations of existing and emerging microporous materials",
                "abstract": "Microporous materials, including zeolites, metal-organic frameworks, and cage compounds, offer diverse functionalities due to their unique dynamics and guest confinement properties. These materials play a significant role in separation, catalysis, and sensing, but their complexity hinders exploration using traditional atomistic simulations. This review explores collective variables (CVs) paired with enhanced sampling as a powerful approach to enable efficient investigation of key features in microporous materials. We highlight successful applications of CVs in studying adsorption, diffusion, phase transitions, and mechanical properties, demonstrating their crucial role in guiding material design and optimisation. The future of CVs lies in integration with techniques like machine learning, allowing for enhanced efficiency and accuracy. By tailoring CVs to specific materials and developing multi-scale approaches we can further unlock the intricacies of these fascinating materials. Simulations are a cornerstone in unravelling the complexities of microporous materials and are crucial for our future understanding.",
                "disciplines": [
                    "3403"
                ]
            },
            "10.1038/s42004-024-01143-0": {
                "title": "The rise of data repositories in materials chemistry",
                "abstract": "FAIR (findable, accessible, interoperable and reusable) data practices are necessary to expedite knowledge discovery, encourage collaboration, and optimise resource use, fostering a robust foundation for future scientific progress. Here, the authors explore the use of FAIR practices to advance materials chemistry research, examining key repositories, highlighting their role in sharing scientific data, and examining the accessibility of these approaches.",
                "disciplines": []
            },
            "10.1039/d3dd00236e": {
                "title": "Machine learning interatomic potentials for amorphous zeolitic imidazolate frameworks",
                "abstract": " Accurate microscopic models of amorphous metal\u2013organic frameworks (MOFs) are difficult to create. Machine learning potentials based on data from ab initio molecular dynamics offer a novel way to achieve this goal. \nThe detailed understanding of the microscopic structure of amorphous phases of metal\u2013organic frameworks (MOFs) remains a widely open question: characterization of these systems is very difficult, both from the experimental and computational point of view. In molecular simulations, approaches have been proposed that rely either on reactive force field, that lack chemical accuracy, or first-principles calculations, that are too computationally expensive. Here, we have found an innovative solution to these problems by training a machine learning potential for the description of disordered phases of a zeolitic imidazolate framework (ZIF). We then used it to produce high-quality atomistic models of ZIF glasses, with accuracy close to density functional theory (DFT) but at far lower computational cost in production runs.",
                "disciplines": [
                    "3407"
                ]
            },
            "10.1039/d3tc03606e": {
                "title": "Topological analysis and control of post-synthetic metalation sites in Zr-based metal\u2013organic frameworks",
                "abstract": " MOFs formed from 8-connecting nodes and 4-connecting linkers can have the flu , scu and csq topologies. Here we show design criteria for making the rare sqc topology and how topology can be used to generate distinct post-synthetic metalation sites. \n The design criteria needed for the formation of the sqc metal\u2013organic framework (MOF) topology, from an 8-connecting node and a 4-connecting linker, are unclear due to a limited number of reports. After recently reporting the MOF UAM-1000 (UAM = University of Adelaide Material), which has this rare sqc topology, we present a study that explores the effect of flexible tetrapyrazole carboxylate linker structure metrics on the topology of Zirconium-based MOFs (Zr-MOFs). By modifying the linker length and width, three new Zr-MOFs (UAM-10, UAM-11, and UAM-1002) were synthesized and characterized. The study reveals that linker dimensions influence the accessible conformations, and along with fine-tuning of synthetic conditions, allow control over MOF topology. Additionally, linker flexibility plays a crucial role in the formation of the sqc over the more common csq topology. Finally, the presence of free bis-pyrazolyl groups in the reported MOFs allowed us to evaluate the potential for post-synthetic metalation (PSMet). UAM-10 and UAM-11 are too rigid, the pyrazole groups lack the appropriate arrangement and therefore these materials do not undergo PSMet. In contrast, UAM-1002 with its scu topology exhibits the right quanta of flexibility needed for successful PSMet, making it a promising platform for studying the chemistry of anchored organometallic complexes. Moreover, the different topology for UAM-1002 versus UAM-1000 changes the nature of the PSMet site (bidentate versus a tetradentate site) despite these being made from the same node and linker building blocks. ",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1021/acs.chemmater.3c01744": {
                "title": "Lowering the Energetic Landscape for Negative Thermal Expansion in 3D-Linker Metal\u2013Organic Frameworks",
                "abstract": "Tuning the coefficient of thermal expansion (CTE) of functional materials is paramount for their practical implementation. The multicomponent nature of metal\u2013organic frameworks (MOFs) offers an opportunity to finely adjust negative thermal expansion (NTE) properties by varying the metal ions and linkers used. We describe a new strategy to adjust the NTE by using organic linkers that include additional rotational degrees of freedom. Specifically, we employ cubane-1,4-dicarboxylate and bicyclo[1.1.1]\u00adpentane-1,3-dicarboxylate to form the MOFs CUB-5 and 3DL-MOF-1, respectively, where each linker has low torsional energy barriers. The core of these nonconjugated linkers is decoupled from the carboxylate functionalities, which frees the relative movement of these components. This results in enhanced NTE compared to the analogous, conjugated system; VT-PXRD results were used to calculate the CTE for 3DL-MOF-1 (\u03b1L = \u221213.9(2) \u00d7 10\u20136 K\u20131), and CUB-5 (\u03b1L = \u221214.7(3) \u00d7 10\u20136 K\u20131), which is greater than the NTE of MOF-5 (\u03b1L = \u221213.1(1) \u00d7 10\u20136 K\u20131). These results identify a new route to enhanced NTE behaviors in IRMOF materials influenced by low energy molecular torsion of the linker.",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1021/acs.inorgchem.3c02337": {
                "title": "Atomic-Scale Elucidation of Unusually Distorted Dimeric Complexes Confined in a Zr-Based Metal\u2013Organic Framework",
                "abstract": "Nanoconfinement in metal-organic framework (MOF) pores can lead to the isolation of unusual or reactive metal complexes. However, MOFs that support the stabilization and precise structural elucidation of metal complexes and small metal clusters are rare. Here, we report a thermally and chemically stable zirconium-based MOF (University of Adelaide Material-1001, UAM-1001) with a high density of free bis-pyrazolyl units that can confine mono- and dinuclear metal complexes. The precursor MOF, UAM-1000, has a high degree of structural flexibility, but post synthetic modification with a bracing linker, biphenyl-4,4'-dicarboxylic acid, partially rigidifies the MOF (UAM-1001). This allows \"matrix isolation\" and detailed structural elucidation of postsynthetically added dimeric complexes bound within a tetradentate binding site formed by two linkers. Dimeric species [Co<sub>2</sub>Cl<sub>4</sub>], [Cu<sub>2</sub>Cl<sub>4</sub>], [Ni<sub>2</sub>Cl<sub>3</sub>(H<sub>2</sub>O)<sub>2</sub>]Cl, and [Rh<sub>2</sub>(CO)<sub>3</sub>Cl<sub>2</sub>] were successfully isolated in UAM-1001 and characterized by single-crystal X-ray diffraction. Comparison of the UAM-1001 isolated species with similar complexes in the solid state reveals that UAM-1001 can significantly distort the structures and enforce notably shorter metal-metal distances. For example, MOF tethering allows isolation of a [Cu<sub>2</sub>Cl<sub>4</sub>] complex that rapidly reacts with water in the solid state. The stability, porosity, and modulated flexibility of UAM-1001 provide an ideal platform material for the isolation and study of new dimeric complexes and their reactivity.",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1063/5.0144827": {
                "title": "Host\u2013guest interactions in framework materials: Insight from modeling",
                "abstract": "The performance of metal\u2013organic and covalent organic framework materials in sought-after applications\u2014capture, storage, and delivery of gases and molecules, and separation of their mixtures\u2014heavily depends on the host\u2013guest interactions established inside the pores of these materials. Computational modeling provides information about the structures of these host\u2013guest complexes and the strength and nature of the interactions present at a level of detail and precision that is often unobtainable from experiment. In this Review, we summarize the key simulation techniques spanning from molecular dynamics and Monte Carlo methods to correlate ab initio approaches and energy, density, and wavefunction partitioning schemes. We provide illustrative literature examples of their uses in analyzing and designing organic framework hosts. We also describe modern approaches to the high-throughput screening of thousands of existing and hypothetical metal\u2013organic frameworks (MOFs) and covalent organic frameworks (COFs) and emerging machine learning techniques for predicting their properties and performances. Finally, we discuss the key methodological challenges on the path toward computation-driven design and reliable prediction of high-performing MOF and COF adsorbents and catalysts and suggest possible solutions and future directions in this exciting field of computational materials science.",
                "disciplines": [
                    "3403"
                ]
            },
            "10.1002/anie.202314378": {
                "title": "A Lantern\u2010Shaped Pd(II) Cage Constructed from Four Different Low\u2010Symmetry Ligands with Positional and Orientational Control: An Ancillary Pairings Approach",
                "abstract": "One of the key challenges of metallo-supramolecular chemistry is to maintain the ease of self-assembly but, at the same time, create structures of increasingly high levels of complexity. In palladium(II) quadruply stranded lantern-shaped cages, this has been achieved through either 1)\u2005the formation of heteroleptic (multi-ligand) assemblies, or 2)\u2005homoleptic assemblies from low-symmetry ligands. Heteroleptic cages formed from low-symmetry ligands, a hybid of these two approaches, would add an additional rich level of complexity but no examples of these have been reported. Here we use a system of ancillary complementary ligand pairings at the termini of cage ligands to target heteroleptic assemblies: these complementary pairs can only interact (through coordination to a single Pd(II) metal ion) between ligands in a cis position on the cage. Complementarity between each pair (and orthogonality to other pairs) is controlled by denticity (tridentate to monodentate or bidentate to bidentate) and/or hydrogen-bonding capability (AA to DD or AD to DA). This allows positional and orientational control over ligands with different ancillary sites. By using this approach, we have successfully used low-symmetry ligands to synthesise complex heteroleptic cages, including an example with four different low-symmetry ligands.",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1002/ange.202314378": {
                "title": "A Lantern\u2010Shaped Pd(II) Cage Constructed from Four Different Low\u2010Symmetry Ligands with Positional and Orientational Control: An Ancillary Pairings Approach",
                "abstract": "Abstract  One of the key challenges of metallo\u2010supramolecular chemistry is to maintain the ease of self\u2010assembly but, at the same time, create structures of increasingly high levels of complexity. In palladium(II) quadruply stranded lantern\u2010shaped cages, this has been achieved through either 1) the formation of heteroleptic (multi\u2010ligand) assemblies, or 2) homoleptic assemblies from low\u2010symmetry ligands. Heteroleptic cages formed from low\u2010symmetry ligands, a hybid of these two approaches, would add an additional rich level of complexity but no examples of these have been reported. Here we use a system of ancillary complementary ligand pairings at the termini of cage ligands to target heteroleptic assemblies: these complementary pairs can only interact (through coordination to a single Pd(II) metal ion) between ligands in a cis position on the cage. Complementarity between each pair (and orthogonality to other pairs) is controlled by denticity (tridentate to monodentate or bidentate to bidentate) and/or hydrogen\u2010bonding capability (AA to DD or AD to DA). This allows positional and orientational control over ligands with different ancillary sites. By using this approach, we have successfully used low\u2010symmetry ligands to synthesise complex heteroleptic cages, including an example with four different low\u2010symmetry ligands. ",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1039/d3ta04707e": {
                "title": "Protein-induced modifications in crystal morphology of a hydrogen-bonded organic framework",
                "abstract": "In this work, we studied the encapsulation of a range of proteins in a hydrogen-bonded organic framework (HOF) comprised of a tetraamidinium cation and diazobenzene-based dicarboxylate anion.\n In this work, we studied the encapsulation of a range of proteins in a hydrogen-bonded organic framework (HOF) comprised of a tetraamidinium cation and diazobenzene-based dicarboxylate anion. We explore the use of external stimuli: light and temperature to modulate HOF crystal growth and size. In particular, we found photo-isomerisation can be used to control the concentration of the trans -azobenzene building block that contributes to HOF formation. When HOF growth was slowed sufficiently, deformation of the crystals and ultimately multicrystal aggregates were observed in the presence of some proteins. We propose that the extent of crystal deformation, consistent with better protein association, may be governed by differences in the type and strength of interactions between proteins and the surface of the growing HOF crystals. ",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1039/d3ce00881a": {
                "title": "Understanding the structural landscape of Mn-based MOFs formed with hinged pyrazole carboxylate linkers",
                "abstract": "Isoreticulation of MOFs made of pyrazole carboxylate linkers and Mn nodes is nontrivial due to linker flexibility and a variety of accessible Mn nodes. The use of tetratopic hinged linkers to form porous 3D MOFs was identified as a viable strategy.\n Metal\u2013organic frameworks (MOFs) capable of post-synthetic metalation (PSMet) have garnered significant interest as supports for catalytic metals. The Mn-based MOF, MnMOF-1 ([Mn 3 ( L2  Me  ) 3 ] where L2  Me  = bis-(4-carboxyphenyl-3,5-dimethylpyrazolyl)methane), has been an exemplar for studying PSMet. Herein we investigate the synthesis of Mn-based MOFs from related flexible ditopic pyrazole carboxylate links, along with the formation of MOFs with similar tetratopic hinged linkers. We show for the first time that MnMOF-1 is likely a kinetic or metastable phase and a newly identified 2D layered material (MnMOF-2D) is the thermodynamically favoured product for this metal\u2013linker combination. Formation of a MnMOF-1 structure with shorter linkers is thwarted by steric clashes that preclude the formation of the Mn 3 cluster. This observation prompted the use of density functional theory (DFT) simulations that showed the target material to be very dense, highly strained and thereby energetically unfavourable, but potentially, a hypothetical MnMOF-1 structure with a longer phenylethynyl spacer would be energetically feasible. Finally, the predominance of 2D MOFs formed with shorter flexible links encouraged us to use tetratopic hinged linkers to form 3D frameworks, which was vindicated by the successful synthesis of two new porous 3D Mn-based MOFs, MnMOF- L4 and MnMOF- L5 . These results highlight that reticular synthesis of MOFs formed with flexible, non-linear linkers is challenging. ",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1002/asia.202300673": {
                "title": "Stoichiometric Control of Guest Recognition of Self\u2010Assembled Palladium(II)\u2010Based Supramolecular Architectures",
                "abstract": "We report flexible [Pd(L)<sub>2</sub> ]<sup>2+</sup> complexes where there is self-recognition, driven by \u03c0-\u03c0 interactions between electron-rich aromatic arms and the cationic regions they are tethered to. This self-recognition hampers the association of these molecules with aromatic molecular targets in solution. In one case, this complex can be reversibly converted to an 'open' [Pd<sub>2</sub> (L)<sub>2</sub> ]<sup>4+</sup> macrocycle through introduction of more metal ion. This is accomplished by the ligand having two bidentate binding sites: a 2-pyridyl-1,2,3-triazole site, and a bis-1,2,3-triazole site. Due to favourable hydrogen bonding, the 2-pyridyl-1,2,3-triazole units reliably coordinate in the [Pd(L)<sub>2</sub> ]<sup>2+</sup> complex to control speciation: a second equivalent of Pd(II) is required to enforce coordination to bis-triazole sites and form the macrocycle. The macrocycle interacts with a molecular substrate with higher affinity. In this fashion we are able to use stoichiometry to reversibly switch between two different species and regulate guest binding.",
                "disciplines": [
                    "3402",
                    "3403",
                    "3405"
                ]
            },
            "10.1038/s41467-023-38737-6": {
                "title": "On the role of history-dependent adsorbate distribution and metastable states in switchable mesoporous metal-organic frameworks",
                "abstract": "A unique feature of metal-organic frameworks (MOFs) in contrast to rigid nanoporous materials is their structural switchabilty offering a wide range of functionality for sustainable energy storage, separation and sensing applications. This has initiated a series of experimental and theoretical studies predominantly aiming at understanding the thermodynamic conditions to transform and release gas, but the nature of sorption-induced switching transitions remains poorly\u00a0understood. Here we report experimental evidence for fluid metastability and history-dependent states during sorption triggering the structural change of the framework and leading to the counterintuitive phenomenon of negative gas adsorption (NGA) in flexible MOFs. Preparation of two isoreticular MOFs differing by structural flexibility and performing direct in situ diffusion studies aided by in situ X-ray diffraction, scanning electron microscopy and computational modelling, allowed assessment of n-butane molecular dynamics, phase state, and the framework response to obtain\u00a0a\u00a0microscopic picture for each step of the sorption process.",
                "disciplines": [
                    "3403",
                    "3406",
                    "4016"
                ]
            },
            "10.26434/chemrxiv-2023-d1s8w": {
                "title": "Lowering the energetic landscape for negative thermal expansion in 3DL-MOFs",
                "abstract": "Tuning the coefficient of thermal expansion (CTE) of functional materials is paramount for their practical implementation. The multicomponent nature of metal-organic frameworks (MOFs) offers an opportunity to finely adjust negative thermal ex-pansion (NTE) properties by varying the metal ions and linkers used. We describe a new strategy to adjust NTE by using organic linkers that include additional rotational degrees of freedom. Specifically, we employ cubane-1,4-dicarboxylate and bicyclo[1.1.1]pentate-1,3-dicarboxylate to form the MOFs CUB-5 and 3DL-MOF-1, respectively, where each linker has low torsional energy barriers. The core of these non-conjugated linkers is decou-pled from the carboxylate functionalities, which frees the relative movement of these components. This results in enhanced NTE compared to the analogous, conjugated system; VT-PXRD results were used to calculate the CTE for 3DL-MOF-1 (\u03b1L = \u221213.9(2) \u00d7 10\u22126 K\u22121), and CUB-5 (\u03b1L = \u221214.7(3) \u00d7 10\u22126 K\u22121), which is greater than the NTE of MOF-5 (\u03b1L = \u221213.1(1) \u00d7 10\u22126 K\u22121). These results identify a new route to enhanced NTE behaviors in IRMOF materials, influenced by low energy molecular torsion of the linker.",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1002/adma.202211478": {
                "title": "Fabrication of 3D Oriented MOF Micropatterns with Anisotropic Fluorescent Properties",
                "abstract": "Micropatterning crystalline materials with oriented pores is necessary for the fabrication of devices with anisotropic properties. Crystalline and porous metal-organic frameworks (MOFs) are ideal materials as their chemical and structural mutability enables precise tuning of functional properties for applications ranging from microelectronics to photonics. Herein, a patternable oriented MOF film is designed: by using a photomask under X-ray exposure, the MOF film decomposes in the irradiated areas, remaining intact in the unexposed regions. The MOF film acts simultaneously as a resist and as functional porous material. While the heteroepitaxial growth from aligned Cu(OH)<sub>2</sub> nanobelts is used to deposit oriented MOF films, the sensitivity to radiation is achieved by integrating a brominated dicarboxylate ligand (Br<sub>2</sub> BDC) into a copper-based MOF Cu<sub>2</sub> L<sub>2</sub> DABCO (DABCO = 1,4-diazabicyclo[2.2.2]octane; L = BDC/Br<sub>2</sub> BDC). The lithographed samples act as diffraction gratings upon irradiation with a laser, thus confirming the quality of the extended MOF micropattern. Furthermore, the oriented MOF patterns are functionalized with fluorescent dyes. As a result, by rotating the polarization angle of the laser excitation, the alignment of the dye in the MOF is demonstrated. By controlling the functional response to light, this MOF patterning protocol can be used for the microfabrication of optical components for photonic devices.",
                "disciplines": [
                    "3403",
                    "4016"
                ]
            }
        }
    },
    "10007512": {
        "title": "Privacy-aware Smart Access Control for Internet-of-Things on Blockchain",
        "abstract": "This project aims to address privacy and trust issues in Internet-of-Things (IoT) access control mechanism of smart critical infrastructure. This project expects to generate new knowledge in the area of IoT access control by leveraging privacy-preserving techniques, blockchain, and machine learning. Expected outcomes of this project include enhanced capability to build improved techniques for privacy aware tamperproof IoT access control with machine learning based anomaly detection. This should provide significant benefits, such as preventing cyber threats on security and privacy of IoT and improving trust in IoT-enabled smart critical infrastructure of Australia.",
        "disciplines": [
            "4604",
            "4606"
        ],
        "publications": {
            "10.1145/3589334.3645329": {
                "title": "GEES: Enabling Location Privacy-Preserving Energy Saving in Multi-Access Edge Computing",
                "abstract": "The global deployment of the 5G network has led to a substantial increase in the deployment of edge servers to host web applications, catering to the growing demand for low service latency by edge web users. Yet, running edge servers 24/7 leads to enormous energy consumption and excessive carbon emissions. Energy-efficient edge resource provision is desired to achieve sustainable development goals in the new multi-access edge computing (MEC) architecture. Recently, several approaches have been proposed to solve the demand response problem for energy saving in cloud computing and MEC. However, accurate location information of edge web users should always be provided, which sacrifices users' privacy. To protect edge web users' location privacy while saving energy in MEC, we systematically formulate this location privacy-preserving edge demand response (LEDR) problem. To solve the LEDR problem effectively and efficiently, we propose a system named GEES by incorporating differential geo-obfuscation to secure user privacy while maximizing system utility and energy efficiency through inferences with theoretical analysis. Extensive and comprehensive experiments are conducted based on a synthetic real-world dataset, and the results demonstrate that GEES outperforms representative approaches by 23.02%, 31.47%, and 17.29% on average in terms of energy efficiency, user privacy and system utility.",
                "disciplines": [
                    "4605",
                    "4606",
                    "4604"
                ]
            }
        }
    },
    "9852761": {
        "title": "Resolving ocean convection: new knowledge for a changing Antarctica",
        "abstract": "This project aims to improve our understanding of the role of convection on the Antarctic margins using a high-resolution, cutting-edge numerical approach. Convection is an important, but poorly understood oceanic process, which diverts heat away from the melting Antarctic ice shelves by transporting cold and salty water from the ocean surface to depth. The project outcomes will be new knowledge of the physics from novel numerical models and theory, supported by insights from observations and model parameterisations. This timely research will improve prediction of sea level rise due to a changing Antarctica and enhance our ability to adapt to future climate scenarios, providing significant environmental and health benefits to Australians.",
        "disciplines": [
            "3708"
        ],
        "publications": {
            "10.1029/2023gl104396": {
                "title": "Double\u2010Diffusive Layer and Meltwater Plume Effects on Ice Face Scalloping in Phase\u2010Change Simulations",
                "abstract": "Abstract Antarctic ice shelves are losing mass at increasing rates, yet the ice\u2010ocean interactions that cause significant ice loss are not well understood. A new approach of high\u2010resolution phase\u2010change simulations is used to model vertical ice melting into a stratified ocean. The ocean dynamics show complicated interplay between a turbulent buoyant meltwater plume and double\u2010diffusive layers, while the ice actively melts and changes topography. At room temperatures, the double\u2010diffusive layer thickness is closely linked to ice scalloping. At lower, more realistic ocean temperatures, the meltwater plume becomes prominent with a laminar\u2010to\u2010turbulent transition imprinting an indent on the melting ice. The double\u2010diffusive layer thickness is consistent with scaling prediction, while the real\u2010world application demonstrates reasonably good matching of the scaling prediction for some Antarctic regions. Our study is a key first step toward the future use of high\u2010resolution phase\u2010change fluid dynamics simulations to better understand Antarctic ice shelves in a changing climate.\nPlain Language Summary Future climate scenarios and sea level rise are closely tied to the accelerating loss of Antarctic ice shelves, which lose significant mass by melting into the surrounding ocean. However, the extent of ice shelf mass loss in a changing climate is currently not well understood, with lack of knowledge on the fine\u2010scale ice\u2010ocean interactions presenting a key restriction on the accuracy of climate predictions. Here, we use a new suite of numerical computer simulations to model an ice face melting into the ocean. In particular, our simulations allow the ice face to melt back and change shape, which previous numerical simulations could not attempt. We see interesting ocean dynamics known as \u201cdouble\u2010diffusive layers\u201d that occur because temperature and salinity both affect the water density. In addition, we also see a buoyant meltwater plume evolve next to the ice face. Both the double\u2010diffusive layers and meltwater plume can influence the ice melting and shape. Our results are a first step in using these new phase\u2010change simulations to model ice\u2010ocean interactions, and will help to better understand the Antarctic response to a changing climate.\nKey Points    High\u2010resolution phase\u2010change simulations are used to examine a vertical ice face melting into a stratified ocean at low temperatures   A distinct laminar\u2010to\u2010turbulent transition occurs in the meltwater plume as it rises, accompanied by an indent in the ice at the transition   Double\u2010diffusive layers adjacent to the turbulent plume are consistent with scaling predictions and are relevant to the ocean application   ",
                "disciplines": [
                    "3708",
                    "3709"
                ]
            }
        }
    },
    "13680186": {
        "title": "Linguistic interference in the contact between Chinese and Brazilians in the city of S\u00e3o Paulo: an ethnographic approach",
        "abstract": "This research proposes to investigate the interference of Chinese on the Portuguese spoken by Chinese immigrants in the city of S\u00e3o Paulo, aiming to 1) describe the multilingual and multidialectal situation of the Chinese immigrant community in S\u00e3o Paulo, considering the possibility of language shift; 2) to analyze three interference phenomena from Chinese to Portuguese, one of a lexical, one grammatical and one phonic nature, in line with Variationist Sociolinguistics. In order to put the research into practice, it will resort to ethnographic observation and the recording of sociolinguistic interviews. The data collected throughout the research will be processed in the ELAN program and in the R platform. The proposed research will contribute to sociolinguistic contact studies, by describing the multilingual and multidialectal situation of the Chinese community in S\u00e3o Paulo and by qualitatively and quantitatively interpreting the patterns of acquisition and variation of Portuguese by immigrants, issues still very little explored in Brazilian and S\u00e3o Paulo Linguistics.",
        "disciplines": [
            "4704",
            "4703"
        ],
        "publications": {
            "10.20396/cel.v65i00.8673331": {
                "title": "Estudos sociolingu\u00edsticos sobre contato dialetal: contribui\u00e7\u00f5es do VARIEM e agenda de pesquisa",
                "abstract": "The speech of migrants in dialectal contact situations has been overlooked in variationist sociolinguistic studies, which tend to focus on the speech of the locally born and raised. Taking into account population mobility and the sociodemographic reality in many Brazilian communities, this article aims to (i) present works developed within the Laboratory VARIEM (UNICAMP) on the speech of Northeastern migrants living in the state of S\u00e3o Paulo, which, taken together, allow for generalizations on the role of Gender, Age of Arrival, and Length of Residence in processes of language variation and change in the speech of migrants; and (ii) map the gaps and pending questions in order to outline a research agenda for sociolinguistic studies on dialectal contact. We argue that the analysis of migrants\u2019 speech, sociodemographic mobility and dialectal contact is necessary for a more comprehensive Theory of Language Variation and Change (Weinreich et al, 2006 [1968]). Although the topic raises a number of challenges, the variationist methodology of linguistic analysis is particularly suitable for observing the complex patterns of language variation in migrants\u2019 speech.",
                "disciplines": [
                    "4703",
                    "4704",
                    "4403"
                ]
            }
        }
    },
    "13666516": {
        "title": "Alpha-Diperfect and Chi-Diperfect Digraphs",
        "abstract": "In 1982, Berge defined two classes of digraphs in order to identify properties in the relationship between independent sets and paths in digraphs. The first class that Berge defined is the class of $\\alpha$-diperfect digraphs. A digraph $D$ is $\\alpha$-diperfect if every subdigraph $D'$ induced from $D$ satisfies the following property: for every maximum independent set of $D'$ there is a partition into paths $\\mathcal{P} $ of $D'$ such that every $P \\in \\mathcal{P}$ contains exactly one vertex of $S$. The second class that Berge defined is the class of $\\chi$-diperfect digraphs. A digraph $D$ is $\\chi$-diperfect if every induced subdigraph $D'$ of $D$ satisfies the following property: for every minimal coloring $\\mathcal{C}$ of $D'$ there is a path $P $ of $D'$ containing exactly one vertex of each color class of $\\mathcal{C}$. -diperfects in terms of proven induced subdigraphs, but this seems to be a very difficult problem and unlikely to be solved in the near future. In this project, we intend to obtain results towards this goal through the investigation of structural properties of these digraph classes and the analysis of specific families of digraphs to try to discover which elements of these families are $\\alpha$-diperfect or $\\chi$- diperfect.",
        "disciplines": [
            "4901",
            "4904"
        ],
        "publications": {
            "10.1016/j.procs.2023.08.230": {
                "title": "Obstructions for \u03c7-diperfectness",
                "abstract": "In 1982, Berge defined the class of \u03c7-diperfect digraphs. A digraph D is \u03c7-diperfect if for every minimum coloring S of D there is a path P containing exactly one vertex of each color class of S and this property holds for every induced subdigraph of D. The ultimate goal in this research area is to obtain a characterization of \u03c7-diperfect digraphs in terms of forbidden induced subdigraphs, but this may be a very difficult problem and not likely to be solved in a near future. Berge showed the first examples of obstructions for \u03c7-diperfect digraphs (i.e. minimal non-\u03c7-diperfect digraphs) by presenting orientations of odd cycles and complements of odd cycles that are not \u03c7-diperfect. In 2022, de Paula Silva, Nunes da Silva and Lee showed characterizations of non-\u03c7-diperfect super-orientations of odd cycles and their complements. Moreover, they showed that these structures are not the only obstructions for \u03c7-diperfect digraphs, by presenting new obstructions with stability number two and three. In this paper, we present new obstructions for \u03c7-diperfect digraphs with arbitrary stability number and arbitrary chromatic number.",
                "disciplines": []
            }
        }
    },
    "13017588": {
        "title": "Pheromone information processing in the social insect brain \u2013 PHEROBRAIN",
        "abstract": "Sociality is classified as one of the major transitions in evolution, and the most advanced level of sociality in animals is found in eusocial insect societies, like honey bees. The success of social insect colonies relies on elaborate communication among the colony members, and in particular on the use of a high number of pheromones. But how does the social insect brain manage to encode such a plethora of highly?meaningful and ecologically?relevant signals? Does it encode social pheromones using dedicated pathways (labeled-line system), a relevant strategy when only a few pheromones are used by the animal (i.e. sexual pheromone), or does it use a combinatorial strategy (many weakly specific lines), in the manner of general odorants? To answer these questions, the PHEROBRAIN project aims to identify and characterize olfactory receptors of the honey bee tuned to pheromonal compounds using a phylogenetic approach and heterologous expression in the Drosophila empty-neuron system (Aim 1). We will then study the central circuits involved in pheromone processing using in vivo calcium imaging on transgenic bees expressing the calcium indicator GCaMP6, recently developed in the scientific coordinator\u2019s team (Aim 2). Finally, we will study the effect of specific olfactory receptor knock-out on bee\u2019s behavior (Aim 3), both in natural conditions and using associative conditioning. Overall, the PHEROBRAIN project will help to understand how evolution has shaped the social insect brain to cope with the increased need for accurate communication channels.",
        "disciplines": [
            "3109",
            "3209"
        ],
        "publications": {
            "10.1371/journal.pbio.3001984": {
                "title": "Multisite imaging of neural activity using a genetically encoded calcium sensor in the honey bee",
                "abstract": "Understanding of the neural bases for complex behaviors in Hymenoptera insect species has been limited by a lack of tools that allow measuring neuronal activity simultaneously in different brain regions. Here, we developed the first pan-neuronal genetic driver in a Hymenopteran model organism, the honey bee, and expressed the calcium indicator GCaMP6f under the control of the honey bee synapsin promoter. We show that GCaMP6f is widely expressed in the honey bee brain, allowing to record neural activity from multiple brain regions. To assess the power of this tool, we focused on the olfactory system, recording simultaneous responses from the antennal lobe, and from the more poorly investigated lateral horn (LH) and mushroom body (MB) calyces. Neural responses to 16 distinct odorants demonstrate that odorant quality (chemical structure) and quantity are faithfully encoded in the honey bee antennal lobe. In contrast, odor coding in the LH departs from this simple physico-chemical coding, supporting the role of this structure in coding the biological value of odorants. We further demonstrate robust neural responses to several bee pheromone odorants, key drivers of social behavior, in the LH. Combined, these brain recordings represent the first use of a neurogenetic tool for recording large-scale neural activity in a eusocial insect and will be of utility in assessing the neural underpinnings of olfactory and other sensory modalities and of social behaviors and cognitive abilities.",
                "disciplines": [
                    "3109",
                    "3209"
                ]
            },
            "10.1101/2022.04.22.489138": {
                "title": "Multisite imaging of neural activity using a genetically encoded calcium sensor in the honey bee",
                "abstract": "ABSTRACT  Understanding of the neural bases for complex behaviors in Hymenoptera insect species has been limited by a lack of tools that allow measuring neuronal activity simultaneously in different brain regions. Here, we developed the first pan-neuronal genetic driver in a Hymenopteran model organism, the honey bee, and expressed the calcium indicator GCaMP6f under the control of the honey bee synapsin promoter. We show that GCaMP6f is widely expressed in the honey bee brain, allowing to record neural activity from multiple brain regions. To assess the power of this tool, we focused on the olfactory system, recording simultaneous responses from the antennal lobe, and from the more poorly investigated lateral horn and mushroom body calyces. Neural responses to 16 distinct odorants demonstrate that odorant quality (chemical structure) and quantity are faithfully encoded in the honey bee antennal lobe. In contrast, odor coding in the lateral horn departs from this simple physico-chemical coding, supporting the role of this structure in coding the biological value of odorants. We further demonstrate robust neural responses to several bee pheromone odorants, key drivers of social behavior, in the lateral horn. Combined, these brain recordings represent the first use of a neurogenetic tool for recording large-scale neural activity in a eusocial insect, and will be of utility in assessing the neural underpinnings of olfactory and other sensory modalities and of social behaviors and cognitive abilities. ",
                "disciplines": [
                    "3109",
                    "3209"
                ]
            }
        }
    },
    "13057636": {
        "title": "Using High Definition transcranial Direct Current Stimulation Guided by Electrophysiology and Diffusion Tensor Imaging to Treat Verbal Retrieval Deficits Secondary to Chronic Traumatic Brain Injury",
        "abstract": "PROJECT SUMMARY Language dysfunction is a common cognitive sequela of traumatic brain injury (TBI) in 31% to 44% of TBI survivors. One of the most prevalent sequelae, word finding difficulty (verbal retrieval deficit), can persist more than 12 months after injury. Effective treatment and mechanism-based studies for such treatment, however, are still lacking. High-definition transcranial direct current stimulation (HD-tDCS) is a novel non-invasive electromodulation approach that has been shown to improve verbal retrieval deficits in TBI by targeting the pre-Supplementary Motor Area (pre-SMA). Disrupted synchronized activity involving the pre-SMA and impaired white matter connectivity linked to the pre-SMA can result in verbal retrieval deficits. Particularly, the left frontal aslant tract (FAT) and fronto-striatal tract (FST) support verbal retrieval function by connecting the pre-SMA to the left inferior frontal gyrus and basal ganglia, respectively. The 3 aims of this proposal are 1) to determine HD-tDCS modulatory effects on synchronized activity involving the pre-SMA using electroencephalography (EEG), 2) to use diffusion tensor imaging (DTI) to examine how baseline integrity of the left FAT and FST affect pre-SMA HD-tDCS therapeutic effects, and 3) to establish predictive models of HD-tDCS induced changes by integrating baseline EEG and DTI measures. Both veterans and civilians with mild to moderate TBI will undergo ten 20-minunte sessions of active or sham HD-tDCS and will be evaluated immediately and at 8 weeks after treatment completion. The central hypothesis is that pre-SMA HD-tDCS will modulate pre-SMA associated synchronized activity to improve verbal retrieval, and that those effects will be predicated on the degree of disruption in baseline white matter integrity and synchronized activity. The expected results will offer a novel neurorehabilitation approach for verbal retrieval deficits across civilian and veteran TBI populations, along with clarification of underlying mechanisms, and provide a framework to guide future research and clinical application of electromodulation to treat TBI-related cognitive sequelae. This proposal is in line with the NIDCD\u2019s strategic plan under \u201cVoice, Speech, and Language Research\u201d including priority area 2 (\u201cIdentify the pathophysiologic and cognitive mechanisms underlying both common and rare voice, speech, and language impairments\u201d) and priority area 3 (\u201cDetection, Diagnosis and Hypothesis-Driven Interventions\u201d). My proposed research will contribute to understanding verbal retrieval deficits in TBI and treating individuals inflicted by impaired communication due to such deficits. The K99/R00 Career Development Award will allow me to acquire data and advance training in cognitive neuropsychology, DTI analysis and predictive modeling in the K99 phase. With this foundation, I will then establish my independent research in the R00 phase that will subsequently lead to independent funding through the NIH R01 mechanism or its equivalent by the end of the award period.",
        "disciplines": [
            "3904"
        ],
        "publications": {
            "10.1002/brb3.3490": {
                "title": "A modified neural circuit framework for semantic memory retrieval with implications for circuit modulation to treat verbal retrieval deficits",
                "abstract": "Word finding difficulty is a frequent complaint in older age and disease states, but treatment options are lacking for such verbal retrieval deficits. Better understanding of the neurophysiological and neuroanatomical basis of verbal retrieval function may inform effective interventions. In this article, we review the current evidence of a neural retrieval circuit central to verbal production, including words and semantic memory, that involves the pre-supplementary motor area (pre-SMA), striatum (particularly caudate nucleus), and thalamus. We aim to offer a modified neural circuit framework expanded upon a memory retrieval model proposed in 2013 by Hart et\u00a0al., as evidence from electrophysiological, functional brain imaging, and noninvasive electrical brain stimulation studies have provided additional pieces of information that converge on a shared neural circuit for retrieval of memory and words. We propose that both the left inferior frontal gyrus and fronto-polar regions should be included in the expanded circuit. All these regions have their respective functional roles during verbal retrieval, such as selection and inhibition during search, initiation and termination of search, maintenance of co-activation across cortical regions, as well as final activation of the retrieved information. We will also highlight the structural connectivity from and to the pre-SMA (e.g., frontal aslant tract and fronto-striatal tract) that facilitates communication between the regions within this circuit. Finally, we will discuss how this circuit and its correlated activity may be affected by disease states and how this circuit may serve as a novel target engagement for neuromodulatory treatment of verbal retrieval deficits.",
                "disciplines": [
                    "5202",
                    "5204"
                ]
            },
            "10.1016/j.clinph.2024.04.002": {
                "title": "Verbal retrieval deficits due to traumatic brain injury are associated with changes in event related potentials during a Go-NoGo task",
                "abstract": "OBJECTIVE: Verbal retrieval (VR) deficits often occur after traumatic brain injury (TBI), but the mechanisms remain unclear. We examined how event-related potentials (ERPs) during a Go-NoGo task were associated with VR deficits.\nMETHODS: Sixty veterans with a history of TBI underwent a neuropsychological battery and a Go-NoGo task with concurrent EEG recording. We compared task performance and ERP measures (N2, P3) between those with and those without persistent injury-related VR deficits. We then used generalized linear modeling to examine the relationship between ERP measures and scores on measures of executive function and processing speed.\nRESULTS: Go-NoGo task performance was comparable between the groups. Those with VR deficits had larger N2 amplitude in NoGo than in Go conditions. In participants with VR deficits, larger NoGo N2/P3 amplitude predicted faster processing speed. Furthermore, larger P3 amplitude and shorter P3 latency of the difference wave (NoGo - Go) predicted faster processing speed in those with VR deficits.\nCONCLUSIONS: Despite no difference in Go-NoGo task performance, ERP amplitude and latency measures associated with cognitive control during Go-NoGo distinguished TBI individuals with VR deficits from those without.\nSIGNIFICANCE: This study furthers our understanding of VR deficits in TBI and implicates potential application of ERP measures in monitoring and treating such deficits.",
                "disciplines": [
                    "3209"
                ]
            },
            "10.1111/ejn.16001": {
                "title": "Differences in electroencephalography oscillations between normal aging and mild cognitive impairment during semantic memory retrieval",
                "abstract": "Semantic memory remains relatively stable with normal cognitive aging and declines in early stages of neurodegenerative disease. We measured electroencephalography (EEG) oscillatory correlates of semantic memory retrieval to examine the effects of normal and pathological aging. Twenty-nine cognitively healthy young adults (YA), 22 cognitively healthy aging adults (HA) and 20 patients with mild cognitive impairment (MCI) completed a semantic memory retrieval task with concurrent EEG recording in which they judged whether two words (features of objects) led to retrieval of an object (retrieval) or not (non-retrieval). Event-related power changes contrasting the two conditions (retrieval vs. non-retrieval) within theta, alpha, low-beta and high-beta EEG frequency bands were examined for normal aging (YA vs. HA) and pathological aging effects (HA vs. MCI). With no behavioural differences between the two normal age groups, we found later theta and alpha event-related power differences between conditions only in YA and a high-beta event-related power difference only in HA. For pathological aging effects, with reduced accuracy in MCI, we found different EEG patterns of early event-related beta power differences between conditions in MCI compared with HA and an event-related low-beta power difference only in HA. Beta oscillations were correlated with behavioural performance only in HA. We conclude that the aging brain relies on faster (beta) oscillations during the semantic memory task. With pathological aging, retrieval accuracy declines and pattern of beta oscillation changes. The findings provide insights about age-related neural mechanisms underlying semantic memory and have implications for early detection of pathological aging.",
                "disciplines": [
                    "5202",
                    "5204"
                ]
            },
            "10.3389/fneur.2023.1177589": {
                "title": "Corrigendum: Case report: Improving verbal retrieval deficits with high definition transcranial direct current stimulation targeting the pre-supplementary motor area in a patient with chronic traumatic brain injury",
                "abstract": "[This corrects the article DOI: 10.3389/fneur.2021.678518.].",
                "disciplines": [
                    "5202",
                    "3202",
                    "3209"
                ]
            },
            "10.1016/j.clinph.2022.08.015": {
                "title": "High-definition transcranial direct current stimulation modulates theta response during a Go-NoGo task in traumatic brain injury",
                "abstract": "OBJECTIVE: High Definition transcranial Direct Current Stimulation (HD-tDCS) has been shown to improve cognitive performance in individuals with chronic traumatic brain injury (TBI), although electrophysiological mechanisms remain unclear.\nMETHODS: Veterans with TBI underwent active anodal (N\u00a0=\u00a015) vs sham (N\u00a0=\u00a010) HD-tDCS targeting the pre-supplementary motor area (pre-SMA). A Go-NoGo task was conducted simultaneously with electroencephalography (EEG) at baseline and after intervention completion.\nRESULTS: We found increased theta event-related spectral perturbation (ERSP) and inter-trial phase coherence (ITPC) during Go in the frontal midline electrodes overlying the pre-SMA after active HD-tDCS intervention, but not after sham. We also found increased theta phase coherence during Go between the frontal midline and left posterior regions after active HD-tDCS. A late increase in alpha-theta ERSP was found in the left central region after active HD-tDCS. Notably, lower baseline theta ERSP/ITPC in the frontal midline region predicted more post-intervention improvement in Go performance only in the active group.\nCONCLUSIONS: There are local and interregional oscillatory changes in response to HD-tDCS modulation in chronic TBI.\nSIGNIFICANCE: These findings may guide future research in utilizing EEG time-frequency metrics not only to measure interventional effects, but also in selecting candidates who may optimally respond to treatment.",
                "disciplines": [
                    "3209"
                ]
            }
        }
    },
    "13057618": {
        "title": "The Planetary Child Health Observatory: an interdisciplinary research initiative and web-based dashboard for mapping enteric infectious diseases and their risk factors and interventions in LMICs",
        "abstract": "PROJECT SUMMARY/ABSTRACT Mapping spatiotemporal variation in the burden of infectious diseases is critical for targeting interventions like vaccines and prioritizing at-risk populations, particularly in Low- and Middle-Income Countries (LMICs), where such diseases are most prevalent. While many priority pathogens have been mapped over entire endemic regions, enteric infectious diseases (EIDs) have not, due to a perception that the necessary spatially referenced data on their prevalence and environmental determinants are not available. However, improvements in differential diagnosis of EIDs, geostatistical methods, and accessibility and accuracy of environmental data mean that it is now possible to carry out such a mapping. The long-term goal of this proposal is to provide the research and stakeholder community with an evidence base for the geographical targeting of enteropathogen-specific child health interventions such as novel vaccines. The overall objective is to apply a big data approach to the modeling of EIDs in combination with advanced geostatistical analyses and global earth observation (EO)- derived datasets, resulting in generalizable estimates of the geographical distribution of these outcomes and of their associations with environmental drivers disseminated via an interactive web-based dashboard. The central hypothesis is that the prevalence of many enteropathogens varies spatiotemporally as a function of climatic, environmental, and socio-demographic factors in a way that can be modelled using global EO datasets and similar products. The rationale underlying the proposed research is that it will enable the identification of target populations for interventions. Specifically, building on existing partnerships between epidemiologists, climatologists, and hydrologists as well as investigators in numerous LMICs, Dr. Colston will: 1) compile and maintain a large database of georeferenced results from studies that diagnosed EIDs in children in LMICs; 2) Apply geostatistical models to EID outcome data (aim 1) and spatiotemporally matched, high resolution environmental covariates to a). draw inferences about underlying biological processes and b). generate prediction maps to identify geographical foci of transmission risk. 3) Establish a Planetary Child Health Observatory (PCHO), an interinstitutional initiative consisting of a). an interactive web-based dashboard and b). an international consortium of investigators. In addition to these research activities, Dr. Colston proposes a career development plan that includes mentorship, experiential and peer-to-peer learning, coursework, publications, and presentations with the objectives of: 1) gaining skills and formal training in geostatistical inference, biostatistics, and large datasets; 2) expanding expertise in applications of environmental and remote sensing-derived datasets in health research; 3) transitioning to research independence by securing follow-on R01 funding. His proposal will be supervised by an outstanding, interdisciplinary mentoring team with complementary methodological and substantive skills. The project will have a positive impact on public health by providing data inputs urgently needed for targeting EID interventions to priority populations in LMICs.",
        "disciplines": [
            "4206"
        ],
        "publications": {
            "10.1101/2024.05.23.24307833": {
                "title": "Spatial variation in housing construction material in low- and middle-income countries: a Bayesian spatial prediction model of a key infectious diseases risk factor and social determinant of health",
                "abstract": "Abstract Housing infrastructure and quality is a major determinant of infectious disease risk and other health outcomes in regions of the world where vector borne, waterborne and neglected tropical diseases are endemic. It is important to quantify the geographical distribution of improvements to the major dwelling components to identify and target resources towards populations at risk. The aim of this study was to model the sub-national spatial variation in housing materials using covariates with quasi-global coverage and use the resulting estimates to map the predicted coverage across the world\u2019s low- and middle-income countries (LMICs). Data relating to the materials used in dwelling construction were sourced from nationally representative household surveys conducted since 2005. Materials used for construction of flooring, walls, and roof were reclassified as improved or unimproved. Households lacking location information were georeferenced using a novel methodology, and a suite of environmental and demographic spatial covariates were extracted at those locations for use as model predictors. Integrated nested Laplace approximation (INLA) models were fitted to obtain and map predicted probabilities for each dwelling component. The dataset compiled included information from households in 283,000 clusters from 350 surveys. Low coverage of improved housing was predicted across the Sahel and southern Sahara regions of Africa, much of inland Amazonia, and areas of the Tibetan plateau. Coverage of improved roofs and walls was high in the Central Asia, East Asia and Pacific and Latin America and the Caribbean regions, while improvements in all three components, but most notably floors, was low in Sub-Saharan Africa. Human development was by far the strongest determinant of dwelling component quality, though vegetation greenness and land use were also relevant markers These findings are made available to the reader as files that can be imported into a GIS for integration into relevant analysis to derive improved estimates of preventable health burdens attributed to housing.",
                "disciplines": [
                    "4406"
                ]
            },
            "10.1093/ofid/ofad655": {
                "title": "The Enterics for Global Health (EFGH) Shigella Surveillance Study in Peru",
                "abstract": "Background: The Enterics for Global Health (EFGH) Peru site will enroll subjects in a periurban area of the low Amazon rainforest. The political department of Loreto lags behind most of Peru in access to improved sources of water and sanitation, per capita income, children born <2.5\u2005kg, and infant and child mortality. Chronic undernutrition as manifested by linear growth shortfalls is common, but wasting and acute malnutrition are not.\nMethods: The recruitment of children seeking care for acute diarrheal disease takes place at a geographic cluster of government-based primary care centers in an area where most residents are beneficiaries of free primary healthcare.\nResults: Rates of diarrheal disease, dysentery, and <i>Shigella</i> are known to be high in the region, with some of the highest rates of disease documented in the literature and little evidence in improvement over the last 2 decades. This study will update estimates of shigellosis by measuring the prevalence of <i>Shigella</i> by polymerase chain reaction and culture in children seeking care and deriving population-based estimates by measuring healthcare seeking at the community level.\nConclusions: Immunization has been offered universally against rotavirus in the region since 2009, and in a context where adequate water and sanitation are unlikely to obtain high standards in the near future, control of principal enteropathogens through immunization may be the most feasible way to decrease the high burden of disease in the area in the near future.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1093/ofid/ofae018": {
                "title": "Population Enumeration and Household Utilization Survey Methods in the Enterics for Global Health (EFGH): Shigella Surveillance Study",
                "abstract": "Background: Accurate estimation of diarrhea incidence from facility-based surveillance requires estimating the population at risk and accounting for case patients who do not seek care. The Enterics for Global Health (EFGH) <i>Shigella</i> surveillance study will characterize population denominators and healthcare-seeking behavior proportions to calculate incidence rates of <i>Shigella</i> diarrhea in children aged 6-35 months across 7 sites in Africa, Asia, and Latin America.\nMethods: The Enterics for Global Health (EFGH) <i>Shigella</i> surveillance study will use a hybrid surveillance design, supplementing facility-based surveillance with population-based surveys to estimate population size and the proportion of children with diarrhea brought for care at EFGH health facilities. Continuous data collection over a 24 month period captures seasonality and ensures representative sampling of the population at risk during the period of facility-based enrollments. Study catchment areas are broken into randomized clusters, each sized to be feasibly enumerated by individual field teams.\nConclusions: The methods presented herein aim to minimize the challenges associated with hybrid surveillance, such as poor parity between survey area coverage and facility coverage, population fluctuations, seasonal variability, and adjustments to care-seeking behavior.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1371/journal.pone.0297775": {
                "title": "The Planetary Child Health & Enterics Observatory (Plan-EO): A protocol for an interdisciplinary research initiative and web-based dashboard for mapping enteric infectious diseases and their risk factors and interventions in LMICs",
                "abstract": "BACKGROUND: Diarrhea remains a leading cause of childhood illness throughout the world that is increasing due to climate change and is caused by various species of ecologically sensitive pathogens. The emerging Planetary Health movement emphasizes the interdependence of human health with natural systems, and much of its focus has been on infectious diseases and their interactions with environmental and human processes. Meanwhile, the era of big data has engendered a public appetite for interactive web-based dashboards for infectious diseases. However, enteric infectious diseases have been largely overlooked by these developments.\nMETHODS: The Planetary Child Health & Enterics Observatory (Plan-EO) is a new initiative that builds on existing partnerships between epidemiologists, climatologists, bioinformaticians, and hydrologists as well as investigators in numerous low- and middle-income countries. Its objective is to provide the research and stakeholder community with an evidence base for the geographical targeting of enteropathogen-specific child health interventions such as novel vaccines. The initiative will produce, curate, and disseminate spatial data products relating to the distribution of enteric pathogens and their environmental and sociodemographic determinants.\nDISCUSSION: As climate change accelerates there is an urgent need for etiology-specific estimates of diarrheal disease burden at high spatiotemporal resolution. Plan-EO aims to address key challenges and knowledge gaps by making and disseminating rigorously obtained, generalizable disease burden estimates. Pre-processed environmental and EO-derived spatial data products will be housed, continually updated, and made publicly available for download to the research and stakeholder communities. These can then be used as inputs to identify and target priority populations living in transmission hotspots and for decision-making, scenario-planning, and disease burden projection.\nSTUDY REGISTRATION: PROSPERO protocol #CRD42023384709.",
                "disciplines": [
                    "4206"
                ]
            },
            "10.21203/rs.3.rs-2640564/v3": {
                "title": "The Planetary Child Health & Enterics Observatory (Plan-EO): a protocol for an interdisciplinary research initiative and web-based dashboard for mapping enteric infectious diseases and their risk factors and interventions in LMICs",
                "abstract": "Background: Diarrhea remains a leading cause of childhood illness throughout the world that is increasing due to climate change and is caused by various species of ecologically sensitive pathogens. The emerging Planetary Health movement emphasizes the interdependence of human health with natural systems, and much of its focus has been on infectious diseases and their interactions with environmental and human processes. Meanwhile, the era of big data has engendered a public appetite for interactive web-based dashboards for infectious diseases. However, enteric infectious diseases have been largely overlooked by these developments.\nMethods: The Planetary Child Health and Enterics Observatory (Plan-EO) is a new initiative that builds on existing partnerships between epidemiologists, climatologists, bioinformaticians, and hydrologists as well as investigators in numerous low- and middle-income countries. Its objective is to provide the research and stakeholder community with an evidence base for the geographical targeting of enteropathogen-specific child health interventions such as novel vaccines. The initiative will produce, curate, and disseminate spatial data products relating to the distribution of enteric pathogens and their environmental and sociodemographic determinants.\nDiscussion: As climate change accelerates there is an urgent need for etiology-specific estimates of diarrheal disease burden at high spatiotemporal resolution. Plan-EO aims to address key challenges and knowledge gaps by making rigorously obtained, generalizable disease burden estimates freely available and accessible to the research and stakeholder communities. Pre-processed environmental and EO-derived spatial data products will be housed, continually updated, and made publicly available to the research and stakeholder communities both within the webpage itself and for download. These inputs can then be used to identify and target priority populations living in transmission hotspots and for decision-making, scenario-planning, and disease burden projection.\nStudy registration: PROSPERO protocol #CRD42023384709.",
                "disciplines": [
                    "4206"
                ]
            }
        }
    },
    "13665345": {
        "title": "Addition of micronutrients to urea to reduce losses from ammonia volatilization and increase corn (Zea mays L.)",
        "abstract": "Urea is the most commonly used nitrogen fertilizer to supply nitrogen (N) to plants. However, when applied to the soil surface, it is hydrolyzed by the enzyme urease and lost by volatilization of ammonia (N-NH3), triggering environmental, economic and human health problems. The urease inhibitor N-(n-butyl) thiophosphoric triamide (NBPT) is widely used to reduce losses by N-NH3, but productivity gains are not always observed, since N may not be the limiting factor. On the other hand, micronutrients such as: boron (B), zinc (Zn), nickel (Ni) and molybdenum (Mo) can inhibit the urease enzyme and simultaneously serve as nutrients for plants. The hypothesis of this project is that granulated urea with micronutrients (B, Zn, Ni or Mo) and coated or not with NBPT will enable the production of new nitrogen fertilizers with increased efficiency that present a reduction in losses due to N-NH3 volatilization and an increase in corn productivity (Zea mays L.). The study will be conducted in four stages: i) Omission of nutrients N, B, Zn, Ni and Mo, in the maize plant conducted in nutrient solution; ii) Production and physical-chemical characterization of new nitrogen fertilizers; iii) Determination of N-NH3 volatilization in a controlled environment and iv) Evaluation of productivity and nutritional status of maize plants cultivated in two different soil and climate environments (very clayey soil and sandy soil). In this step, the volatilization of N-NH3 in the field will also be evaluated. The results will make it possible to understand which micronutrient used in urea granulation is more efficient in reducing losses by N-NH3 and increasing corn productivity, in addition to investigating the need to maintain the coating with NBPT in urea granulated with B, Zn, Ni or Mo. It is expected that the fertilizers developed through this study can arouse industry interest for large-scale production and use in agriculture.",
        "disciplines": [
            "3004",
            "3002"
        ],
        "publications": {
            "10.1002/saj2.20688": {
                "title": "Dolomitic lime and silicate in no\u2010till: Nutritional status, soil fertility, and soybean agronomic performance",
                "abstract": "Abstract  Limestone is the most widely used agricultural input for soil acidity correction and calcium (Ca) and magnesium (Mg) fertilization. However, other materials have the potential to fulfill these purposes, such as steel slags, also known as silicates. Silicates have higher solubility than limestone, serving as agents for increase pH in no\u2010till, in addition to being a source of Ca, Mg, and silicon (Si). This study aimed to compare the effects of surface application of dolomitic lime and calcium magnesium silicate on soil chemical properties, soybean [ Glycine max (L.) Merr.] nutritional status, and grain yield under no\u2010till. The experiment was installed in the northwest Paran\u00e1 State, Brazil, on a Rhodic Eutrustox. Lime and silicate rates were applied by broadcasting before the sowing of soybean. Silicate treatment increases soil Ca 2+ , pH, and base saturation up to a depth of 0.10\u00a0m. By contrast, liming effects on soil chemistry were restricted to the 0.05\u00a0m top layer after 24 months of application. The acidity correction and Ca 2+ supply to greater soil depths and the increased leaf Si as a beneficial element provided by silicate treatment contributed to increasing soybean yield in the 2018/2019 and 2019/2020 seasons. Lime application, regardless of the rate, did not improve soybean yield. Waste from the steel industry can be used as acidity correctives and source of Si, Ca, and Mg, improving the agronomic performance of soybean. \nCore Ideas    Silicate is more efficient in maintaining soil fertility compared to lime.   Changes in soil fertility were observed up to a depth of 0.10\u00a0m after 24 months.   Silicate increases silicon content in soybean leaf.   Surface application of silicate increased soybean yield up to 43%.   Soybean yield did not improve with lime.   ",
                "disciplines": [
                    "3002",
                    "3004"
                ]
            },
            "10.1071/sr23164": {
                "title": "Effects of straw mulching, liming, and soil texture on ammonia volatilisation: a study of conventional and enhanced efficiency fertilisers",
                "abstract": "Context In no-tillage agriculture, maintenance of soil cover combined with liming without incorporation increases nitrogen (N) loss via ammonia (NH3) volatilisation, decreasing the efficiency of nitrogen fertilisers. Aims To quantify N losses by NH3 volatilisation from conventional and enhanced efficiency fertilisers applied to a clayey and a sandy loam soil subjected or not to lime (CaCO3) application and straw mulching. Methods Two laboratory experiments were carried out; one using a clayey soil, and the other using a sandy loam soil. Both experiments followed a 4\u00a0\u00d7\u00a02\u00a0\u00d7\u00a02 factorial design with four N sources (urea, urea-NBPT, urea-formaldehyde, and ammonium sulfate), absence and presence of liming, and absence and presence of Brachiaria ruziziensis straw mulching. NH3 volatilisation was measured using closed flasks containing filter paper soaked with sulfuric acid and quantified by titration with sodium hydroxide. Key results NH3 volatilisation was up to 62% of the N applied. Losses due to NH3 volatilisation from both soil types decreased in the following order of treatment: liming\u00a0+\u00a0straw mulching\u00a0>\u00a0straw mulching only\u00a0>\u00a0liming only. Urea-formaldehyde and ammonium sulfate were the most efficient in reducing NH3 emissions. However, when ammonium sulfate was applied to a clayey soil after liming, it resulted in higher NH3 emissions than conventional urea. Conclusions Urea-formaldehyde showed better performance in reducing NH3 losses due to greater stability in the presence of straw or liming. Implications Soils with straw and limestone can lead to large NH3 volatilisation losses if urea conventional is broadcast.",
                "disciplines": [
                    "3002",
                    "3004"
                ]
            }
        }
    },
    "9689088": {
        "title": "Revealing spatiotemporal slow slip evolution at higher temporal resolution by kinematic GNSS",
        "abstract": "We tackled two issues for estimating slow slip events (SSE) with high temporal resolution based on GPS coordinate time-series data (kinematic coordinate values) by kinematic analysis. The first task is to understand the multipath noise characteristics contained in the kinematic coordinate values, and to evaluate and improve the performance of the side-real filter, which is a reduction method (published as Itoh & Aoki 2022). Specifically, we performed kinematic analysis and applied side-real filters in an experimental observation environment that minimized the sources of coordinate value estimation errors other than multipath. showed the belt. We also obtained the minimum noise level of the kinematic GPS coordinates obtained with the standard analysis settings. As a second task, we applied kinematic coordinates to estimate the spatio-temporal evolution process of actual SSE slip (a scientific paper has been submitted and is under review). Specifically, we attempted to detect SSE, which has been reported in previous studies using GPS data (daily coordinates) at 1-day intervals. By reducing various known error sources, the crustal deformation associated with the SSE can be estimated harmoniously using 30-minute kinematic coordinates as well as diurnal coordinates. We estimated the spatiotemporal evolution of the slip by inverse analysis, and found that the estimated slip process was consistent with that estimated from the diurnal coordinates, and it was possible to estimate the SSE even from the kinematic coordinates with a high noise level. rice field. However, the temporal resolution of the obtained slip is comparable to the estimation result from the daily coordinates. This is because the hyperparameters are arbitrarily set so that the estimation results are not affected by non-tectonic noise contained in the kinematic coordinate values. This suggests that a comprehensive understanding of the noise sources is necessary for estimating the time variation of the slip process over a period of less than one day using the kinematic coordinate time series.",
        "disciplines": [
            "4013"
        ],
        "publications": {
            "10.1029/2023gl104852": {
                "title": "Largest Aftershock Nucleation Driven by Afterslip During the 2014 Iquique Sequence",
                "abstract": "Abstract Various earthquake models predict that aseismic slip modulates the seismic rupture process but actual observations of such seismic\u2010aseismic interaction are scarce. We analyze seismic and aseismic processes during the 2014 Iquique earthquake sequence. High\u2010rate Global Positioning System displacements demonstrate that most of the early afterslip is located downdip of the M 8.1 mainshock and is accompanied by decaying aftershock activity. An intriguing secondary afterslip peak is located \u223c120\u00a0km south of the mainshock epicenter. The area of this secondary afterslip peak likely acted as a barrier to the propagating mainshock rupture and delayed the M 7.6 largest aftershock, which occurred 27\u00a0hr later. Interevent seismicity in this secondary afterslip area ended with a M 6.1 near the largest aftershock epicenter, kicking the largest aftershock rupture in the same area. Hence, the interevent afterslip likely promoted the largest aftershock nucleation by destabilizing its source area, favoring a rate\u2010dependent cascade\u2010up model.\nPlain Language Summary Subduction zone faults host both fast (regular earthquakes, seismic) and slow (aseismic) slip. Simulation models predict that slow slip can affect fast slip processes. We explored such an interaction taking place during the 2014 Iquique earthquake offshore northern Chile using observation data of crustal deformation by Global Positioning System and earthquakes. We discovered that the fast mainshock slip was terminated by a slowly slipping fault zone, which prevented the simultaneous occurrence of the largest aftershock. Furthermore, afterslip, one type of slow slip following the mainshock, helped the occurrence of the largest aftershock 27\u00a0hr after the mainshock. Therefore, the sequential occurrence of large earthquakes can be controlled by slowly slipping faults.\nKey Points    Global Positioning System captured crustal deformation during 27\u00a0hr between the 2014 Iquique mainshock and its largest aftershock   The mainshock and the largest aftershock areas are separated by an aseismic area, likely preventing both from rupturing as a single event   The largest aftershock nucleation is a mixture of seismicity and decelerating afterslip, favoring a rate\u2010dependent cascade\u2010up model   ",
                "disciplines": [
                    "3705",
                    "3706"
                ]
            },
            "10.1038/s41598-022-10957-8": {
                "title": "Imaging evolution of Cascadia slow-slip event using high-rate GPS",
                "abstract": "The slip history of short-term slow slip event (SSE) is typically inferred from daily Global Positioning System (GPS) data, which, however, cannot image the sub-daily processes, leaving the underlying mechanisms of SSEs elusive. To address the temporal resolution issue, we attempted to employ the kinematic subdaily GPS analysis, which has never been applied to SSE studies because its signal-to-noise ratio has been believed too low. By carefully post-processing sub-daily positions to remove non-tectonic position fluctuation, our 30-min kinematic data clearly exhibits the transient motion of a few mm during one Cascadia SSE. A spatiotemporal slip image by inverting the 30-min data exhibits a multi-stage evolution; it consists of an isotropic growth of SSE followed by an along-strike migration and termination within the rheologically controlled down-dip width. This transition at the slip growth mode is similar to the rupture growth of regular earthquakes, implying the presence of common mechanical factors behind the two distinct slip phenomena. The comparison with a slip inversion of the daily GPS demonstrates the current performance and limitation of the subdaily data in the SSE detection and imaging. Better understanding of the non-tectonic noise in the kinematic GPS analysis will further improve the temporal resolution of SSE.",
                "disciplines": [
                    "3706"
                ]
            },
            "10.1186/s40623-022-01584-8": {
                "title": "On the performance of position-domain sidereal filter for 30-s kinematic GPS to mitigate multipath errors",
                "abstract": "The noise level of kinematic Global Positioning System (GPS) coordinates is much higher than static daily coordinates. Therefore, it needs to be improved to capture details of small sub-daily tectonic deformation. Multipath is one of the dominant error sources of kinematic GPS, which the sidereal filter can mitigate. With increasing interest in applying kinematic GPS to early postseismic deformation studies, we investigate the characteristics of multipath errors and the performance of the position-domain sidereal filter using 30-s kinematic coordinates with a length of nearly 5\u00a0days. Experiments using three very short baselines mostly free from atmospheric disturbances show that multipath signature in position-domain has better repeatability at longer periods, and sidereal filtering without low-pass filtering yields a lift of power spectral density (PSD) at periods shorter than 200\u00a0s. These results recommend an empirical practice of low-pass filtering to a sidereal filter. However, a moderate cut-off period maximizes the performance of the sidereal filter because of the smaller multipath signature at longer periods. The amplitude of post-sidereal-filtered fluctuation is less than 6\u00a0mm in standard deviation, which demonstrates the nearly lowest noise level of kinematic GPS used for postseismic and other tectonic deformation studies. Our sidereal filter is proven to mitigate several peaks of power spectral density at periods up to 100,000\u00a0s, but the period dependency of PSD is not fully alleviated by sidereal filtering, which needs future investigation.Graphical Abstract",
                "disciplines": [
                    "3701"
                ]
            }
        }
    },
    "13017694": {
        "title": "Model and reality of radial root water transport \u2013 EAUDISSECT",
        "abstract": "Water uptake by the roots of land plants is a key process for plant survival (and, indirectly, for our survival as well). In the actual context of climate change, water scarcity and water usage conflicts put pressure on farming conditions. A better understanding of water transport from outside of the plants to the inside and all throughout their tissues is likely to bring groundbreaking inputs for fundamental and applied research related to how plants work and adapt. The first step of this transport is called \u201cradial water transport\u201d, during which water flows from the substrate through the various tissues of the root, and into the xylem vessels, which are conductive tissues that will export this water to the rest of the body.From a research perspective radial water transport has been considered alternatively as a biological process or as a physical process. Each approach lacks insights from the other. Our project lies at the interface between both, and will try to establish new links between mathematical modeling and in vivo situations.The objectives of Eaudissect are to:1. Establish a model of radial water transport of a new type2. Improve our capacity to measure hydraulic properties of all tissues crossed by water in the root during the uptake3. Establish methods to validate the predictions of the mathematical model",
        "disciplines": [
            "3108"
        ],
        "publications": {
            "10.1111/nph.19336": {
                "title": "Do roots need a good haircut for water uptake?",
                "abstract": " This article is a Commentary on  Duddek et\u00a0al .\u00a0(2023), 240 : 2484\u20132497  . ",
                "disciplines": [
                    "4101",
                    "4102",
                    "3108"
                ]
            }
        }
    },
    "13057313": {
        "title": "Examining Potential Causal Connections and Mechanisms between Children's Block Play and Mathematics Learning",
        "abstract": "The purpose of this project is to further develop, refine, and evaluate a research-based STEM learning tool (i.e. block play) that tests theories of mathematical learning. Block play is common in preschool settings and is a context in which mathematics skill development may occur. Although a growing body of work has linked block play to mathematical development, there remains little causal evidence to support these relationships. The first objective of the project is to empirically evaluate the impacts of different types of block play on children\u2019s mathematics. The second objective is to evaluate the extent to which children\u2019s mathematical language (spatial and quantitative), spatial skills, and executive function are mechanisms that link block play with children\u2019s mathematical learning. Results from this study will contribute to the theoretical understanding of how and why block play may influence the development of early mathematics, a key component of STEM and school readiness. Finally, this study will advance the research base about low-cost, feasible, and effective strategies for improving childrens\u2019 mathematics learning. To meet the goals of this project, the project team will conduct a randomized controlled trial in which children from low-income backgrounds will be randomly assigned to one of three conditions: unstructured block play, semi-structured block play, or a business-as-usual control group. The block play sessions will be conducted with small groups of children and will be video recorded. It is hypothesized that children who participate in either of the block play conditions will demonstrate greater gains in mathematics compared to children in the business-as-usual condition. Further, it is expected that children in the semi-structured block play condition will experience greater gains in mathematics relative to children in the unstructured condition. The team will also test the extent to which mathematical language ability, spatial ability, and executive function are potential mechanisms that may underlie the association between block play and mathematics. It is hypothesized that gains in mathematical language and spatial skills will mediate the links between both intervention conditions and gains in mathematical learning. However, it is possible that executive function will only be a mechanism between the semi-structured block play condition and mathematics. The project will integrate research findings into classroom instruction, engage in-service teachers in intervention development, provide an early mathematics teacher training, and make all intervention materials publicly available. This project is supported by the EHR Core Research (ECR) program, which supports work that advances fundamental research on STEM learning and learning environments, broadening participation in STEM, and STEM workforce development, with co-funding by the Discovery Research PreK-12 (DRK-12) program. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3903"
        ],
        "publications": {
            "10.3389/fpsyg.2022.1014713": {
                "title": "Moving beyond dosage and adherence: A protocol for capturing dimensions of active child engagement as a measure of fidelity for social-emotional learning interventions",
                "abstract": "Social-emotional competencies are important for school-readiness and can be supported through social-emotional learning (SEL) interventions in the preschool years. However, past research has demonstrated mixed efficacy of early SEL interventions across varied samples, highlighting a need to unpack the black box of which early interventions work, under what conditions, and for whom. In the present article we discuss the critical implementation component of active child engagement in an intervention as a potential point of disconnect between the intervention as designed and as implemented. Children who are physically present but unengaged during an intervention may lead to decreased average impacts of an intervention. Furthermore, measuring young children's active engagement with an intervention may help to guide iterative intervention development. We propose a four-step protocol for capturing the multi-dimensional and varied construct of active child engagement in a SEL intervention. To illustrate the utility of the protocol, we apply it to data from a pilot study of a researcher-implemented, semi-structured block play intervention focused on supporting the development of SEL and math skills in preschoolers. We then present future directions for the integration of active participant engagement into the measurement of implementation of SEL interventions for young children.",
                "disciplines": []
            }
        }
    },
    "13037317": {
        "title": "Accelerating biomarker development through novel statistical methods for analyzing phase III/IV studies",
        "abstract": "Project Summary/Abstract The multitude of candidate cancer biomarkers being discovered across various laboratories hold great potential to enhance the practice of precision medicine. However, it is a long and challenging process \u2013 often culminating in failure \u2013 to rigorously develop and validate these biomarkers before they can be used in clinical practice. In particular, phase III, IV, and V biomarker validation studies are expensive and time- consuming to conduct; it is essential to carefully design and analyze these studies and to make the most ef\ufb01cient use of the specimens collected. Motivated by our collaborative work on biomarker development for cancer early detection, this proposal seeks to develop cutting-edge statistical tools for analyzing phase III and IV biomarker studies in order to accelerate the biomarker development process. The methods proposed in Aim 1 target the selection of primary endpoints and inference procedures to accommodate potential overdiagnosis when assessing screening ef\ufb01cacy in phase IV trials. The methods proposed in Aim 2 enable the combination of phase IV samples with phase III samples in phase III biomarker development. The methods proposed in Aim 3 integrate information from heterogeneous study cohorts (which differ in screening modalities and eligibility criteria) when estimating design parameters for biomarker clinical utility trials. Our statistical methods will have immediate applications to analysis of data from two cancer applica- tions: i) the New Onset Diabetes (NOD) Cohort study and the Early Detection Initiative (EDI) study for pancreatic cancer early detection, and ii) \ufb01ve low-dose CT (LDCT) screening cohorts and the Prostate, Lung, Colorectal, and Ovarian Cancer Screening (PLCO) trial for lung cancer screening. Moreover, the developed methodology will have broader application in other phase III and IV cancer biomarker studies and will be valuable for advancing the NCI Early Detection Research Network (EDRN)'s current priority in designing biomarker clinical utility trials. All statistical programs and algorithms developed in this proposal will be made freely available to the public.",
        "disciplines": [
            "4905"
        ],
        "publications": {
            "10.3390/v15102029": {
                "title": "Stochastic Interventional Vaccine Efficacy and Principal Surrogate Analyses of Antibody Markers as Correlates of Protection against Symptomatic COVID-19 in the COVE mRNA-1273 Trial",
                "abstract": "The COVE trial randomized participants to receive two doses of mRNA-1273 vaccine or placebo on Days 1 and 29 (D1, D29). Anti-SARS-CoV-2 Spike IgG binding antibodies (bAbs), anti-receptor binding domain IgG bAbs, 50% inhibitory dilution neutralizing antibody (nAb) titers, and 80% inhibitory dilution nAb titers were measured at D29 and D57. We assessed these markers as correlates of protection (CoPs) against COVID-19 using stochastic interventional vaccine efficacy (SVE) analysis and principal surrogate (PS) analysis, frameworks not used in our previous COVE immune correlates analyses. By SVE analysis, hypothetical shifts of the D57 Spike IgG distribution from a geometric mean concentration (GMC) of 2737 binding antibody units (BAU)/mL (estimated vaccine efficacy (VE): 92.9% (95% CI: 91.7%, 93.9%)) to 274 BAU/mL or to 27,368 BAU/mL resulted in an overall estimated VE of 84.2% (79.0%, 88.1%) and 97.6% (97.4%, 97.7%), respectively. By binary marker PS analysis of Low and High subgroups (cut-point: 2094 BAU/mL), the ignorance interval (IGI) and estimated uncertainty interval (EUI) for VE were [85%, 90%] and (78%, 93%) for Low compared to [95%, 96%] and (92%, 97%) for High. By continuous marker PS analysis, the IGI and 95% EUI for VE at the 2.5th percentile (519.4 BAU/mL) vs. at the 97.5th percentile (9262.9 BAU/mL) of D57 Spike IgG concentration were [92.6%, 93.4%] and (89.2%, 95.7%) vs. [94.3%, 94.6%] and (89.7%, 97.0%). Results were similar for other D29 and D57 markers. Thus, the SVE and PS analyses additionally support all four markers at both time points as CoPs.",
                "disciplines": [
                    "3107"
                ]
            },
            "10.3389/fnut.2023.1215768": {
                "title": "Regression calibration utilizing biomarkers developed from high-dimensional metabolites",
                "abstract": "Addressing systematic measurement errors in self-reported data is a critical challenge in association studies of dietary intake and chronic disease risk. The regression calibration method has been utilized for error correction when an objectively measured biomarker is available; however, biomarkers for only a few dietary components have been developed. This paper proposes to use high-dimensional objective measurements to construct biomarkers for many more dietary components and to estimate the diet disease associations. It also discusses the challenges in variance estimation in high-dimensional regression methods and presents a variety of techniques to address this issue, including cross-validation, degrees-of-freedom corrected estimators, and refitted cross-validation (RCV). Extensive simulation is performed to study the finite sample performance of the proposed estimators. The proposed method is applied to the Women's Health Initiative cohort data to examine the associations between the sodium/potassium intake ratio and the total cardiovascular disease.",
                "disciplines": [
                    "3210"
                ]
            }
        }
    },
    "13026804": {
        "title": "Investigating the recruitment and retention of ethnic minority teachers, and its relationship to school outcomes",
        "abstract": "England has the most ethnically diverse population in the United Kingdom, and the schools are no different. While it is estimated that 31% of the student population is from ethnic minority background, the majority of school leaders (93%), teachers and teaching assistants (86%), and other staff (87%) are White British by ethnic background. Addressing this mismatch between the teacher workforce and student populations matters for several reasons:\n\nIt can help address the low attainment of ethnic minority pupils, and second to create a more inclusive and diverse school community that reflects the wider society. In national exams, such as the GCSE in England, the lowest attaining pupils are the Gypsy/Roma and Irish travellers, followed by those from Black Carribbean background (DfE 2021). International evidence suggests that exposure to teachers from a similar race/ethnicity provides minority ethnic students with a role model that can help raise their aspiration and close the achievement gap. There is also evidence that increasing the proportion of minority teachers in schools also leads to increased representation of ethnic minority students in gifted programmes, reduced exclusion and lower drop-out rates. \n\nMinority ethnic teachers bring different perspectives and life experiences, exposing our children to cultural diversity, which reflects the languages, cultures and ethnic background of the local community and society at large. To foster a diverse and inclusive society, it is imperative that staff of ethnic minority heritage should be represented across our schools, regardless of the demography of the school population, as this brings a rich cultural diversity to the school community, and fosters better understanding and tolerance among different groups of children. \n\nThere is currently no robust comprehensive research into understanding how we could raise the number of ethnic minority teachers in schools. Previous research tended to be small-scale or based on case studies, which are reliant on the evidence of a self-selected group of individuals. Such findings can be biased as they are based on the voices of volunteers. This new study will:\n1. Map the demographic trends of recruitment and retention of minority ethnic teachers and pupils in England (for which good quality data is available) over the past 10 years. This will give us a clearer picture of the growth of minority ethnic student population vis-a-vis that of teaching staff\n2. Establish the relationship between the ethnic composition of the teaching staff and the attainment of ethnic minority pupils at KS2 and KS4,\n3. Examine the factors that influence the supply and attrition of ethnic minority teachers from international research that is relevant to England\n4. Identify the barriers to recruiting and retaining ethnic minority teachers in schools in England\n5. Identify those factors that facilitate the recruitment and retention of ethnic minority teachers in schools in England\n6. Determine promising approaches from international evidence to attracting and recruiting ethnic minority teachers, relevant to England\n7. Make recommendations for policy and practice on best practice and effective programmes to adopt\nThe study will analyse official government data from the School Workforce Census. UCAS and the NPD. It will systematically review and synthesise international evidence on effective measures to attract and retain teachers. It will also conduct a nationwide survey on barriers and facilitators faced by schools in recruiting and retaining teachers. This will be supplemented by in-depth case studies of schools that have been known to be effective in recruiting and retaining ethnic minority staff.\n\nThe research themes together will provide a more complete and holistic understanding of the issue relating to the supply and retention of ethnic minority teachers in England.",
        "disciplines": [
            "3904",
            "3901",
            "3902"
        ],
        "publications": {
            "10.3390/educsci13080838": {
                "title": "The Ethnic Proportionality of Teachers and Students and the Link to School-Level Outcomes",
                "abstract": "In England, there are proportionately more White British teachers than White British pupils, and so there is a mismatch between the proportion of teachers and pupils of each ethnic minority group. This mismatch may reduce the number of appropriate role models for some pupils and has been linked to differences in school processes and the behaviour and treatment of ethnic minority pupils. The evidence is weaker regarding any link between ethnic disproportionality and attainment. This paper uses school-level school workforce and pupil attainment data to assess this link. The results are presented as correlations between teacher/pupil characteristics and attainment scores at ages 11 and 16 and as regression models predicting attainment scores using teacher/pupil characteristics. There is no evidence here that ethnic (dis)proportionality is linked to discernible differences in pupil attainment once relative poverty is taken into account. However, as the data are linked at the school level rather than the individual level, we cannot separate the attainment of pupils of different ethnic origins, and the ethnic classification for teachers is simply binary. We are working to overcome these data limitations and hope to present future analyses based on individual data with more detailed ethnic groupings to provide a more definitive result.",
                "disciplines": [
                    "3901"
                ]
            },
            "10.12688/routledgeopenres.17798.2": {
                "title": "The disproportionality of ethnic minority teachers in England: trends, patterns, and problems",
                "abstract": "  Abstract    Background: England has an ethnically diverse population; reflected in the teacher workforce, and the student body in schools. However, it is not clear that these figures are in proportion to each other. This paper examines the ethnic profile of students and their teachers and considers their geographical distribution.   Methods : This paper uses existing aggregated official publicly available datasets to describe the patterns and trends in the proportion of ethnic minority teachers compared to ethnic minority pupils in England 2015-2021. Data comes from the Department for Education (DfE), the University and Colleges Admissions Service (UCAS), the Organisation for Economic Co-operation and development (OECD/TALIS), and the Office for National Statistics (ONS).   Results : \u00a0We found that there are proportionately more White British teachers than in the student intakes to schools. This disproportion (where there are more White British teachers among teachers than there are White British pupils among pupils) is worse for promoted school leaders like deputies and headteachers than it is for classroom teachers. In London, due to the exceptional number of ethnic minority students, the disproportion (or mismatch) is worse in London than anywhere else. Areas with the fewest ethnic minority pupils (and teachers), like the North East, have the most proportionate workforce (in this limited sense).   Conclusions: A student lacking any teachers of the same ethnic group might be treated differently at school, and there is some evidence that this might affect their attainment outcomes. The lack of ethnic diversity in some schools and areas, regardless of proportions, may impoverish the diversity of the whole school system. Several possible reasons for these patterns are noted in the paper, but it is clear that ethnic minority applicants to teacher training are less likely to be accepted, and less likely to obtain qualified teacher status or an eventual teaching post. ",
                "disciplines": [
                    "3901",
                    "3902",
                    "3903"
                ]
            },
            "10.12688/routledgeopenres.17798.1": {
                "title": "The disproportionality of ethnic minority teachers in England: trends, patterns, and problems",
                "abstract": "\n                    Background:\n                    England has an ethnically diverse population; reflected in the teacher workforce, and the student body in schools. However, it is not clear that these figures are in proportion to each other. This paper examines the ethnic profile of students and their teachers and considers their geographical distribution.\n                  \n                  \n                  \n                    Methods\n                    : This paper uses existing aggregated official publicly available datasets to describe the patterns and trends in the proportion of ethnic minority teachers compared to ethnic minority pupils in England 2015-2021. Data comes from the Department for Education (DfE), the University and Colleges Admissions Service (UCAS), the Organisation for Economic Co-operation and development (OECD/TALIS), and the Office for National Statistics (ONS).\n                  \n                  \n                  \n                    Results\n                    : Compared to the student intakes to schools, we found that there are more White British teachers than expected. This disproportion (where there are more White British teachers among teachers than there are White British pupils among pupils) is worse for promoted school leaders like deputies and headteachers than it is for classroom teachers. In London, due to the exceptional number of ethnic minority students, the disproportion (or mismatch) is worse in London than anywhere else. Areas with the fewest ethnic minority pupils (and teachers), like the North East, have the most proportionate workforce (in this limited sense).\n                  \n                  \n                  \n                    Conclusions:\n                    A student lacking any teachers of the same ethnic group might be treated differently at school, and there is some evidence that this might affect their attainment outcomes. The lack of ethnic diversity in some schools and areas, regardless of proportions, may impoverish the diversity of the whole school system. Several possible reasons for these patterns are noted in the paper, but it is clear that ethnic minority applicants to teacher training are less likely to be accepted, and less likely to obtain qualified teacher status or an eventual teaching post.\n                  ",
                "disciplines": [
                    "3901",
                    "3902",
                    "3903"
                ]
            }
        }
    },
    "12929255": {
        "title": "Collaborative Research: Advancing Bayesian Thinking in STEM",
        "abstract": "This project aims to serve the national interest by improving statistics instruction through a focus on increasing access to Bayesian methods. Dealing with the complexity of uncertainty is an important part of the scientific process. Like scientists, STEM students need to derive rigorous conclusions from data in their science practice. This project is based upon the premise that wider inclusion of Bayesian methods in STEM curricula can help students understand scientific uncertainty. To support the wider use of these methods, the project plans to build a community of STEM educators who can transform their courses by introducing new instructional materials for Bayesian methods. The project team intends to develop and offer a professional development program for STEM instructors from other institutions that focuses on the use and teaching of Bayesian methods. In addition, teams of instructors will be mentored by the project team in the development of instructional materials. The project will disseminate the instructional materials and project results to the science education community through social media, journal publications, and conference presentations. This goal of this project is to make Bayesian methods as accessible as possible at the undergraduate level through a cross-disciplinary curricular instructor capacity-building program for different STEM fields. Through recruitment of a diverse body of STEM instructors, the project will: 1) Increase the number of undergraduate students who understand Bayesian methods; 2) Enhance the capacity of STEM instructors in Bayesian methods through training and community building; 3) Develop and enrich teaching and learning materials that showcase the use of Bayesian methods in STEM fields. To achieve these objectives, the three collaborating institutions, University of California Irvine, Vassar College, and Duke University, will offer a week-long instructor summer training boot camp. By the end of the boot camp, it is expected that instructor participants will be comfortable using Bayesian methods in answering scientific questions, using appropriate software for teaching Bayesian methods, and designing classroom activities and assessments that support the learning of Bayesian methods. Selected instructors from the boot camp will be mentored by the project team in the development of Bayesian teaching and learning materials, specifically using scientific data from their fields. Using surveys and learning assessments, the project will assess the effectiveness of the summer boot camp. The NSF IUSE: EHR Program supports research and development projects to improve the effectiveness of STEM education for all students. Through the Engaged Student Learning track, the program supports the creation, exploration, and implementation of promising practices and tools. This project is also supported by the NSF IUSE:HSI program, which has the goals of enhancing the quality of undergraduate STEM education, and increasing the recruitment, retention, and graduation rates of students pursuing associate\u2019s or baccalaureate degrees in STEM. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3901"
        ],
        "publications": {
            "10.1080/00031305.2023.2232006": {
                "title": "Introducing Variational Inference in Statistics and Data Science Curriculum",
                "abstract": "Probabilistic models such as logistic regression, Bayesian classification, neural networks, and models for natural language processing, are increasingly more present in both undergraduate and graduate statistics and data science curricula due to their wide range of applications. In this article, we present a one-week course module for students in advanced undergraduate and applied graduate courses on variational inference, a popular optimization-based approach for approximate inference with probabilistic models. Our proposed module is guided by active learning principles: In addition to lecture materials on variational inference, we provide an accompanying class activity, an R shiny app, and guided labs based on real data applications of logistic regression and clustering documents using Latent Dirichlet Allocation with R code. The main goal of our module is to expose students to a method that facilitates statistical modeling and inference with large datasets. Using our proposed module as a foundation, instructors can adopt and adapt it to introduce more realistic case studies and applications in data science, Bayesian statistics, multivariate analysis, and statistical machine learning courses.",
                "disciplines": [
                    "4905"
                ]
            }
        }
    },
    "9852650": {
        "title": "Technology, sustainability, and social equity through Science Fiction",
        "abstract": "This project aims to investigate how youth create science fictions in order to think critically and innovatively about issues related to sustainability, technology, and social equity. The project expects to foster youth voice in mining communities and metropolitan communities in three commonwealth countries (Australia, Canada, and Wales) in collaboration with teachers and experts in the fields of English, arts, and STEM. Expected outcomes include promoting youth wellbeing and creativity and pedagogical collaboration across the arts and STEM to generate co-designed creative solutions for technological, environmental, and social equity futures.",
        "disciplines": [
            "3602"
        ],
        "publications": {
            "10.1080/0969725x.2023.2270357": {
                "title": "Cosmic Beavers",
                "abstract": "In this article, the authors introduce the concept of a \u201cqueer counter-mythology.\u201d They do so by discussing a speculative song they wrote as an enactment of research-creation. Research-creation names an interdisciplinary scholarly praxis where artist-scholars create the artefacts they want to think-with, rather than analysing existing cultural productions. The song discussed in this article, \u201cCosmic Beavers,\u201d proposes a queer counter-mythology that reimagines the historical, colonial archive by foregrounding the stories of giant, trans-dimensional beavers who shred Lewis and Clark and use them to reinforce their Time-Dam. Drawing on this song, as well as queer theories of time and anti-colonial thinkers, the authors suggest that artistic interventions invoke speculative lures that, while not changing history, can complicate state-sanctioned archives and narratives of the past and future: they frame this intervention as a queer counter-mythology.",
                "disciplines": [
                    "4702",
                    "4705",
                    "5003"
                ]
            },
            "10.1177/00345237231183343": {
                "title": "Colonial crises of imagination, climate fictions, and English literary education",
                "abstract": "This paper argues that the contemporary climate crises we see around our planet correlate with a colonial crisis of (literary) imagination. The author engages with Caribbean literary scholar Sylvia Wynter and other anti-colonial scholars to trace how the colonial literary imagination is rooted in the euro-western humanism and racial capitalism that governs the west, the stories and literary forms that frame it, and whose logics continue to be rehearsed across the disciplines\u2014particularly in English literatures taught in school. The paper then argues that to understand the histories of this crisis of imagination and its link to climate crises, and perhaps paradoxically access literature\u2019s speculative potential to imagine different climate futures, literary educators and scholars need to prioritize literatures and literary critiques that are embedded in a different relationship to the imagination and ecology.",
                "disciplines": [
                    "3902"
                ]
            }
        }
    },
    "13017727": {
        "title": "Towards a complete CO2 hydrate slurry-based cooling application \u2013 COOLHYD",
        "abstract": "With a cost equivalent to 20% of global electricity consumption, and highly regulated refrigerants, the refrigeration industry must face several challenges of sustainable development while ensuring its fundamental role for various sectors (food, air conditioning\u2026). The use of phase change material (PCM) slurries in secondary refrigeration is a solution to reduce the amount of refrigerants and improve energy performances. These PCM suspensions can indeed store and convey large quantities of cold by latent heat, an asset for the design and efficiency of installations. CO2 hydrates are high potential PCMs: they have the best latent heat among all PCMs in refrigeration and are stable over a wide range of temperature; they can be produced by gas injection, avoiding energetically penalizing scraping processes; finally, they are green materials because they are made up of water and CO2. A secondary refrigeration system is based on 3 main stages: generation, transport and use (cold restitution). Thus, slurries must meet various constraints related to these stages to ensure good process continuity. In particular, controlling the kinetics of hydrate crystallization and slurry flow conditions, with suitable crystal size distribution (CSD), is still a major stake. By associating three internationally recognized laboratories in complementary fields, Hydrates/Cooling (FRISE), Fluid Mechanics (IMFT) and Process Engineering (LGPM), and relying on different experimental approaches (hydrate slurry pilot system, rheology of cohesive synthetic suspensions, controlled heat flow tubes) and modeling (mass/thermal balance, population balance, rheological models, global dynamic simulation model), the overall objective of the COOLHYD project is to propose a fundamental and systematic approach to address the kinetic, rheology and continuity issues involved in the application of CO2 hydrate slurry-based cooling. We will focus on: understanding the impact of slurry generation conditions on critical properties for the process (CSD, suspended solid fraction, flow regimes); developing models linking these critical properties to rheological (for slurry transport) and thermal (for slurry use) properties; optimizing the energy performance of the overall process, as a function of device architecture and control variables related to generation, transport, and use conditions, in order to provide recommendations for the design of an efficient secondary refrigeration system.",
        "disciplines": [
            "3302"
        ],
        "publications": {
            "10.1016/j.ijheatmasstransfer.2023.124665": {
                "title": "Experimental monitoring of CO2 hydrate slurry crystallization by heat flux rate determination in a jacketed reactor",
                "abstract": "CO2 hydrate slurries are promising phase change materials for secondary refrigeration applications. However, the difficulty of experimentally evaluating the crystallization kinetic of slurries limits their industrial use. Hydrate crystallization kinetics monitoring performs traditionally by a reactor mass balance. However, this method requires assumptions on CO2 liquid phase concentration and the hydration number. This work outlines the development of a specific method to determine kinetics thanks to the direct measure of heat flow through the reactor jacket and its evaluation compared with the mass balance method. The results of each method are then obtained by testing the two kinetic parameters of stirring speed and propeller type. The final hydrate mass fractions obtained with both methods are in good agreement, but the kinetic obtained by the mass balance method is faster than by the heat balance method.",
                "disciplines": [
                    "4004"
                ]
            }
        }
    },
    "13016969": {
        "title": "Skeletal Reorganization of Bicyclic Cyclopropanes \u2013 Skelet_CyProp",
        "abstract": "The aim of Skelet_CyProp project is to exploit an unusual bicyclic cyclopropane skeletal reorganization by combining organocatalysis and superacid activation. Aspiring to reach structural diversity by exploring novel modes of cyclopropane ring-expansion, the objective is through an intertwined experimental-NMR-DFT study, to control stereochemical issues and access complex original molecules from easily accessible precursors.",
        "disciplines": [
            "3407"
        ],
        "publications": {
            "10.1039/d3qm01106b": {
                "title": "Influence of the pendant substituent at the C1 position of a spirobifluorene scaffold on the electronic properties",
                "abstract": "The present work reports the synthesis and the study of a series of organic semi-conductors constructed on an emerging molecular fragment, namely the C1-substituted SBF.\n 1-Substituted fluorenes have emerged in recent years as being among the most efficient functional materials for phosphorescence and thermally activated delayed fluorescence OLEDs. The position C1 of the fluorene is indeed highly interesting to design functional materials with specific properties. This scaffold displays two main characteristics. First, there is a strong \u03c0-conjugation disruption between the pendant substituent attached at C1 and the substituted fluorene. Second, the specific geometry of the C1-fluorene allows through-space interactions between the substituent attached at C1 and the cofacial building unit attached at C9. However, to date, this family of organic-semi-conductors has not been intensively studied yet. In this work, we report the synthesis and the structural, electrochemical and photophysical properties of four 1-substituted spirobifluorene derivatives, constructed with widely known extended \u03c0-conjugated systems: naphthalene, anthracene, phenanthrene and pyrene at the C1 position of spirobifluorene. Using a structure\u2013property relationship approach, we show how the nature of the substituent grafted at C1 significantly modifies the electronic properties (HOMO/LUMO energy levels, triplet state energy levels, etc .). As 1-substituted spirobifluorenes are undoubtedly very promising organic semi-conductors, such a study provides fundamental knowledge to construct future efficient organic materials for specific applications. ",
                "disciplines": [
                    "3403",
                    "3405"
                ]
            }
        }
    },
    "13664814": {
        "title": "Control of Flat Parallel Manipulators with Flexible Links: a Free Approach to Dynamic Models",
        "abstract": "Parallel manipulators can have higher velocity/acceleration ratios and energy efficiency when compared to serial manipulators. Additionally, reducing the inertia of your moving components can further improve this performance. However, this design alternative can generate vibrations that require the implementation of new control strategies in joint and task space. While the former involves accurate models, the latter may require adequate computer vision and image processing equipment. These requirements pose important challenges in the area. In this research project, two control strategies that do not require prior knowledge of the dynamic model are proposed and investigated using a 3RRR with flexible links. The first strategy presents a single control loop: a servo-visual control based on the effector's posture. The second strategy is composed of two control loops: a servo-visual control based on the posture of the effector and another that uses data acquired by extensometers installed in the flexible links. The loop that uses the deformation of the links as a feedback signal will be elaborated with the sliding mode control strategy. Contributions to understanding the role of flexibility in robotic applications are expected.",
        "disciplines": [
            "4007",
            "4010"
        ],
        "publications": {
            "10.1016/j.mechmachtheory.2023.105508": {
                "title": "Hybrid vision/strain-based control strategy for a parallel manipulator with flexible links",
                "abstract": "Parallel manipulators may present higher speed/acceleration ratios and energy efficiency when compared with serial manipulators. In addition, reducing their components\u2019 inertia can further improve performance. However, this design alternative might yield vibrations requiring novel joint and task space control strategies. While the former involves precise models, the latter might require adequate computation vision schemes. These requirements impose critical challenges. This manuscript proposes a hybrid control strategy and experimentally investigates using a 3RRR prototype with flexible links. This hybrid strategy comprises two control loops: position-based visual servo and strain-based feedback control schemes. The strain-based loop uses a sliding mode control and the time derivative of the signals obtained by strain gauges installed in the flexible links. Compared with the position-based visual servo scheme, the hybrid strategy can considerably attenuate the vibrations since the approach reduced the overshoot response by 36% and the maximum value of the Euclidean error on position by 38%, on average.",
                "disciplines": [
                    "4007",
                    "4010"
                ]
            }
        }
    },
    "13300875": {
        "title": "Reducing the burden of respiratory distress after caesarean delivery.",
        "abstract": "Compared with vaginally born babies, babies born at term by caesarean section have a higher risk of needing intensive care due to breathing problems soon after birth. We have recently made a major break-through in understanding why and this project will provide the additional information required to identify effective treatments for these otherwise healthy newborns. Ultimately this research will identify approaches and treatments that will reduce the risk or severity of this breathing problem.",
        "disciplines": [
            "3215",
            "4204",
            "3213"
        ],
        "publications": {
            "10.1016/j.scib.2024.02.010": {
                "title": "The arrival time and energy of FRBs traverse the time-energy bivariate space like a Brownian motion",
                "abstract": "The origin of fast radio bursts (FRBs), the brightest cosmic explosion in radio bands, remains unknown. We introduce here a novel method for a comprehensive analysis of active FRBs' behaviors in the time-energy domain. Using \"Pincus Index\" and \"Maximum Lyapunov Exponent\", we were able to quantify the randomness and chaoticity, respectively, of the bursting events and put FRBs in the context of common transient physical phenomena, such as pulsar, earthquakes, and solar flares. In the bivariate time-energy domain, repeated FRB bursts' behaviors deviate significantly (more random, less chaotic) from pulsars, earthquakes, and solar flares. The waiting times between FRB bursts and the corresponding energy changes exhibit no correlation and remain unpredictable, suggesting that the emission of FRBs does not exhibit the time and energy clustering observed in seismic events. The pronounced stochasticity may arise from a singular source with high entropy or the combination of diverse emission mechanisms/sites. Consequently, our methodology serves as a pragmatic tool for illustrating the congruities and distinctions among diverse physical processes.",
                "disciplines": [
                    "5101"
                ]
            },
            "10.1088/1674-4527/ace179": {
                "title": "Reciprocating Magnetic Fields in the Pulsar Wind Observed from the Black Widow Pulsar J1720-0534",
                "abstract": "We report the radio observations of the eclipsing black widow pulsar J1720\u22120534, a 3.26 ms pulsar in orbit with a low mass companion of mass 0.029 to 0.034 M \u2299. We obtain the phase-connected timing ephemeris and polarization profile of this millisecond pulsar (MSP) using the Five-hundred-meter Aperture Spherical radio Telescope (FAST), the Green Bank Telescope (GBT), and the Parkes Telescope. For the first time from such a system, an oscillatory polarization angle change was observed from a particular eclipse egress with partial depolarization, indicating 10-milliGauss-level reciprocating magnetic fields oscillating in a length scale of 5 \u00d7 103 km (assuming an orbital inclination angle of 90\u00b0) outside the companion\u2019s magnetosphere. The dispersion measure variation observed during the ingresses and egresses shows the rapid raising of the electron density in the shock boundary between the companion\u2019s magnetosphere and the surrounding pulsar wind. We suggest that the observed oscillatory magnetic fields originate from the pulsar wind outside the companion\u2019s magnetosphere.",
                "disciplines": [
                    "5101"
                ]
            },
            "10.1126/science.abl7759": {
                "title": "Frequency-dependent polarization of repeating fast radio bursts\u2014implications for their origin",
                "abstract": "The polarization of fast radio bursts (FRBs), which are bright astronomical transient phenomena, contains information about their environments. Using wide-band observations with two telescopes, we report polarization measurements of five repeating FRBs and find a trend of lower polarization at lower frequencies. This behavior is modeled as multipath scattering, characterized by a single parameter, \u03c3<sub>RM</sub>, the rotation measure (RM) scatter. Sources with higher \u03c3<sub>RM</sub> have higher RM magnitude and scattering time scales. The two sources with the highest \u03c3<sub>RM</sub>, FRB\u00a020121102A and FRB\u00a020190520B, are associated with compact persistent radio sources. These properties indicate a complex environment near the repeating FRBs, such as a supernova remnant or a pulsar wind nebula, consistent with their having arisen from young stellar populations.",
                "disciplines": [
                    "5101"
                ]
            }
        }
    },
    "12964432": {
        "title": "Perfluoroalkyl substances and incident type 2 diabetes in a multi-ethnic population: A metabolome-genome investigation",
        "abstract": "PROJECT SUMMARY Increasing prevalence of type 2 diabetes (T2D) is accompanied by racial/ethnic disparities, but etiological factors promoting the T2D epidemic and T2D disparities are not fully understood. Growing experimental evidence shows that exposures to endocrine-disrupting chemicals (EDCs), such as per- and polyfluoroalkyl substances (PFAS), promote T2D development, likely in synergy with known risk factors such as genetic variations. PFAS are ubiquitous and persistent chemicals that perturb metabolism. However, few prospective studies examined the association between PFAS and T2D risk, and those were almost exclusively in White populations. Previous studies also lacked clinically ascertained T2D diagnosis, investigated only a few of the many potentially hazardous PFAS, and did not examine potential effects of PFAS mixtures or gene\u2013PFAS interactions. State-of- the-art integrated omics approaches can overcome these barriers to advance the field. We propose the first integrated metabolome\u2013genome approach to (1) characterize the associations between PFAS concentrations (individual PFAS and mixtures) in prediagnostic plasma samples and incident T2D risk and potential effect modification by genetic predisposition to T2D using polygenic risk scores as an innovative solution for studying interactions, (2) identify underlying dysregulated metabolic pathways, and (3) identify metabolic signatures in prediagnostic plasma samples defined by EDC exposures and endogenous metabolites associated with T2D risk. We will perform a nested case\u2013control study leveraging BioMe, an ongoing electronic health record-linked biobank with >55,000 participants enrolled while seeking primary care at Mount Sinai Hospital (NY) since 2007. Incident T2D cases are matched (1:1) to BioMe T2D-free controls (N = 1,700) and are of African American, Hispanic and White ancestry, with ~6 years average time between blood draw and T2D diagnosis. We will use prediagnostic plasma to measure PFAS and metabolic pathways using state-of-the-art high-resolution metabolomics (HRM) approaches. We will replicate findings among incident T2D cases and matched controls from the population-based Multiethnic Cohort (MEC) study in Los Angeles and Hawaii with extant genome data and prediagnostic plasma concentrations of PFAS and HRM measured at the same lab as BioMe samples. In contrast to prior studies, we incorporate a wide suite of legacy and emerging PFAS, exposure-mixture effects, and gene\u2013environment interactions by leveraging state-of-the-art metabolome\u2013genome approaches and a rigorous discovery\u2013replication design in two unique, well-phenotyped multiethnic cohorts with prediagnostic plasma samples to identify early biomarkers associated with T2D. This research relies on a multidisciplinary team of seasoned investigators with expertise in environmental/genetic epidemiology, PFAS and T2D research, and state-of-the-art HRM, genomics, and biostatistical exposure\u2013mixture methods. Findings will inform precision medicine approaches for T2D prevention and treatment, particularly for high-risk multiethnic populations.",
        "disciplines": [
            "4202",
            "3105"
        ],
        "publications": {
            "10.1016/j.scitotenv.2024.172840": {
                "title": "Changes in plasma concentrations of per- and Polyfluoroalkyl substances after bariatric surgery in adolescents from the Teen-Longitudinal Assessment of Bariatric Surgery (Teen-LABS) study",
                "abstract": "Exposure to per- and poly-fluoroalkyl substances (PFAS) is ubiquitous due to their persistence in the environment and in humans. Extreme weight loss has been shown to influence concentrations of circulating persistent organic pollutants (POPs). Using data from the multi-center perspective Teen-Longitudinal Assessment of Bariatric Surgery (Teen-LABS) cohort, we investigated changes in plasma-PFAS in adolescents after bariatric surgery. Adolescents (Mean age\u00a0=\u00a017.1\u00a0years, SD\u00a0=\u00a01.5\u00a0years) undergoing bariatric surgery were enrolled in the Teen-LABS study. Plasma-PFAS were measured at the time of surgery and then 6-, 12-, and 36\u00a0months post-surgery. Linear mixed effect models were used to evaluate longitudinal changes in plasma-PFAS after the time of bariatric surgery. This study included 214 adolescents with severe obesity who had available longitudinal measures of plasma-PFAS and underwent bariatric surgery between 2007 and 2012. Underlying effects related to undergoing bariatric surgery were found to be associated with an initial increase or plateau in concentrations of circulating PFAS up to 6\u00a0months after surgery followed by a persistent decline in concentrations of 36\u00a0months (p\u00a0<\u00a00.001 for all plasma-PFAS). Bariatric surgery in adolescents was associated with a decline in circulating PFAS concentrations. Initially following bariatric surgery (0-6\u00a0months) concentrations were static followed by decline from 6 to 36\u00a0months following surgery. This may have large public health implications as PFAS are known to be associated with numerous metabolic related diseases and the significant reduction in circulating PFAS in individuals who have undergone bariatric surgery may be related to the improvement of such metabolic related diseases following bariatric surgery.",
                "disciplines": [
                    "4105"
                ]
            },
            "10.1016/j.envint.2024.108601": {
                "title": "Exposure to per- and polyfluoroalkyl substances and high-throughput proteomics in Hispanic youth",
                "abstract": "BACKGROUND: Strong epidemiological evidence shows positive associations between exposure to per- and polyfluoroalkyl substances (PFAS) and adverse cardiometabolic outcomes (e.g., diabetes, hypertension, and dyslipidemia). However, the underlying cardiometabolic-relevant biological activities of PFAS in humans remain largely unclear.\nAIM: We evaluated the associations of PFAS exposure with high-throughput proteomics in Hispanic youth.\nMATERIAL AND METHODS: We included 312 overweight/obese adolescents from the Study of Latino Adolescents at Risk (SOLAR) between 2001 and 2012, along with 137 young adults from the Metabolic and Asthma Incidence Research (Meta-AIR) between 2014 and 2018. Plasma PFAS (i.e., PFOS, PFOA, PFHxS, PFHpS, PFNA) were quantified using liquid-chromatography high-resolution mass spectrometry. Plasma proteins (n\u00a0=\u00a0334) were measured utilizing the proximity extension assay using an Olink Explore Cardiometabolic Panel I. We conducted linear regression with covariate adjustment to identify PFAS-associated proteins. Ingenuity Pathway Analysis, protein-protein interaction network analysis, and protein annotation were used to investigate alterations in biological functions and protein clusters.\nRESULTS: Results after adjusting for multiple comparisons showed 13 significant PFAS-associated proteins in SOLAR and six in Meta-AIR, sharing similar functions in inflammation, immunity, and oxidative stress. In SOLAR, PFNA demonstrated significant positive associations with the largest number of proteins, including ACP5, CLEC1A, HMOX1, LRP11, MCAM, SPARCL1, and SSC5D. After considering the mixture effect of PFAS, only SSC5D remained significant. In Meta-AIR, PFAS mixtures showed positive associations with GDF15 and IL6. Exploratory analysis showed similar findings. Specifically, pathway analysis in SOLAR showed PFOA- and PFNA-associated activation of immune-related pathways, and PFNA-associated activation of inflammatory response. In Meta-AIR, PFHxS-associated activation of dendric cell maturation was found. Moreover, PFAS was associated with common protein clusters of immunoregulatory interactions and JAK-STAT signaling in both cohorts.\nCONCLUSION: PFAS was associated with broad alterations of the proteomic profiles linked to pro-inflammation and immunoregulation. The biological functions of these proteins provide insight into potential molecular mechanisms of PFAS toxicity.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1016/j.envint.2024.108454": {
                "title": "Associations of dietary intake and longitudinal measures of per- and polyfluoroalkyl substances (PFAS) in predominantly Hispanic young Adults: A multicohort study",
                "abstract": "BACKGROUND: Per- and polyfluoroalkyl substances (PFAS) are pollutants linked to adverse health effects. Diet is an important source of PFAS exposure, yet it is unknown how diet impacts longitudinal PFAS levels.\nOBJECTIVE: To determine if dietary intake and food sources were associated with changes in blood PFAS concentrations among Hispanic young adults at risk of metabolic diseases.\nMETHODS: Predominantly Hispanic young adults from the Children's Health Study who underwent two visits (CHS; n\u00a0=\u00a0123) and young adults from NHANES 2013-2018 who underwent one visit (n\u00a0=\u00a0604) were included. Dietary data at baseline was collected using two 24-hour dietary recalls to measure individual foods and where foods were prepared/consumed (home/restaurant/fast-food). PFAS were measured in blood at both visits in CHS and cross-sectionally in NHANES. In CHS, multiple linear regression assessed associations of baseline diet with longitudinal PFAS; in NHANES, linear regression was used.\nRESULTS: In CHS, all PFAS except PFDA decreased across visits (all p\u00a0<\u00a00.05). In CHS, A 1-serving higher tea intake was associated with 24.8\u00a0%, 16.17\u00a0%, and 12.6\u00a0% higher PFHxS, PFHpS, and PFNA at follow-up, respectively (all p\u00a0<\u00a00.05). A 1-serving higher pork intake was associated with 13.4\u00a0% higher PFOA at follow-up (p\u00a0<\u00a00.05). Associations were similar in NHANES, including unsweetened tea, hot dogs, and processed meats. For food sources, in CHS each 200-gram increase in home-prepared food was associated with 0.90\u00a0% and 1.6\u00a0% lower PFOS at baseline and follow-up, respectively, and in NHANES was associated with 0.9\u00a0% lower PFDA (all p\u00a0<\u00a00.05).\nCONCLUSION: Results suggest that beverage consumption habits and food preparation are associated with differences in PFAS levels in young adults. This highlights the importance of diet in determining PFAS exposure and the necessity of public monitoring of foods and beverages for PFAS contamination.",
                "disciplines": [
                    "4206",
                    "3210"
                ]
            },
            "10.1016/j.envint.2023.108375": {
                "title": "Longitudinal associations between early-life fluoride exposures and cardiometabolic outcomes in school-aged children",
                "abstract": "BACKGROUND/AIM: Fluoride is a natural mineral present in food, water, and dental products, constituting ubiquitous long-term exposure in early childhood and across the lifespan. Experimental evidence shows fluoride-induced lipid disturbances with potential implications for cardiometabolic health. However, epidemiological studies are scarce. For the first time, we evaluated associations between repeated fluoride measures and cardiometabolic outcomes in children.\nMETHODS: We studied\u00a0\u223c\u00a0500 Mexican children from the Programming Research in Obesity, Growth, Environment and Social Stressors (PROGRESS) cohort with measurements on urinary fluoride at age 4, and dietary fluoride at ages 4, 6, and 8\u00a0years approximately. We used covariate-adjusted linear mixed-effects and linear regression models to assess fluoride associations with multiple cardiometabolic outcomes (ages 4-8): lipids (total cholesterol, HDL, LDL, and triglycerides), glucose, HbA1c, adipokines (leptin and adiponectin), body fat, and age- and sex-specific z-scores of body mass index (zBMI), waist circumference, and blood pressure.\nRESULTS: Dietary fluoride intake at age 4 was associated with annual increases in triglycerides [\u03b2 per-fluoride-doubling\u00a0=\u00a02.02 (95\u00a0% CI: 0.37, 3.69)], cholesterol [\u03b2\u00a0=\u00a01.46 (95\u00a0% CI: 0.52, 2.39)], HDL [\u03b2\u00a0=\u00a00.39 (95\u00a0% CI: 0.02, 0.76)], LDL [\u03b2\u00a0=\u00a00.87 (95\u00a0% CI: 0.02, 1.71)], and HbA1c [\u03b2\u00a0=\u00a00.76 (95\u00a0% CI: 0.28, 1.24)], and decreased leptin [\u03b2\u00a0=\u00a0-3.58 (95\u00a0% CI: -6.34, -0.75)] between the ages 4 and 8. In cross-sectional analyses at age 8, higher tertiles of fluoride exposure were associated with increases in zBMI, triglycerides, glucose, and leptin (p-tertile trend\u00a0<\u00a00.05). Stronger associations were observed in boys at year 8 and in girls prior to year 8 (p-sex interaction\u00a0<\u00a00.05). Fewer but consistent associations were observed for urinary fluoride at age 4, indicating increased annual changes in HDL and HbA1c with higher fluoride levels.\nCONCLUSION: Dietary fluoride exposures in early- and mid-childhood were associated with adverse cardiometabolic outcomes in school-aged children. Further research is needed to elucidate whether these associations persist at later ages.",
                "disciplines": [
                    "4206",
                    "3210"
                ]
            },
            "10.1016/j.envres.2023.117611": {
                "title": "Exposure to perfluoroalkyl substances and longitudinal changes in bone mineral density in adolescents and young adults: A multi-cohort study",
                "abstract": "BACKGROUND: Per- and polyfluoroalkyl substances (PFAS) may impair bone development in adolescence, which impacts life-long bone health. No previous studies have examined prospective associations of individual PFAS and their mixture with bone mineral density (BMD) changes in Hispanic young persons, a population at high risk of osteoporosis in adulthood.\nOBJECTIVES: To examine associations of individual PFAS and PFAS mixtures with longitudinal changes in BMD in an adolescent Hispanic cohort and examine generalizability of findings in a mixed-ethnicity young adult cohort (58.4% Hispanic).\nMETHODS: Overweight/obese adolescents from the Study of Latino Adolescents at Risk of Type 2 Diabetes (SOLAR; n\u00a0=\u00a0304; mean follow-up\u00a0=\u00a01.4 years) and young adults from the Southern California Children's Health Study (CHS; n\u00a0=\u00a0137; mean follow-up\u00a0=\u00a04.1 years) were included in this study. Plasma PFAS were measured at baseline and dual x-ray absorptiometry scans were performed at baseline and follow-up to measure BMD. We estimated longitudinal associations between BMD and five PFAS via separate covariate-adjusted linear mixed effects models, and between BMD and the PFAS mixture via quantile g-computation.\nRESULTS: In SOLAR adolescents, baseline plasma perfluorooctanesulfonic acid (PFOS) was associated with longitudinal changes in BMD. Each doubling of PFOS was associated with an average -0.003\u00a0g/cm<sup>2</sup> difference in change in trunk BMD per year over follow-up (95% CI: -0.005, -0.0002). Associations with PFOS persisted in CHS young adults, where each doubling of plasma PFOS was associated with an average -0.032\u00a0g/cm<sup>2</sup> difference in total BMD at baseline (95% CI -0.062, -0.003), though longitudinal associations were non-significant. We did not find associations of other PFAS with BMD; associations of the PFAS mixture with BMD outcomes were primarily negative though non-significant.\nDISCUSSION: PFOS exposure was associated with lower BMD in adolescence and young adulthood, important periods for bone development, which may have implications on future bone health and risk of osteoporosis in adulthood.",
                "disciplines": []
            },
            "10.1016/j.envres.2023.117832": {
                "title": "Per- and polyfluoroalkyl substances, polychlorinated biphenyls, organochlorine pesticides, and polybrominated diphenyl ethers and dysregulation of MicroRNA expression in humans and animals\u2014A systematic review",
                "abstract": "BACKGROUND: Persistent organic pollutants (POPs) are chemicals characterized by their environmental persistence. Evidence suggests that exposure to POPs, which is ubiquitous, is associated with microRNA (miRNA) dysregulation. miRNA are key regulators in many physiological processes. It is thus of public health concern to understand the relationships between POPs and miRNA as related to health outcomes.\nOBJECTIVES: This systematic review evaluated the relationship between widely recognized, intentionally manufactured, POPs, including per- and polyfluoroalkyl substances (PFAS), polychlorinated biphenyls (PCBs), polybrominated diphenyl ethers (PBDEs), and organochlorine pesticides (dichlorodiphenyltrichloroethane [DDT], dichlorodiphenyldichloroethylene [DDE], hexachlorobenzene [HCB]), with miRNA expression in both human and animal studies.\nMETHODS: We used PubMed and Embase to systematically search the literature up to September 29th, 2023. Search results for human and animal studies were included if they incorporated at least one POP of interest in relation to at least one miRNA. Data were synthesized to determine the direction and significance of associations between POPs and miRNA. We utilized ingenuity pathway analysis to review disease pathways for miRNA that were associated with POPs.\nRESULTS: Our search identified 38 eligible studies: 9 in humans and 29 in model organisms. PFAS were associated with decreased expression of miR-19, miR-193b, and miR-92b, as well as increased expression of miR-128, miR-199a-3p, and miR-26b across species. PCBs were associated with increased expression of miR-15a, miR-1537, miR-21, miR-22-3p, miR-223, miR-30b, and miR-34a, as well as decreased expression of miR-130a and let-7b in both humans and animals. Pathway analysis for POP-associated miRNA identified pathways related to carcinogenesis.\nDISCUSSION: This is the first systematic review of the association of POPs with miRNA in humans and model organisms. Large-scale prospective human studies are warranted to examine the role of miRNA as mediators between POPs and health outcomes.",
                "disciplines": [
                    "4105"
                ]
            },
            "10.2337/dc23-0327": {
                "title": "Postprandial Metabolite Profiles and Risk of Prediabetes in Young People: A Longitudinal Multicohort Study.",
                "abstract": "OBJECTIVE: Prediabetes in young people is an emerging epidemic that disproportionately impacts Hispanic populations. We aimed to develop a metabolite-based prediction model for prediabetes in young people with overweight/obesity at risk for type 2 diabetes.\nRESEARCH DESIGN AND METHODS: In independent, prospective cohorts of Hispanic youth (discovery; n = 143 without baseline prediabetes) and predominately Hispanic young adults (validation; n = 56 without baseline prediabetes), we assessed prediabetes via 2-h oral glucose tolerance tests. Baseline metabolite levels were measured in plasma from a 2-h postglucose challenge. In the discovery cohort, least absolute shrinkage and selection operator regression with a stability selection procedure was used to identify robust predictive metabolites for prediabetes. Predictive performance was evaluated in the discovery and validation cohorts using logistic regression.\nRESULTS: Two metabolites (allylphenol sulfate and caprylic acid) were found to predict prediabetes beyond known risk factors, including sex, BMI, age, ethnicity, fasting/2-h glucose, total cholesterol, and triglycerides. In the discovery cohort, the area under the receiver operator characteristic curve (AUC) of the model with metabolites and known risk factors was 0.80 (95% CI 0.72-0.87), which was higher than the risk factor-only model (AUC 0.63 [0.53-0.73]; P = 0.001). When the predictive models developed in the discovery cohort were applied to the replication cohort, the model with metabolites and risk factors predicted prediabetes more accurately (AUC 0.70 [95% CI 40.55-0.86]) than the same model without metabolites (AUC 0.62 [0.46-0.79]).\nCONCLUSIONS: Metabolite profiles may help improve prediabetes prediction compared with traditional risk factors. Findings suggest that medium-chain fatty acids and phytochemicals are early indicators of prediabetes in high-risk youth.",
                "disciplines": [
                    "3205"
                ]
            },
            "10.1021/acs.est.3c02765": {
                "title": "Paired Liver:Plasma PFAS Concentration Ratios from Adolescents in the Teen-LABS Study and Derivation of Empirical and Mass Balance Models to Predict and Explain Liver PFAS Accumulation",
                "abstract": "Animal studies have pointed at the liver as a hotspot for per- and polyfluoroalkyl substances (PFAS) accumulation and toxicity; however, these findings have not been replicated in human populations. We measured concentrations of seven PFAS in matched liver and plasma samples collected at the time of bariatric surgery from 64 adolescents in the Teen-Longitudinal Assessment of Bariatric Surgery (Teen-LABS) study. Liver:plasma concentration ratios were perfectly explained (<i>r</i><sup>2</sup> &gt; 0.99) in a multilinear regression (MLR) model based on toxicokinetic (TK) descriptors consisting of binding to tissue constituents and membrane permeabilities. Of the seven matched plasma and liver PFAS concentrations compared in this study, the liver:plasma concentration ratio of perfluoroheptanoic acid (PFHpA) was considerably higher than the liver:plasma concentration ratio of other PFAS congeners. Comparing the MLR model with an equilibrium mass balance model (MBM) suggested that complex kinetic transport processes are driving the unexpectedly high liver:plasma concentration ratio of PFHpA. Intratissue MBM modeling pointed to membrane lipids as the tissue constituents that drive the liver accumulation of long-chain, hydrophobic PFAS, whereas albumin binding of hydrophobic PFAS dominated PFAS distribution in plasma. The liver:plasma concentration data set, empirical MLR model, and mechanistic MBM modeling allow the prediction of liver from plasma concentrations measured in human cohort studies. Our study demonstrates that combining biomonitoring data with mechanistic modeling can identify underlying mechanisms of internal distribution and specific target organ toxicity of PFAS in humans.",
                "disciplines": [
                    "4105"
                ]
            },
            "10.1021/acs.est.3c00848": {
                "title": "Machine Learning Assisted Discovery of Interactions between Pesticides, Phthalates, Phenols, and Trace Elements in Child Neurodevelopment",
                "abstract": "A growing body of literature suggests that developmental exposure to individual or mixtures of environmental chemicals (ECs) is associated with autism spectrum disorder (ASD). However, investigating the effect of interactions among these ECs can be challenging. We introduced a combination of the classical exposure-mixture Weighted Quantile Sum (WQS) regression and a machine-learning method termed Signed iterative Random Forest (SiRF) to discover synergistic interactions between ECs that are (1) associated with higher odds of ASD diagnosis, (2) mimic toxicological interactions, and (3) are present only in a subset of the sample whose chemical concentrations are higher than certain thresholds. In a case-control Childhood Autism Risks from Genetics and Environment (CHARGE) study, we evaluated multiordered synergistic interactions among 62 ECs measured in the urine samples of 479 children in association with increased odds for ASD diagnosis (yes vs no). WQS-SiRF identified two synergistic two-ordered interactions between (1) trace-element cadmium (Cd) and the organophosphate pesticide metabolite diethyl-phosphate (DEP); and (2) 2,4,6-trichlorophenol (TCP-246) and DEP. Both interactions were suggestively associated with increased odds of ASD diagnosis in the subset of children with urinary concentrations of Cd, DEP, and TCP-246 above the 75th percentile. This study demonstrates a novel method that combines the inferential power of WQS and the predictive accuracy of machine-learning algorithms to discover potentially biologically relevant chemical-chemical interactions associated with ASD.",
                "disciplines": [
                    "4105"
                ]
            },
            "10.1007/s40726-023-00269-4": {
                "title": "PFAS Exposures and the Human Metabolome: A Systematic Review of Epidemiological Studies",
                "abstract": "Purpose of ReviewThere is a growing interest in understanding the health effects of exposure to per- and polyfluoroalkyl substances (PFAS) through the study of the human metabolome. In this systematic review, we aimed to identify consistent findings between PFAS and metabolomic signatures. We conducted a search matching specific keywords that was independently reviewed by two authors on two databases (EMBASE and PubMed) from their inception through July 19, 2022 following PRISMA guidelines.Recent FindingsWe identified a total of 28 eligible observational studies that evaluated the associations between 31 different PFAS exposures and metabolomics in humans. The most common exposure evaluated was legacy long-chain PFAS. Population sample sizes ranged from 40 to 1,105 participants at different stages across the lifespan. A total of 19 studies used a non-targeted metabolomics approach, 7 used targeted approaches, and 2 included both. The majority of studies were cross-sectional (n\u2009=\u200925), including four with prospective analyses of PFAS measured prior to metabolomics.SummaryMost frequently reported associations across studies were observed between PFAS and amino acids, fatty acids, glycerophospholipids, glycerolipids, phosphosphingolipids, bile acids, ceramides, purines, and acylcarnitines. Corresponding metabolic pathways were also altered, including lipid, amino acid, carbohydrate, nucleotide, energy metabolism, glycan biosynthesis and metabolism, and metabolism of cofactors and vitamins. We found consistent evidence across studies indicating PFAS-induced alterations in lipid and amino acid metabolites, which may be involved in energy and cell membrane disruption.",
                "disciplines": [
                    "4104",
                    "4105",
                    "3701"
                ]
            },
            "10.1021/acs.analchem.3c00376": {
                "title": "IDSL.CSA: Composite Spectra Analysis for Chemical Annotation of Untargeted Metabolomics Datasets",
                "abstract": "Poor chemical annotation of high-resolution mass spectrometry data limits applications of untargeted metabolomics datasets. Our new software, the Integrated Data Science Laboratory for Metabolomics and Exposomics\u2500Composite Spectra Analysis (IDSL.CSA) R package, generates composite mass spectra libraries from MS1-only data, enabling the chemical annotation of high-resolution mass spectrometry coupled with liquid chromatography peaks regardless of the availability of MS2 fragmentation spectra. We demonstrate comparable annotation rates for commonly detected endogenous metabolites in human blood samples using IDSL.CSA libraries <i>versus</i> MS/MS libraries in validation tests. IDSL.CSA can create and search composite spectra libraries from any untargeted metabolomics dataset generated using high-resolution mass spectrometry coupled to liquid or gas chromatography instruments. The cross-applicability of these libraries across independent studies may provide access to new biological insights that may be missed due to the lack of MS2 fragmentation data. The IDSL.CSA package is available in the R-CRAN repository at https://cran.r-project.org/package=IDSL.CSA. Detailed documentation and tutorials are provided at https://github.com/idslme/IDSL.CSA.",
                "disciplines": [
                    "3205",
                    "3401"
                ]
            },
            "10.1289/ehp11372": {
                "title": "Metabolic Signatures of Youth Exposure to Mixtures of Per- and Polyfluoroalkyl Substances: A Multi-Cohort Study",
                "abstract": "BACKGROUND: Exposure to per- and polyfluoroalkyl substances (PFAS) is ubiquitous and has been associated with an increased risk of several cardiometabolic diseases. However, the metabolic pathways linking PFAS exposure and human disease are unclear.\nOBJECTIVE: We examined associations of PFAS mixtures with alterations in metabolic pathways in independent cohorts of adolescents and young adults.\nMETHODS: Three hundred twelve overweight/obese adolescents from the Study of Latino Adolescents at Risk (SOLAR) and 137 young adults from the Southern California Children's Health Study (CHS) were included in the analysis. Plasma PFAS and the metabolome were determined using liquid-chromatography/high-resolution mass spectrometry. A metabolome-wide association study was performed on log-transformed metabolites using Bayesian regression with a g-prior specification and g-computation for modeling exposure mixtures to estimate the impact of exposure to a mixture of six ubiquitous PFAS (PFOS, PFHxS, PFHpS, PFOA, PFNA, and PFDA). Pathway enrichment analysis was performed using Mummichog and Gene Set Enrichment Analysis. Significance across cohorts was determined using weighted <math><mi>Z</mi></math>-tests.\nRESULTS: In the SOLAR and CHS cohorts, PFAS exposure was associated with alterations in tyrosine metabolism (meta-analysis <math><mrow><mi>p</mi><mo>=</mo><mn>0.00002</mn></mrow></math>) and <i>de novo</i> fatty acid biosynthesis (<math><mrow><mi>p</mi><mo>=</mo><mn>0.03</mn></mrow></math>), among others. For example, when increasing all PFAS in the mixture from low (<math><mrow><mo>\u223c</mo><mn>30</mn></mrow></math>th percentile) to high (<math><mrow><mo>\u223c</mo><mn>70</mn></mrow></math>th percentile), thyroxine (T4), a thyroid hormone related to tyrosine metabolism, increased by 0.72 standard deviations (SDs; equivalent to a standardized mean difference) in the SOLAR cohort (95% Bayesian credible interval (BCI): 0.00, 1.20) and 1.60 SD in the CHS cohort (95% BCI: 0.39, 2.80). Similarly, when going from low to high PFAS exposure, arachidonic acid increased by 0.81 SD in the SOLAR cohort (95% BCI: 0.37, 1.30) and 0.67 SD in the CHS cohort (95% BCI: 0.00, 1.50). In general, no individual PFAS appeared to drive the observed associations.\nDISCUSSION: Exposure to PFAS is associated with alterations in amino acid metabolism and lipid metabolism in adolescents and young adults. https://doi.org/10.1289/EHP11372.",
                "disciplines": [
                    "3205"
                ]
            },
            "10.1101/2023.02.09.527886": {
                "title": "IDSL.CSA: Composite Spectra Analysis for Chemical Annotation of Untargeted Metabolomics Datasets",
                "abstract": "Poor chemical annotation of high-resolution mass spectrometry data limit applications of untargeted metabolomics datasets. Our new software, the Integrated Data Science Laboratory for Metabolomics and Exposomics - Composite Spectra Analysis (IDSL.CSA) R package, generates composite mass spectra libraries from MS1-only data, enabling the chemical annotation of LC/HRMS peaks regardless of the availability of MS2 fragmentation spectra. We demonstrate comparable annotation rates for commonly detected endogenous metabolites in human blood samples using IDSL.CSA libraries versus MS/MS libraries in validation tests. IDSL.CSA can create and search composite spectra libraries from any untargeted metabolomics dataset generated using high-resolution mass spectrometry coupled to liquid or gas chromatography instruments. The cross-applicability of these libraries across independent studies may provide access to new biological insights that may be missed due to the lack of MS2 fragmentation data. The IDSL.CSA package is available in the R CRAN repository at https://cran.r-project.org/package=IDSL.CSA . Detailed documentation and tutorials are provided at https://github.com/idslme/IDSL.CSA .\nFor Table of Contents Only: ",
                "disciplines": [
                    "3205",
                    "3401"
                ]
            }
        }
    },
    "13056207": {
        "title": "AI-Enabled Droplet Tracking for Crop Spraying Systems",
        "abstract": "This project proposes to develop an artificial intelligence (AI) technique capable of processing images, detecting and tracking all droplets appearing across the image frames, and measuring the droplet size and motion. Our central hypothesis is that the integration of deep-learning techniques into the image processing algorithm will enable precise and reliable detection, tracking, and measuring of droplet motion and size. In addition, the framework will produce consistent results under a variety of uncertain imagery conditions. The rationale is that deep learning extracts meaning from imagery data and human-labeled data to train a learning scheme that increases the reliability and accuracy of droplet tracking.We plan to test this central hypothesis by pursuing the following three specific aims: 1) Develop a deep-learning framework for droplet detection with a fast processing rate, 2) Integrate a filtering algorithm into the deep-learning framework for droplet tracking, and 3) Design and implement the metrics to assess the success rate of droplet detection and tracking.The project outcomes will provide an AI solution to a challenging precision agriculture problem, namely measuring the dynamic property of droplets from a crop spraying system. The tool will lead to the next generation of agricultural nozzles with significantly improved performance, which will improve producer efficiencies and minimize chemical runoff that pollutes the environment.",
        "disciplines": [
            "4603"
        ],
        "publications": {
            "10.3390/make6020035": {
                "title": "Soil Sampling Map Optimization with a Dual Deep Learning Framework",
                "abstract": "Soil sampling constitutes a fundamental process in agriculture, enabling precise soil analysis and optimal fertilization. The automated selection of accurate soil sampling locations representative of a given field is critical for informed soil treatment decisions. This study leverages recent advancements in deep learning to develop efficient tools for generating soil sampling maps. We proposed two models, namely UDL and UFN, which are the results of innovations in machine learning architecture design and integration. The models are meticulously trained on a comprehensive soil sampling dataset collected from local farms in South Dakota. The data include five key attributes: aspect, flow accumulation, slope, normalized difference vegetation index, and yield. The inputs to the models consist of multispectral images, and the ground truths are highly unbalanced binary images. To address this challenge, we innovate a feature extraction technique to find patterns and characteristics from the data before using these refined features for further processing and generating soil sampling maps. Our approach is centered around building a refiner that extracts fine features and a selector that utilizes these features to produce prediction maps containing the selected optimal soil sampling locations. Our experimental results demonstrate the superiority of our tools compared to existing methods. During testing, our proposed models exhibit outstanding performance, achieving the highest mean Intersection over Union of 60.82% and mean Dice Coefficient of 73.74%. The research not only introduces an innovative tool for soil sampling but also lays the foundation for the integration of traditional and modern soil sampling methods. This work provides a promising solution for precision agriculture and soil management.",
                "disciplines": [
                    "4106"
                ]
            },
            "10.1016/j.micromeso.2024.113042": {
                "title": "Predicting the decomposition temperatures of metal-organic frameworks based on the pair distribution functions using a deep learning model",
                "abstract": "The thermal stability is one of the factors that challenge the widespread applications of metal\u2013organic frameworks (MOFs). In order to leverage the high surface areas and remarkable porosities of MOFs, it is of critical importance to understand the dependence of the thermal stability of MOFs on the atomic structures, achieve rapid and accurate predictions on the decomposition temperatures of MOFs, and discover MOF structures with excellent thermal robustness. Herein, a deep learning framework was built to predict the thermal stability of MOFs using the pair distribution functions (PDFs) and certain physical properties of MOFs, where feature engineering was carried out with the random forest algorithm to extract the importance of each feature and various approaches, such as transformer and dense layers, were used to unravel the complicated relationships among features. As a result, the deep learning model was demonstrated highly effective in predicting the decomposition temperatures of MOFs with a dominant accuracy of \u00b110 \u00b0C. The outstanding predictive performance of the model primarily stems from the PDF features as confirmed by their overwhelming importance compared to other features, which highlights the significant role of the local structures of MOFs in determining their structural robustness at elevated temperatures.",
                "disciplines": [
                    "4016"
                ]
            },
            "10.3390/make6010014": {
                "title": "Real-Time Droplet Detection for Agricultural Spraying Systems: A Deep Learning Approach",
                "abstract": "Nozzles are ubiquitous in agriculture: they are used to spray and apply nutrients and pesticides to crops. The properties of droplets sprayed from nozzles are vital factors that determine the effectiveness of the spray. Droplet size and other characteristics affect spray retention and drift, which indicates how much of the spray adheres to the crop and how much becomes chemical runoff that pollutes the environment. There is a critical need to measure these droplet properties to improve the performance of crop spraying systems. This paper establishes a deep learning methodology to detect droplets moving across a camera frame to measure their size. This framework is compatible with embedded systems that have limited onboard resources and can operate in real time. The method leverages a combination of techniques including resizing, normalization, pruning, detection head, unified feature map extraction via a feature pyramid network, non-maximum suppression, and optimization-based training. The approach is designed with the capability of detecting droplets of various sizes, shapes, and orientations. The experimental results demonstrate that the model designed in this study, coupled with the right combination of dataset and augmentation, achieved a 97% precision and 96.8% recall in droplet detection. The proposed methodology outperformed previous models, marking a significant advancement in droplet detection for precision agriculture applications.",
                "disciplines": [
                    "4605"
                ]
            },
            "10.1016/j.compag.2024.108650": {
                "title": "Deep-learning framework for optimal selection of soil sampling sites",
                "abstract": "Soil sampling is one of the most fundamental agricultural processes. The selection of soil sampling locations within a field plays a crucial role in soil-health analysis. The current soil-sampling techniques produce random samples across a field, which are not representative of the field conditions. This work leverages the recent advancements of deep learning in image processing for finding optimal locations that present the important characteristics of a field. The data for training are collected at different fields in local farms with five features: aspect, flow accumulation, slope, NDVI (normalized difference vegetation index), and yield. The soil sampling dataset is challenging because of the unbalance between the number of pixels that represent soil-sampling spots and the number of pixels that represent the background area. In this work, we approach the problem with two methods, the first approach involves utilizing a state-of-the-art model with the convolutional neural network (CNN) backbone, while the second is to innovate a deep-learning design grounded in the concepts of transformer and self-attention. Our framework is constructed with an encoder\u2013decoder architecture with the self-attention mechanism as the backbone. In the encoder, the self-attention mechanism is the key feature extractor, which produces feature maps. In the decoder, we introduce atrous convolution networks to concatenate, fuse the extracted features, and then export the optimal locations for soil sampling. Currently, the model has achieved impressive results on the testing dataset, with a mean accuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean Dice Coefficient of 71.47%, while the performance metrics of the state-of-the-art CNN-based model are 66.08%, 3.85%, and 1.98%, respectively. This indicates that our proposed model outperforms the CNN-based method on the soil-sampling dataset. To the best of our knowledge, our work is the first to provide a soil-sampling dataset with multiple attributes and leverage deep learning techniques to enable the automatic selection of soil-sampling sites. This work lays a foundation for novel applications of data science and machine-learning technologies to solve other emerging agricultural problems.",
                "disciplines": [
                    "4611"
                ]
            },
            "10.1038/s41598-023-34320-7": {
                "title": "A deep-learning framework for spray pattern segmentation and estimation in agricultural spraying systems",
                "abstract": "This work focuses on leveraging deep learning for agricultural applications, especially for spray pattern segmentation and spray cone angle estimation. These two characteristics are important to understanding the sprayer system such as nozzles used in agriculture. The core of this work includes three deep-learning convolution-based models. These models are trained and their performances are compared. After the best model is selected based on its performance, it is used for spray region segmentation and spray cone angle estimation. The output from the selected model provides a binary image representing the spray region. This binary image is further processed using image processing to estimate the spray cone angle. The validation process is designed to compare results obtained from this work with manual measurements.",
                "disciplines": [
                    "3704"
                ]
            },
            "10.1016/j.compag.2022.107325": {
                "title": "AI-enabled droplet detection and tracking for agricultural spraying systems",
                "abstract": "This work leverages recent advancements in computer vision and deep learning to detect and track the motion of droplets captured by a camera. While classical computer vision techniques have been employed for detection and tracking, those approaches have limitations and are not trivially extended to droplets. We approach the problems of droplet detection and tracking through a data-driven framework, in which an annotated database of droplet images is built and object detection and tracking models are trained on this database. The accuracy of the model is evaluated and the whole process is discussed. At this point, droplet geometric properties can be extracted. This information is critical in understanding the effectiveness of a system that is spraying the droplets.",
                "disciplines": [
                    "4608"
                ]
            }
        }
    },
    "12942677": {
        "title": "Collaborative Research: SAI-R: Dynamical Coupling of Physical and Social Infrastructures: Evaluating the Impacts of Social Capital on Access to Safe Well Water",
        "abstract": "Strengthening American Infrastructure (SAI) is an NSF Program seeking to stimulate human-centered fundamental and potentially transformative research that strengthens America\u2019s infrastructure. Effective infrastructure provides a strong foundation for socioeconomic vitality and broad quality of life improvement. Strong, reliable, and effective infrastructure spurs private-sector innovation, grows the economy, creates jobs, makes public-sector service provision more efficient, strengthens communities, promotes equal opportunity, protects the natural environment, enhances national security, and fuels American leadership. To achieve these goals requires expertise from across the science and engineering disciplines. SAI focuses on how knowledge of human reasoning and decision-making, governance, and social and cultural processes enables the building and maintenance of effective infrastructure that improves lives and society and builds on advances in technology and engineering. Access to a safe supply of drinking water is essential for the health and welfare of all people. In many places, private wells are the primary source of water for residents. This SAI research project examines the availability of potable drinking water to individuals and households in settings where private wells are the predominant source of water for residents. Maintaining a safe supply of drinking water may be particularly challenging for residents who lack broad access to social support, as reflected in geographic connections to other communities. This support may be especially important in the aftermath of natural disasters and related hazards that disrupt water supplies. This project uses data on the mobility of cell phone users to characterize the social assistance that residents call upon. Methods are used to account for unequal representation of different groups in such datasets. The analysis considers other variables that may cause variation in water quality, such as demographic and socioeconomic factors. Water quality is evaluated with samples of private wells and surveys with owners. The project places high priority on sharing important findings with stakeholders, including extension services and health departments. The project also contributes to middle and high school curricula that will be shared and used in diverse public school settings. Multiple, complementary datasets are leveraged to examine the ways in which advantageous positions in social networks may contribute to better water quality in private wells, particularly in geographic settings that have been impacted by recent flooding. Social networks are constructed from data on the mobility of cellular phone users, and new algorithmic approaches are developed to address the biases that typify these data. Upon constructing these networks, measures of positions in social networks are used to predict variation in the contamination of private wells. The algorithmic approaches developed for graph neural network analysis will have broader potential applications in similar research that seeks to account for biases in the representativeness of large archival datasets, including biases that disadvantage vulnerable populations. The project involves multiple students, contributing to the training and education of early-career scientists. This award is supported by the Directorate for Social, Behavioral, and Economic (SBE) Sciences and the Directorate for Geosciences. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4407"
        ],
        "publications": {
            "10.1145/3615894.3628507": {
                "title": "Forecasting Urban Mobility using Sparse Data: A Gradient Boosted Fusion Tree Approach",
                "abstract": "Predicting human mobility in urban landscape poses complex challenges, especially when navigating sporadic mobility datasets. This paper introduces a robust predictive model founded on gradient boosted decision trees, designed to forecast human mobility patterns up to 15 days. We propose a unique feature augmentation approach that stresses two pivotal elements: the extraction of user behavior features from past individual mobility trajectories and the integration of temporal variation features based on the mobility patterns of other users during the same periods. Harnessing the capabilities of cutting-edge tree-based algorithms, our model handles missing data and ensures both computational efficiency and model transparency---qualities essential for instantaneous mobility predictions and strategic urban initiatives. A key facet of our methodology is the fusion model tactic, merging the merits of XGBoost and Light-GBM, thereby fortifying prediction reliability, curtailing overfitting, and boosting prediction precision. This paper presents a holistic framework for forecasting extended urban human mobility, providing invaluable perspectives for urban development, transportation planning, and disaster preparedness strategies. The source code can be accessed at https://github.com/he-h/HuMob2023.",
                "disciplines": [
                    "3509"
                ]
            },
            "10.1016/j.scs.2023.104435": {
                "title": "Percolation transitions in urban mobility networks in America's 50 largest cities",
                "abstract": "Urban mobility can be significantly disrupted by various extreme events. The disruptions threaten urban spatial connectivity and affect people's ability to access various essential services. Accurate characterization and timely alert of the critical transitions of urban mobility networks can help mitigate the above risks. However, there lacks an approach to characterize the critical transition state of urban mobility networks and warn their transitions during extreme events. The universality of the characteristics of disrupted mobility networks across different cities is another fundamental question that remains underexplored. By mining big geodata, we construct the mobility networks of the 50 most populous Metropolitan Statistical Areas (MSAs) in the U.S., and study their disruption patterns by conducting network percolation analysis. We find that all mobility networks experience abrupt transitions when reaching a universal critical threshold, at which the giant components of neighborhoods suddenly collapse and dissolve into small clusters. We also develop an indicator, by analyzing the neighborhood cluster distributions, that approximates how far a mobility network is to the critical threshold and provides an early warning of its critical transition. Our findings provide insights into mobility and neighborhood connectivity in cities, which can provide guidance for transportation management, epidemic control, and emergency evacuation.",
                "disciplines": [
                    "4406",
                    "3304"
                ]
            }
        }
    },
    "12937107": {
        "title": "Northeastern IPM Center: Strengthening IPM Adoption 2022 - 2026, Regional Coordination Program",
        "abstract": "Title: Northeastern IPM Center: Strengthening Ipm Adoption 2022 - 2026, Regional Coordination ProgramPD: Grantham, Deborah G. Institution: Cornell UniversityThis is an RCP Regional IPM Center project.The Northeastern Integrated Pest Management Center will strengthen ties to stakeholders in the region and fine-tune operations to fulfill its mission of fostering the development and adoption of IPM in the region.Staff, in collaboration with state IPM partners, multiregional projects, our Advisory Council, scientists, and IPM practitioners, will address critical issues, diversify resources, and provide educational and training opportunities for our clientele.Our six Signature Programs: Community IPM, IPM and Organic Systems, Climate Change and Pests, Pollinators, Next Generation Education, and Advanced Technologies, and four cross-cutting themes: Diversity in IPM, Emerging Invasive Species, Pesticide Resistance, and Economics collect our work under issues significant to the NE and include collaborations with the other RIPMCs on over-arching efforts and specific tasks.The Center will serve as a hub for delivering high quality information to stakeholders, including underserved audiences. We will collaborate with other groups to offer an annual online IPM Conference, a series of IPM Toolbox webinars with practical IPM tools for use in the field, and develop a process for further amplifying IPM success stories from the NE.The Center will communicate successes generated by the Partnership Grants Program, which will fund regional working groups, research, and communication projects. All projects, internal or external, will be designed to maximize evaluation and ensure impact. Funding will support diverse programming on IPM and enhance the Center's capacity to leverage additional funds to advance the mission to implement IPM in a wider geographic and demographic circle.",
        "disciplines": [
            "3507"
        ],
        "publications": {
            "10.1093/jipm/pmac028": {
                "title": "IPM Adoption and Impacts in the United States",
                "abstract": "Abstract\n                  Increased Integrated Pest Management (IPM) adoption hinges not only on the future of innovative research, but also on the willingness of growers to adopt new IPM technologies. Adoption and diffusion of innovations can encounter many different challenges. By better understanding the drivers of and barriers to IPM adoption, future research, extension, and education can better target behavior change. This study sought to better understand the IPM adoption drivers and barriers, along with the impacts of IPM, from the perspective of state IPM coordinators via an online Qualtrics survey. These professionals have a statewide perspective on IPM adoption. There were 37 completed surveys out of 56 email survey invitations, a 66% response rate. Overall, the participants ranked \u2018high cost of practice\u2019 as the most critical barrier to IPM adoption. \u2018Difficulty of implementation\u2019 and \u2018lack of awareness\u2019 were also highly ranked as critical barriers to adoption. When asked about ways to increase IPM adoption, participants ranked \u2018improved cost-benefit analysis\u2019 as the most critically important. Overall, these findings demonstrate the importance of providing improved IPM economic cost-benefit analyses to accompany the promotion of new and existing IPM innovations. Furthermore, even though the results of this study suggest that the impact of the Regional IPM Centers has been increasing regional IPM coordination, communication, collaboration, and cooperation. These findings also suggest a need for more comprehensive extension and education programs to specifically address the perceived \u2018high cost of practice,\u2019 \u2018difficulty of implementation\u2019, and \u2018lack of awareness\u2019 by communicating improved IPM cost-benefit analyses.",
                "disciplines": [
                    "3503"
                ]
            }
        }
    },
    "10032119": {
        "title": "Fixing the Future: The Right to Repair and Equal-IoT",
        "abstract": "Our 2-year interdisciplinary project will investigate how the lack of repairability in the consumer Internet of Things (IoT) will adversely impact equity, inclusion, and sustainability in the digital economy. \n \nIoT products are becoming the default, with wireless connectivity and automation bundled into mundane household items like TVs, energy meters, toys and phones. Whilst the IoT can still be a consumer choice now, its growth means citizens may see it imposed on them in the future. We use theory and methodologies from Human-Computer Interaction (HCI), Design and Law to anticipate the future impacts of a digital divide caused by redundant IoT devices, particularly for lower income households. We will envision how to build more equitable IoT devices and avoid future inequalities posed by the poor long-term cybersecurity, exploitative uses of data and lacking environmental sustainability that define the current IoT.\n \nSome citizens can afford to replace broken devices but others cannot and require support to repair them or face the impacts. We will examine how equality issues from IoT arise across society, generations and geographies. We will then investigate how to create more repairable devices that respect citizens legal rights, provide long-term cybersecurity, minimise eWaste, and are supported by local community repairability networks.\n \nTo do this, we have a research programme driven by stakeholder engagement and co-creation with citizens and project partners, namely:\n\n- Local community repair and maker space, The Making Rooms Blackburn \n- Consumer rights and advocacy group, Which?\n- Public broadcaster and new media experience developers, BBC Research & Development\n- IoT cybersecurity firm, NCC Group\n- Climate futures focused artist, Rachel Jacobs/Active Ingredient, \n- Social inclusion and digital skills body, the Department of Employment and Social Development in the Canadian Government.\n\nOur 4 integrated work packages (WPs) are underpinned by technical prototype development; qualitative evaluation and participatory research activities; public engagement; and policy driven activities to foster change in the sector to address current IoT led inequalities. \n\nKey focal points of the WPs include: examining legal and ethical challenges for equality posed by current IoT; creating and running an IoT Repair Shop installation in Blackburn with citizens and local repair networks; designing prototypes and user experiences that demonstrate how to build in repairability to address inequalities posed by current IoT; and developing an 'Equal-IoT' toolkit that will practically support development of more equitable futures when living with IoT. \n\nThe toolkit is a novel contribution that includes design recommendations and action plans for manufacturers to change current practices; policy guidelines and briefings to shape government activities; digital skills guidelines for enabling repairability in the community; development of an IoT repair shop blueprint model to roll out to other parts of the UK; touring the Repair Shop as a public engagement activity with citizens; developing a manifesto for citizens and repairers to showcase their rights and champion change in IoT development.",
        "disciplines": [
            "4608"
        ],
        "publications": {
            "10.1145/3651171": {
                "title": "On Disused Connected Devices: Understanding Disuse, \u2018Holding On\u2019 and Barriers to Circularity",
                "abstract": "In this article, we explore the complex phenomena behind why people \u201chold on\u201d to disused connected devices, focusing especially on differences between \u201ctraditional\u201d smartphones and computers, and newer categories of smart home devices, wearables, and single-function Internet of Things (IoT) devices. We investigate why and in what contexts different categories of connected devices become disused by their owners; what owners value about their disused devices; and what they perceive to be the barriers to adopting circular practices, for example, by fixing, recycling, or reusing them. Our contribution is to provide a descriptive account of how functional, sentimental, and other values associated with devices shape owners\u2019 perceptions and attitudes toward their \u201cend of life,\u201d for an expanded range of connected products. By highlighting how perceptions of concepts including convenience, ownership, and wastefulness mediate how owners approach the \u201cend of life\u201d of a device, we map the barriers for device owners to engage in more circular practices and highlight opportunities to address them through design. Our study replicates previous findings in the domain, as well as extending them, contributing to how the design of modern IoT devices leads to new barriers, opportunities, and considerations for more circular design.",
                "disciplines": [
                    "4608"
                ]
            },
            "10.1016/j.clsr.2024.105934": {
                "title": "Towards a right to repair for the Internet of Things: A review of legal and policy aspects",
                "abstract": "The way in which consumers engage with, utilise, or discard the technologies in their lives is constantly being reassessed and changed. This paper questions what role the emergent \u201cright to repair\u201d could play in resolving issues posed by the increasing ubiquity of the Internet of Things (IoT). The right gives consumers the ability and freedom to fix their devices, or to fair access to appropriate services that can carry out repair on their behalf. In this paper, firstly we establish the problem space surrounding consumer IoT \u2013 i.e., devices that are interconnected via the internet, enabling them to send and receive data. We reflect on hardware, software, and data components that pose legal and policy challenges for data protection, security, and sustainability. Through a literature review we then reflect on the current socio-legal developments that support or oppose changes in the consumer IoT market in regards to repair. We then highlight gaps in the existing literature that should inform future research trajectories in this area. This includes exploring disparities between environmental and consumer autonomy approaches, assessing consistency in regulatory developments, and market prioritisation. Finally, the paper concludes with a series of key insights and recommendations from our analysis including: recognition of the growing e-Waste problem and the inequalities it exacerbates and perpetuates; the need for identification and argumentation for different formulations of \u201crepair\u201d and how these may impact the implementation of a right going forward; the need for identification of the reasoning behind disparities in governmental approaches to the right to repair; and the need to practically translate better IoT design practices into reality.",
                "disciplines": [
                    "4804",
                    "4806"
                ]
            },
            "10.1145/3594739.3605113": {
                "title": "UbiFix: Tackling Repairability Challenges in Smart Devices",
                "abstract": "IoT products are increasingly becoming the default, with non-IoT versions of common hardware (e.g., TVs and printers) harder to find. Alongside this adoption surge, lack of support, outdated security, and planned obsolescence present concerning sustainability issues, contribute to eWaste growth and widen digital divides globally. This workshop aims to present and discuss legal, social, technical, and design aspects of repair practices, engaging the Ubicomp community in exploring challenges and opportunities for more repairable IoT devices. Focusing on diverse repair scenarios, the workshop seeks to establish a concise, holistic, and inclusive agenda for this research domain's future. Participants will map key research questions to support the movement towards more repairable technology.",
                "disciplines": [
                    "4608"
                ]
            }
        }
    },
    "12956062": {
        "title": "Sustainable citrus growing by controlled release of antibacterial compounds from microgel-based formulations",
        "abstract": "There is a growing need for sustainable methods of combating pests in agriculture. Copper is recognized as the most used antimicrobial agent for this purpose, including in organic productions. One of the agricultural activities that use copper with high frequency and quantity is citrus growing to combat diseases such as citrus canker, caused by the bacterium Xanthomonas citri subsp. citrus. This disease is endemic in the major orange producing regions, with the exception of Europe. Citrus farming generates US$2 billion/year in exports to Brazil, which demonstrates its importance. This project aims to develop sustainable technologies for the protection of citrus and as an alternative to copper. More specifically, we will focus on the fabrication of microgels responsive to specific stimuli and capable of: 1) adhesion to citrus leaves and 2) controlled release of antibacterial compounds. In collaboration with partners from the private sector/Brazilian industries, we will test the effectiveness of our pesticides in the field. Our research is based on the activities of a multidisciplinary team that will contribute with practical solutions for the production of bio-blocks derived from biomass, which will later be used in the production of pesticides to be used in a more sustainable citriculture in the near future. The research group will combine microgels with antibacterial compounds (gallates, dihydroxybenzoates, eugenol), previously evaluated against Xanthomonas. The microgels bind to plant leaves and confer long-term stability to the biomolecules. The microgels, carriers of antimicrobial compounds will be synthesized using biopolymer (chitosan), to ensure its complete biodegradation under environmental conditions (in the field). Extraction and increased biopolymer production will be optimized for large-scale microgel synthesis. The controlled release of bioactive compounds from the microgel will be achieved through the use of environmental triggers (humidity, light, enzymes, etc.) for a precise fight against bacteria. The simulation of rain in the greenhouse will be used to verify the fixation of the microgels/carrier compounds in the leaves. The microgels will be optimized for optimal release and antibacterial efficacy under the culture conditions. In addition, toxicity to bees, and other animal/plant models, will be determined to establish whether the microgels are safe for application. The best microgel/antibacterial compound formulation will be scaled up for field application. Field trials with the company Fundecitrus will determine the effectiveness of the microgel/antibacterial compound in protecting against citrus canker. Field testing will be performed under culture conditions compared to copper and treatment with the unencapsulated antibacterial compounds. Parallel to the development of microgels, the partner company Santa Clara will evaluate the compatibility of antibacterial compounds and adjuvants (normally used in agriculture), preparing formulations that can be evaluated directly and easily in greenhouse and field tests. The formulations will be tested for effectiveness using a greenhouse plant protection test, and the best formulations will subsequently be applied in the field. The environmental impact will be evaluated through biodegradation and ecotoxicity tools. Stability and environmental impact of antibacterial compounds, formulations and microgels will be analyzed through soil degradation and metagenome sequencing (assessment of effects on the soil microbiome). Life cycle assessment and market analysis will be carried out to measure the environmental, economic and social impact of the new technology. A comparative lifecycle assessment of environmental and health impact will be carried out, considering the formulated product that will be developed in this project and the currently used copper-based formulations. (AU)",
        "disciplines": [
            "3004"
        ],
        "publications": {
            "10.1093/lambio/ovae041": {
                "title": "Antibacterial activity of Cymbopogon species essential oils against Xanthomonas citri and their use in post-harvest treatment for citrus canker management",
                "abstract": "Citrus canker is a disease caused by the gram-negative bacterium Xanthomonas citri subp. citri (X. citri), which affects all commercially important varieties of citrus and can lead to significant losses. Fruit sanitization with products such as chlorine-based ones can reduce the spread of the disease. While effective, their use raises concerns about safety of the workers. This work proposes essential oils (EOs) as viable alternatives for fruit sanitization. EOs from Cymbopogon species were evaluated as to their antibacterial activity, their effect on the bacterial membrane, and their ability to sanitize citrus fruit. The in vitro assays revealed that the EOs from C. schoenanthus and C. citratus had a lower bactericidal concentration at 312\u00a0mg L-1, followed by 625\u00a0mg L-1 for C. martini and C. winterianus. Microscopy assay revealed that the bacterial cell membranes were disrupted after 15\u00a0min of contact with all EOs tested. Regarding the sanitizing potential, the EOs with higher proportions of geraniol were more effective in sanitizing acid limes. Fruit treated with C. shoenanthus and C. martini showed a reduction of \u223c68% in the recovery of viable bacterial cells. Therefore, these EOs can be used as viable natural alternatives in citrus fruit disinfection.",
                "disciplines": [
                    "3008"
                ]
            },
            "10.1007/s12155-024-10734-7": {
                "title": "Hemicellulose Biomass Degree of Acetylation (Natural Versus Chemical Acetylation) as a Strategy for Based Packaging Materials",
                "abstract": "Facing increasing social, environmental, and economic pressure to substitute non-renewable fossil resources with renewable ones, hemicellulose has received attention as a substrate for the production of high-value products such as packaging materials because of its non-toxicity, abundance, and biodegradability. Hemicelluloses in the cell wall are naturally substituted with acetyl groups, and the degree and pattern of acetylation vary among plant species, tissue and cell types, and plant maturity. Hemicellulose acetylation influences features such as the flexural properties of wood, polysaccharide interactions, plant growth, and stress resistance. However, hemicellulose is deacetylated during its separation from other biomass polymers, mainly via alkaline solubilization. Therefore, when industrial applications require a certain degree of acetylation, chemical acetylation is necessary, which occurs through an esterification reaction that links acetyl groups to hemicellulose, catalyzed or not. Acetylation may enhance some features of hemicellulose-based packaging materials, such as mechanical strength, processability, thermal stability, hydrophobicity, and oxygen and water vapor permeability. This review provides an update on the latest advances in plant polysaccharide acetylation, including the acetylation mechanism in the plant cell wall as well as the influence of such esterification on plant properties and wood industrial application. Recent developments and progress in hemicellulose chemical acetylation strategies have been summarized, disclosing the advantages and disadvantages of different solvents and catalysts applied and acetylation evaluation methods.",
                "disciplines": [
                    "3106"
                ]
            },
            "10.1016/j.carres.2024.109068": {
                "title": "New blend of renewable bioplastic based on starch and acetylated xylan with high resistance to oil and water vapor",
                "abstract": "Renewable materials of biological origin exhibit attractive properties in relation to traditional plastics, as they can be partially or completely replaced, thereby reducing environmental impacts. Hemicelluloses are a group of polysaccharides that have expanded applications when acetylated. Acetylation can improve the mechanical strength and water vapor barrier properties of xylan-based bioplastics. By partially acetylating xylan in the present study, it was possible to use water as a solvent for the film-forming solution and starch as a second polysaccharide in the formation of bioplastics. Xylan was modified via partial chemical acetylation by varying the reaction time, solvent, and catalyst content. The bioplastics were formed by non-acetylated xylan and acetylated xylan with degrees of substitution (DS) of 0.45 and 0.9, respectively, with starch to form blends using glycerol as a plasticizer. Acetylation with DS 0.45 showed better results in increasing the hydrophilicity of the bioplastic. On the other hand, acetylation influenced the thermal stability of bioplastics, increasing the maximum temperature of the degradation rate from 302\u00a0\u00b0C to 329\u00a0\u00b0C and 315\u00a0\u00b0C, owing to changes in the crystallinity of the polymers. In addition to the modulus of elasticity 2.99 to 290.61 and 274.67\u00a0MPa for the non-acetylated bioplastic and the bioplastic with DS of 0.45 and 0.90, respectively. Thus, the films obtained presented suitable physicochemical properties for use in various industrial applications, such as active and intelligent packaging in the food sector.",
                "disciplines": [
                    "3405"
                ]
            },
            "10.1007/s00253-023-12908-3": {
                "title": "Bifunctional peptides as alternatives to copper-based formulations to control citrus canker",
                "abstract": "Citrus canker is an infectious bacterial disease and one of the major threats to the orange juice industry, a multibillion-dollar market that generates hundreds of thousands of jobs worldwide. This disease is caused by the Gram-negative bacterium Xanthomonas citri subsp. citri. In Brazil, the largest producer and exporter of concentrate orange juice, the control of citrus canker is exerted by integrated management practices, in which cupric solutions are intensively used in the orchards to refrain bacterial spreading. Copper ions accumulate and are as heavy metals toxic to the environment. Therefore, the aim of the present work was to evaluate bifunctional fusion proteins (BiFuProts) as novel and bio-/peptide-based alternatives to copper formulations to control citrus canker. BiFuProts are composed of an anchor peptide able to bind to citrus leaves, and an antimicrobial \u201ckiller\u201d peptide to protect against bacterial infections of plants. The selected BiFuProt (Mel-CgDEF) was bactericidal against X. citri at 125 \u03bcg mL\u22121, targeting the bacterial cytoplasmic membrane within the first minutes of contact. The results in the greenhouse assays proved that Mel-CgDEF at 250 \u03bcg mL\u22121 provided protection against X. citri infection on the leaves, significantly reducing the number of lesions by area when compared with the controls. Overall, the present work showed that the BiFuProt Mel-CgDEF is a biobased and biodegradable possible alternative for substitute cupric formulations.Key points\u2022 The bifunctional fusion protein Mel-CgDEF was effective against Xanthomonas citri.\u2022 Mel-CgDEF action mechanism was the disruption of the cytoplasmic membrane.\u2022 Mel-CgDEF protected citrus leaves against citrus canker disease.",
                "disciplines": [
                    "3004"
                ]
            },
            "10.1007/s00289-024-05152-w": {
                "title": "Hemicellulose additive to chitosan-based bioplastic improved the tensile strength and allowed to control the material swelling",
                "abstract": "This study assessed bioplastics made from different mass proportions of commercial chitosan and banana plant pseudostem-derived hemicelluloses. The bioplastics were prepared by the casting method and characterized for moisture content, water solubility, opacity, water absorption, tensile strength, and thermogravimetric properties. The formulations with hemicelluloses addition showed higher moisture content and water solubility than the chitosan-only bioplastic, the maximum values of these properties (22.3 and 22.4%) were achieved when hemicelluloses were added at the proportion of 10 and 5%, respectively. A positive linear correlation (r\u2009=\u20090.86) was found between added hemicelluloses and opacity, with the highest opacity (1.95\u00a0mm\u22121) achieved in the formulation with the maximum hemicellulose incorporation. The bioplastics containing hemicelluloses exhibited lower swelling (water absorption) than that made only of chitosan, with the formulation featuring the highest hemicelluloses content showed the lowest swelling (229.2%). A negative linear correlation (r\u2009=\u20090.95) was observed between added hemicelluloses and swelling values. The formulation with the highest hemicelluloses content demonstrated statistically significant differences and exhibited the highest tensile strength (18.7\u00a0MPa) and Young\u2019s modulus (66.1\u00a0MPa). Thermogravimetric analysis revealed four stages of mass loss in the bioplastics. Hemicelluloses addition decreased the temperature at maximum mass loss, and the formulation with the lowest hemicelluloses content showed a higher degradation rate than the others.",
                "disciplines": [
                    "3403"
                ]
            },
            "10.3390/polysaccharides4020013": {
                "title": "Xylan Solubilization from Partially Delignified Biomass, and Residual Lignin Removal from Solubilized Xylan",
                "abstract": "Xylan is a macromolecule of industrial interest that can be solubilized from lignocellulosic materials, such as sugarcane bagasse, which is a renewable source. However, the solubilization methods of xylan need to be better developed for use in industrial applications. The main objective of this study was to evaluate xylan solubilization methods with higher yields and purity by using biomasses/fractions of sugarcane: leaf and stem, internode, node, and external fraction. Two strategies were evaluated by applying diluted sodium chlorite, sodium sulfite, and hydrogen peroxide: a delignification of the biomass before xylan solubilization; and the delignification of the solubilized xylan for residual lignin removal. The delignification of the biomass before the xylan solubilization enabled to identify material and specific conditions for yields higher than 90%. Residual lignin varied from 3.14 to 18.06%, with hydrogen peroxide in alkaline medium partial delignification shown to be effective. The delignification of xylan presented better results using diluted hydrogen peroxide, with a reduction of 58.44% of the initial lignin content. The solubilized xylans were used as a substrate for xylanase activities, resulting in higher activity than commercial xylan. In the delignification of the biomasses, hydrogen peroxide was the reagent with better results concerning the yield, purity, and solubility of the xylan. This reagent (diluted) was also better in the delignification of the solubilized xylan, resulting in lower residual lignin content. The solubility and purity tests (low salt content) indicated that the solubilized xylan presented characteristics that were similar to or even better than commercial xylan.",
                "disciplines": [
                    "3106"
                ]
            },
            "10.3389/fagro.2023.1148969": {
                "title": "Oregano essential oil and its main components Thymol and Carvacrol as alternatives to control citrus canker",
                "abstract": "Plant Essential Oils and their constituents are well-known for their properties as antimicrobial agents and are labeled as Generally Recognized as Safe (GRAS), prompting studies around their usage in the control of food-borne microorganisms and phytopathogens. In this study, we evaluated Oregano Essential Oil (OEO), Thymol (THY) and Carvacrol (CAR) for the control of Xanthomonas citri subsp. citri (X. citri). In vitro antibacterial assays revealed that CAR and THY inhibit X. citri growth at the concentrations of 100 \u00b5g.mL-1 and 114 \u00b5g.mL-1, lower than OEO (136 \u00b5g.mL-1). Bactericidal effects were observed at 400 \u00b5g.mL-1 for OEO and 200 ug.mL-1 for CAR and THY. Investigating potential cellular targets for the compounds showed that after 30 minutes of exposure up to 84% of the cells had their membranes disrupted, implicating the membrane as the primary target. Phytotoxicity evaluations using Lactuca sativa and Solanum lycopersicum seeds showed an acute toxic effect in all treatments above 200 \u00b5g.mL-1, except for OEO and THY in S. lycopersicum at lower concentrations. Regarding their protective effect on citrus leaves, CAR showed no effect when compared to the untreated control (0.39 and 0.50 lesions per cm2, respectively). OEO and THY were able to reduce significantly citrus canker symptoms (0.18 and 0.11 lesions per cm2, respectively). In addition, no toxic effects were observed on citrus leaves in all treatments. THY inhibits X. citri growth and the development of citrus canker lesions. These results show that THY as a viable alternative to be used in citrus canker management.",
                "disciplines": [
                    "3006"
                ]
            }
        }
    },
    "12925271": {
        "title": "A k-mer-based search engine for sequencing databases",
        "abstract": "Databases with biological sequencing data hold a treasure trove of biological data that can be used to aid experimental design and find relevant prior experiments for new biological projects. However, these rapidly growing archives are heavily under-utilized due to our inability to rapidly query the raw data within them. Just as search engines transformed our ability to broadly and deeply access information online, search indices have the potential to revolutionize the ways in which sequencing data in these archives is used. In this project methods to enable fast and easy access to these databases will be developed. This will contribute to the \u201cGooglification\u201d of life-science data, spurring broad scientific advances. Additionally, as part of the project, a \u201cWriting in CS\u201d course as well as an exercise booklet for probabilistic analysis of algorithms will be developed. Workshops on emerging methods for sequence analysis will be organized, and training to underrepresented undergraduates, graduate students and postdocs will be provided. This project advances research across all areas of life science that work with sequencing data. It creates powerful indexing data structures and querying algorithms for databases of sequencing experiments. This can allow biologists to query sequencing databases to find experiments which express a certain transcript of interest, show differential levels of expression between two transcripts, contain a known splice junction or gene fusion, or contain a small genome of interest. This project will facilitate a biologist to be able to execute many biologically-stated queries on a database of raw DNA and RNA sequencing experiments. The results of this project will be available on http://medvedevgroup.com/nsf-iibr-project. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3102",
            "4605"
        ],
        "publications": {
            "10.1038/s41586-024-07473-2": {
                "title": "The complete sequence and comparative analysis of ape sex chromosomes",
                "abstract": "Apes possess two sex chromosomes\u2014the male-specific Y chromosome and the X chromosome, which is present in both males and females. The Y chromosome is crucial for male reproduction, with deletions being linked to infertility1. The X chromosome is vital for reproduction and cognition2. Variation in mating patterns and brain function among apes suggests corresponding differences in their sex chromosomes. However, owing to their repetitive nature and incomplete reference assemblies, ape sex chromosomes have been challenging to study. Here, using the methodology developed for the telomere-to-telomere (T2T) human genome, we produced gapless assemblies of the X and Y chromosomes for five great apes (bonobo (Pan paniscus), chimpanzee (Pan troglodytes), western lowland\u00a0gorilla (Gorilla gorilla gorilla), Bornean orangutan (Pongo pygmaeus) and Sumatran orangutan (Pongo abelii)) and a lesser ape (the siamang gibbon (Symphalangus syndactylus)), and untangled the intricacies of their evolution. Compared with the X chromosomes, the ape Y chromosomes vary greatly in size and have low alignability and high levels of structural rearrangements\u2014owing to the accumulation of lineage-specific ampliconic regions, palindromes, transposable elements and satellites. Many Y chromosome genes expand in multi-copy families and some evolve under purifying selection. Thus, the Y chromosome exhibits dynamic evolution, whereas the X chromosome is more stable. Mapping short-read sequencing data to these assemblies revealed diversity and selection patterns on sex chromosomes of more than 100 individual great apes. These reference assemblies are expected to inform human evolution and conservation genetics of non-human apes, all of which are endangered species.",
                "disciplines": [
                    "3102",
                    "3105",
                    "4401"
                ]
            },
            "10.1101/2023.11.30.569198": {
                "title": "The Complete Sequence and Comparative Analysis of Ape Sex Chromosomes",
                "abstract": "Apes possess two sex chromosomes-the male-specific Y and the X shared by males and females. The Y chromosome is crucial for male reproduction, with deletions linked to infertility. The X chromosome carries genes vital for reproduction and cognition. Variation in mating patterns and brain function among great apes suggests corresponding differences in their sex chromosome structure and evolution. However, due to their highly repetitive nature and incomplete reference assemblies, ape sex chromosomes have been challenging to study. Here, using the state-of-the-art experimental and computational methods developed for the telomere-to-telomere (T2T) human genome, we produced gapless, complete assemblies of the X and Y chromosomes for five great apes (chimpanzee, bonobo, gorilla, Bornean and Sumatran orangutans) and a lesser ape, the siamang gibbon. These assemblies completely resolved ampliconic, palindromic, and satellite sequences, including the entire centromeres, allowing us to untangle the intricacies of ape sex chromosome evolution. We found that, compared to the X, ape Y chromosomes vary greatly in size and have low alignability and high levels of structural rearrangements. This divergence on the Y arises from the accumulation of lineage-specific ampliconic regions and palindromes (which are shared more broadly among species on the X) and from the abundance of transposable elements and satellites (which have a lower representation on the X). Our analysis of Y chromosome genes revealed lineage-specific expansions of multi-copy gene families and signatures of purifying selection. In summary, the Y exhibits dynamic evolution, while the X is more stable. Finally, mapping short-read sequencing data from >100 great ape individuals revealed the patterns of diversity and selection on their sex chromosomes, demonstrating the utility of these reference assemblies for studies of great ape evolution. These complete sex chromosome assemblies are expected to further inform conservation genetics of nonhuman apes, all of which are endangered species.",
                "disciplines": [
                    "3102",
                    "3105",
                    "4401"
                ]
            },
            "10.1186/s13015-024-00254-6": {
                "title": "Compression algorithm for colored de Bruijn graphs",
                "abstract": "A colored de Bruijn graph (also called a set of k-mer sets), is a set of k-mers with every k-mer assigned a set of colors. Colored de Bruijn graphs are used in a variety of applications, including variant calling, genome assembly, and database search. However, their size has posed a scalability challenge to algorithm developers and users. There have been numerous indexing data structures proposed that allow to store the graph compactly while supporting fast query operations. However, disk compression algorithms, which do not need to support queries on the compressed data and can thus be more space-efficient, have received little attention. The dearth of specialized compression tools has been a detriment to tool developers, tool users, and reproducibility efforts. In this paper, we develop a new tool that compresses colored de Bruijn graphs to disk, building on previous ideas for compression of k-mer sets and indexing colored de Bruijn graphs. We test our tool, called ESS-color, on various datasets, including both sequencing data and whole genomes. ESS-color achieves better compression than all evaluated tools and all datasets, with no other tool able to consistently achieve less than 44% space overhead. The software is available at http://github.com/medvedevgroup/ESSColor.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1007/978-1-0716-3989-4_3": {
                "title": "Efficient Analysis of Annotation Colocalization Accounting for Genomic Contexts",
                "abstract": "An annotation is a set of genomic intervals sharing a particular function or property. Examples include genes, conserved elements, and epigenetic modifications. A common task is to compare two annotations to determine if one is enriched or depleted in the regions covered by the other. We study the problem of assigning statistical significance to such a comparison based on a null model representing two random unrelated annotations. To incorporate more background information into such analyses and avoid biased results, we propose a new null model based on a Markov chain which differentiates among several genomic contexts. These contexts can capture various confounding factors, such as GC content or sequencing gaps. We then develop a new algorithm for estimating p-values by computing the exact expectation and variance of the test statistic and then estimating the p-value using a normal approximation. Compared to the previous algorithm by Gafurov et al., the new algorithm provides three advances: (1) the running time is improved from quadratic to linear or quasi-linear, (2) the algorithm can handle two different test statistics, and (3) the algorithm can handle both simple and context-dependent Markov chain null models.We demonstrate the efficiency and accuracy of our algorithm on synthetic and real data sets, including the recent human telomere-to-telomere assembly. In particular, our algorithm computed p-values for 450 pairs of human genome annotations using 24 threads in under three hours. The use of genomic contexts to correct for GC-bias also resulted in the reversal of some previously published findings.Availability. The software is freely available at https://github.com/fmfi-compbio/mcdp2 under the MIT licence. All data for reproducibility are available at https://github.com/fmfi-compbio/mcdp2-reproducibility.",
                "disciplines": []
            },
            "10.4230/lipics.wabi.2023.17": {
                "title": "Compression Algorithm for Colored de Bruijn Graphs",
                "abstract": "A colored de Bruijn graph (also called a set of k-mer sets), is a set of k-mers with every k-mer assigned a set of colors. Colored de Bruijn graphs are used in a variety of applications, including variant calling, genome assembly, and database search. However, their size has posed a scalability challenge to algorithm developers and users. There have been numerous indexing data structures proposed that allow to store the graph compactly while supporting fast query operations. However, disk compression algorithms, which do not need to support queries on the compressed data and can thus be more space-efficient, have received little attention. The dearth of specialized compression tools has been a detriment to tool developers, tool users, and reproducibility efforts. In this paper, we develop a new tool that compresses colored de Bruijn graphs to disk, building on previous ideas for compression of k-mer sets and indexing colored de Bruijn graphs. We test our tool, called ESS-color, on various datasets, including both sequencing data and whole genomes. ESS-color achieves better compression than all evaluated tools and all datasets, with no other tool able to consistently achieve less than 44% space overhead.",
                "disciplines": []
            },
            "10.1186/s13015-024-00261-7": {
                "title": "ESKEMAP: exact sketch-based read mapping",
                "abstract": "BackgroundGiven a sequencing read, the broad goal of read mapping is to find the location(s) in the reference genome that have a \u201csimilar sequence\u201d. Traditionally, \u201csimilar sequence\u201d was defined as having a high alignment score and read mappers were viewed as heuristic solutions to this well-defined problem. For sketch-based mappers, however, there has not been a problem formulation to capture what problem an exact sketch-based mapping algorithm should solve. Moreover, there is no sketch-based method that can find all possible mapping positions for a read above a certain score threshold.ResultsIn this paper, we formulate the problem of read mapping at the level of sequence sketches. We give an exact dynamic programming algorithm that finds all hits above a given similarity threshold. It runs in O(|t|+|p|+\u21132)$$\\mathcal {O} (|t| + |p| + \\ell ^2)$$ time and O(\u2113log\u2113)$$\\mathcal {O} (\\ell \\log \\ell )$$ space, where |t| is the number of k$$k$$-mers inside the sketch of the reference, |p| is the number of k$$k$$-mers inside the read\u2019s sketch and \u2113$$\\ell$$ is the number of times that k$$k$$-mers from the pattern sketch occur in the sketch of the text. We evaluate our algorithm\u2019s performance in mapping long reads to the T2T assembly of human chromosome Y, where ampliconic regions make it desirable to find all good mapping positions. For an equivalent level of precision as minimap2, the recall of our algorithm is 0.88, compared to only 0.76 of minimap2.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2023.11.22.568259": {
                "title": "Efficient Analysis of Annotation Colocalization Accounting for Genomic Contexts",
                "abstract": "An annotation is a set of genomic intervals sharing a particular function or property. Examples include genes or their exons, evolutionarily conserved elements, and regions with a particular epigenetic state. A common task is to compare two annotations to determine if one is enriched or depleted in the regions covered by the other. We study the problem of assigning statistical significance to such a comparison based on a null model representing two random unrelated annotations. To incorporate more background information into such analyses,we propose a new null model based on a Markov chain which differentiates among several genomic contexts. These contexts can capture various confounding factors, such as GC content or assembly gaps. We then develop a new algorithm for estimating p-values by computing the exact expectation and variance of the test statistics and then estimating the p-value using a normal approximation. Compared to the previous algorithm by Gafurov et al., the new algorithm provides three advances: (1) the running time is improved from quadratic to linear or quasi-linear, (2) the algorithm can handle two different test statistics, and (3) the algorithm can handle both simple and context-dependent Markov chain null models. We demonstrate the efficiency and accuracy of our algorithm on synthetic and real data sets, including the recent human telomere-to-telomere assembly. In particular, our algorithm computed p-values for 450 pairs of human genome annotations using 24 threads in under three hours. Moreover, the use of genomic contexts to correct for GC bias resulted in the reversal of some previously published findings.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1093/gbe/evad205": {
                "title": "Transcript Isoform Diversity of Ampliconic Genes on the Y Chromosome of Great Apes",
                "abstract": "Y chromosomal ampliconic genes (YAGs) are important for male fertility, as they encode proteins functioning in spermatogenesis. The variation in copy number and expression levels of these multicopy gene families has been studied in great apes; however, the diversity of splicing variants remains unexplored. Here, we deciphered the sequences of polyadenylated transcripts of all nine YAG families (BPY2, CDY, DAZ, HSFY, PRY, RBMY, TSPY, VCY, and XKRY) from testis samples of six great ape species (human, chimpanzee, bonobo, gorilla, Bornean orangutan, and Sumatran orangutan). To achieve this, we enriched YAG transcripts with capture probe hybridization and sequenced them with long (Pacific Biosciences) reads. Our analysis of this data set resulted in several findings. First, we observed evolutionarily conserved alternative splicing patterns for most YAG families except for BPY2 and PRY. Second, our results suggest that BPY2 transcripts and proteins originate from separate genomic regions in bonobo versus human, which is possibly facilitated by acquiring new promoters. Third, our analysis indicates that the PRY gene family, having the highest representation of noncoding transcripts, has been undergoing pseudogenization. Fourth, we have not detected signatures of selection in the five YAG families shared among great apes, even though we identified many species-specific protein-coding transcripts. Fifth, we predicted consensus disorder regions across most gene families and species, which could be used for future investigations of male infertility. Overall, our work illuminates the YAG isoform landscape and provides a genomic resource for future functional studies focusing on infertility phenotypes in humans and critically endangered great apes.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            },
            "10.1101/gr.277679.123": {
                "title": "Efficient mapping of accurate long reads in minimizer space with mapquik",
                "abstract": "DNA sequencing data continue to progress toward longer reads with increasingly lower sequencing error rates. We focus on the critical problem of mapping, or aligning, low-divergence sequences from long reads (e.g., Pacific Biosciences [PacBio] HiFi) to a reference genome, which poses challenges in terms of accuracy and computational resources when using cutting-edge read mapping approaches that are designed for all types of alignments. A natural idea would be to optimize efficiency with longer seeds to reduce the probability of extraneous matches; however, contiguous exact seeds quickly reach a sensitivity limit. We introduce mapquik, a novel strategy that creates accurate longer seeds by anchoring alignments through matches of <i>k</i> consecutively sampled minimizers (k-min-mers) and only indexing k-min-mers that occur once in the reference genome, thereby unlocking ultrafast mapping while retaining high sensitivity. We show that mapquik significantly accelerates the seeding and chaining steps-fundamental bottlenecks to read mapping-for both the human and maize genomes with [Formula: see text] sensitivity and near-perfect specificity. On the human genome, for both real and simulated reads, mapquik achieves a [Formula: see text] speedup over the state-of-the-art tool minimap2, and on the maize genome, mapquik achieves a [Formula: see text] speedup over minimap2, making mapquik the fastest mapper to date. These accelerations are enabled from not only minimizer-space seeding but also a novel heuristic [Formula: see text] pseudochaining algorithm, which improves upon the long-standing [Formula: see text] bound. Minimizer-space computation builds the foundation for achieving real-time analysis of long-read sequencing data.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2023.06.21.545862": {
                "title": "Exact Sketch-Based Read Mapping",
                "abstract": "Abstract\n                Given a sequencing read, the broad goal of read mapping is to find the location(s) in the reference genome that have a \u201csimilar sequence\u201d. Traditionally, \u201csimilar sequence\u201d was defined as having a high alignment score and read mappers were viewed as heuristic solutions to this well-defined problem. For sketch-based mappers, however, there has not been a problem formulation to capture what problem an exact sketch-based mapping algorithm should solve. Moreover, there is no sketch-based method that can find all possible mapping positions for a read above a certain score threshold.\n                \n                  In this paper, we formulate the problem of read mapping at the level of sequence sketches. We give an exact dynamic programming algorithm that finds all hits above a given similarity threshold. It runs in \ud835\udcaa (|\n                  t\n                  | + |\n                  p\n                  | +\n                  \u2113\n                  2\n                  ) time and \u0398(\n                  \u2113\n                  2\n                  ) space, where |\n                  t\n                  | is the number of\n                  k\n                  -mers inside the sketch of the reference, |\n                  p\n                  | is the number of\n                  k\n                  -mers inside the read\u2019s sketch and\n                  \u2113\n                  is the number of times that\n                  k\n                  -mers from the pattern sketch occur in the sketch of the text. We evaluate our algorithm\u2019s performance in mapping long reads to the T2T assembly of human chromosome Y, where ampliconic regions make it desirable to find all good mapping positions. For an equivalent level of precision as minimap2, the recall of our algorithm is 0.88, compared to only 0.76 of minimap2.\n                \n                \n                  2012 ACM Subject Classification\n                  Applied computing \u2192 Computational biology\n                ",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1145/3571723": {
                "title": "Theoretical Analysis of Sequencing Bioinformatics Algorithms and Beyond",
                "abstract": "A case study reveals the theoretical analysis of algorithms is not always as helpful as standard dogma might suggest.",
                "disciplines": []
            },
            "10.1101/2023.05.12.540616": {
                "title": "Compression algorithm for colored de Bruijn graphs",
                "abstract": "Abstract  A colored de Bruijn graph (also called a set of k-mer sets), is a set of k-mers with every k-mer assigned a set of colors. Colored de Bruijn graphs are used in a variety of applications, including variant calling, genome assembly, and database search. However, their size has posed a scalability challenge to algorithm developers and users. There have been numerous indexing data structures proposed that allow to store the graph compactly while supporting fast query operations. However, disk compression algorithms, which do not need to support queries on the compressed data and can thus be more space-efficient, have received little attention. The dearth of specialized compression tools has been a detriment to tool developers, tool users, and reproducibility efforts. In this paper, we develop a new tool that compresses colored de Bruijn graphs to disk, building on previous ideas for compression of k-mer sets and indexing colored de Bruijn graphs. We test our tool, called ESS-color, on various datasets, including both sequencing data and whole genomes. ESS-color achieves better compression than all evaluated tools and all datasets, with no other tool able to consistently achieve less than 44% space overhead. The software is available at http://github.com/medvedevgroup/ESSColor . ",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2023.03.02.530874": {
                "title": "Transcript Isoform Diversity of Ampliconic Genes on the Y Chromosome of Great Apes",
                "abstract": "Y-chromosomal Ampliconic Genes (YAGs) are important for male fertility, as they encode proteins functioning in spermatogenesis. The variation in copy number and expression levels of these multicopy gene families has been recently studied in great apes, however, the diversity of splicing variants remains unexplored. Here we deciphered the sequences of polyadenylated transcripts of all nine YAG families (<i>BPY2</i>, <i>CDY</i>, <i>DAZ</i>, <i>HSFY</i>, <i>PRY</i>, <i>RBMY</i>, <i>TSPY</i>, <i>VCY</i>, and <i>XKRY</i>) from testis samples of six great ape species (human, chimpanzee, bonobo, gorilla, Bornean orangutan, and Sumatran orangutan). To achieve this, we enriched YAG transcripts with capture-probe hybridization and sequenced them with long (Pacific Biosciences) reads. Our analysis of this dataset resulted in several findings. First, we uncovered a high diversity of YAG transcripts across great apes. Second, we observed evolutionarily conserved alternative splicing patterns for most YAG families except for <i>BPY2</i> and <i>PRY</i>. Our results suggest that <i>BPY2</i> transcripts and predicted proteins in several great ape species (bonobo and the two orangutans) have independent evolutionary origins and are not homologous to human reference transcripts and proteins. In contrast, our results suggest that the <i>PRY</i> gene family, having the highest representation of transcripts without open reading frames, has been undergoing pseudogenization. Third, even though we have identified many species-specific protein-coding YAG transcripts, we have not detected any signatures of positive selection. Overall, our work illuminates the YAG isoform landscape and its evolutionary history, and provides a genomic resource for future functional studies focusing on infertility phenotypes in humans and critically endangered great apes.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            },
            "10.1101/2023.01.30.526175": {
                "title": "The omnitig framework can improve genome assembly contiguity in practice",
                "abstract": "Despite the long history of genome assembly research, there remains a large gap between the theoretical and practical work. There is practical software with little theoretical underpinning of accuracy on one hand and theoretical algorithms which have not been adopted in practice on the other. In this paper we attempt to bridge the gap between theory and practice by showing how the theoretical safe-and-complete framework can be integrated into existing assemblers in order to improve contiguity. The optimal algorithm in this framework, called the omnitig algorithm, has not been used in practice due to its complexity and its lack of robustness to real data. Instead, we pursue a simplified notion of omnitigs, giving an efficient algorithm to compute them and demonstrating their safety under certain conditions. We modify two assemblers (wtdbg2 and Flye) by replacing their unitig algorithm with the simple omnitig algorithm. We test our modifications using real HiFi data from the Drosophilia melanogaster and the Caenorhabditis elegans genome. Our modified algorithms lead to a substantial improvement in alignment-based contiguity, with negligible computational costs and either no or a small increase in the number of misassemblies.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2022.12.23.521809": {
                "title": "mapquik: Efficient low-divergence mapping of long reads in minimizer space",
                "abstract": "Abstract  DNA sequencing data continues to progress towards longer reads with increasingly lower sequencing error rates. We focus on the critical problem of mapping, or aligning, low-divergence sequences from long reads (PacBio HiFi) to a reference genome, which poses challenges in terms of accuracy and computational resources when using cutting-edge read mapping approaches that are designed for all types of alignments. A natural idea would be to optimize efficiency with longer seeds to reduce the probability of extraneous matches; however, contiguous exact seeds quickly reach a sensitivity limit. We introduce mapquik , a novel strategy that creates accurate longer seeds by anchoring alignments through matches of k consecutively-sampled minimizers ( k -min-mers) and only indexing k -min-mers that occur once in the reference genome, thereby unlocking ultra-fast mapping while retaining high sensitivity. We demonstrate that mapquik significantly accelerates the seeding and chaining steps \u2014 fundamental bottlenecks to read mapping \u2014 for both the human and maize genomes with > 96% sensitivity and near-perfect specificity. On the human genome, mapquik achieves a 30\u00d7 speed-up over the state-of-the-art tool minimap2 , and on the maize genome, a 350\u00d7 speed-up over minimap2 , making mapquik the fastest mapper to date. These accelerations are enabled not only by minimizer-space seeding but also a novel heuristic \ud835\udcaa( n ) pseudo-chaining algorithm, which improves over the long-standing \ud835\udcaa( n log n ) bound. Minimizer-space computation builds the foundation for achieving real-time analysis of long-read sequencing data. ",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            }
        }
    },
    "12969730": {
        "title": "Addressing Unmet Social Needs among Hospitalized Children",
        "abstract": "PROJECT SUMMARY/ABSTRACT Even before COVID-19, nearly 1.6 million US children experienced homelessness1 and 14% lived in food insecure households.2 Strong associations between children\u2019s health and these unmet social needs3-9 has led many organizations to endorse screening patients for social risks in clinical settings and connecting them to community resources.10-16 Pediatric clinic-to-community linking interventions have shown beneficial health effects in non-hospital settings.17,18 However, there is little evidence about how unmet social needs affect hospitalized children and how to effectively address these needs during inpatient clinical care. Dr. Pantell\u2019s long-term goal is to become an independent investigator leading the development, testing, and implementation of interventions to address unmet social needs in clinical settings to improve patient and population health. His overall objective is to identify which unmet social needs are most strongly associated with unplanned health care utilization among hospitalized children, and then conduct a pilot trial to determine the feasibility and acceptability of implementing a caregiver- and care team member-informed protocol for screening for and addressing these needs in the pediatric inpatient setting. The central hypothesis of his work is that providing resources to address social needs during children\u2019s hospitalizations will increase linkages to social resources, improve health, and reduce unplanned health care utilization. The rationale is that understanding how to successfully implement social care protocols will be crucial to scaling the integration of evidence-based social interventions into clinical settings. To pursue his objective, Dr. Pantell will pursue these specific aims: 1) Use electronic health records (EHRs) to examine associations between unmet social needs and unplanned health care utilization among hospitalized pediatric patients; 2) Use qualitative methods to explore caregiver and care team member perspectives on social needs screening to inform the development of effective inpatient social needs screening strategies and interventions; 3) Conduct a pilot trial to determine the feasibility and acceptability of implementing an inpatient social needs screening and intervention protocol in a tertiary pediatric hospital setting. The proposed work is innovative in its use of a novel method (natural language processing \u2013 a text-mining tool) to address an understudied population (hospitalized children) and advance an underdeveloped area for intervention (addressing social needs). It is significant as it will help advance understanding of 1) which unmet social needs are most strongly related to health outcomes among children; and 2) how to effectively implement protocols in the inpatient setting to address these social needs in order to improve health among children and low-income families, AHRQ priority populations. To successfully pursue his proposed specific aims, Dr. Pantell will receive training in natural language processing, qualitative research, and the conduct of clinical trials through didactic courses and experiential studies at the University of California, San Francisco, where he is an Assistant Professor. He will also be guided by a team of mentors and advisors whose expertise includes EHR research, natural language processing, qualitative methods, social intervention implementation, and the conduct of clinical trials.",
        "disciplines": [
            "4203",
            "4206"
        ],
        "publications": {
            "10.1038/s41390-023-02992-6": {
                "title": "Associations between Social Adversity and Biomarkers of Inflammation, Stress, and Aging in Children",
                "abstract": "BackgroundPrior work has found relationships between childhood social adversity and\u00a0biomarkers of stress, but knowledge gaps remain. To help address these gaps, we explored associations between social adversity and biomarkers of inflammation (interleukin-1\u03b2 [IL-1\u03b2], IL-6, IL-8, tumor necrosis factor-alpha [TNF-\u03b1], and salivary cytokine hierarchical \u201cclusters\u201d based on the three interleukins), neuroendocrine function (cortisol, cortisone, dehydroepiandrosterone, testosterone, and progesterone), neuromodulation (N-arachidonoylethanolamine, stearoylethanolamine, oleoylethanolamide, and palmitoylethanolamide), and epigenetic aging (Pediatric-Buccal-Epigenetic clock).MethodsWe collected biomarker samples of children ages 0\u201317 recruited from an acute care pediatrics clinic and examined their associations with caregiver-endorsed education, income, social risk factors, and\u00a0cumulative adversity. We calculated regression-adjusted means for each biomarker and compared associations with social factors using Wald tests. We used logistic regression to predict being in the highest cytokine cluster based on social predictors.ResultsOur final sample included 537 children but varied based on each biomarker. Cumulative social adversity was significantly associated with having higher levels of all inflammatory markers and with cortisol, displaying a U-shaped distribution. There were no significant relationships between cumulative social adversity and cortisone, neuromodulation biomarkers or epigenetic aging.ConclusionOur findings support prior work suggesting that social stress exposures contribute to increased inflammation in children.ImpactOur study is one of the largest studies examining associations between childhood social adversity and biomarkers of inflammation, neuroendocrine function, neuromodulation, and epigenetic aging. It is one of the largest studies to link childhood social adversity to biomarkers of inflammation, and the first of which we are aware to link cumulative social adversity to cytokine clusters. It is also one of the largest studies to examine associations between steroids and epigenetic aging among children, and one of the only studies of which we are aware to examine associations between social adversity and endocannabinoids among children. Clinical Trial Registration: NCT02746393",
                "disciplines": [
                    "3213"
                ]
            },
            "10.1001/jama.2023.20358": {
                "title": "Hospital Characteristics Associated With Social Needs Activities in the US",
                "abstract": "This study assesses what hospital characteristics, including hospital participation in payment and delivery reform, are associated with activities related to health-related social needs.",
                "disciplines": [
                    "4203"
                ]
            },
            "10.1542/hpeds.2023-007246": {
                "title": "Social and Medical Care Integration Practices Among Children's Hospitals.",
                "abstract": "OBJECTIVES: In response to evidence linking social risk factors and adverse health outcomes, new incentives have emerged for hospitals to screen for adverse social determinants of health (SDOH). However, little information is available about the current state of social risk-related care practices among children's hospitals. To address outstanding knowledge gaps, we sought to describe social risk-related care practices among a national sample of children's hospitals.\nMETHODS: We analyzed responses to the 2020 American Hospital Association Annual Survey. Among children's hospitals, we calculated the prevalence of screening for social needs, strategies to address social risks/needs, partnerships with community-based organizations to address social risks/needs at the individual and community level, and rates of impact assessments of how social risk-related interventions affect outcomes. We also used \u03c72 tests to compare results by hospital characteristics. We weighted results to adjust for nonresponse.\nRESULTS: The sample included 82 children's hospitals. A total of 79.6% screened for and 96.0% had strategies to address at least 1 social risk factor, although rates varied by SDOH domain. Children's hospitals more commonly partnered with community-based organizations to address patient-level social risks than to participate in community-level initiatives. A total of 39.2% of hospitals assessed SDOH intervention effectiveness. Differences in social risk-related care practices commonly varied by hospital ownership and Medicaid population but not by region.\nCONCLUSIONS: We found wide variability in social risk-related care practices among children's hospitals based on the risk domain and hospital characteristics. Findings can be used to monitor whether social risk-related care practices change in the setting of new incentives.",
                "disciplines": [
                    "4203",
                    "4206"
                ]
            },
            "10.1016/j.jpeds.2023.113499": {
                "title": "Structural Racism Operationalized via Adverse Social Events in a Single-Center\u00a0Neonatal Intensive Care Unit",
                "abstract": "OBJECTIVE: To evaluate structural racism in the neonatal intensive care unit (NICU) by determining if differences in adverse social events occur by racialized groups.\nSTUDY DESIGN: Retrospective cohort study of 3290 infants hospitalized in a single center NICU between 2017 and 2019 in the Racial and Ethnic Justice in Outcomes in Neonatal Intensive Care (REJOICE) study. Demographics and adverse social events including infant urine toxicology screening, child protective services (CPS) referrals, behavioral contracts, and security emergency response calls were collected from electronic medical records. Logistic regression models were fit to test the association of race/ethnicity and adverse social events, adjusting for length of stay. Racial/ethnic groups were compared with a White referent group.\nRESULTS: There were 205 families (6.2%) that experienced an adverse social event. Black families were more likely to have experienced a CPS referral and a urine toxicology screen (OR, 3.6; 95% CI, 2.2-6.1 and OR, 2.2; 95% CI, 1.4-3.5). American Indian and Alaskan Native families were also more likely to experience CPS referrals and urine toxicology screens (OR, 15.8; 95% CI, 6.9-36.0 an OR, 7.6; 95% CI, 3.4-17.2). Black families were more likely to experience behavioral contracts and security emergency response calls. Latinx families had a similar risk of adverse events, and Asian families were less likely to experience adverse events.\nCONCLUSIONS: We found racial inequities in adverse social events in a single-center NICU. Investigation of generalizability is necessary to develop widespread strategies to address institutional and societal structural racism and to prevent adverse social events.",
                "disciplines": [
                    "3213"
                ]
            },
            "10.1093/jamia/ocad053": {
                "title": "The association between prescription drug monitoring programs and controlled substance prescribing: a cross-sectional study using data from 2019 National Electronic Health Records Survey.",
                "abstract": "OBJECTIVE: The use of controlled medications such as opioids, stimulants, anabolic steroids, depressants, and hallucinogens has led to an increase in addiction, overdose, and death. Given the high attributes of abuse and dependency, prescription drug monitoring programs (PDMPs) were introduced in the United States as a state-level intervention.\nMATERIALS AND METHODS: Using cross-sectional data from the 2019 National Electronic Health Records Survey, we assessed the association between PDMP usage and reduced or eliminated controlled substance prescribing as well as the association between PDMP usage and changing a controlled substance prescription to a nonopioid pharmacologic therapy or nonpharmacologic therapy. We applied survey weights to produce physician-level estimates from the survey sample.\nRESULTS: Adjusting for physician age, sex, type of medical degree, specialty, and ease of PDMP, we found that physicians who reported \"often\" PDMP usage had 2.34 times the odds of reducing or eliminating controlled substance prescriptions compared to physicians who reported never using the PDMP (95% confidence interval [CI] 1.12-4.90). Adjusting for physician age, sex, type of doctor, and specialty, we found that physicians who reported \"often\" use of the PDMP had 3.65 times the odd of changing controlled substance prescriptions to a nonopioid pharmacologic therapy or nonpharmacologic therapy (95% CI: 1.61-8.26).\nDISCUSSION: These results support the continued use, investment, and expansion of PDMPs as an effective intervention for reducing controlled substance prescription and changing to nonopioid/pharmacologic therapy.\nCONCLUSION: Overall, frequent usage of PDMPs was significantly associated with reducing, eliminating, or changing controlled substance prescription patterns.",
                "disciplines": [
                    "4203"
                ]
            },
            "10.1093/jamia/ocac251": {
                "title": "Characterizing the relative frequency of clinician engagement with structured social determinants of health data",
                "abstract": "OBJECTIVE: Electronic health records (EHRs) are increasingly used to capture social determinants of health (SDH) data, though there are few published studies of clinicians' engagement with captured data and whether engagement influences health and healthcare utilization. We compared the relative frequency of clinician engagement with discrete SDH data to the frequency of engagement with other common types of medical history information using data from inpatient hospitalizations.\nMATERIALS AND METHODS: We created measures of data engagement capturing instances of data documentation (data added/updated) or review (review of data that were previously documented) during a hospitalization. We applied these measures to four domains of EHR data, (medical, family, behavioral, and SDH) and explored associations between data engagement and hospital readmission risk.\nRESULTS: SDH data engagement was associated with lower readmission risk. Yet, there were lower levels of SDH data engagement (8.37% of hospitalizations) than medical (12.48%), behavioral (17.77%), and family (14.42%) history data engagement. In hospitalizations where data were available from prior hospitalizations/outpatient encounters, a larger proportion of hospitalizations had SDH data engagement than other domains (72.60%).\nDISCUSSION: The goal of SDH data collection is to drive interventions to reduce social risk. Data on when and how clinical teams engage with SDH data should be used to inform informatics initiatives to address health and healthcare disparities.\nCONCLUSION: Overall levels of SDH data engagement were lower than those of common medical, behavioral, and family history data, suggesting opportunities to enhance clinician SDH data engagement to support social services referrals and quality measurement efforts.",
                "disciplines": [
                    "4203"
                ]
            }
        }
    },
    "12964047": {
        "title": "Role of PTPRT in colon cancer progression and metastasis",
        "abstract": "Protein tyrosine phosphatase receptor T (PTPRT) is frequently mutated in human cancers, including colorectal cancer. PTPRT has two tyrosine phosphatase domains. While the membrane-proximal domain is an active protein tyrosine phosphatase, it has been thought that the C-terminal domain is a pseudo-phosphatase lacking enzymatic activity. Our preliminary data demonstrated that the pseudo-phosphatase domain of PTPRT is an active enzyme, termed denitrase, that removes nitro-groups (NO\u2082 at the 3-carbon position of the phenol ring of tyrosine) from the Y333 residue in ERK and Y404 residue paxillin. We demonstrated that nitro-Y333 (nY333) Erk increases its kinase activity, whereas nitro-Y404 (nY404) paxillin is likely to transduce cell signal through a \u201creader\u201d (nY binding protein). Further, we generated denitrase-inactivating mutant knockin mice and showed that the mutant mice are susceptible to carcinogen-induced colon tumor development. Recently, several recent bioinformatics studies demonstrated that PTPRT mutations, including those in the denitrase domain, are enriched in metastatic colorectal cancers, suggesting that inactivation of PTPRT denitrase promotes tumor metastasis. Thus, we hypothesize that the PTPRT-regulated ERK and paxillin nitration signaling pathways play a critical role in colorectal progression and metastasis. Three aims are proposed to test this central hypothesis by determining the role of: (1) PTPRT denitrase-regulated paxillin nitration signaling in colorectal cancer progression and invasion; and (2) PTPRT denitrase-regulated Erk nitration signaling in colorectal cancer progression and metastasis. Protein tyrosine nitration is currently believed to be a byproduct of reactive oxygen/nitrogen species and not regulated by enzymes. Success in our proposed studies will establish protein tyrosine nitration as a critical player in colorectal tumor progression and metastasis.",
        "disciplines": [
            "3101",
            "3211"
        ],
        "publications": {
            "10.1038/s41598-024-54655-z": {
                "title": "AI is a viable alternative to high throughput screening: a 318-target study",
                "abstract": "High throughput screening (HTS) is routinely used to identify bioactive small molecules. This requires physical compounds, which limits coverage of accessible chemical space. Computational approaches combined with vast on-demand chemical libraries can access far greater chemical space, provided that the predictive accuracy is sufficient to identify useful molecules. Through the largest and most diverse virtual HTS campaign reported to date, comprising 318 individual projects, we demonstrate that our AtomNet\u00ae convolutional neural network successfully finds novel hits across every major therapeutic area and protein class. We address historical limitations of computational screening by demonstrating success for target proteins without known binders, high-quality X-ray crystal structures, or manual cherry-picking of compounds. We show that the molecules selected by the AtomNet\u00ae model are novel drug-like scaffolds rather than minor modifications to known bioactive compounds. Our empirical results suggest that computational methods can substantially replace HTS as the first step of small-molecule drug discovery.",
                "disciplines": [
                    "4613",
                    "3404",
                    "3303"
                ]
            },
            "10.1172/jci175031": {
                "title": "Neutrophil extracellular traps induced by chemotherapy inhibit tumor growth in vivo",
                "abstract": "Neutrophil extracellular traps (NETs), a web-like structure of cytosolic and granule proteins assembled on decondensed chromatin, kill pathogens and cause tissue damage in diseases. Whether NETs can kill cancer cells is unexplored. Here, we report that a combination of glutaminase inhibitor CB-839 and 5-FU inhibited the growth of PIK3CA-mutant colorectal cancers (CRCs) in xenograft, syngeneic, and genetically engineered mouse models in part through NETs. Disruption of NETs by either DNase I treatment or depletion of neutrophils in CRCs attenuated the efficacy of the drug combination. Moreover, NETs were present in tumor biopsies from patients treated with the drug combination in a phase II clinical trial. Increased NET levels in tumors were associated with longer progression-free survival. Mechanistically, the drug combination induced the expression of IL-8 preferentially in PIK3CA-mutant CRCs to attract neutrophils into the tumors. Further, the drug combination increased the levels of ROS in neutrophils, thereby inducing NETs. Cathepsin G (CTSG), a serine protease localized in NETs, entered CRC cells through the RAGE cell surface protein. The internalized CTSG cleaved 14-3-3 proteins, released BAX, and triggered apoptosis in CRC cells. Thus, our studies illuminate a previously unrecognized mechanism by which chemotherapy-induced NETs kill cancer cells.",
                "disciplines": [
                    "3101",
                    "3211"
                ]
            },
            "10.3389/fgene.2023.1304425": {
                "title": "Unveiling immune checkpoint regulation: exploring the power of in vivo CRISPR screenings in cancer immunotherapy",
                "abstract": "Immune checkpoint inhibitors (ICIs) have revolutionized cancer immunotherapy by reinvigorating antitumor immune responses, but their efficacy remains limited in most patients. To address this challenge and optimize Immune check inhibitor treatment, understanding the underlying molecular intricacies involved is crucial. The emergence of CRISPR-Cas9 technology has empowered researchers to precisely investigate gene function and has introduced transformative shifts in identifying key genes for various physiological and pathological processes. CRISPR screenings, particularly <i>in vivo</i> CRISPR screenings, have become invaluable tools in deciphering molecular networks and signaling pathways governing suppressive immune checkpoint molecules. In this review, we provide a comprehensive overview of <i>in vivo</i> CRISPR screenings in cancer immunotherapy, exploring how this cutting-edge technology has unraveled potential novel therapeutic targets and combination strategies. We delve into the latest findings and advancements, shedding light on immune checkpoint regulation and offering exciting prospects for the development of innovative and effective treatments for cancer patients.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.1186/s13578-023-01102-7": {
                "title": "Phosphorylation at tyrosine 317 and 508 are crucial for PIK3CA/p110\u03b1 to promote CRC tumorigenesis",
                "abstract": "BackgroundPI3K/AKT signaling pathway plays important role in tumorigenesis of human cancer. Protein phosphorylation is crucial for signaling transduction of this pathway. PIK3CA, encoding the catalytic subunit p110\u03b1 of PI3K complex, is one of the most frequently mutated oncogenes in human cancers. However, phosphorylation sites of PIK3CA/p110\u03b1 and their underlying mechanism in tumorigenesis are largely unknown.MethodsTyrosine phosphorylation sites of PIK3CA/p110\u03b1 are identified with Mass-Spectrum. Crispr/CAS9 strategy is applied to generate Y317F and Y508F mutant knock-in cell clones. The growth and metastasis abilities of cells are evaluated in vitro and in vivo. Phospho-proteomics analysis and Western blots are used to demonstrate downstream signaling pathways of PIK3CA/p110\u03b1 tyrosine phosphorylation. In vitro kinase assay is applied to identify the kinase of PIK3CA/p110\u03b1 tyrosine phosphorylation.ResultsTyrosine phosphorylation of PIK3CA/p110\u03b1 is stimulated by growth factors such as EGF, HGF and PDGF. Two tyrosine residues, Y317 and Y508, are identified on PIK3CA/p110\u03b1. Either Y317 or Y508 phosphorylation is essential for tumorigenesis of CRC. Mutation at Y317 of p110\u03b1 reduces the proliferation, migration, and invasion of cancer cells through Src-MLC2 pathway, while mutation at Y508 of p110\u03b1 impairs AKT signaling. Moreover, Src interacts with and phosphorylates p110\u03b1.ConclusionsPIK3CA/p110\u03b1 phosphorylation at Y317 and Y508 play important role in tumorigenesis of colorectal cancer through two independent pathways.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1016/j.gendis.2022.11.003": {
                "title": "PD-L1 expression is regulated by ATP-binding of the ERBB3 pseudokinase domain",
                "abstract": "How PD-L1 expression is regulated in cancer is poorly understood. Here, we report that the ATP-binding activity of ERBB3 pseudokinase regulates PD-L1 gene expression in colorectal cancers (CRCs). ERBB3 is one of the four members of the EGF receptor family, all with protein tyrosine kinase domains. ERBB3 is a pseudokinase with a high binding affinity to ATP. We showed that ERBB3 ATP-binding inactivation mutant reduces tumorigenicity in genetically engineered mouse models and impairs xenograft tumor growth of CRC cell lines. The ERBB3 ATP-binding mutant cells dramatically reduce IFN-\u03b3-induced PD-L1 expression. Mechanistically, ERBB3 regulates IFN-\u03b3-induced PD-L1 expression through the IRS1-PI3K-PDK1-RSK-CREB signaling axis. CREB is the transcription factor that regulates PD-L1 gene expression in CRC cells. Knockin of a tumor-derived ERBB3 mutation located in the kinase domain sensitizes mouse colon cancers to anti-PD1 antibody therapy, suggesting that ERBB3 mutations could be predictive biomarkers for tumors amenable to immune checkpoint therapy.",
                "disciplines": [
                    "3211",
                    "3204"
                ]
            }
        }
    },
    "12964395": {
        "title": "Clinical Translation of a One-Stop-Shop Imaging Method for Abdominal CT",
        "abstract": "ABSTRACT CT imaging is one of the primary diagnostic tools utilized in modern radiology departments, and its importance to modern medicine cannot be overstated. In recent years, spectral CT technologies have been developed to address one of the long-standing technical limitations associated with conventional single-kV CT imaging: anatomical structures with different material compositions may have the same CT number for a given acquisition. Current spectral CT imaging systems have been implemented using advanced x-ray source and/or detector technologies that enable image objects to be rapidly scanned using two distinct x-ray spectra. However, these hardware-based spectral CT systems are not without their own intrinsic limitations. Such limitations include a reduced field-of-view, slower scan speeds, misregistration between the high kV and low kV measurements in dual source systems, lack of tube current modulation for many fast kV-switching systems, and having other clinical workflow/efficiency challenges. In this application, we propose to implement and translate a novel single- kV spectral CT imaging method for abdominal CT applications that overcomes the limitations associated with current spectral CT imaging methods. With this new method, all conventional contrast-enhanced single-kV abdominal CT exams can be used to generate a deluxe series of CT images with the desired spectral CT functionalities including virtual non-contrast CT images, virtual mono-energetic CT images, and quantitative material basis images (i.e., one-stop-shop). This new method enables an integrated clinical workflow to improve clinical diagnostic accuracy while reducing both radiation dose and contrast dose to patients, all while reducing overall healthcare costs. Three specific aims will be carried out to accomplish the overarching objective of this project: 1) Implement and optimize techniques to achieve one-stop-shop single-kV spectral CT imaging for abdominal applications; 2) Validate the proposed one-stop-shop single-kV spectral CT imaging method using the hardware based spectral CT imaging methods; and 3) translate the one-stop-shop single-kV spectral CT imaging method to the clinical environment for clinical performance evaluations. Upon the completion of this project, a unique one-stop-shop CT imaging paradigm will have been implemented and translated to clinical abdominal CT exams to enable one-stop-shop abdominal CT diagnoses with just a single-kV contrast-enhanced CT acquisition. This new technique can be made available to all types of imaging facilities including community hospitals or clinics in developing nations, which is in stark contrast to hardware dual-energy CT and photon counting CT imaging which has been traditionally reserved to high profile academic medical centers that can afford the latest technological platforms.",
        "disciplines": [
            "5105"
        ],
        "publications": {
            "10.1002/mp.16880": {
                "title": "Deep\u2010Interior: A new pathway to interior tomographic image reconstruction via a weighted backprojection and deep learning",
                "abstract": "BACKGROUND: In recent years, deep learning strategies have been combined with either the filtered backprojection or iterative methods or the direct projection-to-image by deep learning only to reconstruct images. Some of these methods can be applied to address the interior reconstruction problems for centered regions of interest (ROIs) with fixed sizes. Developing a method to enable interior tomography with arbitrarily located ROIs with nearly arbitrary ROI sizes inside a scanning field of view (FOV) remains an open\u00a0question.\nPURPOSE: To develop a new pathway to enable interior tomographic reconstruction for arbitrarily located ROIs with arbitrary sizes using a single trained deep neural network model.\nMETHODS: The method consists of two steps. First, an analytical weighted backprojection reconstruction algorithm was developed to perform domain transform from divergent fan-beam projection data to an intermediate image feature space, <math> <semantics><mrow><mi>B</mi> <mo>(</mo> <mover><mi>x</mi> <mo>\u20d7</mo></mover> <mo>)</mo></mrow> <annotation>$B(\\vec{x})$</annotation></semantics> </math> , for an arbitrary size ROI at an arbitrary location inside the FOV. Second, a supervised learning technique was developed to train a deep neural network architecture to perform deconvolution to obtain the true image <math> <semantics><mrow><mi>f</mi> <mo>(</mo> <mover><mi>x</mi> <mo>\u20d7</mo></mover> <mo>)</mo></mrow> <annotation>$f(\\vec{x})$</annotation></semantics> </math> from the new feature space <math> <semantics><mrow><mi>B</mi> <mo>(</mo> <mover><mi>x</mi> <mo>\u20d7</mo></mover> <mo>)</mo></mrow> <annotation>$B(\\vec{x})$</annotation></semantics> </math> . This two-step method is referred to as Deep-Interior for convenience. Both numerical simulations and experimental studies were performed to validate the proposed Deep-Interior method.\nRESULTS: The results showed that ROIs as small as a diameter of 5 cm could be accurately reconstructed (similarity index 0.985 \u00b1 0.018 on internal testing data and 0.940 \u00b1 0.025 on external testing data) at arbitrary locations within an imaging object covering a wide variety of anatomical structures of different body parts. Besides, ROIs of arbitrary size can be reconstructed by stitching small ROIs without additional\u00a0training.\nCONCLUSION: The developed Deep-Interior framework can enable interior tomographic reconstruction from divergent fan-beam projections for short-scan and super-short-scan acquisitions for small ROIs (with a diameter larger than 5 cm) at an arbitrary location inside the scanning FOV with high quantitative reconstruction accuracy.",
                "disciplines": [
                    "5105",
                    "4003"
                ]
            },
            "10.1002/mp.16352": {
                "title": "A quality\u2010checked and physics\u2010constrained deep learning method to estimate material basis images from single\u2010kV contrast\u2010enhanced chest CT scans",
                "abstract": "BACKGROUND: Single-kV CT imaging is one of the primary imaging methods in radiology practices. However, it does not provide material basis images for some subtle lesion characterization tasks in clinical diagnosis.\nPURPOSE: To develop a quality-checked and physics-constrained deep learning (DL) method to estimate material basis images from single-kV CT data without resorting to dual-energy CT acquisition schemes.\nMETHODS: Single-kV CT images are decomposed into two material basis images using a deep neural network. The role of this network is to generate a feature space with 64 template features with the same matrix dimensions of the input single-kV CT image. These 64 template image features are then combined to generate the desired material basis images with different sets of combination coefficients, one for each material basis image. Dual-energy CT image acquisitions with two separate kVs were curated to generate paired training data between a single-kV CT image and the corresponding two material basis images. To ensure the obtained two material basis images are consistent with the encoded spectral information in the actual projection data, two physics constraints, that is, (1) effective energy of each measured projection datum that characterizes the beam hardening in data acquisitions and (2) physical factors of scanners such as detector and tube characteristics, are incorporated into the end-to-end training. The entire architecture is referred to as Deep-En-Chroma in this paper. In the application stage, the generated material basis images are sent to a deep quality check (Deep-QC) network to assess the quality of estimated images and to report the pixel-wise estimation errors for users. The models were developed using 5592 training and validation pairs generated from 48 clinical cases. Additional 1526 CT images from another 13 patients were used to evaluate the quantitative accuracy of water and iodine basis images estimated by Deep-En-Chroma.\nRESULTS: For the iodine basis images estimated by Deep-En-Chroma, the mean difference with respect to dual-energy CT is -0.25 mg/mL, and the agreement limits are [-0.75 mg/mL, +0.24 mg/mL]. For the water basis images estimated by Deep-En-Chroma, the mean difference with respect to dual-energy CT is 0.0 g/mL, and the agreement limits are [-0.01 g/mL, 0.01 g/mL]. Across the test cohort, the median [25th, 75th percentiles] root mean square errors between the Deep-En-Chroma and dual-energy material images are 14 [12, 16] mg/mL for the water images and 0.73 [0.64, 0.80] mg/mL for the iodine images. When significant errors are present in the estimated material basis images, Deep-QC can capture these errors and provide pixel-wise error maps to inform users whether the DL results are\u00a0trustworthy.\nCONCLUSIONS: The Deep-En-Chroma network provides a new pathway to estimating the clinically relevant material basis images from single-kV CT data and the Deep-QC module to inform end-users of the accuracy of the DL material basis images in\u00a0practice.",
                "disciplines": [
                    "5105"
                ]
            }
        }
    },
    "12983607": {
        "title": "LTREB Renewal: Drivers of temperate forest carbon storage from canopy closure through successional time",
        "abstract": "Forest disturbances, such as clear-cutting and fire, typically lead to large losses of carbon and nutrients from forests and their soils. Virtually all forests in the Eastern US are recovering from such disturbances, whether natural or human-caused. It is, however, not well understood what mechanisms control recovery times of forest carbon and nutrient stocks following disturbance. Also not well known is how plant growth, soil development and climate variation interactively regulate recoveries of carbon and nutrients in aging forests. This project uses long-term experimental plots at the University of Michigan Biological Station (a 110-year-old field station in northern Michigan) to investigate how changes in forests lead to overall carbon capture and storage. Globally, forests remove approximately 1/4 of carbon emissions from fossil fuel combustion, with temperate forests, like those studied here, being responsible for almost half of that carbon removal from the atmosphere. However, it is uncertain whether forests will continue to partially offset human-derived carbon emissions as they age and mature following past large-scale disturbances. This project provides critical data and mechanistic understanding needed to predict the magnitude and duration of continued temperate forest carbon uptake, and the ability of forests to provide fiber, fuel, habitat, and many other benefits to society. This long-term (10-year) project began to answer globally significant questions in its productive first 5 years. Researchers are measuring the forests and soils in 6 forest stands (approx. 2 acres each) that were experimentally cut and burned in either 1936, 1948, 1954, 1980, 1998, or 2017. These cutting and burning treatments replicate larger-scale cutting and burning that occurred in the early 1900s across the Great Lakes region within which the experimental stands are nested. Forest structural measurements include patterns of tree, leaf, and branch density and arrangement. Soil measurements include both nutrient distribution and availability and soil carbon fluxes. By using nearby old forests (130- to >200-yr-old) that were not severely cut and burned as reference points, the team is linking disturbance, climate, soil, and vegetation controls to long-term patterns of carbon sequestration in forests that are representative of other forests across the northern U.S. and similar regions in Canada, Europe and Asia. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3007",
            "4102"
        ],
        "publications": {
            "10.1016/j.scitotenv.2022.158267": {
                "title": "Mechanistically-grounded pathways connect remotely sensed canopy structure to soil respiration",
                "abstract": "Variation in the soil-to-atmosphere C flux, or soil respiration (R<sub>s</sub>), is influenced by a suite of biotic and abiotic factors, including soil temperature, soil moisture, and root biomass. However, whether light detection and ranging (lidar)-derived canopy structure is tied to soil respiration through its simultaneous influence over these drivers is not known. We assessed relationships between measures of above- and belowground vegetation density and complexity, and evaluated whether R<sub>s</sub> is linked to remotely sensed canopy structure through pathways mediated by established biotic and abiotic mechanisms. Our results revealed that, at the stand-scale, canopy rugosity-a measure of complexity-and vegetation area index were coupled to soil respiration through their effects on light interception, soil microclimate, and fine root mass density, but this connection was stronger for complexity. Canopy and root complexity were not spatially coupled at the stand-scale, with canopy but not root complexity increasing through stand development. Our findings suggest that remotely sensed canopy complexity could be used to infer spatial variation in R<sub>s</sub>, and that this relationship is grounded in known mechanistic pathways. The broad spatial inference of soil respiration via remotely sensed canopy complexity requires multi-site observations of canopy structure and R<sub>s</sub>, which is possible given burgeoning open data from ecological networks and satellite remote sensing platforms.",
                "disciplines": [
                    "4013",
                    "3007"
                ]
            },
            "10.1016/j.foreco.2022.120301": {
                "title": "Fire after clear-cut harvesting minimally affects the recovery of ecosystem carbon pools and fluxes in a Great Lakes forest",
                "abstract": "Effective forest carbon (C) management requires an understanding of how stand-replacing disturbances affect C pools and fluxes over successional timescales, and how the growth of secondary forests compares with that of undisturbed forests. In the upper Great Lakes region, fires that followed clear-cut harvesting shaped a century-old cohort of secondary forests, but the long-term effects of fire on C cycling in this relatively fire-averse landscape remain poorly understood. We examined how two different stand-replacing disturbances \u2013 one with and the other without fire \u2013 influenced C pools and fluxes through a century of stand development, comparing secondary aspen-dominated (Populus) forests with legacy late successional stands encompassing the ages and species compositions that would be prevalent today in the absence of stand replacement. Our work at the University of Michigan Biological Station (UMBS) used experimental forest chronosequences established following clear-cut harvesting or clear-cut harvesting followed by fire, along with three\u00a0>\u00a0130-yr-old late successional deciduous broadleaf (DBF), evergreen needleleaf (ENF), and mixed (MIX) forest functional types. The successional trajectories and values of total (above- and belowground) ecosystem C mass, net primary production (NPP), and net ecosystem production (NEP) were similar regardless of whether fires occurred following clear-cut harvesting. Moreover, 80\u00a0+\u00a0year old secondary forests\u2019 C pools and fluxes were comparable to late successional ENF and MIX, but were at times lower than DBF. While the century-old secondary forests and legacy stands served as consistent C sinks over the last century, more extreme temperatures in recent years may be eroding NEP by accelerating C losses from soils. We conclude that the compounding effects of fire and clear-cut harvesting were similar to those from clear-cut harvesting alone, possibly because of the disturbance-adapted properties of pioneer species, most notably aspen; however, our results also suggest that changing climate rather than prior disturbance may jeopardize the future of this long-term terrestrial C sink.",
                "disciplines": [
                    "4102"
                ]
            },
            "10.1016/j.ecolind.2022.109004": {
                "title": "Disturbance has variable effects on the structural complexity of a temperate forest landscape",
                "abstract": "The temporal dynamics of forest canopy structure are influenced by disturbances that alter vegetation quantity and distribution. While canopy structural indicators such as leaf area index (LAI), canopy cover, and canopy height have been widely studied in the context of disturbance, the post-disturbance temporal dynamics of structural complexity, which summarizes the heterogeneity of vegetation arrangement, are poorly understood. With the goal of advancing conceptual and empirical understanding of the temporal dynamics of structural complexity following disturbance, we synthesized results from three large-scale disturbance manipulation experiments at the University of Michigan Biological Station (UMBS): the 4-year Forest Resilience Threshold Experiment (FoRTE) manipulating levels of disturbance severity; the decade-long Forest Accelerated Succession Experiment (FASET), in which all early successional tree species were stem-girdled within 39\u00a0ha in the same landscape; and forest chronosequences established following clear-cut harvesting. We found that the temporal dynamics of canopy structure following disturbance were dependent upon three factors: (1) the source and severity of disturbance; (2) the spatial and temporal scales of analysis; and (3) the measure of structure assessed. Unlike vegetation area index and canopy cover, which initially decreased in response to disturbance, structural complexity measures such as canopy and top rugosity did not consistently respond to moderate levels of disturbance severity. Over multi-decadal timescales, structural complexity increased to a maximum, regardless of whether fire occurred at the time of stand establishment, but intervening low-to-moderate severity disturbance in regrown century-old forests altered trajectories of canopy rugosity. We conclude that structural complexity indicators display a more nuanced temporal and directional response to disturbance than conventional leaf area and cover indexes. Predicting what disturbance conditions modify trajectories of structural complexity remains critical to disturbance characterization and the inference of ecosystem functioning.",
                "disciplines": [
                    "4102",
                    "3103"
                ]
            }
        }
    },
    "12929151": {
        "title": "Collaborative Research: HCC: Medium: Co-Design of Shape and Fabrication Plans for Direct-Ink Write Printing Through Predictive Simulation",
        "abstract": "Extrusion-based 3D printing is becoming an important tool in aerospace, automotive, medical, and defense applications, all of which require the highest confidence in their components. With the growth in the use of 3D-printed parts designed for cushioning, impact absorption, and integration of sensors and actuators, the importance of design tools that correctly account for and shape how a part is fabricated has never been more pronounced. Despite this need, current design tools focus exclusively on the part's outer geometric shape and ignore the printing process itself. In other words, the focus is on what is being printed rather than on how it's being printed, such as the path the printer nozzle takes when printing each layer of the part, despite the crucial effect the printing process has on the mechanical properties of the final part. This research will transform the design of 3D-printed parts by allowing users, for the first time, to design not only the part's shape but also its function. New algorithms developed by this project will automatically map from user-specified mechanical behavior to a Fabrication Plan that specifies the low-level details of how the printer should fabricate the part in order to achieve those goals. Since manufacturing applications excite students about STEM in an accessible, tangible way, this project will have additional broad impact by developing educational materials around the relationship between manufacturing and STEM careers, and by sharing project outcomes through established connections to local outreach efforts. This work will close the \"form-function design gap\" by creating new algorithms for co-designing both an object's macroscale shape and microscale fabrication plan, for 3D printers based on Direct-Ink-Write (DIW) technology. A microstructure-aware rod-based simulation will be developed to accurately analyze mechanical behavior of DIW-printed parts an order of magnitude more efficiently than traditional finite element methods. By allowing continuous variation of fabrication plans, the novel intermediate representation defined in this project will open the door for new interactive search and offline optimization strategies for additive manufacturing. Finally, the research will develop a novel bi-level optimization strategy that can jointly design object geometry and fabrication plan, while solving the challenge that each geometric design defines a different manifold of possible fabrication plans. The algorithms developed in this effort will be thoroughly tested against both mechanical experiments in the lab and simulated benchmarks. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4014"
        ],
        "publications": {
            "10.1073/pnas.2318333121": {
                "title": "Milestoning estimators of dissipation in systems observed at a coarse resolution",
                "abstract": "Many nonequilibrium, active processes are observed at a coarse-grained level, where different microscopic configurations are projected onto the same observable state. Such \"lumped\" observables display memory, and in many cases, the irreversible character of the underlying microscopic dynamics becomes blurred, e.g., when the projection hides dissipative cycles. As a result, the observations appear less irreversible, and it is very challenging to infer the degree of broken time-reversal symmetry. Here we show, contrary to intuition, that by ignoring parts of the already coarse-grained state space we may-via a process called milestoning-improve entropy-production estimates. We present diverse examples where milestoning systematically renders observations \"closer to underlying microscopic dynamics\" and thereby improves thermodynamic inference from lumped data assuming a given range of memory, and we hypothesize that this effect is quite general. Moreover, whereas the correct general physical definition of time reversal in the presence of memory remains unknown, we here show by means of physically relevant examples that at least for semi-Markov processes of first and second order, waiting-time contributions arising from adopting a naive Markovian definition of time reversal generally must be discarded.",
                "disciplines": [
                    "5103"
                ]
            },
            "10.1063/5.0158930": {
                "title": "Non-Markov models of single-molecule dynamics from information-theoretical analysis of trajectories",
                "abstract": "Whether single-molecule trajectories, observed experimentally or in molecular simulations, can be described using simple models such as biased diffusion is a subject of considerable debate. Memory effects and anomalous diffusion have been reported in a number of studies, but directly inferring such effects from trajectories, especially given limited temporal and/or spatial resolution, has been a challenge. Recently, we proposed that this can be achieved with information-theoretical analysis of trajectories, which is based on the general observation that non-Markov effects make trajectories more predictable and, thus, more \"compressible\" by lossless compression algorithms. Toy models where discrete molecular states evolve in time were shown to be amenable to such analysis, but its application to continuous trajectories presents a challenge: the trajectories need to be digitized first, and digitization itself introduces non-Markov effects that depend on the specifics of how trajectories are sampled. Here we develop a milestoning-based method for information-theoretical analysis of continuous trajectories and show its utility in application to Markov and non-Markov models and to trajectories obtained from molecular simulations.",
                "disciplines": []
            },
            "10.1145/3588432.3591521": {
                "title": "Data-Free Learning of Reduced-Order Kinematics",
                "abstract": "Physical systems ranging from elastic bodies to kinematic linkages are defined on high-dimensional configuration spaces, yet their typical low-energy configurations are concentrated on much lower-dimensional subspaces. This work addresses the challenge of identifying such subspaces automatically: given as input an energy function for a high-dimensional system, we produce a low-dimensional map whose image parameterizes a diverse yet low-energy submanifold of configurations. The only additional input needed is a single seed configuration for the system to initialize our procedure; no dataset of trajectories is required. We represent subspaces as neural networks that map a low-dimensional latent vector to the full configuration space, and propose a training scheme to fit network parameters to any system of interest. This formulation is effective across a very general range of physical systems; our experiments demonstrate not only nonlinear and very low-dimensional elastic body and cloth subspaces, but also more general systems like colliding rigid bodies and linkages. We briefly explore applications built on this formulation, including manipulation, latent interpolation, and sampling.",
                "disciplines": [
                    "4607"
                ]
            },
            "10.1063/5.0142166": {
                "title": "The effect of time resolution on the observed first passage times in diffusive dynamics",
                "abstract": "Single-molecule and single-particle tracking experiments are typically unable to resolve fine details of thermal motion at short timescales where trajectories are continuous. We show that, when a diffusive trajectory xt is sampled at finite time intervals \u03b4t, the resulting error in measuring the first passage time to a given domain can exceed the time resolution of the measurement by more than an order of magnitude. Such surprisingly large errors originate from the fact that the trajectory may enter and exit the domain while being unobserved, thereby lengthening the apparent first passage time by an amount that is larger than \u03b4t. Such systematic errors are particularly important in single-molecule studies of barrier crossing dynamics. We show that the correct first passage times, as well as other properties of the trajectories such as splitting probabilities, can be recovered via a stochastic algorithm that reintroduces unobserved first passage events probabilistically.",
                "disciplines": [
                    "3406"
                ]
            }
        }
    },
    "12965459": {
        "title": "Establishing CRISPR cell screening for the deer tick Ixodes scapularis, a vector of Lyme and other diseases",
        "abstract": "Project Summary/Abstract Prevention of tick-borne illnesses would be significantly aided by the availability of new strategies for uncovering the functions of tick genes. Ixodes scapularis is an arthropod vector of the Lyme disease spirochete Borrelia burgdorferi and other emerging human pathogens, including the rickettsial agent Anaplasma phagocytophilum, the flavivirus Powassan, and the parasite Babesia microti. Unfortunately, genetic studies of ticks are significantly hindered by practical barriers, including the approximately two-year life cycle of I. scapularis. An alternative approach is to perform CRISPR screening in cultured cells, which in other systems is an established robust and large-scale approach to uncovering new information about cellular activities and pathways. We have successfully developed a method for genome-wide CRISPR screening in insect cells that is extensible to ticks. In this R21 application, we will establish a genome-wide pooled CRISPR cell screening platform for I. scapularis cultured cells as a scientific resource for the community. Tick cell culture has been extensively used to investigate microbial interactions and can be used to predict the complex physiology of I. scapularis without the challenges associated with the long-life cycle of ticks. Specifically, we will use our combined knowledge of I. scapularis cultured cells and CRISPR cell screening to: (i) design single guide RNAs (sgRNAs) for CRISPR modification based on the reference genome sequence and other genome sequences of this species; (ii) identify appropriate U6 promoters for sgRNA expression in I. scapularis cells; (iii) modify cells for screening, such as by making the competent for recombination mediated cassette exchange (RMCE) and by introducing Cas9; and (iv) test and optimize the efficiency of CRISPR-based knockout strategies in these cells. Concurrent with this work, we will develop cell-based assays appropriate for pooled-format screens that interrogate tick immune signaling via the immune defense (IMD) and JAK/STAT pathways. Notably, the type of large-scale and unbiased approach we propose will provide an important complement to reverse genetic in vivo analyses. Establishment of CRISPR screening in I. scapularis cells will propel the field of tick biology forward at a rapid pace, provide novel insights into relationships between arthropod vectors and the microbes they host, foster collaborations between investigators with distinct expertise, and offer new opportunities for mentoring the next generation of scientists.",
        "disciplines": [
            "3009"
        ],
        "publications": {
            "10.1038/s41467-024-46494-3": {
                "title": "Tick hemocytes have a pleiotropic role in microbial infection and arthropod fitness",
                "abstract": "Uncovering the complexity of systems in non-model organisms is critical for understanding arthropod immunology. Prior efforts have mostly focused on Dipteran insects, which only account for a subset of existing arthropod species in nature. Here we use and develop advanced techniques to describe immune cells (hemocytes) from the clinically relevant tick Ixodes scapularis at a single-cell resolution. We observe molecular alterations in hemocytes upon feeding and infection with either the Lyme disease spirochete Borrelia burgdorferi or the rickettsial agent Anaplasma phagocytophilum. We reveal hemocyte clusters exhibiting defined signatures related to immunity, metabolism, and proliferation. Depletion of phagocytic hemocytes affects hemocytin and astakine levels, two I. scapularis hemocyte markers, impacting blood-feeding, molting behavior, and bacterial acquisition. Mechanistically, astakine alters hemocyte proliferation, whereas hemocytin affects the c-Jun N-terminal kinase (JNK) signaling pathway in I. scapularis. Altogether, we discover a role for tick hemocytes in immunophysiology and provide a valuable resource for comparative biology in arthropods.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1128/mbio.02479-23": {
                "title": "Genetic manipulation of an Ixodes scapularis cell line",
                "abstract": "Although genetic manipulation is one of the hallmarks of model organisms, its applicability to non-model species has remained difficult due to our limited understanding of their fundamental biology. For instance, manipulation of a cell line originated from the black-legged tick <i>Ixodes scapularis,</i> an arthropod that serves as a vector for several human pathogens, has yet to be established. Here, we demonstrate the successful genetic modification of the commonly used tick ISE6 line through ectopic expression and clustered regularly interspaced palindromic repeats [(CRISPR)/CRISPR-associated protein 9 (Cas9)] genome editing. We performed ectopic expression using nucleofection and attained CRISPR-Cas9 editing via homology-dependent recombination. Targeting the E3 ubiquitin ligase x-linked inhibitor of apoptosis (<i>xiap</i>) and its substrate <i>p47</i> led to an alteration in molecular signaling within the immune deficiency network and increased infection of the rickettsial agent <i>Anaplasma phagocytophilum</i> in <i>I. scapularis</i> ISE6 cells. Collectively, our findings complement techniques for the genetic engineering of <i>I. scapularis</i> ticks<i>,</i> which currently limit efficient and scalable molecular genetic screens <i>in vivo</i>.IMPORTANCEGenetic engineering in arachnids has lagged compared to insects, largely because of substantial differences in their biology. This study unveils the implementation of ectopic expression and CRISPR-Cas9 gene editing in a tick cell line. We introduced fluorescently tagged proteins in ISE6 cells and edited its genome via homology-dependent recombination. We ablated the expression of <i>xiap</i> and <i>p47</i>, two signaling molecules present in the immune deficiency (IMD) pathway of <i>Ixodes scapularis</i>. Impairment of the tick IMD pathway, an analogous network of the tumor necrosis factor receptor in mammals, led to enhanced infection of the rickettsial agent <i>Anaplasma phagocytophilum</i>. Altogether, our findings provide a critical technical resource to the scientific community to enable a deeper understanding of biological circuits in the black-legged tick <i>I. scapularis</i>.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1101/2023.09.08.556855": {
                "title": "Genetic manipulation of an Ixodes scapularis cell line",
                "abstract": "Abstract  Although genetic manipulation is one of the hallmarks in model organisms, its applicability to non-model species has remained difficult due to our limited understanding of their fundamental biology. For instance, manipulation of a cell line originated from the blacklegged tick Ixodes scapularis, an arthropod that serves as a vector of several human pathogens, has yet to be established. Here, we demonstrate the successful genetic modification of the commonly used tick ISE6 line through ectopic expression and clustered regularly interspaced palindromic repeats (CRISPR)/CRISPR-associated protein 9 (Cas9) genome editing. We performed ectopic expression using nucleofection and attained CRISPR-Cas9 editing via homology dependent recombination. Targeting the E3 ubiquitin ligase X-linked inhibitor of apoptosis ( xiap ) and its substrate p47 led to alteration in molecular signaling within the immune deficiency (IMD) network and increased infection of the rickettsial agent Anaplasma phagocytophilum in I. scapularis ISE6 cells. Collectively, our findings complement techniques for genetic engineering of ticks in vivo and aid in circumventing the long-life cycle of I. scapularis, of which limits efficient and scalable molecular genetic screens.   Importance  Genetic engineering in arachnids has lagged compared to insects, largely because of substantial differences in their biology. This study unveils the implementation of ectopic expression and CRISPR-Cas9 gene editing in a tick cell line. We introduced fluorescently tagged proteins in ISE6 cells and edited its genome via homology dependent recombination. We ablated the expression of xiap and p47 , two signaling molecules present in the immune deficiency (IMD) pathway of I. scapularis . Impairment of the tick IMD pathway, an analogous network of the tumor necrosis factor receptor in mammals, led to enhanced infection of the rickettsial agent A. phagocytophilum . Altogether, our findings provide a critical technical resource to the scientific community to enable a deeper understanding of biological circuits in the blacklegged tick Ixodes scapularis .  ",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1101/2023.08.31.555785": {
                "title": "Tick hemocytes have pleiotropic roles in microbial infection and arthropod fitness",
                "abstract": "Uncovering the complexity of systems in non-model organisms is critical for understanding arthropod immunology. Prior efforts have mostly focused on Dipteran insects, which only account for a subset of existing arthropod species in nature. Here, we describe immune cells or hemocytes from the clinically relevant tick <i>Ixodes scapularis</i> using bulk and single cell RNA sequencing combined with depletion via clodronate liposomes, RNA interference, Clustered Regularly Interspaced Short Palindromic Repeats activation (CRISPRa) and RNA-fluorescence <i>in situ</i> hybridization (FISH). We observe molecular alterations in hemocytes upon tick infestation of mammals and infection with either the Lyme disease spirochete <i>Borrelia burgdorferi</i> or the rickettsial agent <i>Anaplasma phagocytophilum</i>. We predict distinct hemocyte lineages and reveal clusters exhibiting defined signatures for immunity, metabolism, and proliferation during hematophagy. Furthermore, we perform a mechanistic characterization of two <i>I. scapularis</i> hemocyte markers: <i>hemocytin</i> and <i>astakine</i>. Depletion of phagocytic hemocytes affects <i>hemocytin</i> and <i>astakine</i> levels, which impacts blood feeding and molting behavior of ticks. Hemocytin specifically affects the c-Jun N-terminal kinase (JNK) signaling pathway, whereas astakine alters hemocyte proliferation in <i>I. scapularis</i>. Altogether, we uncover the heterogeneity and pleiotropic roles of hemocytes in ticks and provide a valuable resource for comparative biology in arthropods.",
                "disciplines": [
                    "3009"
                ]
            },
            "10.1186/s40168-022-01378-w": {
                "title": "Tick transmission of Borrelia burgdorferi to the murine host is not influenced by environmentally acquired midgut microbiota",
                "abstract": "BackgroundIxodes scapularis is the predominant tick vector of Borrelia burgdorferi, the agent of Lyme disease, in the USA. Molecular interactions between the tick and B. burgdorferi orchestrate the migration of spirochetes from the midgut to the salivary glands\u2014critical steps that precede transmission to the vertebrate host. Over the last decade, research efforts have invoked a potential role for the tick microbiome in modulating tick-pathogen interactions.ResultsUsing multiple strategies to perturb the microbiome composition of B. burgdorferi-infected nymphal ticks, we observe that changes in the microbiome composition do not significantly influence B. burgdorferi migration from the midgut, invasion of salivary glands, or transmission to the murine host. We also show that within 24 and 48 h of the onset of tick feeding, B. burgdorferi spirochetes are within the peritrophic matrix and epithelial cells of the midgut in preparation for exit from the midgut.ConclusionsThis study highlights two aspects of tick-spirochete interactions: (1) environmental bacteria associated with the tick do not influence spirochete transmission to the mammalian host and (2) the spirochete may utilize an intracellular exit route during migration from the midgut to the salivary glands, a strategy that may allow the spirochete to distance itself from microbiota in the midgut lumen effectively. This may explain in part, the inability of environment-acquired midgut microbiota to significantly influence spirochete transmission. Unraveling a molecular understanding of this exit strategy will be critical to gain new insights into the biology of the spirochete and the tick.7AdntFwsX5JjuXz-jKBq7oVideo Abstract",
                "disciplines": [
                    "3107"
                ]
            }
        }
    },
    "13827039": {
        "title": "Inferring cells differentiation processes from single-cell Multiome ATACseq+RNAseq data.",
        "abstract": "By using computational techniques and genomics information, I aim to develop a computational method to analyze the differentiation processes of cells. The resulting computational methodology could be used for exploratory analysis of cell states, a key feature to improve gene therapy.",
        "disciplines": [
            "3102"
        ],
        "publications": {
            "10.1101/2023.12.18.572279": {
                "title": "STAIG: Spatial Transcriptomics Analysis via Image-Aided Graph Contrastive Learning for Domain Exploration and Alignment-Free Integration",
                "abstract": "Abstract Spatial transcriptomics is an essential application for investigating cellular structures and interactions and requires multimodal information to precisely study spatial domains. Here, we propose STAIG, a novel deep-learning model that integrates gene expression, spatial coordinates, and histological images using graph-contrastive learning coupled with high-performance feature extraction. STAIG can integrate tissue slices without prealignment and remove batch effects. Moreover, it was designed to accept data acquired from various platforms, with or without histological images. By performing extensive benchmarks, we demonstrated the capability of STAIG to recognize spatial regions with high precision and uncover new insights into tumor microenvironments, highlighting its promising potential in deciphering spatial biological intricates.",
                "disciplines": [
                    "4611"
                ]
            },
            "10.1093/nar/gkad1164": {
                "title": "Epigenetic characterization of housekeeping core promoters and their importance in tumor suppression",
                "abstract": "In this research, we elucidate the presence of around 11,000 housekeeping cis-regulatory elements (HK-CREs) and describe their main characteristics. Besides the trivial promoters of housekeeping genes, most HK-CREs reside in promoter regions and are involved in a broader role beyond housekeeping gene regulation. HK-CREs are conserved regions rich in unmethylated CpG sites. Their distribution highly correlates with that of protein-coding genes, and they interact with many genes over long distances. We observed reduced activity of a subset of HK-CREs in diverse cancer subtypes due to aberrant methylation, particularly those located in chromosome 19 and associated with zinc finger genes. Further analysis of samples from 17 cancer subtypes showed a significantly increased survival probability of patients with higher expression of these genes, suggesting them as housekeeping tumor suppressor genes. Overall, our work unravels the presence of housekeeping CREs indispensable for the maintenance and stability of cells.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2023.12.03.569795": {
                "title": "Comparative single-cell transcriptomic analysis reveals key differentiation drivers and potential origin of vertebrate retina",
                "abstract": "Despite known single-cell expression profiles in vertebrate retinas, understanding of their developmental and evolutionary expression patterns among homologous cell types remains limited. We examined and compared approximately 230,000 retinal cells from three species and found significant similarities among homologous cell types, indicating inherent regulatory patterns. To understand these shared patterns, we constructed gene regulatory networks for each developmental stage for the three species. We identified 690 regulons governed by 530 regulators across three species, along with 10 common cell type-specific regulators and 16 preserved regulons. RNA velocity analysis pinpointed conserved driver genes and regulators key to retinal cell differentiation in both mouse and zebrafish. Investigation of the origins of retinal cells by examining conserved expression patterns between vertebrate retinal cells and invertebrate Ciona intestinalis photoreceptor-related cells revealed functional similarities in light transduction mechanisms. Our findings offer insights into the evolutionarily conserved regulatory frameworks and differentiation drivers of vertebrate retinal cells.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2023.07.26.550759": {
                "title": "Epigenetic characterization of housekeeping core promoters and their importance in tumor suppression",
                "abstract": "Abstract There has been extensive research on describing cell type-specific (CTS) regulatory interactions, especially between enhancers and promoters. However, constitutively active interactions between CREs have been less studied. In this research, we elucidate the presence of around 11,000 housekeeping CREs (HK-CREs) and describe their main characteristics. Most of the HK-CREs are located in promoter regions, but contrary to expectations, they are not only the promoters of housekeeping genes and are involved in a broader role beyond housekeeping gene regulation. HK-CREs are conserved regions rich in unmethylated CpG sites. Their distribution across chromosomes highly correlates with that of protein-coding genes, and they interact with a large number of target genes in long-distance interactions. In the context of cancer, we observed a reduction in the activity of a subset of HK-CREs, particularly those located at the end of chromosome 19 and associated with zinc finger genes. We investigated the effect of these genes on samples from diverse cancer subtypes, observing a significant reduction in their expression due to aberrant methylation of their core promoters. Finally, an analysis of more than 5,000 patients from 17 cancer subtypes showed an increase in the survival probability of patients with higher expression of these genes, suggesting them as housekeeping tumor suppressor genes. Overall, our work unravels the presence of ubiquitously active CREs indispensable for the maintenance and stability of cells.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1186/s12864-023-09265-w": {
                "title": "Intercellular crosstalk in adult dental pulp is mediated by heparin-binding growth factors Pleiotrophin and Midkine",
                "abstract": "BackgroundIn-depth knowledge of the cellular and molecular composition of dental pulp (DP) and the crosstalk between DP cells that drive tissue homeostasis are not well understood. To address these questions, we performed a comparative analysis of publicly available single-cell transcriptomes of healthy adult human DP to 5 other reference tissues: peripheral blood mononuclear cells, bone marrow, adipose tissue, lung, and skin.ResultsOur analysis revealed that DP resident cells have a unique gene expression profile when compared to the reference tissues, and that DP fibroblasts are the main cell type contributing to this expression profile. Genes coding for pleiotrophin (PTN) and midkine (MDK), homologous heparin-binding growth-factors, possessed the highest differential expression levels in DP fibroblasts. In addition, we identified extensive crosstalk between DP fibroblasts and several other DP resident cells, including Schwann cells, mesenchymal stem cells and odontoblasts, mediated by PTN and MDK.ConclusionsDP fibroblasts emerge as unappreciated players in DP homeostasis, mainly through their crosstalk with glial cells. These findings suggest that fibroblast-derived growth factors possess major regulatory functions and thus have a potential role as dental therapeutic targets.",
                "disciplines": [
                    "3203"
                ]
            }
        }
    },
    "13620593": {
        "title": "Development of new components and processes in biosensors activated by visible light",
        "abstract": "Photoelectrochemical (PEC) biosensors operating under visible LED light irradiation are promising for portable devices that allow detection of tumor markers at very low concentrations. This development requires high performance PEC detection platforms in which pulses of light create locally high ionic fluxes that are sensitive to steric hindrance effects of biorecognition. In this work, we will investigate and manufacture PEC biosensors with sensitization of TiO2 nanocrystalline rods grown on titanium microwires. Activity under visible light irradiation will be enhanced by gold electrodeposition and functionalization of the system with organic molecules such as L-cysteine, 3-mercaptopropionic acid and p-aminobenzoic acid. As an optimization step is essential to achieve the required performance, the materials will be characterized, and their properties correlated with photoactivity and computational studies. We will seek to understand the processes involved in the sensitization of nanocrystalline TiO2 rods in the presence of these organics, as well as their impact on the biosensor performance. (AU)",
        "disciplines": [
            "3406"
        ],
        "publications": {
            "10.1021/acsanm.3c05701": {
                "title": "Label- and Redox Probe-Free Bioelectronic Chip for Monitoring Vitamins C and the 25-Hydroxyvitamin D3 Metabolite",
                "abstract": "Monitoring immune-supporting micronutrients such as vitamins C and D is relevant as these nutrients are involved in metabolic pathways to fight against viruses and bacteria. The simultaneous determination of these biomarkers in the same sample volume is challenging, with multistep protocols if labels and redox probes are required. In this paper, we report on a flexible bioelectronic chip combining a 25-hydroxyvitamin D3 metabolite (25\u00ad(OH)\u00adD3) immunoassay with an electrocatalytic assay for vitamin C. One of the sensors in the chip was made with graphitic carbon nitride modified with the electroactive dye toluidine blue, decorated with electrodeposited 6.5 nm gold nanoparticles, and coated with a layer of anti-25\u00ad(OH)\u00adD3 antibodies. With this sensor, 25\u00ad(OH)\u00adD3 could be detected via chronoamperometry at concentrations ranging from 0.1 to 700 ng mL\u20131 with a limit of detection (LOD) of 0.01 ng mL\u20131. The other sensor had 24.7 nm Pearls carbon nanoparticles whose electroactivity permitted vitamin C detection in the range from 1 to 140 \u03bcM, with an LOD of 0.12 \u03bcM. Since the chip is flexible and does not contain labels or redox probes, it has the potential for use in wearable devices to track vitamins in bodily fluids, aiding personalized nutrition by preventing deficiencies and toxicity.",
                "disciplines": [
                    "3401"
                ]
            },
            "10.1016/j.apsusc.2023.158316": {
                "title": "Controlled electrodeposition of brookite TiO2 for photoelectroanalysis at printed carbon electrodes",
                "abstract": "TiO2-based photoelectrochemical (PEC) (bio)sensors have high photoactivity, chemical stability, and biocompatibility. However, their performance depends on multiple factors, including deposition method, morphology, and interaction with the target analyte. Herein, we describe a PEC platform based on TiO2 electrodeposition directly onto printed carbon electrodes (without heat treatment), designed for point-of-care (POC) applications. Brookite TiO2 nanocrystals were synthesized via electrodeposition in an acidic solution containing TiCl3, and parameters such as pH and temperature were optimized to improve photoelectrocatalytic activity. Photoelectrooxidation of ascorbic acid (AA) with electrodes prepared under optimal conditions (pH 2.5, 80\u00a0\u00b0C) had 10.5 times higher photocurrents than electrodes modified with commercial TiO2 nanoparticles via drop casting. The resulting sensor was highly sensitive and selective for AA, with a linear range from 10 to 1000\u00a0\u00b5M and a limit of detection of 3.25\u00a0\u00b5M (S/N\u00a0=\u00a03). Since brookite TiO2 electrodeposition does not require thermal treatment, printed carbon electrodes on polymer substrates can be used in producing miniaturized devices for sensitive, selective PEC (bio)sensors.",
                "disciplines": [
                    "4103",
                    "3406",
                    "4605"
                ]
            }
        }
    },
    "13560670": {
        "title": "The Construct and Assessment of Interpersonal Love",
        "abstract": "The proliferation of conceptualizations and measures of love has limited progress toward assessing the effects of love on a multiplicity of well-being outcomes and on the ability to assess the determinants of love across settings. We propose to employ long-standing philosophical and theological traditions on love, including non-Western traditions, to synthesize current knowledge, advance the interdisciplinary field, and develop a new set of conceptually grounded measures. \nAided by this synthesis, a lexical analysis of love across cultures, and a comprehensive review of existing survey instruments on love, our measures for the assessment of different forms of love across contexts will help initiate a formal epidemiology of love. The specific construct that will be examined related to love is the \u201cdisposition toward desiring the good of the other\u201d where the intentionally ambiguous phrase \u201cthe good of the other\u201d may itself be understood either as \u201cgood for the other\u201d or as the \u201cgood constituted by the other.\u201d We will refer to the former as \u201ccontributory love\u201d (desiring the good of the other) and the latter as \u201cunitive love\u201d (desiring union with the other) (cf. Thomas Aquinas, Summa Theologica I-II.26.4). \nGuided by our interdisciplinary Advisory Board, we will collect data on responses to the proposed items in a variety of settings in order to assess their psychometric properties. Our interpersonal love items will be classified according to (i) unitive and contributory, (ii) giving and receiving, and (iii) parent-child, spouse, friend, God, neighbor, stranger, and enemy. We will assess the effects of love on outcomes and the determinants of love across settings. Our measures will cover a broader array of understandings of love found in the philosophical, theological, and social science literatures than previous measures. As a result, we expect enhanced ability to predict well-being outcomes, which would help move the interdisciplinary field beyond the current impasse.",
        "disciplines": [
            "5005"
        ],
        "publications": {
            "10.1080/03057240.2024.2333577": {
                "title": "The social and moral ecology of education for flourishing",
                "abstract": "Educational institutions exist in reciprocal relations with broader social and moral ecologies. These ecologies involve interactions of networks of individuals and groups with wider aspects of culture, and are therefore broadly social, and they contain explicit or implicit content with regard to right and wrong, and are therefore moral. There is growing recognition that educational institutions could do more to promote full flourishing for students, teachers, staff, society, and planet, but there has been relatively little attention to the role played by such social and moral ecologies in fostering this desired change. This paper argues that ecosystem stewards can inspire and lead educational institutions in this direction by loving more fully into being a cultural climate that promotes morally good forms of ecosystem-wide flourishing. This includes an exploration of a systems perspective in order to encourage a more intentional and skillful integration of healthy social and moral influences.",
                "disciplines": [
                    "3901"
                ]
            },
            "10.3390/rel14121517": {
                "title": "The Oneness of Love in Works of Love",
                "abstract": "Kierkegaard\u2019s claim that God just is love implies that love is ultimately one reality. Indeed, on more than one occasion, Kierkegaard will make this point explicitly as well as implicitly by frequently asserting the oneness of love. For example, early on in Works of Love, he states plainly that \u201cthis love for the neighbor is not related as a type to other types of love. Erotic love is defined by the object; friendship is defined by the object; only love for the neighbor is defined by love\u201d. What Kierkegaard means by this is that preferential loves are defined by a factor in addition to love itself: the object of that love. Neighbor-love is defined by love itself, which takes as its object the neighbor, or in other words, \u201cunconditionally every human being\u201d. Preferential loves are specified as it were by the person loved in this manner. Neighbor-love is not related as a type to other types of love in that neighbor-love is paradigmatic love; preferential loves are specified, but as recent commentators have shown, are not thereby precluded from also being or filtered by or infused by or coincident with neighbor-love as well. The point of this passage is that there are not distinct, enumerated types of love that, taken together, can be amalgamated into something called \u201clove\u201d, which would be inclusive of distinct kinds. The current paper argues that neighbor-love is meant to be thought of as paradigmatic. Therefore, as a paradigmatic unity, it will also exhibit qualities ordinarily associated with preferential love. Put differently, my claim is that we have reason to conclude that, in the end, features of preferential love will be manifest in neighbor-love just as surely as neighbor-love has an effect on preferential love. I wish to take seriously the claim of Works of Love that, ultimately, love is one. Love, being one, is not comprised of distinct types or subsets. I demonstrate the importance of this point by explaining how all love has its ultimate origin in God (and God just is love). While seemingly a truism, I argue from a variety of passages that the oneness of love has multiple implications throughout the text, implications that further support the theory that neighbor-love is not an alternative to, but rather encompasses features of, preferential loves.",
                "disciplines": [
                    "5005"
                ]
            },
            "10.3390/rel14111427": {
                "title": "Abolishing Anger: A Christian Proposal",
                "abstract": "In recent years, advocates of (so-called) righteous anger have become increasingly vocal and articulate, as is evident from a growing literature defending anger as a moral emotion and tool for social change. Righteous anger has defenders both among secular philosophers\u2014notably Myisha Cherry in her The Case for Rage and Failures of Forgiveness\u2014and Christian theologians and activists, particularly, though by no means only, those drawing inspiration from Thomas Aquinas\u2019s Aristotelian defense of anger. As a Christian theologian writing in the first instance for other Christians, I will argue in what follows that permissive attitudes to anger\u2014even of the \u201crighteous\u201d sort\u2014are fundamentally mistaken, not least because they are inconsistent with the universal obligation to love one\u2019s neighbor as oneself. Christians instead ought to take something approaching an abolitionist approach to anger, as an emotion intrinsically opposed to charity. We can see this most clearly by beginning with the faults of a qualified defense of anger, which I reconstruct from Cherry\u2019s work, and from the work of Thomas Aquinas, whose views on anger are interestingly convergent with hers. (This pairing has at least two advantages: it highlights the essentially traditional character of Cherry\u2019s approach, and illustrates how relatively untutored Aquinas\u2019s Aristotelian treatment of anger is by distinctively theological commitments.) I then sketch and defend the view, with a particular reliance on the Sermon on the Mount, that we ought to seek to abolish anger from our lives and defend that position against three apparent defeaters drawn from the Christian Scriptures.",
                "disciplines": [
                    "5003",
                    "5005"
                ]
            }
        }
    },
    "13488737": {
        "title": "ENERGY COUPLING AND TRANSFER IN REPETITIVE NANOSECOND PULSED PLASMAS",
        "abstract": "Repetitively pulsed nanosecond plasmas at atmospheric pressure promise high energy\n\nefficiency and selectivity. This research is to conduct quantitative studies of the energy coupling\n\nand transfer between nanosecond pulsed power and atmospheric-pressure plasmas for a variety of\n\nDoD applications including plasma-assisted combustion, material processing/modification,\n\nsurface cleaning, and improvement of hypersonic aerodynamics.",
        "disciplines": [
            "5106"
        ],
        "publications": {
            "10.1109/icops45740.2023.10480948": {
                "title": "Evaluating the Impact of Substrate Conductivity on Nanosecond Pulsed Plasma Formation and ROSProduction in Liquid",
                "abstract": "Nonthermal atmospheric pressure plasma jets (APPJ) are of interest to various biomedical applications, including bacteria inactivation, wound healing, and cancer therapy[1], [2]. Biologically active factors such as charged particles, electric field, and reactive oxygen and nitrogen species (RONS), are considered important agents that induce the biomedical effects. These factors can be influenced by the presence of biological materials as part of the electrode circuit. This study investigates the effect of the conductivity of the substrates on the plasma formation and the associated chemistry using a hollow needle-to-ring electrode configuration. Ultrapure water, sodium chloride (NaCl) solutions and phosphate-buffered saline (PBS) solution are used as the substrate. Driven by 200 ns, 9 kV pulses at 2 kHz, a helium ns-APPJ is generated between the hollow needle electrode and the liquid surface. The charges delivered to the substrates are evaluated by jet current measurements and compared among different substrates. Spatiotemporally resolved optical emission spectroscopy was employed to evaluate the effect of the substrate conductivity on the plasma jet formation, gas temperature, and OH(A) production. In addition, measurements of the H2O2 production in the liquid were used to determine the OH concentration in liquid. An equivalent circuit model during the plasma establishment is also discussed.",
                "disciplines": [
                    "3406"
                ]
            },
            "10.1109/icops45740.2023.10481052": {
                "title": "Removal of Organic Pollutants in Water by a Nanosecond Pulsed Sliding Discharge",
                "abstract": "Environmentally persistent organic pollutants have become a concern to the sustainability of the environment, and many of them are harmful to human health. This work explores the feasibility of a lowtemperature plasma-based technology for the degradation of organic pollutants such as Rhodamine-B (Rh-B) and trifluoroacetic acid (TFA) in water. Applying 300-ns, 20 kV pulses at 500 Hz to a strip line-like electrode configuration, sliding discharges are generated at the gas-water interface in one atmospheric air or nitrogen above contaminated water. An average Rh-B reduction of 30% and 19% were achieved with air and nitrogen, respectively, when 20 \u03bcM of Rh-B solution flew through the reactor at a flow rate of 1 mL/s, Over 90% degradation of Rh-B was obtained after 9 cycles of treatment of the plasma operated at 0.12 J per pulse or an average power of 60 W using ambient air as the working gas. The impact of the voltage, working gas, and initial concentration of the organic pollutants on the degradation rate and energy efficiency are discussed. This work demonstrates that the nanosecond sliding discharge-based plasma reactor is a promising technology for water purification and the removal of organic compounds.",
                "disciplines": [
                    "4004"
                ]
            },
            "10.1109/icops45740.2023.10481130": {
                "title": "Initial Investigation of the Mode Transition of a Nanosecond Guided Streamer to Spark",
                "abstract": "Understanding the discharge mode of a nanosecond pulsed atmospheric pressure plasma jet (ns-APPJ) or a guided streamer is of fundamental importance for predicting its properties and applying it for various applications.A recent streamer breakdown study showed that the streamer-to-spark transition under a DC voltage was significantly influenced by the discharge polarity1. Under a pulsed condition, guided streamers driven with a longer pulse duration, or a higher pulse repetition frequency (PRF) resulted in their transitions to spark discharges at lower breakdown voltages2.",
                "disciplines": [
                    "3406"
                ]
            },
            "10.1038/s41598-024-51298-y": {
                "title": "Synergistic effects of nanosecond pulsed plasma and electric field on inactivation of pancreatic cancer cells in vitro",
                "abstract": "Nanosecond pulsed atmospheric pressure plasma jets (ns-APPJs) produce reactive plasma species, including charged particles and reactive oxygen and nitrogen species (RONS), which can induce oxidative stress in biological cells. Nanosecond pulsed electric field (nsPEF) has also been found to cause permeabilization of cell membranes and induce apoptosis or cell death. Combining the treatment of ns-APPJ and nsPEF may enhance the effectiveness of cancer cell inactivation with only moderate doses of both treatments. Employing ns-APPJ powered by 9\u00a0kV, 200\u00a0ns pulses at 2\u00a0kHz and 60-nsPEF of 50\u00a0kV/cm at 1\u00a0Hz, the synergistic effects on pancreatic cancer cells (Pan02) in vitro were evaluated on the metabolic activities of cells and transcellular electrical resistance (TER). It was observed that treatment with ns-APPJ for\u2009>\u20092\u00a0min disrupts Pan02 cell stability and resulted in over 30% cell death. Similarly, applying nsPEF alone,\u2009>\u200920 pulses resulted in over 15% cell death. While the inactivation activity from the individual treatment is moderate, combined treatments resulted in 80% cell death, approximately 3-to-fivefold increase compared to the individual treatment. In addition, reactive oxygen species such as OH and O were identified at the plasma-liquid interface. The gas temperature of the plasma and the temperature of the cell solution during treatments were determined to be near room temperature.",
                "disciplines": [
                    "4004"
                ]
            },
            "10.1109/ppc47928.2023.10311041": {
                "title": "The Effect of Pulse Width on Nanosecond Guided Streamer Breakdown",
                "abstract": "Understanding the initiation and development of guided streamers are important for effectively applying these repeatable, transient discharges for various fields. This study compares the streamer initiation and breakdown for positive helium guided streamers powered by 10-ns, 35-ns, and 200-ns voltage pulses using a hollow needle-to-plate electrode configuration at atmospheric pressure. The streamer initiation and breakdown (streamer-to-spark transition) voltage as functions of the interelectrode gap distance are determined based on voltage-current measurements and high-speed spectroscopy. The breakdown voltage for a repetitively pulsed streamer is compared with a single-shot discharge. The dependence of the pulse repetition frequency and pulse width on streamer breakdown are investigated. It is found that the shorter voltage pulses results in higher overvoltage breakdown. In addition, the discharge mode is assessed with the pulsed voltage and current as well as the rotational temperature of the 2nd positive system of N2.",
                "disciplines": [
                    "3406"
                ]
            },
            "10.1109/ppc47928.2023.10310918": {
                "title": "Nanosecond pulsed plasma jets impinging on water for ammonia generation",
                "abstract": "Carbon-free nitrogen fixation plays an important role for global environmental sustainability, which demands novel approaches with improved nitrogen-use efficiency and allowing end-point fertilizer delivery. The most popular Haber-Bosch process synthesizes ammonia (NH3) from N2 and H2 at high pressures and temperatures. This work investigates the feasibility of using a low-temperature, nanosecond pulsed atmospheric-pressure plasma jet (ns-APPJ) impinging on water for ammonia synthesis. By applying 200 ns, 20 kV pulses at 500 Hz to a hollow needle (0.838 mm ID, 1.270 mm OD), while flowing a N2 gas through the needle at 490-990 sccm, a plasma jet was generated impinging on 1 mL of deionized water in a grounded PMMA cuvette. The gap distance between the needle tip and the water surface was kept at 5 mm. The production of NH3 was found dependent on the treatment time, applied voltage, and gas flow rate. Up to 0.041 mg/hr of NH3 production was obtained in our study. Effects of the use of different feeding gases such as dry air and humid air on the efficiency of NH3 synthesis are also discussed.",
                "disciplines": [
                    "4004"
                ]
            },
            "10.1049/hve2.12382": {
                "title": "On the chronological understanding of the homogeneous dielectric barrier discharge",
                "abstract": "Abstract Dielectric barrier discharges (DBD) are widely utilised non\u2010equilibrium atmospheric pressure plasmas with a diverse range of applications, such as material processing, surface treatment, light sources, pollution control, and medicine. Over the course of several decades, extensive research has been dedicated to the generation of homogeneous DBD (H\u2010DBD), focussing on understanding the transition from H\u2010DBD to filamentary DBD and exploring strategies to create and sustain H\u2010DBD. This paper first discusses the influence of various parameters on DBD, including gas flow, dielectric material, surface conductivity, and mesh electrode. Secondly, a chronological literature review is presented, highlighting the development of H\u2010DBD and the associated understanding of its underlying mechanisms. This encompasses the generation of H\u2010DBD in helium, nitrogen, and air. Lastly, the paper provides a brief overview of multiple\u2010current\u2010pulse (MCP) behaviours in H\u2010DBD. The objective of this article is to provide a chronological understanding of homogeneous dielectric barrier discharge (DBD). This understanding will aid in the design of new experiments aimed at better comprehending the mechanisms behind H\u2010DBD generation and ultimately assist in achieving large\u2010volume H\u2010DBD in an air environment.",
                "disciplines": [
                    "5106",
                    "4008"
                ]
            },
            "10.21203/rs.3.rs-3143506/v1": {
                "title": "Synergistic effects of nanosecond pulsed plasma and electric field on inactivation of pancreatic cancer cells in vitro",
                "abstract": "Nanosecond pulsed atmospheric pressure plasma jets (ns-APPJs) produce reactive plasma species, including charged particles and reactive oxygen and nitrogen species (RONS), which can induce oxidative stress in biological cells. Nanosecond pulsed electric field (nsPEF) has also been found to cause permeabilization of cell membranes and induce apoptosis or cell death. Combining the treatment of ns-APPJ and nsPEF may enhance the effectiveness of cancer cell inactivation with only moderate doses of both treatments. Employing ns-APPJ powered by 9 kV, 200 ns pulses at 2 kHz and 60-nsPEF of 50 kV/cm at 1 Hz, the synergistic effects on pancreatic cancer cells (Pan02) <i>in vitro</i> were evaluated on cell viability and transcellular electrical resistance (TER). It was observed that treatment with ns-APPJ for &gt;2 min disrupts Pan02 cell stability and resulted in over 30% cell death. Similarly, applying nsPEF alone, &gt;20 pulses resulted in over 15% cell death. While the inactivation activity from the individual treatment is moderate, combined treatments resulted in 80% cell death, approximately 3-to-5-fold increase compared to the individual treatment. In addition, reactive oxygen species such as OH and O were identified at the plasma-liquid interface. The gas temperature of the plasma and the temperature of the cell solution during treatments were determined to be near room temperature.",
                "disciplines": [
                    "4004"
                ]
            },
            "10.4271/03-16-08-0061": {
                "title": "Repetitive Multi-pulses Enabling Lean CH4-Air Combustion Using Surface Discharges",
                "abstract": "<div>The development of efficient and reliable ignition systems for lean fuel-air\n                    mixtures is of great interest for applications associated with the use of\n                    combustion in transportation, electricity production, and other heavy\n                    industries. In this study, we report the use of repetitive nanosecond pulsed\n                    surface discharges for the ignition of lean methane (CH<sub>4</sub>)-air\n                    mixtures at pressures above 1 bar. Powered by ten 10-ns voltage pulses at 10\n                    kHz, a commercially available non-resistive spark plug was used to generate\n                    surface discharges, which were able to ignite CH<sub>4</sub>-air mixtures at 1.5\n                    bar and with equivalence ratios (\u03d5) ranging from 1.0 to 0.5. At the leanest\n                    conditions, e.g., \u03d5 \u2264 0.6, nitric oxide (NO) and nitrogen dioxide\n                        (NO<sub>2</sub>) emission were reduced to <10% of their values at \u03d5 =\n                    1.0, demonstrating the advantage of lean burn in emission reduction. Consistent\n                    ignition was obtained under extremely lean conditions (e.g., \u03d5 = 0.5) with a\n                    minimum of five pulses and a minimum Coulomb transfer of 82 \u03bcC. Additionally,\n                    the surface plug durability was tested for 114 hours or over 12 million pulse\n                    trains by operating the surface plug in 3.5 bar of dry air at 30 pulse trains\n                    per second. This study shows that the use of repetitive nanosecond pulses with\n                    surface discharge-based plugs holds promise for a durable ignition solution.</div>",
                "disciplines": [
                    "4017",
                    "4002"
                ]
            }
        }
    },
    "13527345": {
        "title": "The Uncomfortable Museum: Towards Safe, Brave Spaces",
        "abstract": "An uncomfortable museum explores the feeling of discomfort caused by the treatment of difficult social issues, which in the museum space can vary between, for example, anger, disgust, fear, shame, guilt and anxiety. In addition, museum exhibitions can bring about uncomfortable, difficult to verbalize, bodily affective experiences. The project aims to understand these experiences, especially with the help of transformative pedagogy that shakes up familiar patterns of thought and action. In the project, we approach discomfort with hope, relying on the so-called reparative or corrective turn of feminist research, which refers to the effort to remain open to even surprising breaks in norms, privileges and positions of power. By researching ways to transform difficult feelings into corrective action, the project opens a completely new perspective for researching the social effects of museum operations.\n \nFrom these starting points, our project produces pioneering and ambitious researched information for the use of both researchers and the museum industry. In practice, we investigate (1) with what tools the power structures stemming from the history of museums can be identified and how they can be challenged with the means of museum pedagogy based on transformative learning; (2) what kind of possibilities the methods combining science and art open up for understanding the experiences of discomfort; (3) we develop methodological tools for qualitative research of museum visitors' experiences; and (4) we analyze the ways in which museums deal with uncomfortable topics and taboos in their exhibitions. In the project, we show how discomfort can be a pedagogical and even transformative resource, with which the museum enables reparative, transformative activities in the exhibition space. Discomfort can therefore be understood as a resource that, through the creation of cracks, produces insights, corrective action and a change in ways of thinking.",
        "disciplines": [
            "4302"
        ],
        "publications": {
            "10.1080/02560046.2024.2316302": {
                "title": "Uncomfortable Knowledges and Transformative Learning: Reimagining the Museum in the Art of Gustafsson&Haapoja",
                "abstract": "Destructive human action is causing interconnected ecological and social challenges on an unprecedented scale. Scholars and artists from varied fields have critically expressed their concern about this in their research and practice. In this article, we interrogate the transformative potential of critically engaged art by analysing the work of the Finnish artist duo Gustafsson&Haapoja, a collaboration between writer Laura Gustafsson and visual artist Terike Haapoja. Gustafsson&Haapoja\u2019s work focuses on the intersecting human exceptionalist, racist, imperialist, patriarchal, and capitalist histories of violence towards nonhuman animals and dehumanised humans. These histories often provoke uncomfortable affects. As such, they can be challenging to confront. To account for this difficulty, we approach Gustafsson&Haapoja\u2019s art through the idea of transformative learning, a process designed to shake established thinking and behavioural patterns. We investigate how Gustafsson&Haapoja\u2019s art\u2014and art more generally\u2014could function as a transformative learning resource and enable sudden ruptures in hegemonic cultural norms, privileges, and power positions. We focus on how transformative learning emerges through central features in Gustafsson&Haapoja\u2019s work: (1) their investigation and reimagination of the museum, an institution historically tied to notions of humanity and human action; and (2) their critical dissection of the complex relationship between Western-centric conceptualisations of humanity and its \u201cothers.\u201d The article is based on a theoretical discussion and a qualitative analysis of works, exhibitions, and texts published by Gustafsson&Haapoja\u2019s Museum of Becoming (2020\u201321) as well as an interview with the artists.",
                "disciplines": [
                    "3601"
                ]
            }
        }
    },
    "12953192": {
        "title": "LGBT+ media representation on BBC's Strictly Come Dancing: Same-sex dance pairings as a means to promote inclusive participation in ballroom dancing?",
        "abstract": "What people see on television, film and in the news media can have significant impact on how they understand the world, interact and empathise with others in their everyday lives. In sports and leisure entertainment, media representations can influence how people treat LGBT+ individuals and their corresponding access to leisure opportunities. In 2021, we witnessed a huge step forward for the UK's LGBT+ ballroom dance community when Strictly Come Dancing (SCD) changed its 18-year long traditional format to include a male-male professional/amateur dance partnership into its line-up, following its first female-female coupling in 2020. SCD's shift was accompanied by increased media representations of LGBT+ lives and relationships through gay-identifying dancers and portrayals of the UK's LGBT+ ballroom dance culture. My main aim in this Fellowship is to leverage this active media discourse inspired by SCD to maximise impact and dissemination of my PhD research on UK's LGBT+ ballroom dance culture, so as to increase the visibility and acceptance of LGBT+ dancers in partner dancing.\n\nDespite growing media visibility of same-sex dancing such as in SCD's 2021 finale, and the possibilities it holds for deconstructing dominant gender discourse in mainstream dancing, the subject remains understudied. My PhD is a pioneering work examining LGBT+ dancers' lived experiences of competitive same-sex ballroom dancing through a queer feminist lens. The novelty of my PhD lies in my visual methodology involving photo-elicitation with visual artefacts (Tillmann-Healy, 2001; Boylorn, 2008) and auto-ethnography as a photographer and dancer, to propose a sociological framework for the examination of dancing bodies as material and discursive, relational and resistive. I show that we cannot envision new possibilities for promoting inclusive dance expressions through the same heteronormative patterns, proposing an analytical framework which recognises diversity in transgressive practices across the categories of sex, gender and sexuality. In this Fellowship, I aim to maximise dissemination by leveraging the creative potentials of my visual methodology in my publications and activities, using photography to stimulate new ways of perceiving and articulating gendered and sexual bodies within and beyond academia.\n\nI aim to achieve maximum impact to bring about visible socio-cultural shifts in attitudes towards LGBT+ dancers by broadening my audience base beyond academia. I draw on multiple publication mediums and on teaching to reach out to diverse audience. My journal article is targeted at academics to inspire new lines of inquiry for dance studies which celebrates diversity and differences. I will teach 2 hours per week in the autumn to widen my outreach in academia. Beyond academia, I will adapt a monograph from my PhD, present at two conferences and create a website to bring issues of gender and sexuality to the forefront of ballroom dance education and draw attention to alternative dance practices. I will achieve community impact through hosting a photography exhibition with dance workshop in the University of Kent, titled \"Reimagining Ballroom Dancing\", where I share insights on the UK's LGBT+ dance culture and create opportunities beyond London for inclusive participation in ballroom dancing.\n\nI aim to effectively draw on SCD to engage with non-academics, by incorporating up-to-date developments of SCD into my PhD work. I will carry out further limited research (16.7% of the programme) to explore how shifts in SCD's media representation of same-sex dancers relates to the lived experiences of LGBT+ dancers examined in my PhD. This work extends impact by informing LGBT+ media representations in British reality TV programmes such as Dancing with the Stars and Dancing on Ice. I sustain impact achieved in this Fellowship through an ESRC New Investigator Grant to expand my focus to include differently-abled and gender non-conforming dancers.",
        "disciplines": [
            "3604",
            "4405"
        ],
        "publications": {
            "10.1177/01634437231219141": {
                "title": "LGBT+ mainstreaming on strictly come dancing: Queering the norms of ballroom dancing",
                "abstract": "This paper proposes that LGBT+ mainstreaming on reality television programme Strictly Come Dancing creates space for audience demand for radical, authentic representations of same-sex desire and intimacy, both of which challenges normative representations of ballroom dancing. Integrating concepts of normativity and authenticity explored in existing scholarship, I argue against the encountering through a defensive stance, of reality TV\u2019s normalization of queer narratives to promote authentic, inclusive representation. Focusing on dance-themed British reality TV programme for family entertainment, I draw on a queer reading of 285 newspaper articles on Strictly Come Dancing\u2019s same-sex dance partnerships and 35 interviews with LGBT+ equality dancers in the United Kingdom, to conclude that active engagement with mechanisms of normalization can open up spaces for a reclamation of queer representation in its authenticity. The article makes a contribution to media and cultural studies and queer television scholarship through a troubling of anti-normativity, proposing a working with normativity to achieve queer inclusivity.",
                "disciplines": [
                    "4405",
                    "4701"
                ]
            },
            "10.1177/16094069231182015": {
                "title": "Gender and Sexuality Performances Among LGBT+ Equality Dancers: Photo-Elicitation as a Method of Inquiry",
                "abstract": "In its classical form, ballroom dancing constitutes heterosexual dance couples enacting conservative forms of masculinity and femininity. A normative focus, both in scholarship and in practice, on the classical form in competitive ballroom dancing (also known as Dancesport) excludes the lived narratives of LGBT + dancers practicing the sport outside of the mainstream. Equality Dancesport is one such example, with dancers performing in diverse partnership typologies and adopting less gender-segregated dance roles and movements. Drawing on the photo-elicitation exercise, embedded within in-depth interviews, conducted as part of a broader ethnographic study on the equality Dancesport scene in the United Kingdom, I demonstrate how the strategy informed a ground-up emergence of a queer theoretical framework for understanding masculinities and femininities across the sex, gender and sexuality categorical divides. Four key opportunities afforded by photo elicitation are identified, namely (1) invoking new queer knowledge which blurs the binary divide in how concepts of masculinities and femininities are investigated in existing dance scholarship, (2) facilitating the development of more egalitarian researcher/participant relationships, (3) enabling affective, detailed and fluid narrations of lived experiences of dancing, and (4) positioning interviewees as dance spectators and inspiring reflections on the community. The paper concludes with three recommendations for negotiating the pitfalls of using a photo elicitation technique in dance studies. First, researchers need to recognise the limits of inclusivity offered by photo elicitation and practice sensitivity towards participants. Second, integrating photographs with other visual methods such as videos can enable researchers to leverage the strengths of different visual tools to inspire talk about broader topics. Third, before using the method, researchers need to develop mental strength for coping with negative talk, to achieve more holistic understanding of participants\u2019 sentiments and motivations and as a duty of accountability towards them.",
                "disciplines": [
                    "4405",
                    "3604"
                ]
            },
            "10.1177/00113921231182182": {
                "title": "LGBT+ ballroom dancers and their shoes: Fashioning the queer self into existence",
                "abstract": "This article examines the role of dance shoes in LGBT+ ballroom dancers\u2019 identity formation and expression on the dancefloor. Applying Entwistle\u2019s (2015) \u2018situated bodily practice\u2019 to an analysis of ethnographic field notes and 35 interviews, I highlight that dancers\u2019 performative constitution of subversive identities through reiterative mobilisation of the traditional symbolic values of dance shoes is influenced by the material. The article makes a key contribution to sociological knowledge on performativity through an introduction of materialities of place, bodies and artefacts into a close reading of reiterative acts. I argue that a closer look into performative acts is necessary for determining whether and how resistance is constituted, recognised and reproduced, taking into account how materialities interweave with discourse in order to give credit to subversive agents emerging in the micro-moments.",
                "disciplines": [
                    "4405"
                ]
            }
        }
    },
    "13028842": {
        "title": "Challenge of the use of drugs in fish farming in the context of One Health: evaluation of efficacy, safety and risk analysis",
        "abstract": "One of humanity's greatest challenges is to ensure food security in a sustainable production system in line with the One Health concept. Foods from aquaculture that have a high nutritional quality are decisive in the production of animal protein. Brazil has enormous potential to leverage the exploration of aquaculture due to its favorable climatic conditions and extensive water resources that allow the production of a wide variety of fish species. The expansion of the sector in the country favors the production of food for the national and international market and contributes to the creation of jobs. The implementation of intensive and/or super-intensive production systems in fish farming constitutes conditions of greater vulnerability in terms of the spread of infectious diseases among animals, in the event of the occurrence of pathogens of microbial origin, directly affecting the health of the fish, and the food safety for consumers. In contrast to other agricultural sectors, aquaculture in Brazil still lacks authorized veterinary medicines designed to treat diseases in farmed fish species. Added to this is the fact that the few products for use on fish had their studies carried out in countries in the northern hemisphere and not in countries with tropical and subtropical climates, such as Brazil, which has higher water body temperatures, which will directly influence pharmacokinetic parameters, which are fundamental when considering food safety. It is worth highlighting that one of the factors that needs to be considered in the continuous use of antimicrobial drugs in production is the possible development of antimicrobial resistance, which can impact animal, human and environmental health. Therefore, this production sector urges for more alternative products for veterinary use, with studies carried out considering national breeding conditions, which are effective and safe for animals and the consumer. Cooperation between the private sector and academia is a fundamental strategy to meet this demand. For medicines to be used authorized, in addition to having proven efficacy, they must undergo a risk assessment that encompasses animal, human and environmental health. In the context of risk assessment, aiming to establish maximum residue limits, it is necessary to carry out clinical studies with the radiolabeled active pharmaceutical ingredient and, to this end, it is essential to have an infrastructure to carry out clinical trials and laboratory analysis that allow working with radiolabeled molecules within safety standards (radioprotection). Added to this is the need to also assess the impact of these veterinary products on the environment and, in the case of antimicrobials, the importance of assessing antimicrobial resistance to these medicines. Therefore, the main goal of this research project is to establish a pioneering infrastructure in Brazil that will allow evaluating the effectiveness and safety of using veterinary medicines in Brazilian fish farming, so that the country can leverage production in this sector and contribute to the food security in a sustainable way and in line with the One Health concept (animal health, human health and environmental protection). This pioneering infrastructure is a starting point for Brazil to have knowledge of standards, methods and procedures to assess the safety of the use of veterinary medicines in the agricultural sector and will continue in the long term, serving other projects in the future. To overcome the challenges, this study counts on the participation of researchers from the three state universities in S\u00e3o Paulo, investment from the private sector, international collaboration with a consortium with the European Community, in addition to the support of MAPA and the International Atomic Energy Agency. (AU)",
        "disciplines": [
            "3005",
            "3006"
        ],
        "publications": {
            "10.1002/cjce.25286": {
                "title": "Bioactive dry extract production from Hymenaea courbaril L. bark via spouted bed drying",
                "abstract": "Abstract  The work aims to develop and optimize a powdered phytopharmaceutical product from the stem bark of Hymenaea courbaril L. (jatob\u00e1) by the spouted bed drying. The study commenced with the extraction of bioactive compounds present in the plant raw material by dynamic maceration using ethanol/water 70% (v/v) at a temperature of 50\u00b0C for 60 min, for the ratio stem bark: solvent mass of 1:10 (w/w). The extract quality was assessed by quantifying chemical markers via spectrophotometry (total polyphenols and tannins) and through antioxidant activity by 2,2\u2010diphenyl\u20101\u2010picrylhydrazyl (DPPH) assay. The extractive solution was concentrated, added with drying adjuvant, and submitted to spouted bed drying. Product quality was evaluated by moisture content ( X p ), water activity (a W ), powder diameter, total polyphenols, and tannins content (P T and T T ), and antioxidant activity, expressed as the extract concentration needed to reduce 50% of the DDPH radical (IC 50 ). Spouted bed drying performance was evaluated through the drying yield ( R EC ), product accumulation (A c ), and thermal efficiency ( \u03b7 ). The optimal processing conditions were: inlet gas temperature, T gi : 150\u00b0C, the ratio of the mass feed flow rate of the concentrated extract to the evaporation capacity of the dryer, W s / W max : 45%, and the drying gas flow rate relative to minimum spouting, Q / Q ms : 1.85. Under these conditions, it is predicted to obtain a dried extract with X p = 4.9% w/w, P T = 26.0% w/w, R EC = 77.7% w/w, \u03b7 = 44.3%, and A c = 10% w/w, with adequate values of a W , T T , and high antioxidant activity. ",
                "disciplines": [
                    "4004"
                ]
            },
            "10.1080/07373937.2024.2318437": {
                "title": "Optimized spouted bed production of antioxidant dried powder from green tea",
                "abstract": "This study evaluated the feasibility and optimization of the spouted bed drying to produce standardized dried Camellia sinensis extract. We explored processing variables such as inert particle type (Teflon\u00ae or glass beads), drying aid concentration (colloidal SiO2\u2014Aerosil 200\u00ae), and drying inlet temperatures (80, 110, or 140 \u00b0C). Regression analysis of the results allowed for constructing response surface graphs, highlighting variable impacts on product properties and spouted bed performance. The optimal conditions involved Teflon\u00ae beads and a drying temperature of 110 \u00b0C, resulting in a product with excellent moisture content, water activity, and active constituent retention. The product demonstrated significant antioxidant activity in DPPH assays, with an IC50 between 4.4 to 6.7 \u00b5g/mL, surpassing the synthetic antioxidant butylated hydroxytoluene (BHT), which had an IC50 of 12.5 \u00b5g/mL. Rancimat assays showed that the dried extract effectively protected crude sunflower oil from oxidation, increasing its shelf life from 8.2 to 13.1 months.",
                "disciplines": [
                    "3006"
                ]
            },
            "10.1016/j.etap.2024.104382": {
                "title": "Evaluating the persistence of malachite green residues in tilapia and pacu fish",
                "abstract": "Although banned in food-producing animals, residues of malachite green (MG) and its primary metabolite, leucomalachite green (LMG), have been found in fish due to illegal use in aquaculture and the release of industrial wastewater, which represent a serious risk to food and environmental securities. This study aimed to investigate the residue depletion profile of MG and LMG in edible tissues of Nile tilapia (Oreochromis niloticus) and pacu (Piaractus mesopotamicus) cultured simultaneously under the same environmental conditions to support control measures in case of abuse. An analytical method involving QuEChERS sample preparation and liquid chromatography coupled to tandem mass spectrometry was developed, validated, and applied to quantify MG and LMG residues in fish fillets from two depletion experiments after treatment by immersion bath (MG at 0.10\u00a0mg\u00a0L<sup>-1</sup> for 60\u00a0min). During the experiment, the average water temperature was 30 \u00baC, while the pH was 6.9. The method is selective, precise (CV = 0.4 - 22%) and accurate (recovery 92 - 114%). The limits of detection and quantification are 0.15 and 0.5\u00a0ng\u00a0g<sup>-1</sup>, respectively. In both species, the sum of MG and LMG residues were quantified up to the 32nd day post-exposure, and the concentrations were significantly higher in the pacu fillets (up to 3284\u00a0ng\u00a0g<sup>-1</sup>) than in Nile tilapia (up to 432\u00a0ng\u00a0g<sup>-1</sup>). The sums of MG and LMG residues were below 2\u00a0ng\u00a0g<sup>-1</sup> at 44 days and 342 days for Nile tilapia and pacu, respectively - the Minimum Required Performance Limit (MRPL) for analytical methods intended to monitor forbidden substances in food according to old European Commission guidelines. The persistence of MG residues in pacu may be attributed to its higher lipid content, which favors the accumulation of the non-polar metabolite LMG. These results provide insights into the concern about human, animal, and environmental health risks resulting from unauthorized use or aquatic contamination by industrial wastewater containing MG residues.",
                "disciplines": [
                    "4104",
                    "4105"
                ]
            },
            "10.1080/19440049.2023.2283769": {
                "title": "Levamisole incorporation in fish feed \u2013 Ensuring the medication dose and avoidance of leaching into the water",
                "abstract": "Levamisole, an anthelmintic and immunostimulant drug, has been studied as a promising alternative for aquaculture use. While oral administration through feeding is the main route of administration in fish farming, no studies evaluating methods of levamisole incorporation into the feed have been reported so far. Therefore, this study aimed to evaluate potential procedures for levamisole incorporation in extruded fish feed using ethyl cellulose, gelatin, or vegetable oil, to avoid drug leaching to the water during the animal's medication. A suitable LC-MS/MS method was optimized (full factorial design), validated, and applied to evaluate the efficiency of the process, the homogeneity of the drug concentration, and the leaching rate. The method has been demonstrated to be selective, precise (RSD &lt; 4.9%), accurate (recovery &gt; 98.4%), and linear (<i>r</i>\u2009&gt;\u20090.99, 125-750\u2009mg kg<sup>-1</sup>). The incorporation procedures using the three coating agents showed high incorporation efficiency (70%) and a homogeneous drug concentration among the extruded feed pellets. A low levamisole leaching rate was verified in the feed prepared using the ethyl cellulose coating procedure (4.3% after 15\u2009min of immersion in the water). On the other hand, fish feed coated with gelatin and oil resulted in a high leaching rate (30-35% after 15\u2009min). Thus, this study shows that coating ethyl cellulose may be a promising procedure for levamisole incorporation in fish feed and with the potential to enhance its use in animal production while reducing environmental contamination.",
                "disciplines": [
                    "3005"
                ]
            },
            "10.3390/ani13152499": {
                "title": "Residue Depletion Profile and Estimation of Withdrawal Period for Sulfadimethoxine and Ormetoprim in Edible Tissues of Nile Tilapia (Oreochromis sp.) on Medicated Feed",
                "abstract": "Sulfadimethoxine (SDM) and ormetoprim (OMP) are antimicrobials used in combination to treat bacterial infections in fish farming. The use of this drug combination is not yet regulated in some countries, such as Brazil. Due to the lack of regulated drugs for aquaculture in Brazil, this study investigated the residue depletion profile of SDM and OMP in Nile tilapia (<i>Oreochromis</i> sp.) after oral administration. Fish were treated with medicated feed containing a 5:1 ratio of SDM:OMP at the dose of 50 mg kg BW<sup>-1</sup> for five consecutive days with an average water temperature of 28 \u00b0C. The drugs were incorporated into the feed by using a gelatin coating process which promoted homogeneity in drug concentration and prevented the drug leaching into the water during medication. The SDM and OMP determination in fish fillets (muscle plus skin in natural proportions) was performed using the QuEChERS approach followed by LC-MS/MS quantification. The analytical method was validated according to Brazilian and selected international guidelines. A withdrawal period of 9 days (or 252 \u00b0C days) was estimated for the sum of SDM and OMP residues at concentration levels below the maximum residue level of 100 \u00b5g kg<sup>-1</sup>.",
                "disciplines": [
                    "3005"
                ]
            }
        }
    },
    "13825899": {
        "title": "New Developments in Intermediation Theory: on side effects caused by innovation and efficiency improvements of intermediation technology",
        "abstract": "Modern online platforms are flooded with amateur intermediaries, overloaded with advertising, and a phenomenon known as search addiction. In this study, we present an original economic model that explicitly considers three new factors: a reputation mechanism that replaces intermediary skills, a new intermediary mode called platform mode, and sales constraints typified by the coronavirus pandemic. We analyze whether the phenomenon occurs, whether it requires policy intervention from an economic perspective, and if so, what kind of policy is optimal. From the perspective of consumer protection, it provides a new perspective on desirable entry regulations into the intermediary business, stabilization policies that take structural changes into account, and industrial regulations.",
        "disciplines": [
            "3503"
        ],
        "publications": {
            "10.1016/j.jet.2024.105798": {
                "title": "Strategic limitation of market accessibility: Search platform design and welfare",
                "abstract": "This paper explores the relationship between market accessibility and various participants' welfare in an intermediated directed-search market. For a general class of meeting technologies, we provide a necessary and sufficient condition under which efficiency requires imperfect accessibility, such that each seller's listing is only observed by some but not all buyers. We show that the platform optimally implements the efficient outcome, but fully extracts surplus from the transactions it intermediates. We also find that in general, buyers prefer to minimize market accessibility, while sellers prefer a weakly greater accessibility level than that which is socially efficient. The efficiency of imperfect accessibility is robust to the introduction of a second chance for unmatched buyers to search.",
                "disciplines": [
                    "3803"
                ]
            }
        }
    },
    "13043554": {
        "title": "Towards a net-zero CO2 emissions chemical industry",
        "abstract": "To limit global warming below 2 \u00b0C, all sectors of human activity will have to reach net-zero carbon emissions by mid-century. On the road to net-zero emissions, the chemical industry faces a special challenge in that a large fraction of chemical products contain carbon, mostly of fossil origin, and is therefore virtually impossible to decarbonize. Though less investigated than other \u201chard-to-abate\u201d sectors, the chemical industry contributes to about 5% of today\u2019s global carbon emissions, with the demand for major chemicals (such as methanol, ammonia and plastics) being projected to grow 2.5-fold by 2050, resulting in more than 5 billion tons of carbon emissions per year in a business-as-usual scenario. A net-zero-emissions (hereafter simply net-zero) chemical industry is possible and can be achieved via multiple technology pathways. These are based (i) on the use of fossil fuels and current chemical processes and infrastructure coupled with carbon capture and storage, (ii) on the use of captured CO2 as a feedstock together with carbon-free hydrogen in new chemical processes producing carbon-rich chemicals (such as methanol and plastics), (iii) on the use of carbon-free hydrogen for producing carbon-free chemicals (such as ammonia), and (iv) on the use of biomass grown and processed for the specific purpose of making chemicals.The project has multiple objectives. First, we aim at assessing the aforementioned net-zero pathways, to provide a rigorous quantification of their net-zero claims via their lifecycle assessment. Second, we aim at assessing the required infrastructure and supply chain changes to enable a net-zero chemical industry. Third, we aim at understanding the environmental feasibility of net-zero pathways, by performing a wider environmental assessment in terms of the global implications on water scarcity and water-food-energy nexus of a net-zero chemical industry. More specifically, we aim at (i) discussing the global impact of a net-zero chemical industry on electricity and heat consumption, land use and water consumption, (ii) discussing the implications of a net-zero chemical industry on the development of carbon and hydrogen supply chains, (iii) determining the environmental feasibility of a net-zero chemical industry, when putting it into perspective with the Earth\u2019s biophysical limits, or planetary boundaries, and (iv) determining the technical, environmental, economical, and geographical circumstances under which different net-zero pathways are preferable.To this end, we are teaming up with a team of researchers at Carnegie Institution for Science, at Stanford University, which complement our expertise on chemical processes and supply chains, with their expertise on environmental assessment, water scarcity and planetary boundary assessments. This exchange project will set up the scientific collaboration, enabling the aforementioned analysis and fostering a future partnership within the contexts of net-zero emissions energy systems and water-food-energy nexus.",
        "disciplines": [
            "4004"
        ],
        "publications": {
            "10.1038/s41467-023-41107-x": {
                "title": "Global land and water limits to electrolytic hydrogen production using wind and solar resources",
                "abstract": "Proposals for achieving net-zero emissions by 2050 include scaling-up electrolytic hydrogen production, however, this poses technical, economic, and environmental challenges. One such challenge is for policymakers to ensure a sustainable future for the environment including freshwater and land resources while facilitating low-carbon hydrogen production using renewable wind and solar energy. We establish a country-by-country reference scenario for hydrogen demand in 2050 and compare it with land and water availability. Our analysis highlights countries that will be constrained by domestic natural resources to achieve electrolytic hydrogen self-sufficiency in a net-zero target. Depending on land allocation for the installation of solar panels or wind turbines, less than 50% of hydrogen demand in 2050 could be met through a local production without land or water scarcity. Our findings identify potential importers and exporters of hydrogen or, conversely, exporters or importers of industries that would rely on electrolytic hydrogen. The abundance of land and water resources in Southern and Central-East Africa, West Africa, South America, Canada, and Australia make these countries potential leaders in hydrogen export.",
                "disciplines": [
                    "4802"
                ]
            },
            "10.1016/j.oneear.2023.05.006": {
                "title": "Net-zero emissions chemical industry in a world of limited resources",
                "abstract": "The chemical industry is responsible for about 5% of global CO2 emissions and is key to achieving net-zero targets. Decarbonizing this industry, nevertheless, faces particular challenges given the widespread use of carbon-rich raw materials, the need for high-temperature heat, and the complex global value chains. Multiple technology routes are now available for producing chemicals with net-zero CO2 emissions based on biomass, recycling, and carbon capture, utilization, and storage. However, the extent to which these routes are viable with respect to local availability of energy and natural resources remains unclear. In this review, we compare net-zero routes by quantifying their energy, land, and water requirements and the corresponding induced resource scarcity at the country level and further discuss the technical and environmental viability of a net-zero chemical industry. We find that a net-zero chemical industry will require location-specific integrated solutions that combine net-zero routes with circular approaches and demand-side measures and might result in a reshaping of the global chemicals trade.",
                "disciplines": []
            },
            "10.1088/1748-9326/acd5e8": {
                "title": "Achieving net-zero emissions in agriculture: a review",
                "abstract": "Agriculture accounts for 12% of global annual greenhouse gas (GHG) emissions (7.1 Gt CO2 equivalent), primarily through non-CO2 emissions, namely methane (54%), nitrous oxide (28%), and carbon dioxide (18%). Thus, agriculture contributes significantly to climate change and is significantly impacted by its consequences. Here, we present a review of technologies and innovations for reducing GHG emissions in agriculture. These include decarbonizing on-farm energy use, adopting nitrogen fertilizers management technologies, alternative rice cultivation methods, and feeding and breeding technologies for reducing enteric methane. Combined, all these measures can reduce agricultural GHG emissions by up to 45%. However, residual emissions of 3.8 Gt CO2 equivalent per year will require offsets from carbon dioxide removal technologies to make agriculture net-zero. Bioenergy with carbon capture and storage and enhanced rock weathering are particularly promising techniques, as they can be implemented within agriculture and result in permanent carbon sequestration. While net-zero technologies are technically available, they come with a price premium over the status quo and have limited adoption. Further research and development are needed to make such technologies more affordable and scalable and understand their synergies and wider socio-environmental impacts. With support and incentives, agriculture can transition from a significant emitter to a carbon sink. This study may serve as a blueprint to identify areas where further research and investments are needed to support and accelerate a transition to net-zero emissions agriculture.",
                "disciplines": [
                    "4104"
                ]
            },
            "10.1088/1748-9326/aca815": {
                "title": "Energy and food security implications of transitioning synthetic nitrogen fertilizers to net-zero emissions",
                "abstract": "By synthetically producing nitrogen fertilizers from ammonia (NH3), the Haber\u2013Bosch process has been feeding humanity for more than one hundred years. However, current NH3 production relies on fossil fuels, and is energy and carbon intensive. This commits humanity to emissions levels not compatible with climate goals and commits agricultural production to fossil fuels dependency. Here, we quantify food and energy implications of transitioning nitrogen fertilizers to net-zero CO2 emissions. We find that 1.07 billion people are fed from food produced from imported nitrogen fertilizers. An additional 710 million people are fed from imported natural gas feedstocks used for fertilizers production, meaning that 1.78 billion people per year are fed from imports of either fertilizers or natural gas. These findings highlight the reliance of global food production on trading and fossil fuels, hence its vulnerability to supply and energy shocks. However, alternative routes to achieve net-zero emissions in NH3 production exist, which are based on carbon capture and storage, electrification, and biomass. These routes comply with climate targets while mitigating the risks associated with food security. Yet, they require more land, energy, and water than business-as-usual production, exacerbating land and water scarcity and the use of limited natural resources. Transitioning fertilizers to net-zero emissions can contribute to climate and food security goals, although water, land, and energy trade-offs should be considered.",
                "disciplines": [
                    "4004"
                ]
            }
        }
    },
    "12942330": {
        "title": "CNS Core: Medium: A Systems and User-based Approach to Floating Point Correctness and Resilience",
        "abstract": "Computer arithmetic approximates the forms of arithmetic that humans use. This approximation can lead to errors for at least two reasons: computer arithmetic is inherently limited in the range and precision of numbers it can handle, and some familiar rules of \u201chuman arithmetic\u201d may not apply, leading software developers to introduce bugs that lead to errors. In addition, computer arithmetic implementations, both in hardware and software, are quickly becoming more complex, potentially making developers more conservative out of fear of introducing new kinds of bugs by using them. This project will approach these problems from two new perspectives. From the user perspective, the project will study scientific and other software developers to better gauge their understanding of floating point arithmetic, the most common form of computer arithmetic in scientific applications, and to develop insights on how to better train developers. From the systems perspective, the project will study how to virtualize floating point arithmetic with high performance, making it easier to plug in alternative computer arithmetic systems with different properties, and tools for detecting problems with particular arithmetic systems. The project will also study important scientific applications using the tools it develops, as well as those developed by others. Science and engineering applications are increasingly critical to the economic, military, and environmental health of the nation. It is essential that such applications produce trustworthy results, regardless of the complexity of computer arithmetic and its implementations. Because computer arithmetic, and, more specifically, the IEEE standard for floating point arithmetic on which the project focuses, is a common denominator for most such applications, the project has the potential to improve such applications. Additionally, the project has the potential to better understand software developers, particularly scientific software developers, and thus develop better ways to train them with regard to floating point arithmetic. A collaboration with two national labs forms part of the project, and this will allow access both to scientific developers and to scientific applications that will serve to ground the project and hopefully also provide direct benefit beyond the expected research contributions. The project will also develop a training methodology for scientific developers, and an appropriate lab for undergraduates. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4612"
        ],
        "publications": {
            "10.1145/3617232.3624856": {
                "title": "TrackFM: Far-out Compiler Support for a Far Memory World",
                "abstract": "Large memory workloads with favorable locality of reference can benefit by extending the memory hierarchy across machines. Systems that enable such far memory configurations can improve application performance and overall memory utilization in a cluster. There are two current alternatives for software-based far memory: kernel-based and library-based. Kernel-based approaches sacrifice performance to achieve programmer transparency, while library-based approaches sacrifice programmer transparency to achieve performance. We argue for a novel third approach, the compiler-based approach, which sacrifices neither performance nor programmer transparency. Modern compiler analysis and transformation techniques, combined with a suitable tightly-coupled runtime system, enable this approach. We describe the design, implementation, and evaluation of TrackFM, a new compiler-based far memory system. Through extensive benchmarking, we demonstrate that TrackFM outperforms kernel-based approaches by up to 2\u00d7 while retaining their programmer transparency, and that TrackFM can perform similarly to a state-of-the-art library-based system (within 10%). The application is merely recompiled to reap these benefits.",
                "disciplines": [
                    "3301"
                ]
            }
        }
    },
    "12933035": {
        "title": "EAGER: Investigating the Feasibility and Scope of Automated Refactoring for Distributed Software",
        "abstract": "As software is maintained over its lifetime and new features are added, it often becomes necessary to restructure the software to continue working with expected functionality and performance. This restructuring, called refactoring, is tedious and error-prone, consuming software development time and delaying releases. In modern software development processes, refactoring is routine but only applies to software running on one machine. With the increasing ubiquity of distributed applications, such as those for the web, mobile systems, and the Internet of Things, refactoring techniques do not apply. This EAGER grant explores the issues involved in extending refactoring to distributed systems. Refactoring is the application of semantics-preserving program transformations to restructure software for better performance, modularity, and other attributes. Refactoring has become an integral part of the modern software development processes, but only for centralized software that runs within a single address space. When evolving a distributed system, programmers apply existing refactoring techniques to its individual components, treating them as separate, unrelated parts, so these techniques remain unaware of the distributed communication across these parts. When programmers can refactor only the individual parts of a distributed system, (1) the overall system\u2019s execution semantics may not be preserved, and (2) the system\u2019s distribution cannot be changed, thus making it impossible to fulfill many important objectives for modifying modern distributed systems. Distributed applications have many accompanying challenges \u2013 such as being written by independent programmers in decentralized ecosystems and in multiple languages with different semantics that need to be related and preserved. This EAGER grant will uncover technical possibilities and challenges as a step toward understanding and addressing these challenges. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4612",
            "4606"
        ],
        "publications": {
            "10.1109/cloudcom59040.2023.00047": {
                "title": "Undoing CRDT Operations Automatically",
                "abstract": "In a distributed replicated data system, Conflict-free Replicated Data Types (CRDTs) keep data replicas consistent on different nodes, while providing intuitive programming abstractions for accessing and modifying the replicas. Due to user errors, program bugs, or hardware malfunctions, a CRDT can be updated incorrectly, so the effect of the executed CRDT update operations needs to be undone. However, because CRDT libraries rarely include the undo capability, adding it requires modifying source code by hand, a task that is hard to accomplish in a modular and reusable fashion. As a result, programmers end up adding this advanced functionality in an ad-hoc fashion, with the resulting code being hard to understand, maintain, and reuse. To address this problem, this paper presents AUTO-UNDO, an automatic approach that generates and actuates undo functionality for existing CRDT libraries, based on simple configurations and without modifying the library code by hand. The configurations specify which CRDT operations undo each other and the conditions that trigger the execution of undo procedures. Based on the configuration, AUTO-UNDO generates and actuates a sequence of update operations that undo the specified updates on a given replica. We have implemented and evaluated AUTO-UNDO in JavaScript, a popular CRDT language, demonstrating our approach\u2019s effectiveness, flexibility, and efficiency. Our experiences show that AUTO-UNDO effectively provides the undo capability for CRDT-based applications, thus streamlining the complexity of adding features to distributed programming frameworks.",
                "disciplines": [
                    "4606",
                    "4612"
                ]
            },
            "10.1007/s11761-024-00391-1": {
                "title": "A meta-pattern for building QoS-optimal mobile services out of equivalent microservices",
                "abstract": "A QoS-optimal service balances reliability, execution cost, and latency to satisfy application requirements. In emerging distributed environments, with their unreliable and resource-scarce mobile/IoT devices, it is hard but essential to optimize the QoS of mobile services. Fortunately, these environments are characterized by ever-growing equivalent functionalities that satisfy the same requirements by different means. The combined execution of equivalent microservices has been used to improve QoS (e.g., majority voting for accuracy, speculative parallelism for latency, and failover for reliability). These executions are commonly described as workflow patterns, crude-grained recurring interactions across microservices within a service. However, as the number of equivalent microservices grows, applying a crude-grained pattern may cause severely unbalanced QoS, while nesting these patterns is convoluted to implement and expensive to maintain. In this article, we introduce a novel workflow meta-pattern for defining fine-grained workflow patterns that describe QoS-optimal combined executions of equivalent microservices. The meta-pattern employs a domain-specific algebraic expression to specify the invocation sequences of equivalent microservices, and a Boolean function to determine whether to terminate the execution. To evaluate the applicability of our meta-pattern, we build a Scala functional programming library, by which we further develop edge computing and cognitive service applications. Our experiments show that applying our meta-pattern to define such workflow patterns saves programmer effort, while the resulting patterns effectively improve the QoS of distributed applications.",
                "disciplines": [
                    "4606"
                ]
            },
            "10.1109/percomworkshops56833.2023.10150370": {
                "title": "OS3: The Art and the Practice of Searching for Open-Source Serverless Functions",
                "abstract": "Serverless computing enables service developers to focus on creating useful services, without being concerned about how these services would be deployed and provisioned. Many developers reuse existing open-source serverless functions to create their own functions. However, existing technologies for searching open-source software repositories have not taken into consideration the unique features of serverless functions. This paper presents a novel approach to searching for serverless functions, called Open-Source Serverless Search (OS3) that maximizes the utility of the returned serverless functions by (1) basing the search process on both descriptive keywords and library usages, thus increasing the search results' precision and completeness; (2) filtering and ranking the search results based on the software license, to accommodate the unique requirements of deploying serverless functions on dissimilar platforms, including cloud and edge computing. Implemented in 3K lines of Python, with a search space of 5,981 serverless repositories from four major serverless platforms, OS3 outperforms existing search approaches in terms of the suitability of the search results, based on our evaluation with realistic use cases.",
                "disciplines": [
                    "4610",
                    "4612"
                ]
            },
            "10.1016/j.comcom.2023.04.027": {
                "title": "Trusted and privacy-preserving sensor data onloading",
                "abstract": "To personalize their services (e.g., advertisement, navigation, healthcare), mobile apps collect sensor data. Typically, they upload the collected sensor data to the cloud, which returns the inferred user profiles required to personalize mobile services. However, privacy concerns and network connectivity/congestion issues can render cloud-based processing inapplicable. If different apps collect the same type of sensor data, app providers can collaborate by combining their data collections to infer on-device the user profiles required for personalization. Although major mobile platforms provide on-device data sharing mechanisms, these direct data exchanges provide no privacy protection. As an alternative to direct data sharing, we present differentially privatized sensor data onloading for app providers\u2019 collaboration. With our approach, app providers can safely collaborate by using shared sensor data to personalize their mobile services. We realize our approach as a middleware that acts as a trusted intermediary. The middleware aggregates the sensor data contributed by individual apps, which execute statistical queries against the combined datasets. Furthermore, the middleware\u2019s adaptive privacy-preserving scheme (1) computes and adds the required amount of noise to the query results so as to balance utility and privacy; (2) introduces a Trust-Data Theory so as to detect and remove spurious data from the combined collections; (3) rewards active contributing app providers so as to incentivize data contribution; (4) integrates a Trusted Execution Environment (TEE) so as to secure all data processing. Our evaluation shows that it is feasible and useful to personalize mobile services while protecting data privacy: queries\u2019 execution time is within 10 ms; participants\u2019 dissimilar privacy/utility requirements are satisfied; untrustworthy data are effectively detected; mobile services are personalized, and data privacy of both app providers and users are preserved. 1 1 This article is a revised and extended version of our prior paper, published in the 12th EAI International Conference on Mobile Computing, Applications and Services (MobiCASE 2021) (Liu et\u00a0al., 2022).",
                "disciplines": [
                    "4604",
                    "4605",
                    "4606",
                    "4608"
                ]
            },
            "10.1109/apsec57359.2022.00034": {
                "title": "Toward a Better Alignment Between the Research and Practice of Code Search Engines",
                "abstract": "When studying the research literature, one comes to the impression of code search engines as an essential software development tool that developers use regularly to accomplish their daily tasks. Driven by this impression, researchers primarily focus on improving the performance of code search. Nevertheless, as we argue in this paper, this impression is mostly unfounded. As a result, developers and researchers hold dissimilar perspectives on what code search engines are and their most important characteristics, with developers\u2019 perspectives and the state of the art often diverging widely. This paper aims at reconciling these divergent perspectives by drawing a comprehensive picture of code search engines, as reflected in developers\u2019 experiences and perspectives as well as the state of the art. To that end, we first survey more than 100 software developers to ascertain their usages of and preferences for code search engines. We then review the state of the art on this topic by analyzing academic papers, industry releases, and open-source projects. Finally, we juxtapose the results of our two investigations to synthesize a call-for-action for researchers and industry practitioners to better meet the demands of software developers when it comes to searching for code. Our findings can be used to better align the state of the art and practice of code search engines, leading to wider adoption and more effective use of this powerful software development tool.",
                "disciplines": [
                    "4609",
                    "4612"
                ]
            },
            "10.1109/cloudcom55334.2022.00016": {
                "title": "Quality of Information Matters: Recommending Web Services for Performance and Utility",
                "abstract": "Widely used in modern software systems, web services have become a standard means of provisioning remote resources. As the number of available web services increases, multiple services that satisfy the same functional requirement can be used interchangeably. Given a set of interchangeable services, a software developer needs to find a web service that would provide the best performance and utility. However, web services are recommended based only on their system-related performance characteristics (so called QoS, whose properties include latency, reliability, availability, etc.), while their data-related performance characteristics (e.g., data freshness, correctness, coverage, etc.) are often overlooked. As a consequence, a recommended service may end up delivering information that is inaccurate or outdated, but with high performance. To address this problem, this paper introduces Quality of Information (QoI), a quality metric complementary to QoS, that measures to which degree a web service satisfies data-related non-functional requirements. To minimize the manual effort required to evaluate the results of invoking individual services, we introduce a comparative testing methodology based on the new concept of Objects of Interest (OI). By using OI, developers can normalize the relevant information obtained from dissimilar services, so it can be automatically compared. To concretely realize our ideas, we create QiSR, a system that recommends web services based on their QoI metrics. QiSR helps developers in determining how to match services\u2019 input and output with application data requirements and how to measure the information quality of services. To evaluate the effectiveness of QiSR, we test it on representative manually selected web services. Our evaluation shows that services recommended based on both QoI and QoS exhibit better combined performance and utility than services recommend on QoS alone.",
                "disciplines": [
                    "4606",
                    "4609",
                    "4612"
                ]
            }
        }
    },
    "13057846": {
        "title": "MicroRNA210 and neuroinflammation in acute brain injury of ischemic Stroke",
        "abstract": "PROJECT SUMMARY lschemic stroke is the major type of stroke with high mortality and morbidity, and the health care costs are exorbitant and result in a significant societal burden. Currently although limited therapies including thrombolysis and endovascular clot removal have been approved for the treatment of acute ischemic brain injury, many patients still die or remain disabled. Underlying mechanisms remain poorly understood, hindering the development of effective and specific treatments for this health concern. Thus, there is an urgent need to further investigate the molecular mechanisms and identify effective therapeutic targets. Neuroinflammation is a critical contributor to the pathophysiology of acute ischemic brain injury, in which microglial activation plays a central role. We have recently discovered that microRNA210 (miR210) inhibition significantly reduced brain microglial activation and inflammatory response post-stroke in mice. Our preliminary data also showed miR210 mimic transfection upregulated pro-inflammatory cytokine in primary microglia, and miR210 inhibition reduced the expression of pro-inflammatory cytokine IL-1 f3 after oxygen-glucose deprivation (OGD). These findings suggest a new mechanism of miR210 in microglial inflammatory response contributing to ischemic brain injury. The mitochondria are a major target of miR210 during hypoxia and reprogramming of mitochondrial metabolic switch from oxidative phosphorylation to glycolysis contributes to pro-inflammatory microglial activation. We and others have demonstrated that miR210 reduces mitochondrial oxidative phosphorylation by negatively regulating a number of electron transport chain (ETC)-related genes in multiple cells and increases mitochondrial dysfunction. However, whether miR210 promotes metabolic shift in hypoxic mitochondrial respiration in favor of glycolysis and drives pro-inflammatory microglial response in the setting of stroke is unknown and requires further investigation. Thus, this proposal will attempt to reveal the mechanistic links of metabolic reprogramming in miR210-mediated pro-inflammatory microglial activation in ischemic brain injury. We will evaluate the mechanism of miR210-mediated mitochondrial metabolic shift in programming of proinflammatory microglia and neurotoxicity. We will also determine whether and to what extent miR210 deficiency inhibits microglial mitochondrial dysfunction and reduces neuroinflammation after acute ischemic brain injury. We expect to generate unique insights into the novel role of epigenetic mechanism in the activation of microglial pro-inflammatory phenotype through metabolic shift in the brain post-stroke. The outcome of this study will delineate the mechanism of miR210 in driving microglial inflammatory response. It represents a major breakthrough and paradigm-shifting focus of research and will provide new visions into a novel target of miR210 in potential therapeutic strategies for acute ischemic brain injury.",
        "disciplines": [
            "3209"
        ],
        "publications": {
            "10.1371/journal.pone.0285434": {
                "title": "3D doppler ultrasound imaging of cerebral blood flow for assessment of neonatal hypoxic-ischemic brain injury in mice",
                "abstract": "Cerebral blood flow (CBF) acutely reduces in neonatal hypoxic-ischemic encephalopathy (HIE). Clinic studies have reported that severe CBF impairment can predict HIE outcomes in neonates. Herein, the present study uses a non-invasive 3D ultrasound imaging approach to evaluate the changes of CBF after HI insult, and explores the correlation between CBF alterations and HI-induced brain infarct in mouse pups. The neonatal HI brain injury was induced in postnatal day 7 mouse pups using the Rice-Vannucci model. Non-invasive 3D ultrasound imaging was conducted to image CBF changes with multiple frequencies on mouse pups before common carotid artery (CCA) ligation, immediately after ligation, and 0 or 24 hours after HI. Vascularity ratio of the ipsilateral hemisphere was acutely reduced after unilateral ligation of the CCA alone or in combination with hypoxia, and partially restored at 24 hours after HI. Moreover, regression analysis showed that the vascularity ratio of ipsilateral hemisphere was moderately correlated with brain infarct size 24 hours after HI, indicating that CBF reduction contributes to of HI brain injury. To further verify the association between CBF and HI-induced brain injury, a neuropeptide C-type natriuretic peptide (CNP) or PBS was intranasally administrated to the brain of mouse pups one hour after HI insult. Brain infarction, CBF imaging and long-term neurobehavioral tests were conducted. The result showed that intranasal administration of CNP preserved ipsilateral CBF, reduced the infarct size, and improved neurological function after HI brain injury. Our findings suggest that CBF alteration is an indicator for neonatal HI brain injury, and 3D ultrasound imaging is a useful non-invasive approach for assessment of HI brain injury in mouse model.",
                "disciplines": [
                    "3213"
                ]
            },
            "10.1186/s13578-023-01012-8": {
                "title": "Fetal hypoxia results in sex- and cell type-specific alterations in neonatal transcription in rat oligodendrocyte precursor cells, microglia, neurons, and oligodendrocytes",
                "abstract": "BackgroundFetal hypoxia causes vital, systemic, developmental malformations in the fetus, particularly in the brain, and increases the risk of diseases in later life. We previously demonstrated that fetal hypoxia exposure increases the susceptibility of the neonatal brain to hypoxic-ischemic insult. Herein, we investigate the effect of fetal hypoxia on programming of cell-specific transcriptomes in the brain of neonatal rats.ResultsWe obtained RNA sequencing (RNA-seq) data from neurons, microglia, oligodendrocytes, A2B5+ oligodendrocyte precursor cells, and astrocytes from male and female neonatal rats subjected either to fetal hypoxia or control conditions. Substantial transcriptomic responses to fetal hypoxia occurred in neurons, microglia, oligodendrocytes, and A2B5+ cells. Not only were the transcriptomic responses unique to each cell type, but they also occurred with a great deal of sexual dimorphism. We validated differential expression of several genes related to inflammation and cell death by Real-time Quantitative Polymerase Chain Reaction (qRT-PCR). Pathway and transcription factor motif analyses suggested that the NF-kappa B (NF\u03baB) signaling pathway was enriched in the neonatal male brain due to fetal hypoxia, and we verified this result by transcription factor assay of NF\u03baB-p65 in whole brain.ConclusionsOur study reveals a significant impact of fetal hypoxia on the transcriptomes of neonatal brains in a cell-specific and sex-dependent manner, and provides mechanistic insights that may help explain the development of hypoxic-ischemic sensitive phenotypes in the neonatal brain.",
                "disciplines": [
                    "3213"
                ]
            },
            "10.1161/strokeaha.122.041651": {
                "title": "MicroRNA-210 Downregulates TET2 (Ten-Eleven Translocation Methylcytosine Dioxygenase 2) and Contributes to Neuroinflammation in Ischemic Stroke of Adult Mice",
                "abstract": "BACKGROUND: Stroke is a leading cause of morbidity and mortality worldwide. Neuroinflammation plays a key role in acute brain injury of ischemic stroke. MicroRNA-210 (miR210) is the master hypoxamir and regulates microglial activation and inflammation in a variety of diseases. In this study, we uncovered the mechanism of miR210 in orchestrating ischemic stroke-induced neuroinflammation through repression of TET2 (ten-eleven translocation methylcytosine dioxygenase 2) in the adult mouse brain.\nMETHODS: Ischemic stroke was induced in adult WT (wild type) or miR210 KO (miR210 deficient) mice by transient intraluminal middle cerebral artery occlusion. Injection of TET2 silencing RNA or miR210 complementary locked nucleic acid oligonucleotides, or miR210 KO mice were used to validate miR210-TET2 axis and its role in ischemic brain injury. Furthermore, the effect of TET2 overexpression on miR210-stimulated proinflammatory cytokines was examined in BV2 microglia. Post assays included magnetic resonance imaging scan for brain infarct size; neurobehavioral tests, reverse transcription-quantitative polymerase chain reaction, and Western blot for miR210; and TET2 levels, flow cytometry, and ELISA for neuroinflammation in the brain after stroke or microglia in vitro.\nRESULTS: miR210 injection significantly reduced TET2 protein abundance in the brain, while miR210 complementary locked nucleic acid oligonucleotides or miR210 KO preserved TET2 regardless of ischemic brain injury. TET2 knockdown reversed the protective effects of miR210 inhibition or miR210 KO on ischemic stroke-induced brain infarct size and neurobehavioral deficits. Moreover, flow cytometry and ELISA assays showed that TET2 knockdown also significantly dampened the anti-inflammatory effect of miR210 inhibition on microglial activation and IL (interleukin)-6 release after stroke. In addition, overexpression of TET2 in BV2 microglia counteracted miR210-induced increase in cytokines.\nCONCLUSIONS: miR210 inhibition reduced ischemic stroke-induced neuroinflammatory response via repression of TET2 in the adult mouse brain, suggesting that miR210 is a potential treatment target for acute brain injury after ischemic stroke.",
                "disciplines": [
                    "4201",
                    "3202",
                    "3209"
                ]
            }
        }
    },
    "13525115": {
        "title": "The democratic epistemic capacities in the age of algorithms",
        "abstract": "The project Democratic epistemic capacity in the age of algorithms (DECA) investigates the political, social, psychological and technological mechanisms that develop and hinder epistemic capacity in different contexts and at different levels of Finnish society, from the everyday experiences of laypeople to institutional professional practices, public debates about critical issues and the strategic crafting of laws and regulations. The project updates existing empirical tools to conceptualise epistemically healthy democracy as a way of producing trust, security and equality. DECA promotes access to reliable knowledge, the right to be recognised and represented and the ability to participate in knowledge production. It facilitates an understanding of how existing social inequalities intersect with epistemic capabilities, and promotes policy innovations, educational reforms and new media ethics frameworks for safeguarding society's epistemic capacity in the age of algorithms.",
        "disciplines": [
            "4408"
        ],
        "publications": {
            "10.1080/15534510.2023.2279662": {
                "title": "The price of (dis)trust \u2013 profiling believers of (dis)information in the Hungarian context",
                "abstract": "Taking a person-centered approach \u2013 we explored different constellations of social-psychological characteristics associated with (dis)information belief in order to identify distinct subgroups whose (dis)information belief stems from different social or political motives. Hungarian participants (N = 296) judged the accuracy of fake and real news items with a political (pro/anti-government) and nonpolitical narrative. Two profiles of \u2018fake news believers\u2019 and two of \u2018fake news non-believers\u2019 emerged, with a high conspiracy mentality being the main marker of the former two. These two \u2018fake news believers\u2019 profiles were distinguishable: one exhibited extreme trust in the media and in politicians, and the other deep distrust. Our results suggest that not only political distrust, but also excessive trust can be associated with disinformation belief in less democratic social contexts.",
                "disciplines": [
                    "5205",
                    "3506"
                ]
            },
            "10.1111/nana.12994": {
                "title": "The war in Ukraine and the ambivalent figure of \u2018Babushka\u2019: Intersectional nation\u2010building and the delegitimisation/legitimisation of war on YouTube",
                "abstract": "Abstract  In this article, we demonstrate how international social\u2010media discussions offer a platform for taking a stance on the war in Ukraine, redrawing national boundaries and legitimising their defence. We do so by analysing data that consist of comments triggered by a viral YouTube video depicting an encounter between an ageing civilian woman, labelled \u2018Babushka Z\u2019, and a Ukrainian soldier. Using a critical discursive psychological framework, we identify five interpretative repertoires: vulnerability , incapacity , national continuity , masculinised warriorship and righteousness . Our analysis illuminates how these repertoires draw on and reproduce intersecting categorisations based on gender, age and ethnic heritage. With the help of these categorisations, the repertoires build competing images of the actions of the figures in the video, which come to symbolise in various ways both patriotism and treason, heroism and cowardice. By aligning with competing historical\u2010national narratives, the commentors use these images to (de)legitimise the war and its actors. ",
                "disciplines": [
                    "4701",
                    "3605"
                ]
            },
            "10.1080/14680777.2023.2258298": {
                "title": "Discursive analysis of intersectional moral exclusions in online discussions on women to be repatriated to Finland from the Al-Hol camp",
                "abstract": "In spring 2019, there was a heated debate in the media concerning the Al-Hol camp in Syria, where a number of women and children were detained. This article explores intersectional dynamics of exclusion in online comments on news items regarding the repatriation of women and children from Al-Hol to Finland. The analytical framework is based on critical discursive psychology combined with an intersectional lens. The analysis distinguished three interpretative repertoires: the repertoire of a foreign threat, the repertoire of neglected maternal obligations, and the repertoire of irrationality. Within these repertoires, three subject positions were also applied to women\u2014the deceitful villain, the bad mother, and brainwashed fools\u2014with two subject positions applied to children\u2014innocent children and future threats. The analysis shows the dialectical nature of positionings through which the Otherness of these women is constructed via the interplay with evaluations of their motherhood and positions applied to other actors, such as Muslim men and Finns. Moreover, the analysis shows how positionings mobilise intersectional categorisations based on gender, age, ethnicity, religion, nationality, and race.",
                "disciplines": [
                    "4405",
                    "4701"
                ]
            }
        }
    },
    "12937073": {
        "title": "Remembering a Forgotten Pest: Bt Resistance and Monitoring in European Corn Borer",
        "abstract": "Transgenic crops have controlled insects for over 20 years. Recently, Bt crops have failed due to emerging resistance in many insects. Resistance threatens the durability and sustainability of a critical and valuable biotechnology control tactic for insects. We will investigate resistance in the European corn borer, Ostrinia nubilalis. European corn borer (ECB) was a classic example of successful control by Bt-corn. In 2018, Bt-corn expressing the toxin Cry1F failed to control ECB in 4 fields in Nova Scotia, Canada. This is the first ever report of a field failure by ECB. We suspect that the emergence of Cry1F resistance in Nova Scotia poses a severe risk for further spread across North America, as well as accelerates resistance evolution in the remaining Bt traits. This project will expand our understanding of Bt resistance in European Corn Borer to develop strategies that prevent resistance evolution and protect Bt durability. Our proposal focuses on 1) Estimating the risck and spread of Cry1F resistance; 2) Determine the potential and risk for additional Cry resistance in ECB; 3) Investigate the efficacy of other Cry proteins and cross resistance with Cry1F. Our team will implement an international and interdisciplinary approach to understand the risk that ECB resistance poses for the continued durability and sustainability of transgenic biotechnology.",
        "disciplines": [
            "3001"
        ],
        "publications": {
            "10.1038/s41598-023-35252-y": {
                "title": "Genetic mutations linked to field\u2010evolved Cry1Fa-resistance in the European corn borer, Ostrinia nubilalis",
                "abstract": "Transgenic corn, Zea mays (L.), expressing insecticidal toxins such as Cry1Fa, from Bacillus thuringiensis (Bt corn) targeting Ostrinia nubilalis (H\u00fcbner) (Lepidoptera: Crambidae) resulted in over 20\u00a0years of management success. The first case of practical field-evolved resistance by O. nubilalis to a Bt corn toxin, Cry1Fa, was discovered in Nova Scotia, Canada, in 2018. Laboratory-derived Cry1Fa-resistance by O. nubilalis was linked to a genome region encoding the ATP Binding Cassette subfamily C2 (ABCC2) gene; however, the involvement of ABCC2 and specific mutations in the gene leading to resistance remain unknown. Using a classical candidate gene approach, we report on O. nubilalis ABCC2 gene mutations linked to laboratory-derived and field-evolved Cry1Fa-resistance. Using these mutations, a DNA-based genotyping assay was developed to test for the presence of the Cry1Fa-resistance alleles in O. nubilalis strains collected in Canada. Screening data provide strong evidence that field-evolved Cry1Fa-resistance in O. nubilalis maps to the ABCC2 gene and demonstrates the utility of this assay for detecting the Cry1Fa resistance allele in O. nubilalis. This study is the first to describe mutations linked to Bt resistance in O. nubilalis and provides a DNA-based detection method that can be used for monitoring.",
                "disciplines": [
                    "3001"
                ]
            }
        }
    },
    "12949524": {
        "title": "Teamwork Under Pressure: Effective Team Processes During Extreme Events",
        "abstract": "Today, work teams increasingly face unprecedented challenges in a volatile, uncertain, complex, and often ambiguous environment. Such intense or extreme phenomena are not usually encountered by all organisational teams. However, most teams at some point will face more local challenges, such as the sudden absence of a key team member. Researchers have realised that teams need to effectively overcome such challenging situations. Therefore, we can learn from teams whose daily reality revolves around mitigating risks in uncertain and volatile systems with regular exposure to the risk of injury or death: Teams in extreme environments.An extreme environment can be defined as (a) task contexts that are atypical in terms of the level of demands (e.g. time pressure) or the type of demands (e.g., danger) and (b) settings in which ineffective performance has severe consequences (Bell et al., 2016). This typically includes teams in isolated, confined and extreme (ICE) environments like Antarctica or space and extreme action teams like first responders, firefighters or healthcare emergency teams. These action teams are built around dynamic, intense performance events often under time-pressure. Teams in extreme environments typically must manage pressing task demands (i.e. act) but simultaneously process emerging information, re-evaluate and make strategic decisions about the immediate future (i.e. think). Less is known about how teams balance competing task requirements (acting vs thinking) and ensure that they do not lose sight of the big picture during high-pressure events.Three critical processes in teams potentially counteract the adverse effects of high-pressure situations on team functioning: Team reflection, leader inclusiveness and team decision making. The three processes foster collaboration, expand the team's field of attention, and explicitly encourage team members to contribute to information processing (Schmutz, Lei, et al., 2018; Uitdewilligen & Waller, 2018; Weiss et al., 2018). This research programme's overall goal is to investigate the effects of these three processes on team functioning and performance using a hybrid research approach with teams from various industries.The proposed research programme is structured into three closely related projects. Project A will investigate team reflection during performance events (i.e., in-action team reflection) and after (i.e. debriefings) in teams and multiteam systems in a combination of controlled laboratory settings and with medical emergency teams. Project B will examine the nature of leader inclusiveness in action teams, starting with a systematic literature review. Using qualitative research methods the project will identify task characteristics of extreme events and explore when and how leader inclusiveness is applied in various settings (i.e. military, emergency medicine, paramedics, space travel, Antarctica expeditions). Besides, Project B will conduct an experimental field study manipulating leader inclusiveness with military and medical teams training highly realistic emergency scenarios. Finally, Project C will delineate effects of team reflection and leader inclusiveness on team decision making, particularly information sharing by adopting the hidden-profile paradigm to extreme action teams. Two studies will be conducted with military and medical teams investigating the interplay between team reflection and leader inclusiveness with information sharing in high and low time pressure conditions using hidden-profile tasks specifically designed for medical and military settings. Together, these projects will reveal robust results about the effectiveness and boundary conditions of team reflection, leader inclusiveness and decision making. This body of research will provide valuable insights for teams facing stressful and dynamic events both in extreme environments and more traditional organisational settings. More broadly, the proposed research programme will advance scientific knowledge of teams in extreme environments-a growing field in psychology and organisational sciences.",
        "disciplines": [
            "4608"
        ],
        "publications": {
            "10.1177/10596011231193176": {
                "title": "How Team Familiarity Mitigates Negative Consequences of Team Composition Disruptions: An Analysis of Premier League Teams",
                "abstract": "In today\u2019s dynamic work environment, teams are increasingly confronted with disruptions. While there are different types of disruptions that teams face, we contend that team composition disruptions that occur during the completion of a team\u2019s task can be especially challenging. We also argue that it is important to consider different types of team composition changes as they create different demands for team adaptation. Specifically, we assess the effects of loss of a team member and change in team membership resulting from injury substitution. We examine how these two types of team composition disruptions impact coordination and team outcomes (i.e., goals scored) by leveraging data from 2,280 soccer games in the English Premier League. We found that team member loss impaired both team coordination and outcomes while team member substitution only impacted team coordination. Moreover, we build upon and extend existing research that has examined team familiarity by distinguishing between familiarity that is built amongst members on the current team (i.e., current team familiarity) and familiarity that has developed as a result of members working together in prior teams (i.e., prior team familiarity). This distinction appears important as we did not find evidence of a main effect of prior team familiarity on coordination but found evidence of a reversing curvilinear effect of current team familiarity on coordination. Finally, the indirect effect of team member loss on team outcomes through team coordination was more pronounced when teams had low (compared to high) prior team familiarity.",
                "disciplines": [
                    "3505",
                    "3507"
                ]
            },
            "10.1016/j.jhin.2023.03.002": {
                "title": "WHO \u2018My five moments for hand hygiene\u2019 in anaesthesia induction: a video-based analysis reveals novel system challenges and design opportunities",
                "abstract": "BACKGROUND: Anaesthesia induction is a fast-paced, complex activity that involves a high density of hand-to-surface exposures. Hand hygiene (HH) adherence has been reported to be low, which bears the potential for unnoticed pathogen transmission between consecutive patients.\nAIM: To study the fit of the World Health Organization's (WHO) five moments of HH concept to the anaesthesia induction workflow.\nMETHODS: Video recordings of 59 anaesthesia inductions were analysed according to the WHO HH observation method considering each hand-to-surface exposure of every involved anaesthesia provider. Binary logistic regression was used to determine risk factors for non-adherence, i.e. professional category, gender, task role, gloves, holding of objects, team size and HH moment. Additionally, half of all videos were recoded for quantitative and qualitative analysis of provider self-touching.\nFINDINGS: Overall, 2240 HH opportunities were met by 105 HH actions (4.7%). The drug administrator role (odds ratio (OR): 2.2), the senior physician status (OR: 2.1), donning (OR: 2.6) and doffing (OR: 3.6) of gloves were associated with higher HH adherence. Notably, 47.2% of all HH opportunities were caused by self-touching behaviour. Provider clothes, face, and patient skin were the most frequently touched surfaces.\nCONCLUSION: The high density of hand-to-surface exposures, a high cognitive load, prolonged glove use, carried mobile objects, self-touching, and personal behaviour patterns were potential causes for non-adherence. A purpose-designed HH concept based on these results, involving the introduction of designated objects and provider clothes to the patient zone, could improve HH adherence and microbiological safety.",
                "disciplines": [
                    "4203"
                ]
            },
            "10.1177/10596011221150756": {
                "title": "Exceeding the Ordinary: A Framework for Examining Teams Across the Extremeness Continuum and Its Impact on Future Research",
                "abstract": "Work teams increasingly face unprecedented challenges in volatile, uncertain, complex, and often ambiguous environments. In response, team researchers have begun to focus more on teams whose work revolves around mitigating risks in these dynamic environments. Some highly insightful contributions to team research and organizational studies have originated from investigating teams that face unconventional or extreme events. Despite this increased attention to extreme teams, however, a comprehensive theoretical framework is missing. We introduce such a framework that envisions <i>team extremeness</i> as a continuous, multidimensional variable consisting of <i>environmental extremeness</i> (i.e., external team context) and <i>task extremeness</i> (i.e., internal team context). The proposed framework allows every team to be placed on the team extremeness continuum, bridging the gap between literature on extreme and more traditional teams. Furthermore, we present six propositions addressing how team extremeness may interact with team processes, emergent states, and outcomes using core variables for team effectiveness and the well-established input-mediator-output-input model to structure our theorizing. Finally, we outline some potential directions for future research by elaborating on temporal considerations (i.e., patterns and trajectories), measurement approaches, and consideration of multilevel relationships involving team extremeness. We hope that our theoretical framework and theorizing can create a path forward, stimulating future research within the organizational team literature to further examine the impact of team extremeness on team dynamics and effectiveness.",
                "disciplines": [
                    "3507"
                ]
            }
        }
    },
    "13525579": {
        "title": "Future School of Comprehensive Well-Being (SCHOOLWELL)",
        "abstract": "SchoolWell presents high impact ground-breaking multidisciplinary research in children's and youths' comprehensive wellbeing and means to cultivate it, at school. We will undertake longitudinal nested multimethod interactive intervention research in vivo. Our project contributes to the scientific renewal in the field of wellbeing research and research-based solutions for proactively enhancing equal comprehensive wellbeing at school 1) by scaling-up the research through building a novel comprehensive multidisciplinary framework, including physical, mental and socio-pedagogical dimensions of wellbeing, 2) by creating an arsenal of measures for studying it, 3) by identifying the wellbeing equality gaps, and 4)  by creating effective means and supporting materials to enhance comprehensive wellbeing and learning, ingrained in the basic socio-pedagogical practices of the school.",
        "disciplines": [
            "3901"
        ],
        "publications": {
            "10.1080/08039488.2024.2322495": {
                "title": "The Finnish Adoptive Family Study of Schizophrenia: differences in somatic diseases and conditions between adoptees with high or low genetic risk for schizophrenia spectrum disorders",
                "abstract": "BACKGROUND AND AIMS: There is some evidence that offspring of patients with schizophrenia have higher somatic morbidity, which is thought to be partially due to genetic links between somatic disorders and schizophrenia. This study explored differences in somatic diseases and conditions of adoptees with high genetic risk (HR) or low genetic risk (LR) for schizophrenia spectrum disorders.\nMATERIAL AND METHODS: The study is part of the Finnish Adoptive Family Study of Schizophrenia. The adoptive research design used made it possible to examine how the somatic health of adoptees raised in similar adoptive families, is affected by their genetic susceptibility to schizophrenia. The study sample consisted of 373 adoptees, of whom 190 had HR and 183 had LR for schizophrenia spectrum disorders. Data on somatic morbidity were gathered from the hospital records and from the national registers of the Care Register of Health Care and the Social Insurance Institution.\nRESULTS: The only statistically significant difference found was in genitourinary diseases, the likelihood being twofold higher in HR adoptees compared to LR adoptees (16.8% vs. 8.2%; adj. OR = 2.13, 95% CI 1.06-4.25, <i>p</i>\u00a0=\u00a0.033). Adoptees who were female and aged over 40 had a higher prevalence of genitourinary illnesses than non-adoptees.\nCONCLUSION: The significant prevalence of genitourinary diseases in adoptees at risk for schizophrenia spectrum disorders suggests that some specific somatic diseases and schizophrenia may have a shared hereditary etiology. More research is required for specific somatic diseases in study populations that can differentiate between the effects of genetic and environmental factors.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1007/s00787-024-02406-w": {
                "title": "Child- and parent-related determinants for out-of-home care in a nationwide population with neurodevelopmental disorders: a register-based Finnish birth cohort 1997 study",
                "abstract": "Neurodevelopmental disorders (NDDs) are among the most common health issues in childhood and adolescence. Psychiatric disorders are known to be overrepresented among children using child welfare services and placed in out-of-home care (OHC). Child- and parent-related determinants for OHC among a national population with NDDs were evaluated utilising longitudinal register data from the national Finnish Birth Cohort 1997 (n\u2009=\u200958,802) from birth to 18 years (1997\u20132015). The cohort members with NDDs (n\u2009=\u20095,143, 9% of total cohort) formed our study population. Based on their history of OHC, cohort members with NDD were categorised to OHC (n\u2009=\u2009903) and non-OHC groups (n\u2009=\u20094,240). Of all cohort members with NDDs, 17.6% had a history of OHC. Within NDDs, a significant excess of ADHD diagnosis was observed in the OHC group compared to the non-OHC group (49% vs. 26%). The OHC group with NDDs was significantly characterised by having comorbid psychiatric diagnosis for conduct and oppositional disorders (adj. RR 2.21), substance use disorders (adj. RR 1.61) and depression and anxiety disorders (adj. RR 1.60). Of all parent-related determinants, the most prevailing in the OHC group compared to the non-OHC group, was social assistance received by parent (88% vs. 44.5%). The longer the period (in years) for received social assistance, the greater the likelihood for OHC (adj. RRs range from 2.41 for one year to 5.24 for over 4 years). Further, significantly associating determinants for OHC were parental psychiatric disorders (adj. RR 1.42) and parental death (adj. RR 1.23). Our findings from the population-based cohort of children and adolescents with NDDs highlight the importance of screening and assessment of family situation. Also, effective prevention and treating of comorbid psychiatric disorders, especially conduct and oppositional disorders is essential.",
                "disciplines": [
                    "5203",
                    "5201"
                ]
            },
            "10.1142/s0219877024500275": {
                "title": "Description of Crowdsourcing and AI-Based Tool for Knowledge Management and Systems Change in Public Services",
                "abstract": "This study presents a crowdsourcing IT platform and working model intended to support knowledge management processes and systems change to help public service organizations fulfill their purpose and perform their tasks in a rapidly changing environment. The tool brings together tacit and explicit knowledge regarding organizational processes in one database and provides an AI-assisted platform for knowledge processing. Additionally, it allows for disseminating refined data to grassroots-level actors, enables the implementation of initiatives, and monitors their effectiveness. By utilizing crowdsourcing, the tool leverages the collective intelligence of actors across organizational boundaries, thereby promoting collective, knowledge-based learning and organizational self-renewal.",
                "disciplines": [
                    "3507"
                ]
            },
            "10.1155/2023/2516746": {
                "title": "Evaluation of Psychometric Properties of a New Research Instrument for Measuring Collective Impact Based Cross-Sectoral Collaboration and Leadership: Oulu Collective Impact Study",
                "abstract": "Cross-sectoral collaboration is a widely used strategy in social and healthcare services. The main purpose of this way of working is to bring together organizations and their expertise to solve defined problems. A collective impact (CI)-based model is one of the promising approaches to create prerequisites for functional collaboration between different sectors. The CI-based cross-sectoral collaboration model has been implemented in the City of Oulu since the year 2019. During the implementation processes as well as underlined in the literature, the role of effective leadership has been highlighted as an essential prerequisite for the successful realization of CI-related work. Furthermore, the need for a research instrument to measure the realization of cross-sectoral collaboration including different CI-based domains and the effectiveness of leadership has been emphasized. The aim of this study was to evaluate the psychometric properties of a new research instrument developed for this purpose, named the Oulu cross-sectoral Collaboration and Leadership (OCL) scale. The OCL scale is based on the CI approach, with leadership as an additional domain. The psychometric properties of the OCL scale were evaluated for validity and reliability. Two-factor analyses with varimax rotation were performed to verify that the items included in each domain formed a homogeneous entity. The number of respondents in the online survey was 254, covering 37% of the target group of professionals. The Cronbach\u2019s alpha of the seven domains ranged from 0.875 to 0.929, reflecting good to excellent internal consistency. The results of the factor analyses showed that the items in all the domains of this research instrument work together as a group in an appropriate manner, measuring the same object. Suggestions for further development of the instrument are also presented. The OCL scale proved to be a promising tool for research purposes and for assessing collaborative development work of public services. This also gives an opportunity to measure changes in cross-sectoral collaboration during the CI-based implementation process.",
                "disciplines": [
                    "4203",
                    "4206",
                    "4409"
                ]
            },
            "10.1080/08039488.2023.2222698": {
                "title": "Depression and dissociation mediate the association between bullying victimization and self-cutting",
                "abstract": "BACKGROUND: Bullying victimization is experienced by more than 10% of children and adolescents worldwide and has been associated with numerous negative mental health consequences, such as depression and dissociation.\nAIMS: We investigated the association between bullying victimization and self-cutting in a Finnish adolescent population and whether depression and dissociation act as mediators in this association.\nMETHODS: We used cross-sectional questionnaire data from Finnish students (age 13-18; <i>N</i>\u2009=\u20093345; boys <i>n</i>\u2009=\u20091454; girls <i>n</i>\u2009=\u20091891). Logistic regression and mediation analyses were performed.\nRESULTS: Bullying victimized adolescents were younger, more likely to be afraid to go to school, had fewer friends, felt lonelier, and had a poorer relationship with family members, as well as higher level of depressive and dissociative symptoms compared to non-bullied adolescents. According to logistic regression analysis, the association between bullying and self-cutting remained significant despite all other adjustments besides those for depressive symptoms. In serial mediation analysis, depressive and dissociative symptoms mediated the effect of bullying victimization on self-cutting, regardless of their order in the model.\nCONCLUSIONS: Self-cutting is more common among bullying victimized adolescents than their peers. The association is mediated by depressive and dissociative symptoms. More studies are needed to clarify the exact mechanisms <i>via</i> which depressive and dissociative symptoms interact with the association between bullying and self-harm.",
                "disciplines": [
                    "3213"
                ]
            },
            "10.3389/fpsyg.2023.1183704": {
                "title": "The \u201cLet\u2019s Talk about Children\u201d intervention in a Finnish school context: fidelity, parents\u2019 experiences, and perceived benefits",
                "abstract": "The Let's Talk about Children intervention is a tool for parents and professionals to work together to promote children's positive development, resilience, and psychosocial well-being in social and healthcare services, at school, and in day care. The aim of this study was to evaluate the fidelity, parents' experiences, and perceived benefits of using the Let's Talk about Children intervention in a school context. Participants (<i>N</i>\u2009=\u200965 first-grader parents) completed an online questionnaire after the intervention. The results show that the intervention was delivered as designed and conducted with high fidelity. Parents' experiences of the Let's Talk about Children discussions were positive, parents felt that the atmosphere was good during the discussion, and the participants reported benefits from the intervention. <b>Clinical trial registration:</b>ClinicalTrials.gov, identifier NCT05038280.",
                "disciplines": []
            },
            "10.1111/acer.15119": {
                "title": "Cortical thickness is inversely associated with transcranial magnetic stimulation\u2010evoked N45 potential among young adults whose heavy drinking began in adolescence",
                "abstract": "BACKGROUND: Adolescence is a particularly vulnerable stage of development in terms of the deleterious effects of alcohol. Both lower gray matter (GM) volume and greater GABAergic activity have been associated with chronic alcohol consumption during adolescence. However, the association between these measures has not been investigated.\nMETHODS: In this exploratory study, we compared 26 young adults with a 10year history of heavy alcohol consumption\u00a0with 21 controls who used little or no alcohol. Simultaneous transcranial magnetic stimulation and electroencephalography were used to assess transcranial magnetic stimulation-evoked N45 potentials, reflecting a balance between GABAergic inhibition and N-methyl-D-aspartate (NMDA) receptor-mediated glutaminergic excitation in the brain. GM thickness was measured from magnetic resonance images and GM and N45 potentials were then correlated.\nRESULTS: Cortical thickness was significantly lower in several brain regions in the heavy-drinking group than the light-drinking group. The N45 amplitude was significantly larger frontally in the heavy-drinking group. Among heavy drinkers, there were several statistically significant correlations between thinner GM and larger frontal N45 amplitudes that were not detectable in the light-drinking group. The strongest correlations were detected in the frontal and parietal lobes, especially in the left superior frontal gyrus and the left supramarginal gyrus, and in both hemispheres in the superior parietal lobes.\nCONCLUSIONS: These findings show that a thinner cortex and greater inhibitory neurotransmission are correlated in certain brain regions among young, long-term heavy alcohol users. Studies are needed to explore the possible causal mechanisms underlying these effects.",
                "disciplines": [
                    "5202"
                ]
            },
            "10.1080/20008066.2023.2191396": {
                "title": "The associations between metabolic profiles and sexual and physical abuse in depressed adolescent psychiatric outpatients: an exploratory pilot study",
                "abstract": "<b>Background</b>: Sexual and physical abuse have been associated with long-term systemic alterations such as low-grade inflammation and changes in brain morphology that may be reflected in the metabolome. However, data on the metabolic consequences of sexual and physical abuse remain scarce.<b>Objective</b>: This pilot study sought to investigate changes in the metabolite profile related to sexual and physical abuse in depressed adolescent psychiatric outpatients.<b>Method</b>: The study included 76 patients aged 14-18 years, whose serum samples were analysed with a targeted metabolite profiling methodology. We estimated the associations between metabolite concentrations and the Trauma and Distress Scale (TADS) Sexual and Physical Abuse factor scores using three linear regression models (one unadjusted and two adjusted) per metabolite and trauma type pair. Additional variables in the two adjusted models were 1) the lifestyle indicators body mass index, tobacco use, and alcohol use, and 2) depression scores and the chronicity of depression.<b>Results</b>: TADS Sexual Abuse scores associated positively with homogentisic acid, as well as cystathionine, and negatively with choline in linear regression analysis, whereas TADS Physical Abuse scores associated negatively with AMP, choline, \u03b3-glutamyl cysteine and succinate, and positively with D-glucuronic acid.<b>Conclusions</b>: This pilot study did not include a healthy control group for comparison and the cohort was relatively small. Nevertheless, we observed alterations in metabolites related to one-carbon metabolism, mitochondrial dysfunction, oxidative stress, and inflammation in depressed patients with a history of sexual or physical abuse.",
                "disciplines": [
                    "3205"
                ]
            },
            "10.1007/s00787-022-02107-2": {
                "title": "Social leisure time activities as a mediating link between self-reported psychological symptoms in adolescence and psychiatric morbidity by young adulthood: the Northern Finland 1986 Birth Cohort study",
                "abstract": "Research indicates that adolescent psychological symptoms are associated with subsequent mental health disorders. Studies also show the association of leisure activity with improved current and future mental health. However, research is limited on whether social leisure time activity is a mediating link in the association between psychological symptoms and later psychiatric morbidity. We examined whether adolescence-related social leisure time activity, per se, is a mediating link in the association between adolescent psychological symptoms and later psychiatric morbidity. The study population was based on the Northern Finland Birth Cohort 1986 Study (NFBC 1986; n\u2009=\u20096709; 3227 males). Psychological symptoms at age 15\u201316\u00a0years were measured with the Youth Self Report (YSR) questionnaire. Study participants\u2019 psychiatric morbidity by the age of 33\u00a0years was assessed using the diagnoses from the nationwide health care registers. Our results showed an association between psychological symptoms and leisure time activities that varied depending on the level of social activity. Leisure time activity was found to be a mediating link between psychological symptoms in adolescence and psychiatric disorders in early adulthood. Adolescence-related leisure time activities, which differed with regard to social interactions, appeared to serve as a mediating link between adolescent psychological symptoms and later onset of psychiatric disorders. Socially active leisure time during adolescence is related to better long-term mental health, while socially inactive leisure time associates with the likelihood of later psychiatric morbidity. To prevent psychiatric disorders, enhancing such leisure time activities in society is highly recommended.",
                "disciplines": [
                    "5203"
                ]
            },
            "10.1007/s11218-022-09734-2": {
                "title": "Dynamics between perceived social support and study engagement among primary school students: A three-year longitudinal survey",
                "abstract": "Perceived high study engagement relates to higher school achievement and has been found to promote social and emotional well-being as well. Social support for studying has typically been examined as a resource for study engagement. However, the interrelation between social support and study engagement is likely to be bidirectional: engaged students might be more willing to find and share social support in their studies. The students' emotions and attitudes toward studying (i.e., study engagement) may also influence the teachers\u2019 and guardians\u2019 tendency to provide support for that individual student\u2019s studies. This study explores the bidirectional interrelations between perceived social support for studying and perceived study engagement using three-wave longitudinal survey data in which students are followed from the fourth to sixth grade collected in 2017, 2018, and 2019 (N\u2009=\u20092401). The data are analyzed using the random-intercept cross-lagged panel model (RI-CLPM). The results indicate that perceived study engagement is a stronger and more consistent predictor of later perceived social support from teachers and among peers than vice versa. Moreover, teacher support has a bidirectional interrelation with study engagement. Girls perceive more study engagement, teacher support, and peer support in the fourth and fifth grades when compared with boys.",
                "disciplines": [
                    "3901",
                    "3904"
                ]
            }
        }
    },
    "12917803": {
        "title": "The Long-Run Causal Effects of Single-Sex High Schools on Adult Outcomes: Survey and Experiments",
        "abstract": "The proposed research focuses on the roles of an educational institution \u2013 single-sex schools (vs. coeducational schools)\u2013 in affecting gender differences in adult attitudes toward gender and family as well as demographic and socioeconomic life-course outcomes. A unique policy in a large city until 2009 required random assignment of middle-school graduates to high schools regardless of whether schools were single-sex or coeducational, and public or private. This policy provides an excellent opportunity to estimate causal effects of single-sex schools, compared to most other contexts where students or their families typically select single-sex vs. coeducational schools and thus it is challenging to draw causal inferences on the impacts of single-sex schools. Establishing whether single-sex schooling experiences affect gender-related attitudes and life-course outcomes can inform the design of school environments conducive to gender equality in the broader society. This project is supported by the Sociology Program and the Science of Broadening Participation Program. The project assesses whether single-sex high school experiences have long-run effects on individuals\u2019 gender and family attitudes, attitudes toward competition, trust, and reciprocity, and major demographic and socioeconomic outcomes in their 30s and 40s. Previous studies by the research team and others have examined the impact of the random high-school assignment on short-term educational outcomes. This extends the research to longer-run effects into middle adulthood. In order to have data to assess long-run causal effects of single-sex schools on three sets of outcomes (attitudes, demographic, and socioeconomic outcomes), an online survey is conducted to collect a variety of information on men and women in the ages 33-52 at the time of the survey in 2023-24 who graduated from high schools during the random assignment regime. In addition to traditional survey questions to measure individuals\u2019 attitudes toward gender, family, competition, trust, and reciprocity, vignettes and behavioral experiments also are included in the online survey. This design allows the team to capture attitudinal dimensions that are considered difficult to measure with traditional survey questions and to compare insights from survey experiments and traditional survey questions. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3801"
        ],
        "publications": {
            "10.1016/j.rssm.2023.100876": {
                "title": "The long-run causal effects of single-sex schooling on work-related outcomes in South Korea",
                "abstract": "This study explores the lasting impact of single-sex versus coeducational high schools on gender disparities in adult life in South Korea, which is a country characterized by marked gender inequality. Leveraging Seoul\u2019s unique policy of randomly assigning students to high schools, we examine how school type influences attainment of bachelor\u2019s degrees, working full\u00a0time, and attitudes towards competition, risk taking, and working mothers. Our findings reveal that adult women in their 30s and 40s from all-girls high schools are more likely to earn at least a bachelor\u2019s degree, work full\u00a0time, enjoy competition, take risks, and hold more positive attitudes towards working mothers compared to those from coeducational high schools. The effects of all-boys schools are not statistically significant across most outcomes. Our research highlights the potential of single-sex schooling, particularly all-girls schools, to help address gender inequality in Korea. This study fills a gap in the research by looking at the long-term impacts of single-sex high-school education on six work-related outcomes and suggests that such schools can help reduce gender disparities. Further research is needed to understand the specific mechanisms through which single-sex schooling influences these outcomes.",
                "disciplines": [
                    "4405"
                ]
            }
        }
    },
    "13788715": {
        "title": "Big data in monitoring tourist traffic and valorization of cultural ecosystem services in forest areas within the metropolises of Warsaw and Vienna",
        "abstract": "The possibility of recreation in forest areas is particularly important for residents of urban areas, especially densely populated areas (metropolises, agglomerations, conurbations), where, due to the spatial policy pursued by the authorities, there are relatively few green areas and they are subject to constant pressure from other players for space. \u2013 developers. The disappearance of green areas in cities is, of course, also associated with the search for places to relax, which also increases the pressure on the natural environment. The significant role of forest areas in meeting one of the basic needs of society, which is contact with nature, has been emphasized in numerous scientific works for many years. It has long been known that forest areas have a positive impact on the well-being and mental health of people who decide to spend time in the forest. The important role of forests in this respect could be seen during the lockdown caused by the coronavirus pandemic. Recreation in forest areas is also one of the elements of so-called ecosystem services, i.e. benefits that society obtains from natural areas. The role and importance of forest areas, as well as their size understood as area per person, varies. Strong pressure and penetration of forest areas, mainly in the vicinity of agglomerations and naturally valuable areas, may result in exceeding the natural capacity of forest ecosystems and, consequently, in their degradation. Poorly organized tourist traffic also poses a threat to the forest in the form of fires, destruction of vegetation, irrational harvesting of forest undergrowth, disturbing animals, littering the forest, etc. One of the ways to eliminate the potential negative effects of recreation and tourism is to have information about society's preferences, times and places. tourist traffic and its intensity. This information may constitute the basis for making decisions regarding the arrangement and adaptation of infrastructure for various user groups, and the channeling of tourist traffic to match it to a specific user group. Taking the above into account, the project focuses on the possibilities of providing cultural ecosystem services (CES) by urban and suburban forest areas in two metropolitan areas of Warsaw and Vienna. In addition, society's demand for this type of services will be determined, as well as elements related to recreational mobility (hot spots, directions of movement) will be examined. The project will use the latest technological solutions and large data sets (Big Data) from many sources to map and valorize CES. Data resources include: social geographic information data (e.g. from Flickr, Twitter); open spatial data from Copernicus, OGD Vienna projects; survey research, GPS data. Therefore, an important goal of the project is also to explore the potential and limitations of Big Data in CES analyses. The project will use the advanced cyber-infrastructure of the \"Center for Scientific Geospatial Analyzes and Satellite Computing (CENAGIS)\" to perform analyses. The expected project results include: identification of factors influencing the recreational use of forest areas; CES valorization; mapping the temporal and spatial distribution of activities in forest areas; indicating the directions of movement of society from their place of residence to selected forest complexes; development of Big Data processing and analysis methodology for their use for CES.  The activities envisaged in the project are intended to better understand the behavior and needs of society in the field of recreation in forest areas, identify areas with the highest potential CES that should be preserved and provide tools for making decisions in the field of forest area management and spatial planning. The project will be conducted by an interdisciplinary team of scientists from Poland and Austria, who will combine their knowledge in the field of social sciences, forestry, recreation monitoring with geoinformation and the analysis of large data sets.",
        "disciplines": [
            "3007"
        ],
        "publications": {
            "10.3390/f15020354": {
                "title": "Unveiling the Essential Role of Green Spaces during the COVID-19 Pandemic and Beyond",
                "abstract": "The COVID-19 pandemic highlighted the essential role of urban and rural green spaces for societies coping with global public health crisis. During this particular time, a significant body of research was devoted to human\u2013nature relationships, as well as the use and importance of green spaces, both from the management and visitors\u2019 perspectives, along with the vital role of nature in human health and wellbeing. Furthermore, the pandemic experience induced new paradigms in spatial and urban planning, along with the management of forest and protected areas seeing the crucial role of green spaces in shaping long-term socio-environmental resilience and sustainability. Thus, after the official end of the pandemic, our study aimed to provide a systematic review of the international research related to green spaces within the context of the COVID-19 pandemic, focusing on those published between 2020 and 2023. The literature search within SCOPUS and Web of Science databases was conducted on 16 May 2023. A dataset of 161 articles was analyzed using a two-stage analysis. In the first stage, screening based on the title, abstract, and keywords was carried out. In the second stage, a detailed full text analysis was carried out, resulting in a final dataset of 66 articles related to the scope of this review. This article gives an in-depth methodological and conceptual overview, also referring to the applied research and management context related to green spaces in urban and rural environments. It concludes with lessons learned and poses open questions for future research related to green space planning and management. The literature review shows that institutions managing green spaces in cities and forests are facing new challenges. These include pursuing sustainable management policies in cities, ensuring equitable access to urban green space and community participation in the decision-making process, adapting suburban forest management to social expectations, and the recreational development of forest areas taking into account social needs and ecosystem sustainability.",
                "disciplines": [
                    "3103",
                    "3007"
                ]
            },
            "10.1007/s11629-023-8914-3": {
                "title": "Mapping cultural ecosystem services in mountain forests using mobile phone data",
                "abstract": "The aim of the work was to determine the spatial distribution of activity in the forest on the area of the Forest Promotional Complex \u201cSudety Zachodnie\u201d using mobile phone data. The study identified the sites with the highest (hot spot) and lowest (cold spot) use. Habitat, stand, demographic, topographic and spatial factors affecting the distribution of activity were also analyzed. Two approaches were applied in our research: global and local Moran\u2019s coefficients, and a machine learning technique, Boosted Regression Trees. The results show that 11,503,320 visits to forest areas were recorded in the \u201cSudety Zachodnie\u201d in 2019. The most popular season for activities was winter, and the least popular was spring. Using global and local Moran\u2019s I coefficients, three small hot clusters of activity and one large cold cluster were identified. Locations with high values with similar neighbours (hot-spots) were most often visited forest areas, averaging almost 200,000 visits over 2019. Significantly fewer visits were recorded in cold-spots, the average number of visits to these areas was about 4,500. The value of global Moran\u2019s I was equal to 0.54 and proved significant positive spatial autocorrelation. Results of Boosted Regression Trees modeling of visits in forest, using tree stand habitat and spatial factors accurately explained 76% of randomly selected input data. The variables that had the greatest effect on the distribution of activities were the density of hiking and biking trails and diversity of topography. The methodology presented in this article allows delineation of Cultural Ecosystem Services hot spots in forest areas based on mobile phone data. It also allows the identification of factors that may influence the distribution of visits in forests. Such data are important for managing forest areas and adapting forest management to the needs of society while maintaining ecosystem stability.",
                "disciplines": [
                    "4102"
                ]
            },
            "10.14746/quageo-2023-0016": {
                "title": "Visits in Forests During the Covid-19 Pandemic in the Cross-Border Area of Poland, the Czech Republic and Germany",
                "abstract": "Mobile phone data were used to examine the differences in the number and structure of visitors to the Forest Promotion Complex Sudety Zachodnie in 2019 (pre-pandemic year) and 2020 (pandemic year). The studies not only compared the total number of visitors in each year, but also distinguished four pandemic and restriction periods. This allowed us to capture the dynamics of the impact of the pandemic on visits to forest areas. The results show that although the total number of visitors increased in 2020 compared to 2019, different trends were observed in each pandemic period. In general, the number of visitors to forest areas decreased during the first lockdown, as well as during the ban on entering green areas and forests. However, during the easing of restrictions and the second lockdown in the fall of 2020, there was an increase in visitor numbers. The article also shows the evolution of visitor numbers at a very detailed level of a grid of 750 \u00d7 750 m. During the pandemic, the structure of visitors also changed taking into account the place of residence. Local tourism was more important than national tourism. A significant decrease in the number of visitors from abroad was also observed, which is a consequence of the introduced restrictions on travel between countries. The methodology presented in this article can be used not only to study the impact of the pandemic on visits in forest, but also to manage forest areas with a view to adapting forest management to the needs of society.",
                "disciplines": [
                    "3508",
                    "3504",
                    "3506"
                ]
            }
        }
    },
    "13042111": {
        "title": "Operative TV: Audiovisual Closed-Circuits from the Military to the Classroom, 1930s-1990s",
        "abstract": "From video surveillance to online teaching, from drone warfare, highway management to telemedicine: closed-circuit images take up multiple spaces today. Despite being quotidian, their history remains largely unknown. Operative TV\u2019s goal is to fill this gap by providing the first ever study of audiovisual closed-circuits in the longue dur\u00e9e. It scrutinizes the closed-circuits\u2019 diversity between the 1930s and the 1990s and develops case studies from the USA, France, the UK, Germany, and Switzerland - countries crucial for the development of closed-circuits and providing access to resources for writing the history of a medium whose images were conceived as instruments rather than representations.Distributed under Industrial Television and CCTV (for closed-circuit television), the systems were developed in Europe and the USA mainly by enterprises active in televisual R&D (i.e., RCA, Grundig, and many more). In their most basic organization, they connected a camera with a monitor by cable; more sophisticated designs allowed for the video recording of content or bi-directional conversation. While CCTV today stands as a synonym of the surveillance camera, its historical applications were at least as heterogeneous as contemporary closed-circuits and used on factory floors and in nuclear plants, in hospitals and schools. In this study, subproject (SP) 2 focuses on surveillance operations. However, Operative TV also emphasizes televisual practices beyond the surveillance framework and the closed-circuit\u2019s embeddedness in multiple institutional spaces. In lieu of using a narrow definition of what I call audiovisual closed-circuits (AVCC), I comprehend AVCC as a flexible and pluriform system: its applicability beyond the surveillance camera paradoxically stems from its closed design. Drawing upon multinational archival research, Operative TV examines two main hypotheses. First, it posits that the analysis of television in industrial, educational, and military contexts cannot be based on habitual analytical categories such as texts or spectators. Instead, AVCC necessitates a methodological shift towards an understanding of audiovisual production as a chain of operations that allows analyzing the entanglement of human and non-human actors. AVCC\u2019s usefulness indeed was contingent on the interplay of heterogeneous elements including operators, screens, infrastructures, and images: their interdependence, rather than the isolated components, should form the core of a historical enquiry. Second, Operative TV argues that the history of AVCC, an analog-electronic technology, nourishes a media archaeology of the digital. AVCC emerged at the same moment as digital computers; it coexisted and sometimes converged with digital machines. Before the computer definitively took over factory and office floors, television was used as a tool for operations ranging from targeting to instructing: analyzing AVCC\u2019s alleged \u201cuniversality\u201d (Journal d\u2019Yverdon 1955) allows to better understand the emergence of our digital society. To discuss these two hypotheses, the project introduces an original framework drawing upon recent media theory, and looks more specifically at four operations performed by AVCC (SP 1 to 4). In addition to the operation of surveilling (SP 2), targeting (SP 1) was a central - and first - function of closed-circuits from the 1930s on; automating the workplace and instructing students (SP 3 & 4) were other tasks performed by AVCC in the postwar years. Sustained by complex human-machines ecologies, these operations would rapidly be executed by digital computers: before their digitization, they were the realm of analog TV.",
        "disciplines": [
            "3605"
        ],
        "publications": {
            "10.18146/view.297": {
                "title": "Audiovisual Heritage and its Uses at the Swiss Public Broadcaster: A Dialogue on Opportunities and Constraints for Archives and Academics",
                "abstract": "Conjointly conceived by an archivist at the Radio T\u00e9l\u00e9vision Suisse (RTS, the French speaking PSB) and two media historians, this paper aims at discussing the diversity of uses of digitised AV heritage in Switzerland through the lenses of their professional experience. It focuses on the RTS as a particularly productive case study since the RTS has not only been a pioneer in digitising AV heritage and in promoting its holdings to the broader audience, but it also actively develops new tools for internal use, in particular speech to text technologies and more recently AI-based automation for image treatment and analysis, and datamining tools. Through a discussion of current projects at the RTS, the paper provides insights into the most recent uses and reuses of digitised AV heritage in Switzerland.",
                "disciplines": [
                    "4302"
                ]
            },
            "10.18146/tmg.835": {
                "title": "Decentring the Broadcasting Dispositif: Educational Closed-Circuits, Military-Industrial Entanglements, and Useful TV",
                "abstract": "Between the 1950s and the 1970s, the introduction of ETV into classrooms was supported by ongoing experiments regarding the medium\u2019s affordances and technological design: educators and financing bodies experimented with televisual forms that embraced non-commercial broadcasting, national and regional programming, and even transmissions by planes. Analysing educational television in the USA, this paper focuses on one specific dispositif, namely the televisual closed-circuit (CCTV). While the closed-circuit projects have been widely documented in the postwar period and have received some attention from television and media historians, the analytical focus has remained on educational CCTV. This paper suggests a shift in perspective that embeds the educational closed-circuit within a broader history of televisual CCTV. In addition to serving school reforms, postwar CCTV systems were frequently used in military and industrial settings, where they fostered automation, surveillance, and tele-command. The analysis of educational television through the lens of closed-circuits brings to the fore such military-industrial entanglements and their links with the educational sector, and shines a new light on the history of educational TV overall.",
                "disciplines": [
                    "4303"
                ]
            },
            "10.5117/9789463727815": {
                "title": "Television before TV",
                "abstract": "Television before TV rethinks the history of interwar television by exploring the medium\u2019s numerous demonstrations organized at national fairs and international exhibitions in the late 1920s and 1930s. Building upon extensive archival research in Britain, Germany, and the United States, Anne-Katrin Weber analyses the sites where the new medium met its first audiences. She argues that public displays offered spaces where television's symbolic, cultural, political, and social definitions were negotiated and eventually stabilized; for the historian, the exhibitions therefore constitute crucial events to understand not only the medium's pre-war emergence, but also its subsequent domestication in the post-war years. Designed as a transnational study, her book highlights the multiple circulations of artefacts and ideas across borders of democratic and totalitarian regimes alike. Richly illustrated with 100 photographs, Television before TV finally emphasizes that even without regular programmes, interwar television was widely seen.",
                "disciplines": [
                    "4701",
                    "4702",
                    "4303",
                    "3605"
                ]
            }
        }
    },
    "12931483": {
        "title": "Collaborative Research: RUI: Bank type, bank market ecologies, and support of small businesses",
        "abstract": "American banking has long denied credit to borrowers in poor and marginalized communities. Yet that system contains a striking variety of lending organizations, ranging from global corporate behemoths to community banks, credit unions and community development institutions, that embrace very different business models missions and values, and that relate to borrowers and communities, including poor and traditionally marginalized minority ones, in very different ways. This project analyzes that organizational variety and its impact in the Paycheck Protection Program (PPP) to determine how differences in lending organizations and the ecologies or mixes of lenders that populate banking markets shape\u2013and might enhance\u2014access to credit for small business in poor and non-white communities. Ideally suited for this study, the PPP was a federal government program that worked though the nations\u2019 existing lenders to issue nearly 12 million loans to businesses to keep workers on payroll during the pandemic, and produced detailed data on where and to whom lenders lent. To address the impact of lender organizational form and bank market ecologies on credit flows, this project combines interviews of lenders and borrowers with multi-level quantitative analyses of a new data set on all PPP loans that links: a) data on lending by seven lender types and socio-economic conditions in 32,000 communities, with b) data on the organizational compositions of 625 regional banking markets that served those communities. These analyses contribute broadly to understanding how organization shapes inequality, while extending organizational ecology and institutional research on organizational form and complexity to new outcomes. They address a key gap in our knowledge of class and ethno-racial divides in banking and credit, integrating work in organizational studies, economic sociology and political economy on bank organization, banking systems and their economic impacts with research in sociology, law and allied fields, which extensively analyzes banking and credit as sites of discrimination and segregation, but commonly sets organizational variety in banking aside (or focus on large banks) to document broader systemic tendencies. And by identifying possibilities for greater inclusivity within American banking\u2014and in government programs that work though that system \u2013 this project highlights new avenues for reform, including building the capacities of lenders that engage traditionally marginalized communities and altering mixes of institutions in regional markets. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3507"
        ],
        "publications": {
            "10.1177/08912424231163485": {
                "title": "Bank Types, Inclusivity, and Paycheck Protection Program Lending During COVID-19",
                "abstract": "<p>How do differences in bank or lending institution type shape access to credit for small businesses in poor and/or minority communities in the United States? Banking systems are populated by lenders that differ qualitatively in their organizational forms, business models and missions, and that connect\u2014or fail to connect\u2014to small business borrowers and local communities in divergent ways. The authors analyze data on the Paycheck Protection Program and its over 11 million loans made to businesses across the United States to trace how these differences shaped the flow of credit to poor and minority communities. The authors find substantial differences across seven lender types, both in their propensities to avoid or lend to firms in traditionally marginalized communities, and in how much they lend to poor and majority\u2013minority communities relative to their nonpoor and majority White counterparts. From this variety within American banking, the authors identify two potential pathways for more inclusive lending.</p>",
                "disciplines": [
                    "3801",
                    "4404",
                    "4407"
                ]
            }
        }
    },
    "12948113": {
        "title": "Scholar at Risk Nataliia Hendel",
        "abstract": "Nataliia Hendel is a Ukrainian researcher in international humanitarian law, fleeing the conflict in Ukraine. She is a professor in the Department of International Law and Comparative Law at the International Humanitarian University, Odessa. She has more than 70 publications to her credit, whether contributions for monographs or articles in periodicals. She has more than 10 years of teaching and research experience in the field of international law. She now has the opportunity to join the Geneva Academy of International Humanitarian Law and Human Rights (joint center of the Faculty of Law of the University of Geneva and the IHEID) as a scientific collaborator in the team of Prof Gloria Gaggioli.",
        "disciplines": [
            "4803",
            "4807"
        ],
        "publications": {
            "10.1007/978-94-6265-515-7": {
                "title": "International Conflict and Security Law, A Research Handbook",
                "abstract": "This unique two-volume book covers virtually the whole spectrum of international conflict and security law. It proceeds from values protected by international law (Part I), through substantive rules in which these values are embodied (Part II), to international and domestic institutions that enforce the law (Part III). It subsequently deals with current challenges in the application of rules of international conflict and security law (Part IV), and crimes as the most serious violations of those rules (Part V). Finally, in the section on case studies (Part VI), lessons learnt from a number of conflict situations are discussed. Written by an international team of experts representing all the major legal systems of the world, the book is intended as a reference work for students and researchers, domestic and international judges, as well as for legal advisers to governments and international and non-governmental organisations. Sergey Sayapin is Associate Professor and Associate Dean at KIMEP University, School of Law in Almaty, Kazakhstan. Rustam Atadjanov is Assistant Professor at KIMEP University, School of Law in Almaty, Kazakhstan. Umesh Kadam is formerly Additional Professor at the National Law School of India University, Bangalore, India and Legal Adviser with the International Committee of the Red Cross. Gerhard Kemp is Professor of Law at the University of Derby in the United Kingdom. Nicol\u00e1s Zambrana-T\u00e9var is Associate Professor at KIMEP University, School of Law in Almaty, Kazakhstan. No\u00eblle Qu\u00e9nivet is Professor in International Law at the University of the West of England, Bristol Law School in the United Kingdom.",
                "disciplines": [
                    "4801",
                    "4807"
                ]
            }
        }
    },
    "12964737": {
        "title": "Novel computational strategies to deconvolute co-occurring conditions in Down syndrome",
        "abstract": "PROJECT SUMMARY The triplication of chromosome 21, which encodes ~225 genes, is the cause of Down syndrome. Individuals with Down syndrome experience a wide and variable spectrum of co-occurring conditions. Though we know the cause, which is trisomy 21, we have a poor understanding of how and why this chromosomal abnormality drives associated co-occurring conditions. A better mechanistic understanding of these connections will provide the basis for not only improving the care of individuals with Down syndrome but also for the general population. Research efforts such as the Human Trisome and INCLUDE Project are generating multi-omics data on large cohorts of individuals with trisomy 21 to gain such mechanistic insights. Given the complexity of the problem \u2013 the dosage increased of ~225 genes connected to a wide spectrum of conditions \u2013 existing tools for -omic data analysis struggle to leverage this information properly and separate generic from context-specific cellular responses. We must be able to analyze these data in the context of the full disease spectrum that individuals with DS experience, from genes to proteins to pathways. Further complicating these analyses, we and others have shown that certain genes and pathways are hypersensitive to perturbation, thus we often identify generic responses through standard analysis methods, when our goal is to find disease- and context-specific changes. These hyperresponsive genes and pathways obscure context-specific signals. We propose to develop the methodology to find the context-specific signal associated with trisomy 21. Our first aim is to develop methods to identify shared genetic mechanisms between complex diseases and molecular changes in Down syndrome co-occurring conditions. We will leverage genomic and transcriptomic datasets from a wide array of previously collected association studies. Our second aim is to develop a method to separate generic from context-specific signals in -omic datasets. We will employ a novel generative neural network simulation to generate different disease contexts, for which individual -omic samples can be compared. Our third aim is to determine the molecular connections between chromosome 21 genes and the co-occurring condition using search over knowledge graphs. All methods developed will be made public through the INCLUDE Data Coordination Center platforms.",
        "disciplines": [
            "3105"
        ],
        "publications": {
            "10.1038/s41467-023-41057-4": {
                "title": "Projecting genetic associations through gene expression patterns highlights disease etiology and drug mechanisms",
                "abstract": "Genes act in concert with each other in specific contexts to perform their functions. Determining how these genes influence complex traits requires a mechanistic understanding of expression regulation across different conditions. It has been shown that this insight is critical for developing new therapies. Transcriptome-wide association studies have helped uncover the role of individual genes in disease-relevant mechanisms. However, modern models of the architecture of complex traits predict that gene-gene interactions play a crucial role in disease origin and progression. Here we introduce PhenoPLIER, a computational approach that maps gene-trait associations and pharmacological perturbation data into a common latent representation for a joint analysis. This representation is based on modules of genes with similar expression patterns across the same conditions. We observe that diseases are significantly associated with gene modules expressed in relevant cell types, and our approach is accurate in predicting known drug-disease pairs and inferring mechanisms of action. Furthermore, using a CRISPR screen to analyze lipid regulation, we find that functionally important players lack associations but are prioritized in trait-associated modules by PhenoPLIER. By incorporating groups of co-expressed genes, PhenoPLIER can contextualize genetic associations and reveal potential targets missed by single-gene strategies.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            },
            "10.1093/gigascience/giad047": {
                "title": "Hetnet connectivity search provides rapid insights into how biomedical entities are related",
                "abstract": "BACKGROUND: Hetnets, short for \"heterogeneous networks,\" contain multiple node and relationship types and offer a way to encode biomedical knowledge. One such example, Hetionet, connects 11 types of nodes-including genes, diseases, drugs, pathways, and anatomical structures-with over 2 million edges of 24 types. Previous work has demonstrated that supervised machine learning methods applied to such networks can identify drug repurposing opportunities. However, a training set of known relationships does not exist for many types of node pairs, even when it would be useful to examine how nodes of those types are meaningfully connected. For example, users may be curious about not only how metformin is related to breast cancer but also how a given gene might be involved in insomnia.\nFINDINGS: We developed a new procedure, termed hetnet connectivity search, that proposes important paths between any 2 nodes without requiring a supervised gold standard. The algorithm behind connectivity search identifies types of paths that occur more frequently than would be expected by chance (based on node degree alone). Several optimizations were required to precompute significant instances of node connectivity at the scale of large knowledge graphs.\nCONCLUSION: We implemented the method on Hetionet and provide an online interface at https://het.io/search. We provide an open-source implementation of these methods in our new Python package named hetmatpy.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1038/s41592-023-01886-z": {
                "title": "Machine learning in rare disease",
                "abstract": "High-throughput profiling methods (such as genomics or imaging) have accelerated basic research and made deep molecular characterization of patient samples routine. These approaches provide a rich portrait of genes, molecular pathways and cell types involved in disease phenotypes. Machine learning (ML) can be a useful tool for extracting disease-relevant patterns from high-dimensional datasets. However, depending upon the complexity of the biological question, machine learning often requires many samples to identify recurrent and biologically meaningful patterns. Rare diseases are inherently limited in clinical cases, leading to few samples to study. In this Perspective, we outline the challenges and emerging solutions for using ML for small sample sets, specifically in rare diseases. Advances in ML methods for rare diseases are likely to be informative for applications beyond rare diseases for which few samples exist with high-dimensional data. We propose that the method community prioritize the development of ML techniques for rare disease research.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            },
            "10.1093/nar/gkad289": {
                "title": "MyGeneset.info: an interactive and programmatic platform for community-curated and user-created collections of genes",
                "abstract": "Gene definitions and identifiers can be painful to manage-more so when trying to include gene function annotations as this can be highly context-dependent. Creating groups of genes or gene sets can help provide such context, but it compounds the issue as each gene within the gene set can map to multiple identifiers and have annotations derived from multiple sources. We developed MyGeneset.info to provide an API for integrated annotations for gene sets suitable for use in analytical pipelines or web servers. Leveraging our previous work with MyGene.info (a server that provides gene-centric annotations and identifiers), MyGeneset.info addresses the challenge of managing gene sets from multiple resources. With our API, users readily have read-only access to gene sets imported from commonly-used resources such as Wikipathways, CTD, Reactome, SMPDB, MSigDB, GO, and DO. In addition to supporting the access and reuse of approximately 180k gene sets from humans, common model organisms (mice, yeast, etc.), and less-common ones (e.g. black cottonwood tree), MyGeneset.info supports user-created gene sets, providing an important means for making gene sets more FAIR. User-created gene sets can serve as a way to store and manage collections for analysis or easy dissemination through a consistent API.",
                "disciplines": [
                    "3102"
                ]
            },
            "10.1101/2023.01.21.525030": {
                "title": "A publishing infrastructure for AI-assisted academic authoring",
                "abstract": "In this work we investigate how models with advanced natural language processing capabilities can be used to reduce the time-consuming process of writing and revising scholarly manuscripts. To this end, we integrate large language models into the Manubot publishing ecosystem to suggest revisions for scholarly text. We tested our AI-based revision workflow in three case studies of existing manuscripts, including the present one. Our results suggest that these models can capture the concepts in the scholarly text and produce high-quality revisions that improve clarity. Given the amount of time that researchers put into crafting prose, we anticipate that this advance will revolutionize the type of knowledge work performed by academics.",
                "disciplines": [
                    "3602"
                ]
            },
            "10.1016/j.gpb.2022.09.011": {
                "title": "SOPHIE: Generative Neural Networks Separate Common and Specific Transcriptional Responses",
                "abstract": "Genome-wide transcriptome profiling identifies genes that are prone to differential expression (DE) across contexts, as well as genes with changes specific to the experimental manipulation. Distinguishing genes that are specifically changed in a context of interest from common differentially expressed genes (DEGs) allows more efficient prediction of which genes are specific to a given biological process under scrutiny. Currently, common DEGs or pathways can only be identified through the laborious manual curation of experiments, an inordinately time-consuming endeavor. Here we pioneer an approach, Specific cOntext Pattern Highlighting In Expression data (SOPHIE), for distinguishing between common and specific transcriptional patterns using a generative neural network to create a background set of experiments from which a null distribution of gene and pathway changes can be generated. We apply SOPHIE to diverse datasets including those from human, human cancer, and bacterial pathogen Pseudomonas aeruginosa. SOPHIE identifies common DEGs in concordance with previously described, manually and systematically determined common DEGs. Further molecular validation indicates that SOPHIE detects highly specific\u00a0but\u00a0low-magnitude biologically relevant transcriptional changes. SOPHIE's measure of specificity can complement log<sub>2</sub> fold change values generated from traditional DE analyses. For example, by filtering the set of DEGs, one can identify genes that are specifically relevant to the experimental condition of interest. Consequently, these results can inform future research directions. All scripts used in these analyses are available at https://github.com/greenelab/generic-expression-patterns. Users can access https://github.com/greenelab/sophie to run SOPHIE on their own data.",
                "disciplines": [
                    "3102",
                    "3105"
                ]
            }
        }
    },
    "12967831": {
        "title": "Multiscale Simulation Software for Energy Transduction in Biomolecular Systems: From Electrons to the Mesoscale",
        "abstract": "Multiscale Computational Framework for Biomolecular Energy Transduction: From Electrons to the Mesoscale\u00a0 \n\nThis project concerns a theory, modeling, and simulation team devoted to the development of new leading edge computer simulation\u00a0software for the study of the way in which systems composed of biological molecules transfer energy (\u201cenergy transduction\u201d). It involves researchers across three universities and with two key Department of Energy Laboratory collaborations. This combined effort \u2013\u00a0which includes the development of open source exascale scientific computing software developed and carried out on DOE leadership class computers \u2013\u00a0is unique in both its scope and methodology. The project precisely targets chemical transformations and energy transduction processes across multiple scales in complex environments and systems related to the supported research of DOE Basic Energy Sciences. Many, if not most, of the challenging energy transduction processes \u00a0to model accurately involve molecular systems that couple phenomena over a wide range of time and length scales. Striking examples begin with chemical reactions where the catalysis is activated by localized electronic and atomic factors that are in turn coupled to the slow macromolecular dynamics taking place over much larger distances and timescales, as often occurs in biomolecular systems, e.g., for adenosine triphosphate (ATP) production, i.e., the \u201cfuel of life\u201d. Most molecular machines that perform directed useful work in biological systems are designed according to this multiscale coupling principle, whereby the local chemistry involving the chemical reactions of the molecules are coupled to large structural reorganization (e.g., in biomolecular \u201cmotors\u201d and a host of other important systems). Equally important are the systems where electron transfer drives proton transport, thus creating a chemical gradient which is then utilized by proteins to perform useful work, such as the production of ATP. This multiscale simulation project \u2013\u00a0and the software it will produce \u2013\u00a0will allow for an\u00a0unprecedented computational platform to model, analyze, and understand critically important energy transducing \u201cnano-machines\u201d in biology. Such information, while extremely valuable in its own right, will also serve to aid experimental researchers in the design of new synthetic bio-inspired energy transducing systems at the nanoscale and beyond.",
        "disciplines": [
            "3406"
        ],
        "publications": {
            "10.1021/acs.jpcb.4c01987": {
                "title": "Molecular Dynamics Simulation of Complex Reactivity with the Rapid Approach for Proton Transport and Other Reactions (RAPTOR) Software Package",
                "abstract": "Simulating chemically reactive phenomena such as proton transport on nanosecond to microsecond and beyond time scales is a challenging task. <i>Ab initio</i> methods are unable to currently access these time scales routinely, and traditional molecular dynamics methods feature fixed bonding arrangements that cannot account for changes in the system's bonding topology. The Multiscale Reactive Molecular Dynamics (MS-RMD) method, as implemented in the Rapid Approach for Proton Transport and Other Reactions (RAPTOR) software package for the LAMMPS molecular dynamics code, offers a method to routinely sample longer time scale reactive simulation data with statistical precision. RAPTOR may also be interfaced with enhanced sampling methods to drive simulations toward the analysis of reactive rare events, and a number of collective variables (CVs) have been developed to facilitate this. Key advances to this methodology, including GPU acceleration efforts and novel CVs to model water wire formation are reviewed, along with recent applications of the method which demonstrate its versatility and robustness.",
                "disciplines": [
                    "3407"
                ]
            },
            "10.1021/acs.jctc.3c00663": {
                "title": "An Ab Initio Correction Vector Restricted Active Space Approach to the L\u2011Edge XAS and 2p3d RIXS Spectra of Transition Metal Complexes",
                "abstract": "We describe an ab initio approach to simulate L-edge X-ray absorption (XAS) and 2p3d resonant inelastic X-ray scattering (RIXS) spectroscopies. We model the strongly correlated electronic structure within a restricted active space and employ a correction vector formulation instead of sum-over-state expressions for the spectra, thus eliminating the need to calculate a large number of intermediate and final electronic states. We present benchmark simulations of the XAS and RIXS spectra of the iron complexes [FeCl<sub>4</sub>]<sup>1-/2-</sup> and [Fe(SCH<sub>3</sub>)<sub>4</sub>]<sup>1-/2-</sup> and interpret the spectra by deconvolving the correction vectors. Our approach represents a step toward simulating the X-ray spectroscopies of larger metal cluster systems that play a pivotal role in biology.",
                "disciplines": [
                    "3402"
                ]
            },
            "10.1021/acs.jpcb.3c04473": {
                "title": "OpenMSCG: A Software Tool for Bottom-Up Coarse-Graining",
                "abstract": "The \"bottom-up\" approach to coarse-graining, for building accurate and efficient computational models to simulate large-scale and complex phenomena and processes, is an important approach in computational chemistry, biophysics, and materials science. As one example, the Multiscale Coarse-Graining (MS-CG) approach to developing CG models can be rigorously derived using statistical mechanics applied to fine-grained, i.e., all-atom simulation data for a given system. Under a number of circumstances, a systematic procedure, such as MS-CG modeling, is particularly valuable. Here, we present the development of the OpenMSCG software, a modularized open-source software that provides a collection of successful and widely applied bottom-up CG methods, including Boltzmann Inversion (BI), Force-Matching (FM), Ultra-Coarse-Graining (UCG), Relative Entropy Minimization (REM), Essential Dynamics Coarse-Graining (EDCG), and Heterogeneous Elastic Network Modeling (HeteroENM). OpenMSCG is a high-performance and comprehensive toolset that can be used to derive CG models from large-scale fine-grained simulation data in file formats from common molecular dynamics (MD) software packages, such as GROMACS, LAMMPS, and NAMD. OpenMSCG is modularized in the Python programming framework, which allows users to create and customize modeling \"recipes\" for reproducible results, thus greatly improving the reliability, reproducibility, and sharing of bottom-up CG models and their applications.",
                "disciplines": []
            },
            "10.26434/chemrxiv-2023-w0h1p": {
                "title": "OpenMSCG: A Software Tool for Bottom-up Coarse-graining",
                "abstract": "The \u201cbottom-up\u201d approach to coarse-graining \u2013 for building accurate and efficient computational models to simulate large-scale and complex phenomena and processes \u2013 is an important approach in computational chemistry, biophysics, and materials science. As one example, the multiscale coarse-graining (MS-CG) approach to developing CG models can be rigorously derived using statistical mechanics applied to fine-grained, i.e., all-atom simulation data for a given system. Under a number of circumstances, a systematic procedure such as MS-CG modeling is particularly valuable. Here we present the development of the OpenMSCG software, a modularized open-source software that provides a collection of successful and widely applied bottom-up CG methods, including Boltzmann Inversion (BI), Force-Matching (FM), Ultra-Coarse-Graining (UCG), Relative Entropy Minimization (REM), Essential Dynamics Coarse-Graining (ED-CG), and Heterogeneous Elastic Network Modeling (HeteroENM). OpenMSCG is a high-performance and comprehensive toolset that can be used to derive CG models from large-scale fine-grained simulation data in file formats from common molecular dynamics (MD) software packages, such as GROMACS, LAMMPS and NAMD. OpenMSCG is modulized in the Python programming framework, which allows users to create and customize modeling \u201crecipes\u201d for reproducible results, thus greatly improving the reliability, reproducibility, and sharing of bottom-up CG models and their applications.",
                "disciplines": [
                    "4601"
                ]
            },
            "10.1073/pnas.2305899120": {
                "title": "Unveiling the catalytic mechanism of GTP hydrolysis in microtubules",
                "abstract": "Microtubules (MTs) are large cytoskeletal polymers, composed of \u03b1\u03b2-tubulin heterodimers, capable of stochastically converting from polymerizing to depolymerizing states and vice versa. Depolymerization is coupled with hydrolysis of guanosine triphosphate (GTP) within \u03b2-tubulin. Hydrolysis is favored in the MT lattice compared to a free heterodimer with an experimentally observed rate increase of 500- to 700-fold, corresponding to an energetic barrier lowering of 3.8 to 4.0 kcal/mol. Mutagenesis studies have implicated \u03b1-tubulin residues, \u03b1:E254 and \u03b1:D251, as catalytic residues completing the \u03b2-tubulin active site of the lower heterodimer in the MT lattice. The mechanism for GTP hydrolysis in the free heterodimer, however, is not understood. Additionally, there has been debate concerning whether the GTP-state lattice is expanded or compacted relative to the GDP state and whether a \"compacted\" GDP-state lattice is required for hydrolysis. In this work, extensive quantum mechanics/molecular mechanics simulations with transition-tempered metadynamics free-energy sampling of compacted and expanded interdimer complexes, as well as a free heterodimer, have been carried out to provide clear insight into the GTP hydrolysis mechanism. \u03b1:E254 was found to be the catalytic residue in a compacted lattice, while in the expanded lattice, disruption of a key salt bridge interaction renders \u03b1:E254 less effective. The simulations reveal a barrier decrease of 3.8 \u00b1 0.5 kcal/mol for the compacted lattice compared to a free heterodimer, in good agreement with experimental kinetic measurements. Additionally, the expanded lattice barrier was found to be 6.3 \u00b1 0.5 kcal/mol higher than compacted, demonstrating that GTP hydrolysis is variable with lattice state and slower at the MT tip.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1101/2023.05.01.538927": {
                "title": "Unveiling the Catalytic Mechanism of GTP Hydrolysis in Microtubules",
                "abstract": "Microtubules (MTs) are large cytoskeletal polymers, composed of \u03b1\u03b2-tubulin heterodimers, capable of stochastically converting from polymerizing to depolymerizing states and vice-versa. Depolymerization is coupled with hydrolysis of GTP within \u03b2-tubulin. Hydrolysis is favored in the MT lattice compared to free heterodimer with an experimentally observed rate increase of 500 to 700 fold, corresponding to an energetic barrier lowering of 3.8 to 4.0 kcal/mol. Mutagenesis studies have implicated \u03b1-tubulin residues, \u03b1:E254 and \u03b1:D251, as catalytic residues completing the \u03b2-tubulin active site of the lower heterodimer in the MT lattice. The mechanism for GTP hydrolysis in the free heterodimer, however, is not understood. Additionally, there has been debate concerning whether the GTP-state lattice is expanded or compacted relative to the GDP-state and whether a \"compacted\" GDP-state lattice is required for hydrolysis. In this work, extensive QM/MM simulations with transition-tempered metadynamics free energy sampling of compacted and expanded inter-dimer complexes, as well as free heterodimer, have been carried out to provide clear insight into the GTP hydrolysis mechanism. \u03b1:E254 was found to be the catalytic residue in a compacted lattice, while in the expanded lattice disruption of a key salt bridge interaction renders \u03b1:E254 less effective. The simulations reveal a barrier decrease of 3.8 \u00b1 0.5 kcal/mol for the compacted lattice compared to free heterodimer, in good agreement with experimental kinetic measurements. Additionally, the expanded lattice barrier was found to be 6.3 \u00b1 0.5 kcal/mol higher than compacted, demonstrating that GTP hydrolysis is variable with lattice state and slower at the MT tip.\nSignificance Statement: Microtubules (MTs) are large and dynamic components of the eukaryotic cytoskeleton with the ability to stochastically convert from a polymerizing to a depolymerizing state and vice-versa. Depolymerization is coupled to the hydrolysis of guanosine-5'-triphosphate (GTP), which is orders of magnitude faster in the MT lattice than in free tubulin heterodimers. Our results computationally ascertain the catalytic residue contacts in the MT lattice that accelerate GTP hydrolysis compared to the free heterodimer as well as confirm that a compacted MT lattice is necessary for hydrolysis while a more expanded lattice is unable to form the necessary contacts and thereby hydrolyze GTP.",
                "disciplines": [
                    "3101"
                ]
            }
        }
    },
    "13527564": {
        "title": "Center of Excellence in Complex Disease Genetics-from Discovery to Precision Medicine",
        "abstract": "Human genetics has proven to be instrumental for identifying novel molecular mechanisms underlying common complex diseases and holds the promise of improved, targeted treatment as well as prediction, prevention and diagnosis. Building on unique resources and extensive track record in disease genetic studies in Finland, the Centre of Excellence in Complex Disease Genetics (CoECDG) develops and applies strategies for the identification of risk and protective variants, with focus on high-impact low-frequency alleles that contribute significantly to common diseases, and to implement strategies for genomic precision medicine. The CoECDG will also lead national efforts to implement genomic findings into prevention and personalized treatment of common complex diseases. In our second funding term, we expand our activities to new disease areas and develop strategies for better understanding the mechanisms through which genes contribute to disease, disease progression and treatment responses.",
        "disciplines": [
            "3105"
        ],
        "publications": {
            "10.1101/2023.12.22.23300430": {
                "title": "A Phenome-wide association study of genetically determined nicotine metabolism reveals novel links with health-related outcomes",
                "abstract": "Abstract  Background Faster nicotine metabolism associates with heavier smoking and challenges in smoking cessation. Understanding which traits and diseases associate with the rate of nicotine metabolism, defined as the 3-hydroxycotinine-to-cotinine-ratio, also known as the nicotine metabolite ratio (NMR), is crucial for drug development and personalized interventions for treating nicotine addiction.   Methods and Findings We performed a hypothesis-free phenome-wide association study (PheWAS) of over 21,000 outcome variables from UK Biobank (UKB) to explore how the NMR associates with the phenome. As the exposure variable, we used a genetic score for faster nicotine metabolism based on 10 putatively causal genetic variants, explaining 33.8 % of the variance in the NMR. We analyzed ever and never smokers separately to assess whether the associations had a causal pathway through smoking. Additionally, we performed complementary PheWASs in FinnGen and MRBase. A total of 57 outcome variables reached phenome-wide significance at a false discovery rate of 5 %. We observed expected associations with several phenotypes related to both smoking and nicotine, but could not replicate prior findings on cessation. Most importantly, we found some associations that did not appear to differ between ever and never smokers, suggesting the pathways of these associations may not involve smoking: faster nicotine metabolism was associated with less favourable liver enzyme and lipid values, as well as increased coffee and tea consumption. The main limitation was the potential bias due to UKB\u2019s enrichment with healthier individuals. Additionally, as we restricted our analyses to individuals of European ancestry to avoid bias due to population stratification, the generalizability of our results to other ethnic groups is limited.   Conclusions Our findings support a possibility that a future smoking cessation therapy converting fast metabolizers of nicotine to slower ones could work without adverse side effects and potentially even provide other health-related benefits. ",
                "disciplines": [
                    "3105",
                    "4202",
                    "3214"
                ]
            }
        }
    },
    "13300651": {
        "title": "Coronary artery mimicking blood clot test: A point-of-care prothrombotic prediction device for patient-specific diagnosis",
        "abstract": "This biomedical engineering program aims to develop a patient-specific biochip to diagnose and predict blood clot tendency at an earlier stage. The point-of-care prothrombotic prediction device will be suitable for patients with high blood clot risks such as diabetes and, more recently, the COVID-19. It also serves as a testing platform for new anti-platelet and anti-coagulant drugs, and as a way for surgeons to screen patients for anti-thrombotic before operating to avoid uncontrolled bleeding.",
        "disciplines": [
            "4003"
        ],
        "publications": {
            "10.1002/agt2.386": {
                "title": "Movable typing of full\u2010lumen personalized Vein\u2010Chips to model cerebral venous sinus thrombosis",
                "abstract": "Abstract Cerebral venous sinus thrombosis (CVST) is a type of stroke associated with COVID\u201019 vaccine\u2010induced immune thrombotic thrombocytopenia. The precise etiology of CVST often remains elusive due to the highly heterogeneous nature of its governing mechanisms, specifically, Virchow's triad that involves altered blood flow, endothelial dysfunction, and hypercoagulability, which varies substantially amongst individuals. Existing diagnostic and monitoring approaches lack the capability to reflect the combination of these patient\u2010specific thrombotic determinants. In response to this challenge, we introduce a Vein\u2010Chip platform that recapitulates the CVST vascular anatomy from magnetic resonance venography and the associated hemodynamic flow profile using the \u201cChinese Movable Type\u2010like\u201d soft stereolithography technique. The resultant full\u2010lumen personalized Vein\u2010Chips, functionalized with endothelial cells, enable in\u2010vitro thrombosis assays that can elucidate distinct thrombogenic scenarios between normal vascular conditions and those of endothelial dysfunction. The former displayed minimal platelet aggregation and negligible fibrin deposition, while the latter presented significant fibrin extrusion from platelet aggregations. The low\u2010cost movable typing technique further enhances the potential for commercialization and broader utilization of personalized Vein\u2010Chips in surgical labs and at\u2010home monitoring. Future research and development in this direction will pave the way for improved management and prevention of CVST, ultimately benefiting both patients and healthcare systems.",
                "disciplines": [
                    "4003"
                ]
            },
            "10.1002/adfm.202214179": {
                "title": "Novel Movable Typing for Personalized Vein\u2010Chips in Large Scale: Recapitulate Patient\u2010Specific Virchow's Triad and its Contribution to Cerebral Venous Sinus Thrombosis",
                "abstract": "Abstract The Vein\u2010Chip recapitulates CVST Virchow's triad and enables systematic characterization of venous thrombogenesis with respect to fibrin formation and platelet aggregation. Distinct from the arterial setting, platelets universally adhere across the entire CVS Vein\u2010Chip independent of stenotic geometry and flow disturbance. Intriguingly, fibrin propagates along with the flow direction, but exclusively deposits to the inner vessel wall. Upon inflammatory endothelial injury, fibrin deposition mirrors to the outer vessel wall, but still not in the lumen. Together, the Vein\u2010Chip promises future applications for personalized thrombotic assessment and monitoring.",
                "disciplines": [
                    "4012",
                    "4003"
                ]
            }
        }
    },
    "12977126": {
        "title": "Robust Explanations using Diverse Adversarially Trained Ensembles, Multi-Modal Contrastive Learning, and Attribution-based Confidence Metrics",
        "abstract": "Robust Explanations using Diverse Adversarially Trained Ensembles, Multi-Modal Contrastive Learning, and Attribution-based Confidence Metrics \n\nPublic Project Summary \n\nRickard Ewetz, University of Central Florida (Lead Principal Investigator)\n Sumit Kumar Jha, University of Texas at San Antonio (Co-Principal Investigator) \n\nModern neural networks have surpassed human-level performance for many challenging tasks and are rapidly being deployed within real-world applications. The phenomenal performance of these networks comes from a large number of parameters and the non-linear interactions among them. This complex and high-dimensional dynamics makes it difficult for a human to understand and visualize why an AI system makes a particular decision. Robust methods for explaining AI decisions are needed to enhance the broad adoption of AI in scientific applications. \n\nWhile there has been a lot of work on explainable AI over the last decade, the emphasis often has been on the use of model gradients. We are not proposing a refinement to one of these gradient-based methods; instead, we are leveraging several new ideas, including symbolic reasoning, adversarially robust networks, synthesizing counterfactual inputs, multi-modal perceivers, self-supervised learning, and ensembles of diverse models. Our goal is to create robust multi-modal explanations using unsupervised learning for data including images, time series, text in the form of visualizations including super-pixels/text for images, and rules such as natural laws for time series. Robustness will be achieved by a combination of robust diverse ensembles of neural networks and faster adversarial training using stochastic generators. Attribution-based confidence metrics will be used to identify the envelope of the correct operation of neural networks. All work will be performed on state-of-the-art networks such as Transfomers and Perceivers.\n\nOur proposed effort will initiate a new wave of explainable AI. This will have a strong impact on many scientific disciplines where AI is being used for pursuing challenging tasks that ultimately require human trust, such as life sciences, deep reinforcement learning, physics, and cyber-physical systems. The project is also expected to broadly impact the scientific community by enabling the analysis of large datasets and models for scientific discovery.",
        "disciplines": [
            "4611"
        ],
        "publications": {
            "10.1109/milcom58377.2023.10356332": {
                "title": "Counterexample Guided Inductive Synthesis Using Large Language Models and Satisfiability Solving",
                "abstract": "Generative large language models (LLMs) can follow human-provided instruction prompts and generate human-like responses. Apart from natural language responses, they have been found to be effective at generating formal artifacts such as code, plans, and logical specifications. Despite their remarkably improved accuracy, these models are still known to produce factually incorrect or contextually inappropriate results despite their syntactic coherence \u2013 a phenomenon often referred to as hallucinations. This limitation makes it difficult to use these models to synthesize formal artifacts used in safety-critical applications. Unlike tasks such as text summarization and question-answering, bugs in code, plan, and other formal artifacts produced by LLMs can be catastrophic. We posit that we can use the satisfiability modulo theory (SMT) solvers as deductive reasoning engines to analyze the generated solutions from the LLMs, produce counterexamples when the solutions are incorrect, and provide that feedback to the LLMs exploiting the dialog capability of LLMs. This interaction between inductive LLMs and deductive SMT solvers can iteratively steer the LLM to generate the correct response. In our experiments, we use planning over the domain of blocks as our synthesis task for evaluating our approach. We use GPT-4, GPT3.5 Turbo, Davinci, Curie, Babbage, and Ada as the LLMs and Z3 as the SMT solver. Our method allows the user to communicate the planning problem in natural language; even the formulation of queries to SMT solvers is automatically generated from natural language. Thus, the proposed technique can enable non-expert users to describe their problems in natural language, and the combination of LLMs and SMT solvers can produce provably correct solutions.",
                "disciplines": [
                    "4602",
                    "4612"
                ]
            }
        }
    },
    "12963127": {
        "title": "Exogenous ketones target geroscience pathways and ameliorate geriatric syndromes",
        "abstract": "This application for the NIA Research and Entrepreneurial Development Immersion Award (K01) describes the five-year career development plan of Dr. Brianna Stubbs, a translational scientist at The Buck Institute for Research on Aging, Novato, CA. Dr. Stubbs\u2019 long-term career goal is to be an independent clinical researcher and entrepreneur, and to build a track record of translating academic concepts into therapeutics targeting aging and age-related disease. The specific career development goals outlined in this application include developing expertise in the study of geroscience biomarkers; clinical work with older adults, IND enabling studies for drug development, and translational entrepreneurship. Dr. Stubbs will be supported by a team of academic, industry and business development mentors to accomplish these career development goals. The career development plan and research plan of Dr. Stubbs includes individualized mentorship with her mentorship team, formal coursework, and meetings, and is built around immersion in The Buck Business Development Department, experience in an academic clinical trial of older adults and in an industry drug development program. Dr. Stubbs will use biospecimens from these studies in her Research Plan. The plan will complement and extend Dr. Stubbs\u2019 extensive experience in clinical research with young adults, human physiology, and development of ketone-based consumer food products, to equip her to be an independent entrepreneur-scientist. The overall objective of the research plan is to identify geroscience biomarkers for use in future ketone-based drug development. Ketones are produced from stored fat during fasting or strenuous exercise and strong preclinical data demonstrates that they can impact lifespan and healthspan by acting as an oxidative fuel and a signaling metabolite. The central hypothesis of this project is that ketone bodies modulate geroscience pathways common to geriatric syndromes including inflammation, senescence, and mitochondrial health. The specific aims of the research plan are to investigate the effects of exogenous ketones on the specific geroscience mechanisms of inflammation, senescence, and mitochondrial health in a rodent model of heart failure and in pre-frail and frail older adults, and to correlate changes in these pathways to functional outcomes. The application is relevant to NIH and NIA because Dr. Stubbs\u2019 career goal is to leverage an understanding of the multifactorial pathways that regulate aging and longevity to provide translational therapies for the multifactorial geriatric syndromes. The anticipated results of the research plan will advance the progress of ketone-based treatments for heart failure. If successful, Dr. Stubbs\u2019 career will result in the development of multiple interventions for geriatric syndromes, which ultimately leads to greater health and independence in older adults.",
        "disciplines": [
            "3214"
        ],
        "publications": {
            "10.1101/2024.05.03.24306699": {
                "title": "Daily consumption of ketone ester, bis-octanoyl (R)-1,3-butanediol, is safe and tolerable in healthy older adults, a randomized, parallel arm, double-blind, placebo-controlled, pilot study",
                "abstract": "Objectives: Ketone bodies are endogenous metabolites produced during fasting or a ketogenic diet that have pleiotropic effects on aging pathways. Ketone esters (KEs) are compounds that induce ketosis without dietary changes, but KEs have not been studied in an older adult population. The primary objective of this trial was to determine tolerability and safety of KE ingestion in older adults.\nDesign: Randomized, placebo-controlled, double-blinded, parallel-arm trial, with a 12-week intervention period ( <b>NCT05585762</b> ).\nSetting: General community, Northern California, USA.\nParticipants: Community-dwelling older adults, independent in activities of daily living, with no unstable acute medical conditions (n=30) were randomized and n=23 (M= 14, F=9) completed the protocol.\nIntervention: Participants were randomly allocated to consume either KE (bis-octanoyl (R)-1,3-butanediol) or a taste, appearance, and calorie-matched placebo (PLA) containing canola oil.\nMeasurements: Tolerability was assessed using a composite score from a daily log for 2-weeks, and then via a bi-weekly phone interview. Safety was assessed by vital signs and lab tests at screening and weeks 0, 4 and 12, along with tabulation of adverse events.\nResults: There was no difference in the prespecified primary outcome of proportion of participants reporting moderate or severe nausea, headache, or dizziness on more than one day in a two-week reporting period (KE n =2 (14.3% [90% CI = 2.6 - 38.5]); PLA n=1 (7.1% [90% CI = 0.4 - 29.7]). Dropouts numbered four in the PLA group and two in the KE group. A greater number of symptoms were reported in both groups during the first two weeks; symptoms were reported less frequently between 2 - 12 weeks. There were no clinically relevant changes in safety labs or vital signs in either group.\nConclusions: This KE was safe and well-tolerated in healthy older adults. These results provide a foundation for use of KEs in aging research.\nHighlights: Ketones esters induce ketosis without dietary changes and may target aging biologyStudies of ketone esters were limited in duration and focused on younger adultsWe found ketone esters were safe and tolerable for 12 weeks in healthy older adults.",
                "disciplines": [
                    "4206"
                ]
            },
            "10.1101/2024.04.16.24305925": {
                "title": "A randomized open-label, observational study of the novel ketone ester, bis octanoyl (R)-1,3-butanediol, and its acute effect on \u00df-hydroxybutyrate and glucose concentrations in healthy older adults",
                "abstract": "Bis-octanoyl (R)-1,3-butanediol (BO-BD) is a novel ketone ester (KE) ingredient which increases blood beta-hydroxybutyrate (BHB) concentrations rapidly after ingestion. KE is hypothesized to have beneficial metabolic effects on health and performance, especially in older adults. Whilst many studies have investigated the ketogenic effect of KE in young adults, they have not been studied in an exclusively older adult population, for whom age-related differences in body composition and metabolism may alter the effects. This randomized, observational, open-label study in healthy older adults (n = 30, 50% male, age = 76.5 years, BMI = 25.2 kg/m<sup>2</sup>) aimed to elucidate acute tolerance, blood BHB and blood glucose concentrations for 4 hours following consumption of either 12.5 or 25 g of BO-BD formulated firstly as a ready-to-drink beverage (n = 30), then as a re-constituted powder (n = 21), taken with a standard meal. Both serving sizes and formulations of BO-BD were well tolerated, and increased blood BHB, inducing nutritional ketosis (\u2265 0.5mM) that lasted until the end of the study. Ketosis was dose responsive; peak BHB concentration (C<sub>max</sub>) and incremental area under the curve (iAUC) were significantly greater with 25 g compared to 12.5 g of BO-BD in both formulations. There were no significant differences in C<sub>max</sub> or iAUC between formulations. Blood glucose increased in all conditions following the meal; there were no consistent significant differences in glucose response between conditions. These results demonstrate that both powder and beverage formulations of the novel KE, BO-BD, induce ketosis in healthy older adults, facilitating future research on functional effects of this ingredient in aging.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1101/2023.10.25.23297571": {
                "title": "Rationale and protocol for a safety, tolerability and feasibility randomized, parallel group, double-blind, placebo-controlled, pilot study of a novel ketone ester targeting frailty via immunometabolic geroscience mechanisms",
                "abstract": "Background: Frailty is a geriatric syndrome characterized by chronic inflammation and metabolic insufficiency that creates vulnerability to poor outcomes with aging. We hypothesize that geroscience interventions, which target mechanisms of aging, could ameliorate frailty. Metabolites such as ketone bodies are candidate geroscience interventions, having pleiotropic effects on inflammo-metabolic aging mechanisms. Ketone esters (KEs) induce ketosis without dietary changes, but KEs have not been studied in an older adult population. Our long-term goal is to examine if KEs modulate geroscience mechanisms and clinical outcomes relevant to frailty in older adults.\nObjectives: The primary objective of this randomized, placebo-controlled, double-blinded, parallel-group, pilot trial is to determine tolerability of 12-weeks of KE ingestion in a generalizable population of older adults (\u2265 65 years). Secondary outcomes include safety and acute blood ketone kinetics. Exploratory outcomes include physical function, cognitive function, quality of life, aging biomarkers and inflammatory measures.\nMethods: Community-dwelling adults who are independent in activities of daily living, with no unstable acute medical conditions (n=30) will be recruited. The study intervention is a KE or a taste, appearance, and calorie matched placebo beverage. Initially, acute 4-hour ketone kinetics after 12.5g or 25g of KE consumption will be assessed. After collection of baseline safety, functional, and biological measurements, subjects will randomly be allocated to consume KE 25g or placebo once daily for 12-weeks. Questionnaires will assess tolerability daily for 2-weeks, and then via phone interview at bi-monthly intervals. Safety assessments will be repeated at week 4. All measures will be repeated at week 12.\nConclusion: This study will evaluate feasibility, tolerability, and safety of KE consumption in older adults and provide exploratory data across a range of geroscience-related endpoints. This data will inform design of larger trials to rigorously test KE effects on geroscience mechanisms and clinical outcomes relevant to frailty.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.3389/fphys.2023.1202186": {
                "title": "A systematic review and meta-regression of exogenous ketone infusion rates and resulting ketosis\u2014A tool for clinicians and researchers",
                "abstract": "<b>Introduction:</b> Ketone bodies such as beta-hydroxybutyrate (BHB) have pleiotropic functional benefits as fuel and signaling metabolites and may have multiple clinical applications. An alternative to inducing ketosis by dietary modification is intravenous delivery of exogenous sources of ketones. It is unknown whether there is a strong relationship between BHB infusion rate and blood BHB concentrations in the published literature; this information is vital for clinical studies investigating therapeutic effects of ketosis. This systematic review aimed to aggregate available data and address this gap. <b>Methods:</b> The PubMed and EMBASE databases were searched, and data were extracted from 23 manuscripts where BHB was infused and maximum and/or steady state BHB levels assessed. Infusion rate was adjusted when racemic BHB was infused but only D-BHB was measured. <b>Results:</b> Using a random effects meta-regression, strong linear relationships between BHB infusion rate and maximal (y = 0.060 + 0.870x, <i>R</i> <sup>2</sup> = 87.2%, <i>p</i> &lt; 0.0001) and steady state (y = -0.022 + 0.849x, <i>R</i> <sup>2</sup> = 86.9%, <i>p</i> &lt; 0.0001) blood BHB concentrations were found. Sensitivity analysis found this relationship was stronger when studies in non-healthy populations were excluded (y = 0.059 + 0.831x, <i>R</i> <sup>2</sup> = 96.3%, <i>p</i> &lt; 0.0001). <b>Conclusion:</b> There is a strong relationship between BHB infusion rate and blood BHB concentrations; the regressions described here can be used by clinicians or researchers to determine ketone delivery required for a target blood concentration.",
                "disciplines": [
                    "3202"
                ]
            }
        }
    },
    "13046073": {
        "title": "Testing the viability of Majorana-based platforms for topological quantum computation through theore",
        "abstract": "A promising approach to overcoming the most serious problem associated with the realization of quantum computing (QC), which is esse,ntially generated by quantum decoherence, is to harness the underlying robustness of topological quantum states. This topological ap,proach to QC has been experimentally pursued for over a decade, spearheaded by the efforts to realize Majorana zero modes (MZMs) ? e,mergent non-Abelian quasiparticles that can be used as building blocks for topological qubits ? using semiconductor-superconductor (,SM-SC) hybrid nanowire structures. While this effort is still facing serious challenges, particularly in the areas of materials grow,th and device engineering, and has not yet generated a functional topological qubit, it has fueled significant experimental and theo,retical advances, in particular regarding the modeling of hybrid nanostructures under non-ideal, laboratory conditions. More recentl,y, a number of Majorana platforms that could provide viable (possibly better) alternatives to SM-SC nanowires have been proposed. Al,though there are claims of successful observation of topological quantum states in some of these systems, the alternative topologica,l QC platforms have not yet been subjected to the same level of theoretical and modeling scrutiny as their SM-SC nanowire counterpar,ts. This project proposes the theoretical and numerical study of five types of systems that represent promising candidates for a Maj,orana-based platform for topological QC: (1) planar Josephson junctions, (2) twisted bilayer graphene ? transition metal dichalcogen,ide (TMD) heterostructures, (3) ferromagnet ? TMD van der Waals heterostructures, (4) iron-based superconductors, and (5) Kitaev-Hei,senberg spin-liquids (such as RuCl3). The study is based on a set of modeling tools that incorporate the experimentally relevant, no,n-ideal factors typically ignored in the preliminary analyses based on ?toy? models. Essentially motivated by the critical need for,realistic modeling of the proposed Majorana-based platforms, this project will (i) provide estimates of the highest disorder/inhomog,eneity levels consistent with the presence of topological states, (ii) develop and test measurement protocols for the unambiguous de,tection of topological states, and (iii) design components of qubit devices and evaluate the feasibility of qubit manipulation schem,es. The project will substantially broaden the scope of the theoretical and numerical investigation of Majorana-based platforms for,topological QC and will provide significant support to the experimental efforts in this area. Ultimately, this project will help str,eamlining the selection of the optimal platform(s) for Majorana-based topological qubits.Approved for Public Release",
        "disciplines": [
            "4009"
        ],
        "publications": {
            "10.1103/physrevb.109.205301": {
                "title": "Magnetochiral anisotropy induced nonlinear planar Hall effect in topological insulator surface states",
                "abstract": "In an intriguing recent experiment, it has been found that the two-dimensional (2D) surface states of a three-dimensional (3D) strong topological insulator (TI) support a nonzero Hall voltage transverse to an applied electric field even when the external magnetic field is in the plane (i.e., the in-plane Lorentz force vanishes). This so-called planar Hall effect (PHE) of TI surface states is found to be nonlinear, i.e., the Hall voltage scales quadratically with the applied electric field and linearly with the in-plane magnetic field. In this paper, we calculate the nonlinear PHE for strong topological insulator surface states with broken particle-hole symmetry and warping and provide results that interpolate continuously between the Dirac and normal fermion regimes, which can be compared with future experiments.",
                "disciplines": [
                    "5104"
                ]
            },
            "10.1103/physrevb.108.195303": {
                "title": "Magnetochiral anisotropy-induced nonlinear Hall effect in spin-orbit coupled Rashba conductors",
                "abstract": "We theoretically predict the existence of a nonzero magnetochiral anisotropy-induced nonlinear Hall effect or a second harmonic Hall voltage transverse to an applied current in spin-orbit coupled Rashba conductors in the presence of an in-plane magnetic field B. This is distinct from the Berry curvature dipole (BCD)-induced nonlinear Hall effect in systems with a nontrivial band structure because the former requires broken time-reversal symmetry while the BCD-induced effect is nonzero even in time-reversal symmetric systems. This result is independent of the existence of other types of interactions, such as hexagonal warping or cubic Dresselhaus interactions. We find that for E\u2225B, the magnitude of the nonlinear Hall current flowing in a direction perpendicular to the applied electric field is exactly 1/3 of the magnitude of the nonlinear rectification current responsible for magnetoresistance parallel to the applied electric field obtained in the E\u22a5B configuration.",
                "disciplines": [
                    "5104"
                ]
            }
        }
    },
    "13017579": {
        "title": "The olfactory system, a gateway to appease body and mind \u2013 BreathSmellRelax",
        "abstract": "At a time when the search for well-being has become a societal priority and when medical practices aim at minimizing pharmacological approaches in chronic diseases, our project proposes to explore how, at the crossroads between emotions and breathing, the olfactory system represents a particularly efficient gateway to relaxation. The originality of our project lies in that it combines both physiological and neurophysiological approaches to test the hypothesis that an emotionally positive smell can induce a deep and slow breathing that could elicit both large brainwave modifications and behavioral relaxation. The cutting-edge nature of this proposal relies on its potential for breakthrough in wellness improvement as it proposes to use emotionally positive smells as an olfactory remediation to relieve breathing discomfort in dyspneic patients.",
        "disciplines": [
            "3209"
        ],
        "publications": {
            "10.1523/eneuro.0197-23.2023": {
                "title": "A Unifying Method to Study Respiratory Sinus Arrhythmia Dynamics Implemented in a New Toolbox",
                "abstract": "Respiratory sinus arrhythmia (RSA), the natural variation in heart rate synchronized with respiration, has been extensively studied in emotional and cognitive contexts. Various time or frequency-based methods using the cardiac signal have been proposed to analyze RSA. In this study, we present a novel approach that combines respiratory phase and heart rate to enable a more detailed analysis of RSA and its dynamics throughout the respiratory cycle. To facilitate the application of this method, we have implemented it in an open-source Python toolbox called physio This toolbox includes essential functionalities for processing electrocardiogram (ECG) and respiratory signals, while also introducing this new approach for RSA analysis. Inspired by previous research conducted by our group, this method enables a cycle-by-cycle analysis of RSA providing the possibility to correlate any respiratory feature to any RSA feature. By employing this approach, we aim to gain a more accurate understanding of the neural mechanisms associated with RSA.",
                "disciplines": [
                    "3208"
                ]
            }
        }
    },
    "13017546": {
        "title": "Identifying SARS-CoV-2-like and other coronaviruses able to infect humans in bats from Indochina peninsula \u2013 BAT-CoV-ASIA",
        "abstract": "The objective of the project is to identify bat coronaviruses close to SARS-CoV-2 and other alpha and betacoronaviruses in Southeast Asia capable of infecting humans, using metagenomic, phylogeny, structural and cellular biology approaches",
        "disciplines": [
            "3102"
        ],
        "publications": {
            "10.3390/v15091897": {
                "title": "Genotype and Phenotype Characterization of Rhinolophus sp. Sarbecoviruses from Vietnam: Implications for Coronavirus Emergence",
                "abstract": "Bats are a major reservoir of zoonotic viruses, including coronaviruses. Since the emergence of SARS-CoV in 2002/2003 in Asia, important efforts have been made to describe the diversity of <i>Coronaviridae</i> circulating in bats worldwide, leading to the discovery of the precursors of epidemic and pandemic sarbecoviruses in horseshoe bats. We investigated the viral communities infecting horseshoe bats living in Northern Vietnam, and report here the first identification of sarbecoviruses in <i>Rhinolophus thomasi</i> and <i>Rhinolophus siamensis</i> bats. Phylogenetic characterization of seven strains of Vietnamese sarbecoviruses identified at least three clusters of viruses. Recombination and cross-species transmission between bats seemed to constitute major drivers of virus evolution. Vietnamese sarbecoviruses were mainly enteric, therefore constituting a risk of spillover for guano collectors or people visiting caves. To evaluate the zoonotic potential of these viruses, we analyzed in silico and in vitro the ability of their RBDs to bind to mammalian ACE2s and concluded that these viruses are likely restricted to their bat hosts. The workflow applied here to characterize the spillover potential of novel sarbecoviruses is of major interest for each time a new virus is discovered, in order to concentrate surveillance efforts on high-risk interfaces.",
                "disciplines": [
                    "3107"
                ]
            }
        }
    },
    "13055948": {
        "title": "Epigenetics and PD",
        "abstract": "PUBLIC ABSTRACT\n\nWhen motor symptoms become evident in patients with Parkinson's disease (PD), more than 70% of the dopaminergic neurons are already lost.  At this stage neuroprotective treatment can be less effective, as the neuronal function is difficult to restore once it is lost.  The identification or early markers of disease is thus crucial for making a difference in the management and treatment of Parkinson's disease.  We already know that certain clinical presentations (such as the impairment of the REM sleep or hyposmia) as well as being a carrier of specific gene mutations (such as the gene GBA and LRRK2) can greatly increase the risk of developing PD.  People with these features are called Prodromal PD subjects.   \n\n \n\nTreating subjects that will develop PD in a prodromal stage will be actually very promising.  \n\n However, we are still lacking biomarkers able to predict the development of PD in subjects at high risk of this condition, such as prodromal subjects.   \n\n \n\nInflammation is one of the pathogenic mechanisms implicated in PD.  Different studies have shown that inflammatory cells in patients with PD are more reactive and present differences in gene expression.  To assess the activation and differences in regulation of the gene expression machinery in pre-motor stages of the disease can be informative in understanding how pathogenic mechanisms of PD start to develop, and thus possibly how to contrast them, as well as around possible levels of risks of developing PD in prodromal subjects.   \n\n \n\nOne of the mechanisms that regulate the inflammatory response are the epigenetic mechanisms, which are DNA changes that can affect when and how genes are expressed.  Epigenetic mechanisms, such as methylation, can be influenced by internal mechanisms of the cells but also by the interaction with factors from the environment where we live (such as the exposure to toxin, certain medication, pollutions).  Therefore, studying the methylation profiles of a target tissue and the correlation with the exposure to certain environmental triggers can be very informative of these changes.   \n\n \n\nWith the present project we propose to study the epigenetic (methylation) changes in a circulating blood cell (monocytes) in a cohort of prodromal subjects for PD, to compare them with the signatures from subjects with PD and control subjects, and to correlate these data with the information from a questionnaire exploring the exposure to different environmental triggers.   \n\n \n\nOur analysis will allow us to establish (1) whether methylation changes in the inflammatory cells correlate with the exposure to specific environmental factors that can be targeted by preventive treatment, and (2) whether changes in the inflammatory cells specifically found in patients with PD are already present in prodromal stages, suggesting an early activation of the immune response in the onset of the disease and offering a new biomarker for detection of early stages of disease.  \n\n \n\nThis project has the potential to target a broad range of subjects with PD and their family members because it can allow (1) the identification of possible biomarkers that can be informative to suggest participation in neuroprotective clinical trials even before development of motor symptoms.  If validated, the same biomarkers can be also studied in subjects with no prodromal symptoms with PD and assess their predictive values in predicting PD through longitudinal studies; (2) the clarification of the role and the timeline of the activation of the immune response in Parkinson's disease and thus suggest possible preventive treatments; (3) increase our understanding of the effect of exposure to specific neurotoxic and environmental factors on the inflammatory cells in PD; (4) proper discussion with family members of subjects with PD, with certain genetic mutations or with prodromal symptoms, about their risks of developing PD.   \n\n \n\nThe results of this research will need to be validated in a validation cohort and in a larger population.  Thus, we expect this could lead to possible applicability in about 4 years.",
        "disciplines": [
            "3202"
        ],
        "publications": {
            "10.1016/j.prdoa.2024.100251": {
                "title": "Clinical prediction of GBA carrier status in Parkinson\u2019s disease",
                "abstract": "Introduction: Given the unique natural history of <i>GBA</i>-related Parkinson's disease (<i>GBA</i>-PD) and the potential for novel treatments in this population, genetic testing prioritization for the identification of <i>GBA</i>-PD patients is crucial for prognostication, individualizing treatment, and stratification for clinical trials. Assessing the predictive value of certain clinical traits for the <i>GBA</i>-variant carrier status will help target genetic testing in clinical settings where cost and access limit its availability.\nMethods: In-depth clinical characterization through standardized rating scales for motor and non-motor symptoms and self-reported binomial information of a cohort of subjects with PD (n\u00a0=\u00a0100) from our center and from the larger cohort of the Parkinson's Progression Marker Initiative (PPMI) was utilized to evaluate the predictive values of clinical traits for <i>GBA</i> variant carrier status. The model was cross-validated across the two cohorts.\nResults: Leveraging non-motor symptoms of PD, we established successful discrimination of <i>GBA</i> variants in the PPMI cohort and study cohort (AUC 0.897 and 0.738, respectively). The PPMI cohort model successfully generalized to the study cohort data using both MDS-UPDRS scores and binomial data (AUC 0.740 and 0.734, respectively) while the study cohort model did not.\nConclusions: We assessed the predictive value of non-motor symptoms of PD for identifying <i>GBA</i> carrier status in the general PD population. These data can be used to determine a simple, clinically oriented model using either the MDS-UPDRS or subjective symptom reporting from patients. Our results can inform patient counseling about the expected carrier risk and test prioritization for the expected identification of <i>GBA</i> variants.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.3390/ijms24108995": {
                "title": "Brain Calcifications: Genetic, Molecular, and Clinical Aspects",
                "abstract": "Many conditions can present with accumulation of calcium in the brain and manifest with a variety of neurological symptoms. Brain calcifications can be primary (idiopathic or genetic) or secondary to various pathological conditions (e.g., calcium-phosphate metabolism derangement, autoimmune disorders and infections, among others). A set of causative genes associated with primary familial brain calcification (PFBC) has now been identified, and include genes such as <i>SLC20A2</i>, <i>PDGFB</i>, <i>PDGFRB</i>, <i>XPR1</i>, <i>MYORG</i>, and <i>JAM2</i>. However, many more genes are known to be linked with complex syndromes characterized by brain calcifications and additional neurologic and systemic manifestations. Of note, many of these genes encode for proteins involved in cerebrovascular and blood-brain barrier functions, which both represent key anatomical structures related to these pathological phenomena. As a growing number of genes associated with brain calcifications is identified, pathways involved in these conditions are beginning to be understood. Our comprehensive review of the genetic, molecular, and clinical aspects of brain calcifications offers a framework for clinicians and researchers in the field.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.3390/ijms24032247": {
                "title": "The SMN Complex at the Crossroad between RNA Metabolism and Neurodegeneration",
                "abstract": "In the cell, RNA exists and functions in a complex with RNA binding proteins (RBPs) that regulate each step of the RNA life cycle from transcription to degradation. Central to this regulation is the role of several molecular chaperones that ensure the correct interactions between RNA and proteins, while aiding the biogenesis of large RNA-protein complexes (ribonucleoproteins or RNPs). Accurate formation of RNPs is fundamentally important to cellular development and function, and its impairment often leads to disease. The survival motor neuron (SMN) protein exemplifies this biological paradigm. SMN is part of a multi-protein complex essential for the biogenesis of various RNPs that function in RNA metabolism. Mutations leading to SMN deficiency cause the neurodegenerative disease spinal muscular atrophy (SMA). A fundamental question in SMA biology is how selective motor system dysfunction results from reduced levels of the ubiquitously expressed SMN protein. Recent clarification of the central role of the SMN complex in RNA metabolism and a thorough characterization of animal models of SMA have significantly advanced our knowledge of the molecular basis of the disease. Here we review the expanding role of SMN in the regulation of gene expression through its multiple functions in RNP biogenesis. We discuss developments in our understanding of SMN activity as a molecular chaperone of RNPs and how disruption of SMN-dependent RNA pathways can contribute to the SMA phenotype.",
                "disciplines": [
                    "3101",
                    "3102"
                ]
            }
        }
    },
    "12964063": {
        "title": "Reprogramming myeloid cells to inhibit cancer development",
        "abstract": "Immunosuppressive myeloid cells including myeloid-derived suppressor cells (MDSCs) contribute to multiple steps of cancer development. A better understanding of the molecular regulation of the functions of these myeloid cells and the signaling pathways will support development of novel anti-cancer therapeutic strategies. The leukocyte Ig-like receptor subfamily B (LILRB) proteins are a group of immune inhibitory receptors with intracellular immunoreceptor tyrosine-based inhibitory motifs. We have been studying the roles of these receptors in cancer development and immune regulation. The studies by us and others suggest that the LILRB family is becoming the next wave of myeloid immune checkpoint targets for cancer treatment. Here we demonstrated that LILRB3, a myeloid- specific member of this family, is functionally expressed on human MDSCs, and supports cancer development in mouse models. Importantly, we identified galectin-4 as an extracellular protein that binds to LILRB3 and induces LILRB3 activation, and the intracellular domain of LILRB3 interacts with the adaptor protein TRAF2 to contribute to NF\u03baB upregulation. Furthermore, we developed anti-LILRB3 blocking antibodies that efficiently inhibit immunosuppressive activity of human MDSCs in vitro and cancer development in xenografted humanized mice and in LILRB3-transgenic mice. Our study suggests that LILRB3 represents an attractive novel target for cancer treatment. Based on new preliminary results, we propose the following Aims to test the hypothesis that LILRB3-initiated signaling in immunosuppressive myeloid cells supports cancer development. In Aim 1, we will determine the function of LILRB3 expressed on myeloid cells in cancer development. We will then determine whether galectin-4 regulates LILRB3- mediated signaling in tumor microenvironment to support cancer development in Aim 2. Finally we will dissect LILRB3 signaling in immunosuppressive myeloid cells in Aim 3. Our study will elucidate the molecular mechanisms by which LILRB3 regulates the activity of immunosuppressive myeloid cells, and lead to the development of innovative anti-cancer strategies based on targeting LILRB3 signaling.",
        "disciplines": [
            "3211",
            "3204",
            "3101"
        ],
        "publications": {
            "10.1016/j.isci.2023.108171": {
                "title": "Comprehensive characterization of patient-derived xenograft models of pediatric leukemia",
                "abstract": "Patient-derived xenografts (PDX) remain valuable models for understanding the biology and for developing novel therapeutics. To expand current PDX models of childhood leukemia, we have developed new PDX models from Hispanic patients, a subgroup with a poorer overall outcome. Of 117 primary leukemia samples obtained, successful engraftment and serial passage in mice were achieved in 82 samples (70%). Hispanic patient samples engrafted at a rate (51/73, 70%) that was similar to non-Hispanic patient samples (31/45, 70%). With a new algorithm to remove mouse contamination in multi-omics datasets including methylation data, we found PDX models faithfully reflected somatic mutations, copy-number alterations, RNA expression, gene fusions, whole-genome methylation patterns, and immunophenotypes found in primary tumor (PT) samples in the first 50 reported here. This cohort of characterized PDX childhood leukemias represents a valuable resource in that germline DNA sequencing has allowed the unambiguous determination of somatic mutations in both PT and PDX.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.1158/2326-6066.cir-23-0496": {
                "title": "LILRB3 Supports Immunosuppressive Activity of Myeloid Cells and Tumor Development.",
                "abstract": "The existing T cell-centered immune checkpoint blockade therapies have been successful in treating some but not all patients with cancer. Immunosuppressive myeloid cells, including myeloid-derived suppressor cells (MDSC), that inhibit antitumor immunity and support multiple steps of tumor development are recognized as one of the major obstacles in cancer treatment. Leukocyte Ig-like receptor subfamily B3 (LILRB3), an immune inhibitory receptor containing tyrosine-based inhibitory motifs (ITIM), is expressed solely on myeloid cells. However, it is unknown whether LILRB3 is a critical checkpoint receptor in regulating the activity of immunosuppressive myeloid cells, and whether LILRB3 signaling can be blocked to activate the immune system to treat solid tumors. Here, we report that galectin-4 and galectin-7 induce activation of LILRB3 and that LILRB3 is functionally expressed on immunosuppressive myeloid cells. In some samples from patients with solid cancers, blockade of LILRB3 signaling by an antagonistic antibody inhibited the activity of immunosuppressive myeloid cells. Anti-LILRB3 also impeded tumor development in myeloid-specific LILRB3 transgenic mice through a T cell-dependent manner. LILRB3 blockade may prove to be a novel approach for immunotherapy of solid cancers.",
                "disciplines": [
                    "3211",
                    "3204"
                ]
            },
            "10.1101/2023.12.07.570715": {
                "title": "Reconstructing Spatial Transcriptomics at the Single-cell Resolution with BayesDeep",
                "abstract": "Spatially resolved transcriptomics (SRT) techniques have revolutionized the characterization of molecular profiles while preserving spatial and morphological context. However, most next-generation sequencing-based SRT techniques are limited to measuring gene expression in a confined array of spots, capturing only a fraction of the spatial domain. Typically, these spots encompass gene expression from a few to hundreds of cells, underscoring a critical need for more detailed, single-cell resolution SRT data to enhance our understanding of biological functions within the tissue context. Addressing this challenge, we introduce BayesDeep, a novel Bayesian hierarchical model that leverages cellular morphological data from histology images, commonly paired with SRT data, to reconstruct SRT data at the single-cell resolution. BayesDeep effectively model count data from SRT studies <i>via</i> a negative binomial regression model. This model incorporates explanatory variables such as cell types and nuclei-shape information for each cell extracted from the paired histology image. A feature selection scheme is integrated to examine the association between the morphological and molecular profiles, thereby improving the model robustness. We applied BayesDeep to two real SRT datasets, successfully demonstrating its capability to reconstruct SRT data at the single-cell resolution. This advancement not only yields new biological insights but also significantly enhances various downstream analyses, such as pseudotime and cell-cell communication.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.1016/j.cell.2023.11.008": {
                "title": "Dissecting embryonic and extraembryonic lineage crosstalk with stem cell co-culture",
                "abstract": "Embryogenesis necessitates harmonious coordination between embryonic and extraembryonic tissues. Although stem cells of both embryonic and extraembryonic origins have been generated, they are grown in different culture conditions. In this study, utilizing a unified culture condition that activates the FGF, TGF-\u03b2, and WNT pathways, we have successfully derived embryonic stem cells (FTW-ESCs), extraembryonic endoderm stem cells (FTW-XENs), and trophoblast stem cells (FTW-TSCs) from the three foundational tissues of mouse and cynomolgus monkey (Macaca fascicularis) blastocysts. This approach facilitates the co-culture of embryonic and extraembryonic stem cells, revealing a growth inhibition effect exerted by extraembryonic endoderm cells on pluripotent cells, partially through extracellular matrix signaling. Additionally, our cross-species analysis identified both shared and unique transcription factors and pathways regulating FTW-XENs. The embryonic and extraembryonic stem cell co-culture strategy offers promising avenues for developing more faithful embryo models and devising more developmentally pertinent differentiation protocols.",
                "disciplines": [
                    "3206"
                ]
            },
            "10.1093/abt/tbad025": {
                "title": "Fc gamma receptors promote antibody-induced LILRB4 internalization and immune regulation of monocytic AML",
                "abstract": "The immune checkpoint leukocyte immunoglobulin-like receptor B4 (LILRB4) is found specifically on the cell surface of acute monocytic leukemia (monocytic AML), an aggressive and common subtype of AML. We have developed a humanized monoclonal IgG<sub>1</sub> LILRB4-blocking antibody (h128-3), which improved immune regulation but reduced cell surface expression of LILRB4 in monocytic AML models by 40-60%. Interestingly, most of this effect was neutralized by mutation of the Fc region of the antibody (h128-3/N297A), which prevents interaction with Fc gamma receptors (Fc\u03b3Rs). This suggested that there is Fc\u03b3R-dependent antigenic modulation underlying h128-3's effects, a mechanism known to alter the function of antibodies targeting B-cell malignancies. We disrupted the Fc-Fc\u03b3R interaction pharmacologically and with stable CRISPR-Cas9-mediated genetic knockout of Fc\u03b3Rs in monocytic AML cell lines to investigate the role of Fc\u03b3R-dependent antigenic modulation in the regulation of LILRB4 by h128-3. When Fc\u03b3RI is inhibited or removed from the surface of monocytic AML cells, h128-3 cannot optimally perform its blocking function, resulting in activation of the LILRB4 inhibitory receptor and leading to a 15-25% decrease in T-cell-mediated cytotoxicity <i>in vitro</i>. In the absence of Fc\u03b3RI, scaffolding by Fc\u03b3RIIa allows h128-3 to maintain LILRB4-blocking function. Here we define a Fc\u03b3R-dependent antigenic modulation mechanism underlying the function of an immunoreceptor blocking antibody for the first time in myeloid malignancy. This research will facilitate the development of safe, precision-targeted antibody therapeutics in myeloid malignancies with greater potency and efficacy.",
                "disciplines": [
                    "3101",
                    "3204"
                ]
            },
            "10.1016/j.celrep.2023.113280": {
                "title": "ZNF692 organizes a hub specialized in 40S ribosomal subunit maturation enhancing translation in rapidly proliferating cells",
                "abstract": "Increased nucleolar size and activity correlate with aberrant ribosome biogenesis and enhanced translation in cancer cells. One of the first and rate-limiting steps in translation is the interaction of the 40S small ribosome subunit with mRNAs. Here, we report the identification of the zinc finger protein 692 (ZNF692), a MYC-induced nucleolar scaffold that coordinates the final steps in the biogenesis of the small ribosome subunit. ZNF692 forms a hub containing the exosome complex and ribosome biogenesis factors specialized in the final steps of 18S rRNA processing and 40S ribosome maturation in the granular component of the nucleolus. Highly proliferative cells are more reliant on ZNF692 than normal cells; thus, we conclude that effective production of small ribosome subunits is critical for translation efficiency in cancer cells.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1101/2023.06.18.545488": {
                "title": "Integrating Image and Molecular Profiles for Spatial Transcriptomics Analysis",
                "abstract": "Abstract The spatially resolved transcriptomics (SRT) field has revolutionized our ability to comprehensively leverage image and molecular profiles to elucidate spatial organization of cellular microenvironments. Current clustering analysis of SRT data primarily relies on molecular information and fails to fully exploit the morphological features present in histology images, leading to compromised accuracy and interpretability. To overcome these limitations, we have developed a multi-stage statistical method called iIMPACT. It includes a finite mixture model to identify and define histology-based spatial domains based on AI-reconstructed histology images and spatial context of gene expression measurements, and a negative binomial regression model to detect domain-specific spatially variable genes. Through multiple case studies, we demonstrate iIMPACT outperformed existing methods, confirmed by ground truth biological knowledge. These findings underscore the accuracy and interpretability of iIMPACT as a new clustering approach, providing valuable insights into the cellular spatial organization and landscape of functional genes within spatial transcriptomics data.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.3390/cancers15102788": {
                "title": "The MYC-YBX1 Circuit in Maintaining Stem-like Vincristine-Resistant Cells in Rhabdomyosarcoma",
                "abstract": "Rhabdomyosarcoma (RMS) is a pediatric soft tissue sarcoma that causes significant devastation, with no effective therapy for relapsed disease. The mechanisms behind treatment failures are poorly understood. Our study showed that treatment of RMS cells with vincristine led to an increase in CD133-positive stem-like resistant cells. Single cell RNAseq analysis revealed that MYC and YBX1 were among the top-scoring transcription factors in CD133-high expressing cells. Targeting MYC and YBX1 using CRISPR/Cas9 reduced stem-like characteristics and viability of the vincristine-resistant cells. MYC and YBX1 showed mutual regulation, with MYC binding to the YBX1 promoter and YBX1 binding to MYC mRNA. The MYC inhibitor MYC361i synergized with vincristine to reduce tumor growth and stem-like cells in a zebrafish model of RMS. MYC and YBX expression showed a positive correlation in RMS patients, and high MYC expression correlated with poor survival. Targeting the MYC-YBX1 axis holds promise for improving survival in RMS patients.",
                "disciplines": [
                    "3211"
                ]
            },
            "10.1101/2023.03.07.531525": {
                "title": "Dissecting embryonic and extra-embryonic lineage crosstalk with stem cell co-culture",
                "abstract": "Faithful embryogenesis requires precise coordination between embryonic and extraembryonic tissues. Although stem cells from embryonic and extraembryonic origins have been generated for several mammalian species(Bogliotti et al., 2018; Choi et al., 2019; Cui et al., 2019; Evans and Kaufman, 1981; Kunath et al., 2005; Li et al., 2008; Martin, 1981; Okae et al., 2018; Tanaka et al., 1998; Thomson et al., 1998; Vandevoort et al., 2007; Vilarino et al., 2020; Yu et al., 2021b; Zhong et al., 2018), they are grown in different culture conditions with diverse media composition, which makes it difficult to study cross-lineage communication. Here, by using the same culture condition that activates FGF, TGF-\u03b2 and WNT signaling pathways, we derived stable embryonic stem cells (ESCs), extraembryonic endoderm stem cells (XENs) and trophoblast stem cells (TSCs) from all three founding tissues of mouse and cynomolgus monkey blastocysts. This allowed us to establish embryonic and extraembryonic stem cell co-cultures to dissect lineage crosstalk during early mammalian development. Co-cultures of ESCs and XENs uncovered a conserved and previously unrecognized growth inhibition of pluripotent cells by extraembryonic endoderm cells, which is in part mediated through extracellular matrix signaling. Our study unveils a more universal state of stem cell self-renewal stabilized by activation, as opposed to inhibition, of developmental signaling pathways. The embryonic and extraembryonic stem cell co-culture strategy developed here will open new avenues for creating more faithful embryo models and developing more developmentally relevant differentiation protocols.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1080/13543784.2023.2179482": {
                "title": "Antibody therapies for the treatment of acute myeloid leukemia: exploring current and emerging therapeutic targets",
                "abstract": "INTRODUCTION: Acute myeloid leukemia (AML) is the most common and deadly type of leukemia affecting adults. It is typically managed with rounds of non-targeted chemotherapy followed by hematopoietic stem cell transplants, but this is only possible in patients who can tolerate these harsh treatments and many are elderly and frail. With the identification of novel tumor-specific cell surface receptors, there is great conviction that targeted antibody therapies will soon become available for these patients.\nAREAS COVERED: In this review, we describe the current landscape of known target receptors for monospecific and bispecific antibody-based therapeutics for AML. Here, we characterize each of the receptors and targeted antibody-based therapeutics in development, illustrating the rational design behind each therapeutic compound. We then discuss the bispecific antibodies in development and how they improve immune surveillance of AML. For each therapeutic, we also summarize the available pre-clinical and clinical data, including data from discontinued trials.\nEXPERT OPINION: One antibody-based therapeutic has already been approved for AML treatment, the CD33-targeting antibody-drug conjugate, gemtuzumab ozogamicin. Many more are currently in pre-clinical and clinical studies. These antibody-based therapeutics can perform tumor-specific, elaborate cytotoxic functions and there is growing confidence they will soon lead to personalized, safe AML treatment options that induce durable remissions.",
                "disciplines": [
                    "3211",
                    "3204"
                ]
            },
            "10.1016/j.bbrc.2022.09.019": {
                "title": "A perspective on LILRBs and LAIR1 as immune checkpoint targets for cancer treatment",
                "abstract": "Immunosuppressive myeloid cells in the tumor microenvironment inhibit anti-tumor immunity and support tumor development. The leukocyte Ig-like receptor subfamily B (LILRB) proteins and the related receptor LAIR1 are immune checkpoint receptors that support the immunosuppressive activity of myeloid cells. All LILRBs and LAIR1 have intracellular immunoreceptor tyrosine-based inhibitory motifs in their signaling domains, but the individual proteins have different functions. The determinants of the distinct functions of these inhibitory receptors likely rest in their interactions with different ligands and other surface proteins, characteristic signaling domains, and expression dynamics in different cell types regulated by various extrinsic cues and transcription factors. Significant advancement of immuno-oncology therapeutic products based on targeting or reprogramming of LILRB- and LAIR1-mediated signaling is anticipated.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.3389/fimmu.2022.996026": {
                "title": "Blocking LAIR1 signaling in immune cells inhibits tumor development",
                "abstract": "The current immune checkpoint blockade therapy has been successful in treating some cancers but not others. New molecular targets and therapeutic approaches of cancer immunology need to be identified. Leukocyte associated immunoglobulin like receptor 1 (LAIR1) is an immune inhibitory receptor expressing on most immune cell types. However, it remains a question whether we can specifically and actively block LAIR1 signaling to activate immune responses for cancer treatment. Here we report the development of specific antagonistic anti-LAIR1 monoclonal antibodies and studied the effects of LAIR1 blockade on the anti-tumor immune functions. The anti-LAIR1 antagonistic antibody stimulated the activities of T cells, natural killer cells, macrophages, and dendritic cells <i>in vitro</i>. The single-cell RNA sequencing analysis of intratumoral immune cells in syngeneic human LAIR1 transgenic mice treated with control or anti-LAIR1 antagonist antibodies indicates that LAIR1 signaling blockade increased the numbers of CD4 memory T cells and inflammatory macrophages, but decreased those of pro-tumor macrophages, regulatory T cells, and plasmacytoid dendritic cells. Importantly, the LAIR1 blockade by the antagonistic antibody inhibited the activity of immunosuppressive myeloid cells and reactivated T cells from cancer patients <i>in vitro</i> and impeded tumor metastasis in a humanized mouse model. Blocking LAIR1 signaling in immune cells represents a promising strategy for development of anti-cancer immunotherapy.",
                "disciplines": [
                    "3211",
                    "3204"
                ]
            }
        }
    },
    "13017118": {
        "title": "Deciphering HEArt-liVEr commuNication in nonalcohoLic fattY liver disease \u2013 HEAVENLY",
        "abstract": "Nonalcoholic fatty liver disease (NAFLD) is a major public health issue and an independent risk factor for myocardial infarction (MI) in epidemiological studies. Post-MI cardiac repair conditions patient outcome. Extracellular vesicles (EVs) are vectors of information between organs, found more abundantly in the plasma of NAFLD patients. EVs are implicated in MI. Based on our preliminary data showing that NAFLD directly impairs post-MI cardiac repair in mice without usual CV risk factors, and that circulating EVs from NAFLD patients are enriched in liver proteins, we hypothesize that NAFLD impairs post-MI cardiac repair via liver-derived EVs. By combining our complementary expertise, we will: 1/ delineate the consequences of each stage of NAFLD on post-MI cardiac repair using 3 complementary NAFLD models; and 2/ identify mechanisms underlying liver-heart communication in NAFLD and MI, using hypothesis-based and unbiased approaches.",
        "disciplines": [
            "3201"
        ],
        "publications": {
            "10.1111/liv.15927": {
                "title": "Prognosis algorithms for acute decompensation of cirrhosis and ACLF",
                "abstract": "Accurate prediction of survival in patients with cirrhosis is crucial, as patients who are unlikely to survive in the short-term need to be oriented to liver transplantation and to novel therapeutic approaches. Patients with acute decompensation of cirrhosis without or with organ dysfunction/failure, the so-called acute-on-chronic liver failure (ACLF), have a particularly high short-term mortality. Recognizing the specificity of this clinical situation, dedicated classifications and scores have been developed over the last 15\u2009years, including variables (e.g. organ failures and systemic inflammation) not part of the formerly available cirrhosis severity scores, namely Child-Pugh score or MELD. For patients with acute decompensation of cirrhosis, it led to the development of a dedicated score, the Clif-C-AD score, independently validated. For more severe patients, three different scoring systems have been proposed, by European, Asian and North American societies namely Clif-C-ACLF, AARC score and NASCELD-ACLF respectively. These scores have been validated, and are widely used across the world. The differences and similarities between these scores, as well as their validation and limitations are discussed here. Even if these scores and classifications have been a step forward in favouring homogeneity between studies, and in helping making decisions for individual patients, their predictive value for mortality can still be improved as their area under the ROC curve does not exceed .8. Novel scores including biomarkers reflecting the pathophysiology of acute decompensation of cirrhosis might help reach that goal.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1101/2023.11.17.23298672": {
                "title": "ClustALL: A robust clustering strategy for stratification of patients with acutely decompensated cirrhosis",
                "abstract": "Abstract Patient heterogeneity represents a significant challenge for both individual patient management and clinical trial design, especially in the context of complex diseases. Most existing clinical classifications are based on scores built to predict patients\u2019 outcomes. These classical methods may thus miss features that contribute to heterogeneity without necessarily translating into prognostic implications. To address patient heterogeneity at hospital admission, we developed ClustALL, a computational pipeline designed to handle common clinical data challenges such as mixed data types, missing values, and collinearity. ClustALL also facilitates the unsupervised identification of multiple and robust stratifications. We applied ClustALL to a prospective European multicentre cohort of patients with acutely decompensated cirrhosis (AD) (n=766), a highly heterogeneous disease. ClustALL identified five robust stratifications for patients with AD, using only data at hospital admission. All stratifications included markers of impaired liver function and number of organ dysfunction or failure, and most included precipitating events. When focusing on one of these stratifications, patients were categorized into three clusters characterized by typical clinical features but also having a prognostic value. Re-assessment of patient stratification during follow-up delineated patients\u2019 outcomes, with further improvement of the prognostic value of the stratification. We validated these findings in an independent prospective multicentre cohort of patients from Latin America (n=580). In conclusion, this study developed ClustALL, a novel and robust stratification method capable of addressing challenges tied to intricate clinical data and applicable to complex diseases. By applying ClustALL to patients with AD, we identified three patient clusters, offering insights that could guide future clinical trial design.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1111/liv.15665": {
                "title": "Endothelial autophagy is not required for liver regeneration after partial hepatectomy in mice with fatty liver",
                "abstract": "BACKGROUND & AIMS: <AbstractText Label=\"BACKGROUND &amp; AIMS\">Patients with non-alcoholic fatty liver disease (NAFLD) have impaired liver regeneration. Liver endothelial cells play a key role in liver regeneration. In non-alcoholic steatohepatitis (NASH), liver endothelial cells display a defect in autophagy, contributing to NASH progression. We aimed to determine the role of endothelial autophagy in liver regeneration following liver resection in NAFLD.</AbstractText>\nMETHODS: <AbstractText Label=\"METHODS\">First, we assessed autophagy in primary endothelial cells from wild type mice fed a high fat diet and subjected to partial hepatectomy. Then, we assessed liver regeneration after partial hepatectomy in mice deficient (Atg5<sup>lox/lox</sup> ;VE-cadherin-Cre<sup>+</sup> ) or not (Atg5<sup>lox/lox</sup> ) in endothelial autophagy and fed a high fat diet. The role of endothelial autophagy in liver regeneration was also assessed in ApoE<sup>-/-</sup> hypercholesterolemic mice and in mice with NASH induced by methionine- and choline-deficient diet.</AbstractText>\nRESULTS: <AbstractText Label=\"RESULTS\">First, autophagy (LC3II/protein) was strongly increased in liver endothelial cells following hepatectomy. Then, we observed at 40 and 48\u2009h and at 7\u2009days after partial hepatectomy, that Atg5<sup>lox/lox</sup> ;VE-cadherin-Cre<sup>+</sup> mice fed a high fat diet had similar liver weight, plasma AST, ALT and albumin concentration, and liver protein expression of proliferation (PCNA), cell-cycle (Cyclin D1, BrdU incorporation, phospho-Histone H3) and apoptosis markers (cleaved Caspase-3) as Atg5<sup>lox/lox</sup> mice fed a high fat diet. Same results were obtained in ApoE<sup>-/-</sup> and methionine- and choline-deficient diet fed mice, 40\u2009h after hepatectomy.</AbstractText>\nCONCLUSION: <AbstractText Label=\"CONCLUSION\">These results demonstrate that the defect in endothelial autophagy occurring in NASH does not account for the impaired liver regeneration occurring in this setting.</AbstractText>",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1016/j.cgh.2023.04.016": {
                "title": "Bleeding and Thrombotic Complications in Patients With Cirrhosis: A State-of-the-Art Appraisal",
                "abstract": "Much has evolved over the past 25 years regarding our understanding of the coagulopathy of liver disease. Paradoxically, this form of coagulopathy is relatively hypercoagulability despite the common clinical impression of a hemorrhagic tendency. The latter is largely driven by portal-mesenteric venous pressure (ie, portal hypertension) and has little to do with hemostatic pathways. It cannot be emphasized enough that the INR does not offer a meaningful measure in this situation and may lead to interventions such as fresh frozen plasma that can actually worsen portal pressure and hence pressure-driven bleeding. With regard to procedure-related bleeding, we point out substantial differences in the definition of high-risk procedures and propose a new operational definition dependent on the applicability of local hemostatic measures, although this requires further investigation. The common occurrence of venous thrombosis in these patients requires careful consideration of hemostatic pathways and overall risk and benefit of intervention. The decision regarding anticoagulation therapy needs to be driven not only by a global assessment including history of non-portal hypertensive-related bleeding, but also by fall risk which can result in head trauma in patients prone to encephalopathy. This is probably best estimated by frailty but has yet to be adequately investigated. In the background of these concerns, several superimposed and complex conditions including infections and renal dysfunction should be taken into account. Inherited forms of thrombophilia in the setting of cirrhosis perhaps do not outweigh the thrombophilia inherent to liver disease but warrant further consideration.",
                "disciplines": [
                    "3201"
                ]
            },
            "10.1016/j.jhepr.2022.100667": {
                "title": "Management of splanchnic vein thrombosis",
                "abstract": "The expression splanchnic vein thrombosis encompasses Budd-Chiari syndrome and portal vein thrombosis. These disorders have common characteristics: they are both rare diseases which can cause portal hypertension and its complications. Budd-Chiari syndrome and portal vein thrombosis in the absence of underlying liver disease share many risk factors, among which myeloproliferative neoplasms represent the most common; a rapid comprehensive work-up for risk factors of thrombosis is needed in these patients. Long-term anticoagulation is indicated in most patients. Portal vein thrombosis can also develop in patients with cirrhosis and in those with porto-sinusoidal vascular liver disease. The presence and nature of underlying liver disease impacts the management of portal vein thrombosis. Indications for anticoagulation in patients with cirrhosis are growing, while transjugular intrahepatic portosystemic shunt is now a second-line option. Due to the rarity of these diseases, studies yielding high-grade evidence are scarce. However, collaborative studies have provided new insight into the management of these patients. This article focuses on the causes, diagnosis, and management of patients with Budd-Chiari syndrome, portal vein thrombosis without underlying liver disease, or cirrhosis with non-malignant portal vein thrombosis.",
                "disciplines": [
                    "3201"
                ]
            }
        }
    },
    "12962770": {
        "title": "Impacts of SARS-CoV-2 Infection and Age on Musculoskeletal Health",
        "abstract": "PROJECT SUMMARY/ABSTRACT The Coronavirus Disease 2019 (COVID-19) pandemic as of June 14, 2021, has totaled 176.02 million cases, 3.80 million deaths, and 2.37 billion vaccine doses have been administered globally. However, many have suffered prior to the vaccine and have survived or will still suffer without the vaccine. Therefore, determining the possible long-term health ramifications post-infection, how they vary based on age at the time of infection, and whether disease severity differentially impacts long-term health is imperative. Information on how COVID-19 affects bone metabolism and homeostasis is limited. This is of crucial concern because the aging population generally has higher bone loss and are at the highest risk of developing severe COVID-19 infection. The objective of the current application is to determine whether long-term deficits in bone mass are experienced following SARS-CoV-2 infection. The long-term goal is to develop potential treatment strategies to combat COVID-19 related bone loss. Preliminary studies showed that in a K18-hACE2 mouse model of COVID-19, surviving mice infected with 1x103 or 1x104 PFU exhibited up to a 24% reduction in trabecular bone volume fraction just 2 weeks post infection (p<0.001). Infected mice had a 63% increase in osteoclast numbers (p<0.0002) and a 30% increase in surface occupied by osteoclasts (p<0.02) compared to non-infected controls. Additionally, mice infected with any dose of SARS-CoV-2 had a 40% increase in megakaryocytes (MKs) within their femoral bone marrow compared to that observed in mock-infected controls (p<0.008). Further, previously conducted studies showed that MKs regulate bone mass and osteoclast (OC) formation (aged MKs increase OCs and have increased RANKL expression). Moreover, patients with severe forms of COVID-19 have upregulated expression of numerous cytokines and growth factors which is known as an inflammatory cytokine storm. Many of these cytokines, including IL-6 and TNF-\u03b1, are known to regulate OCs and/or MKs and may be responsible for the bone loss observed in the preliminary studies. Based on these observations it is hypothesized that i) SARS-CoV-2 infection results in long-term health complications in the musculoskeletal system, and ii) SARS-CoV-2 infection and the associated cytokine storm increases MK- stimulated OC formation. To test this hypothesis, two specific aims will be pursued: 1- determine whether following SARS-CoV-2 infection the bone loss observed remains over time and whether age at the time of infection impacts the severity of bone loss induced by SARS-CoV-2 infection, and: 2- investigate the mechanisms by which OC formation and bone resorption are increased as a consequence of SARS-CoV-2 infection and age, including the extent to which MKs from infected mice induce OC formation and bone resorption. The successful completion of these studies will deepen the understanding of the health implications post-infection with SARS-COV-2 and will demonstrate how disease severity, age, and MKs influence skeletal homeostasis as well as OC formation and resorption.",
        "disciplines": [
            "3202"
        ],
        "publications": {
            "10.1007/s11914-023-00843-1": {
                "title": "SARS-CoV-2 and its Multifaceted Impact on Bone Health: Mechanisms and Clinical Evidence",
                "abstract": "Purpose of ReviewSARS-CoV-2 infection, the culprit of the COVID-19 pandemic, has been associated with significant long-term effects on various organ systems, including bone health. This review explores the current understanding of the impacts of SARS-CoV-2 infection on bone health and its potential long-term consequences.Recent FindingsAs part of the post-acute sequelae of SARS-CoV-2 infection, bone health changes are affected by COVID-19 both directly and indirectly, with multiple potential mechanisms and risk factors involved. In vitro and preclinical studies suggest that SARS-CoV-2 may directly infect bone marrow cells, leading to alterations in bone structure and osteoclast numbers. The virus can also trigger a robust inflammatory response, often referred to as a \"cytokine storm\", which can stimulate osteoclast activity and contribute to bone loss. Clinical evidence suggests that SARS-CoV-2 may lead to hypocalcemia, altered bone turnover markers, and a high prevalence of vertebral fractures. Furthermore, disease severity has been correlated with a decrease in bone mineral density. Indirect effects of SARS-CoV-2 on bone health, mediated through muscle weakness, mechanical unloading, nutritional deficiencies, and corticosteroid use, also contribute to the long-term consequences. The interplay of concurrent conditions such as diabetes, obesity, and kidney dysfunction with SARS-CoV-2 infection further complicates the disease's impact on bone health.SummarySARS-CoV-2 infection directly and indirectly affects bone health, leading to potential long-term consequences.\u00a0This review article is part of a series of multiple manuscripts designed to determine the utility of using artificial intelligence for writing scientific reviews.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1007/s11914-023-00842-2": {
                "title": "COVID-19 and Bone Loss: A Review of Risk Factors, Mechanisms, and Future Directions",
                "abstract": "Purpose of ReviewSARS-CoV-2 drove the catastrophic global phenomenon of the COVID-19 pandemic resulting in a multitude of systemic health issues, including bone loss. The purpose of this review is to summarize recent findings related to bone loss and potential mechanisms.Recent FindingsThe early clinical evidence indicates an increase in vertebral fractures, hypocalcemia, vitamin D deficiencies, and a loss in BMD among COVID-19 patients. Additionally, lower BMD is associated with more severe SARS-CoV-2 infection. Preclinical models have shown bone loss and increased osteoclastogenesis. The bone loss associated with SARS-CoV-2 infection could be the result of many factors that directly affect the bone such as higher inflammation, activation of the NLRP3 inflammasome, recruitment of Th17 cells, the hypoxic environment, and changes in RANKL/OPG signaling. Additionally, SARS-CoV-2 infection can exert indirect effects on the skeleton, as mechanical unloading may occur with severe disease (e.g., bed rest) or with BMI loss and muscle wasting that has also been shown to occur with SARS-CoV-2 infection. Muscle wasting can also cause systemic issues that may influence the bone. Medications used to treat SARS-CoV-2 infection also have a negative effect on the bone. Lastly, SARS-CoV-2 infection may also worsen conditions such as diabetes and negatively affect kidney function, all of which could contribute to bone loss and increased fracture risk.SummarySARS-CoV-2 can negatively affect the bone through multiple direct and indirect mechanisms. Future work will be needed to determine what patient populations are at risk of COVID-19-related increases in fracture risk, the mechanisms behind bone loss, and therapeutic options.\u00a0This review article is part of a series of multiple manuscripts designed to determine the utility of using artificial intelligence for writing scientific reviews.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1007/s11914-023-00855-x": {
                "title": "The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health",
                "abstract": "Purpose of ReviewThere were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts.Recent FindingsUnfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism.SummaryThe main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.",
                "disciplines": [
                    "3202"
                ]
            }
        }
    },
    "12925677": {
        "title": "Collaborative Research: The influence of subglacial discharge on the oceanic fate of meltwater from the Greenland ice sheet",
        "abstract": "This study concentrates on the influence that melt waters from Greenland fjords has on the circulation of the Labrador Sea to determine the fate of the melt water to the North Atlantic Ocean. The premise of the proposal is that fresh water discharged from glaciers and trapped below the ocean\u2019s surface on East Greenland has different fate from the fresh water that reaches the surface. The difference in destination between surface and subsurface fresh waters is because the wind should drive surface waters distinctly from subsurface waters, which are more isolated from the wind forcing. The study will be carried out with computer model simulations and satellite data. Findings from this study should have implications for global scale models that study water sinking in the North Atlantic and its impact on climate. The project will support one graduate student and will organize a workshop on climate processes for math & science teachers in Georgia. This project will investigate transport processes in the Labrador Sea, from areas of direct influence of Greenland ice sheet melt water to areas in the Labrador Sea where deep convection occurs in winter. The goal of the proposal is to identify and quantify the effect of subglacial discharge on transport pathways in the Labrador Sea. The hypothesis is that subsurface melt water from East Greenland\u2019s fjords will be transported to the Labrador Sea more effectively than surface melt water. If this hypothesis is proven accurate, then it will show that the correct depiction of fjord circulation is essential for representation of large-scale circulation and convection in ocean models. The proposal also hypothesizes that, with global warming, outflow plumes will either a) be more influenced by winds off W Greenland and reduce transport of melt water into central Labrador Sea, or b) increase flow instabilities and spatial variability that will increase transport into central Labrador Sea. Satellite observations and model simulations will quantify the relative importance of the two possible outcomes of the latter hypothesis and the effects of melt water on winter convection. The work is justified by the need to represent subglacial discharge on eastern Greenland, in contrast to the surface input of land-terminating glaciers on West Greenland. As Broader Impacts, the project will support one grad student and one research scientist, partially. The PIs will organize a 1-day workshop on climate processes for math & science teachers, as part of Georgia\u2019s Long Term Ecological Research. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "3709",
            "3708",
            "3705"
        ],
        "publications": {
            "10.3390/rs15235545": {
                "title": "Satellite-Derived Lagrangian Transport Pathways in the Labrador Sea",
                "abstract": "The offshore transport of Greenland coastal waters influenced by freshwater input from ice sheet melting during summer plays an important role in ocean circulation and biological processes in the Labrador Sea. Many previous studies over the last decade have investigated shelfbreak transport processes in the region, primarily using ocean model simulations. Here, we use 27 years of surface geostrophic velocity observations from satellite altimetry, modified to include Ekman dynamics based on atmospheric reanalysis, and virtual particle releases to investigate seasonal and interannual variability in transport of coastal water in the Labrador Sea. Two sets of tracking experiments were pursued, one using geostrophic velocities only, and another using total velocities including the wind effect. Our analysis revealed substantial seasonal variability, even when only geostrophic velocities were considered. Water from coastal southwest Greenland is generally transported northward into Baffin Bay, although westward transport off the west Greenland shelf increases in fall and winter due to winds. Westward offshore transport is increased for water from southeast Greenland so that, in some years, water originating near the east Greenland coast during summer can be transported into the central Labrador Sea and the convection region. When wind forcing is considered, long-term trends suggest decreasing transport of Greenland coastal water during the melting season toward Baffin Bay, and increasing transport into the interior of the Labrador Sea for water originating from southeast Greenland during summer, where it could potentially influence water column stability. Future studies using higher-resolution velocity observations are needed to capture the role of submesoscale variability in transport pathways in the Labrador Sea.",
                "disciplines": [
                    "4012",
                    "3708"
                ]
            },
            "10.1029/2022gl102689": {
                "title": "Greenland Subglacial Discharge as a Driver of Hotspots of Increasing Coastal Chlorophyll Since the Early 2000s",
                "abstract": "Abstract Subglacial discharge emerging from the base of Greenland's marine\u2010terminating glaciers drives upwelling of nutrient\u2010rich bottom waters to the euphotic zone, which can fuel nitrate\u2010limited phytoplankton growth. Here, we use buoyant plume theory to quantify this subglacial discharge\u2010driven nutrient supply on a pan\u2010Greenland scale. The modeled nitrate fluxes were concentrated in a few critical systems, with half of the total modeled nitrate flux anomaly occurring at just 14% of marine\u2010terminating glaciers. Increasing subglacial discharge fluxes results in elevated nitrate fluxes, with the largest flux occurring at Jakobshavn Isbr\u00e6 in Disko Bay, where subglacial discharge is largest. Subglacial discharge and nitrate flux anomaly also account for significant temporal variability in summer satellite chlorophyll a (Chl) within 50\u00a0km of Greenland's coast, particularly in some regions in central west and northwest Greenland.\nPlain Language Summary  Greenland ice\u2010sheet runoff is often discharged into fjords at the base of marine\u2010terminating glaciers as subglacial discharge, which can drive buoyant upwelling of nutrient\u2010rich bottom waters and fuel phytoplankton growth in the upper ocean. We combine a buoyant plume model with updated estimates of glacier depth, runoff rates, and profiles of temperature, salinity, and nitrate to estimate nutrient upwelling on a pan\u2010Greenland scale. The modeled nutrient upwelling is concentrated in a few major glacier systems with the largest subglacial discharge fluxes, and increasing runoff drives substantially increased modeled nutrient fluxes. We find that modeled nutrient upwelling can explain temporal variability in coastal surface chlorophyll a in some areas, particularly in west Greenland, which hosts the island's most exported fish catches by volume and value. \nKey Points    We use buoyant plume theory to model subglacial discharge\u2010driven nitrate fluxes across Greenland's largest marine\u2010terminating glaciers   The largest positive nitrate flux anomalies are concentrated in a few major systems with the largest subglacial discharge fluxes   Runoff and modeled nitrate upwelling can explain temporal variability in surface cholorophyll in some coastal areas in west Greenland   ",
                "disciplines": [
                    "3708",
                    "3709"
                ]
            },
            "10.3390/rs14236069": {
                "title": "Coastal Summer Freshening and Meltwater Input off West Greenland from Satellite Observations",
                "abstract": "Coastal waters off west Greenland are strongly influenced by the input of low salinity water from the Arctic and from meltwater from the Greenland Ice Sheet. Changes in freshwater content in the region can play an important role in stratification, circulation, and primary production; however, investigating salinity variability in the region is challenging because in situ observations are sparse. Here, we used satellite observations of sea surface salinity (SSS) from the Soil Moisture and Ocean Salinity mission produced by LOCEAN and by the Barcelona Expert Center (SMOS LOCEAN and SMOS BEC) and from the Soil Moisture Active Passive mission produced by the Jet Propulsion Laboratory (SMAP JPL) as well as by Remote Sensing Systems (SMAP RSS) to investigate how variability in a narrow coastal band off west Greenland is captured by these different products. Our analyses revealed that the various satellite SSS products capture the seasonal freshening off west Greenland from late spring to early fall. The magnitudes of the freshening and of coastal salinity gradients vary between the products however, being attenuated compared to historical in situ observations in most cases. The seasonal freshening off southwest Greenland is intensified in SMAP JPL and SMOS LOCEAN near the mouth of fjords characterized by large inputs of meltwater near the surface, which suggests an influence of meltwater from the Greenland Ice Sheet. Synoptic observations from 2012 following large ice sheet melting revealed good agreement with the spatial scale of freshening observed with in situ and SMOS LOCEAN data. Our analyses indicate that satellite SSS can capture the influence of meltwater input and associated freshwater plumes off coastal west Greenland, but those representations differ between products.",
                "disciplines": [
                    "3708",
                    "3709",
                    "4013"
                ]
            }
        }
    },
    "12964617": {
        "title": "Effects of Poly(ethylene glycol) Immunogenicity on Implant Biocompatibility",
        "abstract": "PROJECT SUMMARY Poly(ethylene glycol) (PEG) based hydrogels are widely used in medical devices and are being studied for the delivery of protein and cellular therapeutics. While these biomaterials are widely regarded as biologically inert, concerns over PEG\u2019s immunogenicity have emerged in recent years. It has been estimated that 20-30% of the population has antibodies against PEG due to exposure via pharmaceuticals, cosmetics, and other PEG- containing products. While an anti-PEG immune response has been found to reduce the efficacy of intravenously administered PEGylated drugs, the impact on the biocompatibility of PEG hydrogels has not previously been studied and is currently unknown. To address this knowledge gap, this project has two Specific Aims that encompass comprehensive in vivo testing to evaluate the host response to PEG hydrogels of varying physical and chemical properties. In these experiments, PEG hydrogels will be implanted subcutaneously in mice, and the host response will be evaluated at early, intermediate, and late timepoints using histology, immunohistochemistry, flow cytometry, and blood testing. The key comparison in these experiments will be between animals conditioned to mount an anti-PEG response and immunologically na\u00efve controls. The project has two Specific Aims. Aim 1 focuses on PEG hydrogel formulations that lack hydrolytically and enzymatically cleavable linkers. Hydrogels that differ in modulus, crosslinking chemistry, and functionalization with cell-adhesive peptides will be systematically studied. Aim 2 focuses on PEG hydrogel formulations that contain hydrolytically and enzymatically degradable linkers. In addition to evaluating the host response, the impact of the anti-PEG immune response on the in vivo degradation rate of these hydrogels will be investigated via non-invasive imaging in a longitudinal study. The results of this project will either alleviate concerns over PEG immunogenicity for biomaterial implants or motivate future investigations on strategies to mitigate its effects.",
        "disciplines": [
            "4003"
        ],
        "publications": {
            "10.1038/s41467-024-46327-3": {
                "title": "Impact of PEG sensitization on the efficacy of PEG hydrogel-mediated tissue engineering",
                "abstract": "While poly(ethylene glycol) (PEG) hydrogels are generally regarded as biologically inert blank slates, concerns over PEG immunogenicity are growing, and the implications for tissue engineering are unknown. Here, we investigate these implications by immunizing mice against PEG to stimulate anti-PEG antibody production and evaluating bone defect regeneration after treatment with bone morphogenetic protein-2-loaded PEG hydrogels. Quantitative analysis reveals that PEG sensitization increases bone formation compared to naive controls, whereas histological analysis shows that PEG sensitization induces an abnormally porous bone morphology at the defect site, particularly in males. Furthermore, immune cell recruitment is higher in PEG-sensitized mice administered the PEG-based treatment than their naive counterparts. Interestingly, naive controls that were administered a PEG-based treatment also develop anti-PEG antibodies. Sex differences in bone formation and immune cell recruitment are also apparent. Overall, these findings indicate that anti-PEG immune responses can impact tissue engineering efficacy and highlight the need for further investigation.",
                "disciplines": [
                    "4003"
                ]
            }
        }
    },
    "12964178": {
        "title": "Leveraging PMN immune response to overcome ADT resistance in bone metastatic prostate cancer",
        "abstract": "Metastatic castration-resistant prostate cancer (mCRPC) is deadly and currently incurable. Approximately 90% of patients CRPC become resistant to 2nd line androgen deprivation therapy (ADT; which primarily target androgen receptor (AR) signaling and present with bone metastatic disease. Although ADT remains a beneficial therapy for mCRPC patients, mechanisms of cancer resistance in mCRPC and specifically, in the bone environment, the most frequent site of CRPC metastasis, is poorly understood. Understanding contributing factors to PCa disease progression is needed for further development of efficacious therapies. ADT was previously shown to be critical for differentiation and function of polymorphonuclear leukocytes/neutrophils (PMNs) which are \u201cfirst responder\u201d innate immune cells that comprise ~40-50% of the bone marrow cavity. We recently showed that PMNs are protective against bone metastatic prostate cancer (BM-PCa) however, the PMN anti-tumoral immune response diminishes as the tumor progresses. To examine PMN phenotypical changes throughout PCa progression in patients, my group functionally and molecularly characterized peripheral blood PMNs from PCa patients at different stages: 1) Localized PCa, 2) bone metastatic hormone-sensitive (mCSPC), and 3) mCRPC patient. We found that PMN function was highly suppressed by 2nd line ADT through increased receptor 1 expression of transforming growth factor beta (TGF\u03b2), an anti-inflammatory cytokine important for promoting BM-PCa and cancer-induced bone disease. Using preclinical bone metastasis mouse models, we were able to significantly suppress mCRPC growth in bone using 2nd line ADT in combination with either bipolar androgen therapy (BAT; exogenous testosterone) to boost PMN anti-tumor response OR PMN-specific genetic deletion of T\u03b2R1. Based on our preliminary findings, we hypothesize that: anti-tumor PMNs are suppressed/ \u201cswitched off\u201d by androgen regulation via T\u03b2R1 signaling and this can be leveraged to improve mCRPC outcomes. This will be tested in the following aims: Aim 1. Define the impact of androgen regulation on PMN anti-tumor immune response. Aim 2. Determine the mechanism of T\u03b2R1-mediated PMN immune response in BM-PCa. Aim 3. Delineate the therapeutic potential of dual T\u03b2R1/AR regulation for improving mCRPC therapeutic outcomes. Primary Objective: To develop a novel immunotherapeutic strategy for treating BM-PCa by enhancing PMN anti-tumor response and overcoming PCa resistance to ADT. Study Design: For Aim 1, we will identify the impact of androgen signaling on PMN polarization ex vivo (using patient-derived PMNs and mouse bone marrow PMNs) and in vivo using normal PCa, non-metastatic and bone metastatic PCa cells) and in vivo (using mouse intratibial bone metastasis models). For Aim 2, we will delineate the role of T\u03b2R1 in PMN response to mCRPC using T\u03b2R1 knockout models. For Aim 3, we will define the therapeutic potential for using combination BAT with a novel bone-targeted T\u03b2R1 inhibitor.",
        "disciplines": [
            "3211",
            "3202",
            "3204"
        ],
        "publications": {
            "10.1002/cam4.6761": {
                "title": "Beyond the horizon: Neutrophils leading the way in the evolution of immunotherapy",
                "abstract": "Cancer is a complex and dynamic disease, initiated by a multitude of intrinsic mutations and progressed with the assistance of the tissue microenvironment, encompassed by stromal cells including immune cell infiltration. The novel finding that tumors can evade anti-cancer immune functions shaped the field of immunotherapy, which has been a revolutionary approach for the treatment of cancers. However, the development of predominantly T cell-targeted immunotherapy approaches, such as immune checkpoint inhibition, also brought about an accumulation of evidence demonstrating other immune cell drivers of tumor progression, such as innate immune cells and notably, neutrophils. In the past decade, neutrophils have emerged to be primary mediators of multiple cancer types and even in recent years, are gaining attention for their potential use in the next generation of immunotherapies. Here, we review current immunotherapy strategies and thoroughly discuss the roles of neutrophils in cancer and novel neutrophil-targeted methods for treating cancer.",
                "disciplines": [
                    "3211",
                    "3204"
                ]
            },
            "10.3389/fonc.2023.1100585": {
                "title": "Osteoid cell-derived chemokines drive bone-metastatic prostate cancer",
                "abstract": "One of the greatest challenges in improving prostate cancer (PCa) survival is in designing new therapies to effectively target bone metastases. PCa regulation of the bone environment has been well characterized; however, bone-targeted therapies have little impact on patient survival, demonstrating a need for understanding the complexities of the tumor-bone environment. Many factors contribute to creating a favorable microenvironment for prostate tumors in bone, including cell signaling proteins produced by osteoid cells. Specifically, there has been extensive evidence from both past and recent studies that emphasize the importance of chemokine signaling in promoting PCa progression in the bone environment. Chemokine-focused strategies present promising therapeutic options for treating bone metastasis. These signaling pathways are complex, with many being produced by (and exerting effects on) a plethora of different cell types, including stromal and tumor cells of the prostate tumor-bone microenvironment. \u200bThis review highlights an underappreciated molecular family that should be interrogated for treatment of bone metastatic prostate cancer (BM-PCa).",
                "disciplines": [
                    "3202",
                    "3211"
                ]
            }
        }
    },
    "13285834": {
        "title": "CONTROL  COllaborative human-auTonomy inteRaction for airpOrt digitaLization",
        "abstract": "Purpose and goal: \nThe project aims to investigate the research question how to integrate human-computer interaction and perceptual aspects in the design of comand and control interfaces for autonomous systems of systems in future airports. \n \nExpected results and effects: \nThe project intends to strengthen the industry\u00b4s ability to develop and implement autonomous systems and digital tools, promote the development of resource-efficient transport solutions and strengthen competitiveness and national and international growth. \n \nApproach and implementation: \nThe project focuses on an experimental platform for systems of systems, including validation of the environment and development and testing of concept.",
        "disciplines": [
            "4608"
        ],
        "publications": {
            "10.1109/vtc2023-fall60731.2023.10333522": {
                "title": "Real-time Live-Video Streaming in Delay-Critical Application: Remote-Controlled Moving Platform",
                "abstract": "Recent advancement in multimedia and communication network technology have made interactive multimedia and tele-operation applications possible. Teledriving, teleoperation, and video-based remote-controlling require real-time live-video streaming and are delay critical in principle. Supporting such applications over wireless networks for mobile users can pose fundamental challenges in maintaining video quality and service latency requirements. This paper investigates the factors affecting the end-to-end delay in a video-based, remotely controlled moving platform application. It involves the real-time acquisition of environmental information (visually) and the delay-sensitive video streaming to remote operators over wireless networks. This paper presents an innovative experimental testbed developed using a remote-controlled toy truck, off-the-shelf cameras, and wireless fidelity (Wi-Fi) network. It achieves ultra-low end-to-end latency and helped us in performing the delay, network, and video quality evaluations. Extending the experimental study, we also propose a real-time live-media streaming control (RTSC) algorithm that maximizes the video quality by selecting the best streaming (network, video, and camera) configuration while meeting the delay and network availability constraints. RTSC improves the live-streaming video quality by about 33% while meeting the ultra-low latency (< 200 milliseconds) requirement under constrained network availability conditions.",
                "disciplines": [
                    "4006",
                    "4008",
                    "4603"
                ]
            }
        }
    },
    "13242554": {
        "title": "Non-coding flavivirus RNA as key target to engineer live-attenuated vaccines that are \u2018safe-by-design\u2019",
        "abstract": "Vaccines are essential to control infectious diseases in humans. An efficient, safe and cheap vaccine type is the live-attenuated vaccine. A live-attenuated vaccine consists of a viable, harmless version of the virus. A group of viruses for which vaccines are required are the flaviviruses. These viruses pose a threat to public health because they are spreading around the world and causing disease. In this project we will therefore generate live-attenuated vaccines for West Nile virus and Tick-borne encephalitis virus. This will be done by eliminating production of a small RNA molecule that is essential for the virus to cause disease.",
        "disciplines": [
            "3207"
        ],
        "publications": {
            "10.1128/jvi.00100-23": {
                "title": "Subgenomic flavivirus RNA as key target for live-attenuated vaccine development.",
                "abstract": "Live-attenuated flavivirus vaccines confer long-term protection against disease, but the design of attenuated flaviviruses does not follow a general approach. The non-coding, subgenomic flavivirus RNA (sfRNA) is produced by all flaviviruses and is an essential factor in viral pathogenesis and transmission. We argue that modulating sfRNA expression is a promising, universal strategy to finetune flavivirus attenuation for developing effective flavivirus vaccines of the future.",
                "disciplines": [
                    "3204"
                ]
            }
        }
    },
    "13826224": {
        "title": "Creation of high-performance thermoelectric materials by Bloch orbital engineering and high entropy",
        "abstract": "In anticipation of application to thermoelectric power generation devices for medium- and low-temperature waste heat recovery, orbit analysis using first-principles calculations was conducted for thermoelectric material candidate materials that are inexpensive, have high thermal and chemical stability, and have excellent mechanical properties. We will create novel thermoelectric materials that have both a huge electrical output factor and low thermal conductivity by using Bloch orbital engineering to dramatically change the band structure based on this theory, and by making the composition more entropic.",
        "disciplines": [
            "3403"
        ],
        "publications": {
            "10.1021/acs.jpcc.3c05477": {
                "title": "Three-Center Bonds in an Al\u2013Pd\u2013Co Quasicrystalline Approximant: Wannier Function-Based Chemical Bonding Analysis",
                "abstract": "The relationship between the valence electronic state and crystal structure of aluminum\u2013transition-metal quasicrystals and their approximants remains to be elucidated. The origin of the semiconducting band structure on the Katz\u2013Gratias\u2013Boudard-type 1/1 approximants has yet to be clarified. We calculated the electronic structure of an Al\u2013Pd\u2013Co 1/1 quasicrystalline approximant (Al92Pd8Co28 per unit cell) using density functional theory and analyzed the approximant\u2019s valence orbital character by constructing maximally localized Wannier functions. Among the 304 Wannier functions constructed from the valence bands, 288 were localized around transition metal atoms and 12 were localized between two Co atoms. The other four functions were localized around the center of three-membered rings of Co atoms, which indicates the presence of three-center bonds in this approximant. This situation is an exception to the Yannello\u2013Fredrickson and Kitahara\u2019s electron rules, which explain the valence electronic states of aluminum\u2013transition metal approximants and their related intermetallic compound semiconductors considering only two-center bonds. In this study, these rules are expanded to consider three-center bonds, making it possible to explain the semiconducting origin. This work indicates that the electron rule considering three-center bonds can be applied to quasicrystals and other approximants that have triangle networks.",
                "disciplines": [
                    "3402",
                    "3407"
                ]
            },
            "10.1021/acsaem.3c01370": {
                "title": "Effect of Off-Stoichiometry and Point Defects on Thermoelectric Properties of a W\u2011Substituted Fe2VAl Heusler Compound",
                "abstract": "Fe2VAl-based Heusler thermoelectric materials are attractive for power supplies used in practical applications to drive Internet of things (IoT) devices using low-temperature waste heat at temperatures of less than 500 K. In this paper, we present a simple method to introduce point defects and disorder at Fe/V sites via W substitution to enhance the thermoelectric performance of Fe2\u2013x W x VAl (x = 0, 0.05, 0.1, and 0.15) samples. We obtained a relatively high dimensionless figure of merit zT of 0.28 at 423 K for the samples with x = 0.05 and 0.1. Although both samples had the same maximum zT value, the sample with x = 0.05 showed a power factor of 4.7 mW m\u20131 K\u20132 at 423 K, which was higher than that (3.7 mW m\u20131 K\u20132 at 423 K) of the sample with x = 0.1. In addition, the thermal conductivity of 7.1 W m\u20131 K\u20131 at 423 K of the sample with x = 0.05 was higher than that (5.7 W m\u20131 K\u20131 at 423 K) of the sample with x = 0.1. We confirmed that the synthesized sample with x = 0.05 showed excellent thermal durability that allowed it to maintain almost constant electrical resistivity and Seebeck coefficient for 10,000 min; this was confirmed by exposure tests performed at 423 and 573 K. The current simple fabrication process, which uses a combination of melting and sintering methods, will be attractive for mass production of the W-substituted Fe2VAl-based Heusler compound with the relatively high zT of 0.28.",
                "disciplines": [
                    "3402"
                ]
            }
        }
    },
    "12964479": {
        "title": "Stereopsis and Suppression in Strabismus and Amblyopia",
        "abstract": "Abstract Amblyopia (\u2018lazy eye\u2019) is a neuro-development disorder of the visual cortex that occurs early in life and affects about 3% of the population worldwide. Amblyopia is associated with reduced visual acuity and contrast sensitivity in the non-dominant eye. In addition, the majority of individuals with amblyopia do not have measurable stereopsis or the ability to perceive depth from binocular information, which negatively impacts many tasks of daily life including eye-hand coordination and navigation. While studies have shown that about 25% of the amblyopic population does have residual stereopsis, the retinal locus that mediates this function is unknown. This proposal tests the hypothesis that when stereopsis is present in amblyopia, it is the periphery and not the central visual field that mediates depth perception. The first aim uses a novel procedure to map stereopsis in both central and peripheral locations to determine whether residual stereopsis is in fact mediated by the periphery. Our pilot data suggest that it is the periphery that mediates stereopsis in amblyopia. We will also determine whether this peripheral stereopsis accounts for fusional vergence, the movement of the two eyes to fuse monocular images to form a binocular percept. The second aim examines the relation between residual stereopsis and the documented suppression of the non-dominant eye under conditions of binocular viewing. We will measure the suppression zone for each individual and relate it to the zone of stereo-deficiency measured for that same individual. This within-participant comparison is essential to understanding the relation between suppression and stereo-deficiency in this special group of amblyopic individuals who have residual stereopsis. This group comprises about 50% of those with anisometropia (unequal refractive error), and about 10-40% of those with strabismus (eye deviation). This study will characterize each observer\u2019s capacity for stereopsis across the visual field including the periphery, which has been ignored previously. The third aim will use electroencephalography (EEG) combined with a procedure to localize cortical source that produces the signals to understand the neural basis of suppression in individuals with and without stereopsis, and how well the non-dominant eye signal is represented on its own, and in the presence of a stimulus in the other eye, as well as how the two eyes\u2019 signals are combined at different levels of the cortical hierarchy. If the peripheral visual field has a significant contribution to stereopsis in amblyopia, our study will establish the importance of clinically evaluating the potential for stereopsis in the periphery and for training peripheral locations to improve stereopsis.",
        "disciplines": [
            "3212",
            "4201"
        ],
        "publications": {
            "10.3389/fnins.2023.1217993": {
                "title": "The utility of peripheral stereopsis",
                "abstract": "This perspective article makes the case for evaluating and training peripheral stereopsis, particularly when the central visual field is compromised in one or both eyes. Examples of clinical conditions that preferentially affect the central visual field include macular degeneration, which affects the central macular region in one or both eyes, and amblyopia where the central field is often affected in one eye, but the peripheral field is largely intact. While binocular acuity may be preserved when the monocular central field of one eye is affected, fine stereopsis is compromised because it requires intact vision in corresponding locations in the two eyes. Even in these clinical conditions, recent studies that map stereoacuity at locations across the visual field demonstrate that the periphery supports coarse stereopsis, and that training efforts to use residual stereopsis may have greater benefit if they take this finding into account.",
                "disciplines": [
                    "3212"
                ]
            },
            "10.1016/j.visres.2023.108296": {
                "title": "Eye movements in visual impairment",
                "abstract": "This Special Issue describes the impact of visual impairment on visuomotor function. It includes contributions that examine gaze control in conditions associated with abnormal visual development such as amblyopia, dyslexia and neurofibromatosis as well as disorders associated with field loss later in life, such as macular degeneration and stroke. Specifically, the papers address both gaze holding (fixation), and gaze-following behavior (single saccades, sequences of saccades and smooth-pursuit) that characterize active vision in daily life and evaluate the influence of both pathological and simulated field loss. Several papers address the challenges to reading and visual search; describing how the patterns of eye movements in these real-world tasks adapt to visual impairment and highlighting how they could serve as diagnostic markers of visuomotor function.",
                "disciplines": [
                    "3212"
                ]
            }
        }
    },
    "13285469": {
        "title": "ENding HIV transmission to infants by Generating Evidence to optimize care for pregnant and postpartum Adolescent Girls and young women with HIV in Tanzania (ENGAGE)",
        "abstract": "In sub-Saharan Africa, adolescent girls and young women (AGYW) aged 15-24 years are more likely than older women to acquire HIV, and once pregnant, to transmit HIV to their infants and drop out of care. This highlights an urgent need to revisit the current one-size-fits-all model of prevention of mother-to-child transmission (PMTCT) programs.\u00a0The purpose of this project is to optimize PMTCT care for AGYWs, and later their infants, in Tanzania \u2013 a setting where HIV remains endemic. To do so, we will use data from a large registry-based cohort (N\u224813,800 with\u00a022% 15-24 years) to\u00a0investigate PMTCT service uptake, retention and health outcomes for AGYWs, as well as subsequent pregnancies and contraceptive use (study 1). We will combine this with a nested prospective cohort to identify social-structural predictors of these outcomes (study 2). We will utilize findings to develop (together with young women, health providers and managers) and prototype a package of micro-interventions that can be implemented in routine care to optimize PMTCT services for AGYWs. Using a cluster-randomized design, we will pilot-test the intervention package for feasibility and preliminary effect, as well as cost-effectiveness.\u00a0\u00a0This five-year project is highly feasible considering the multidisciplinary team with skills and experience in both implementation and experimental research, and will contribute much-needed evidence to advance PMTCT care for AGYWs in line with their unique needs.",
        "disciplines": [
            "3213",
            "4206"
        ],
        "publications": {
            "10.1016/j.jad.2023.07.014": {
                "title": "Longitudinal trajectories of sickness absence among young adults with a history of depression and anxiety symptoms in Sweden",
                "abstract": "BACKGROUND: Depression and anxiety are associated with increased risk of sickness absence (SA), yet the developmental patterns of SA remain unclear. We aimed to identify trajectories of SA in young adults with depression and/or anxiety, accounting for sociodemographic and occupational factors.\nMETHODS: Longitudinal study of 1445 twin individuals with elevated depressive/anxiety symptoms in late adolescence or young adulthood (age range: 19-30), assessed in Swedish surveys completed in 2005. Through linkage to nationwide registries, individuals were prospectively followed from 2006 to 2018. The outcome included consecutive annual days of SA, which were analyzed using group-based trajectory modeling. Multinomial logistic regression estimating odds ratios (OR) with 95\u00a0% confidence intervals (CI) was used to examine associations of age, sex, and educational level with the resulting SA trajectories.\nRESULTS: Four distinct SA trajectories were identified in the total sample: 'high-increasing' (6\u00a0%), 'low-increasing' (12\u00a0%), 'high-decreasing' (13\u00a0%), and 'low-constant' (69\u00a0%). Increasing age was associated with higher odds of belonging to the low-increasing trajectory (OR\u00a0=\u00a01.07, 95 % CI\u00a0=\u00a01.02-1.12). Women had higher odds of belonging to the low-increasing trajectory (OR\u00a0=\u00a01.67, 95 % CI\u00a0=\u00a01.10-2.53), compared with men. Higher education was associated with lower odds of belonging to high-increasing (OR\u00a0=\u00a00.34, 95 % CI\u00a0=\u00a00.22-0.54) and high-decreasing (OR\u00a0=\u00a00.59, 95 % CI\u00a0=\u00a00.43-0.81) trajectories, compared with lower education. Few differences were observed in analyses stratified by occupational sector.\nLIMITATIONS: Information on potential confounders (e.g., psychiatric comorbidity, work-environment factors) was not available.\nCONCLUSIONS: Among young adults with prior depression/anxiety, close to every fifth showed rising SA trajectories over time. This calls for targeted strategies to improve public mental health already at young ages.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1001/jamanetworkopen.2023.17905": {
                "title": "Associations of Internalizing and Externalizing Problems in Childhood and Adolescence With Adult Labor Market Marginalization",
                "abstract": "Importance: Mental health problems in early life are associated with labor market marginalization, especially in youths with persistent internalizing and externalizing problems. However, previous research has not adjusted for familial (genetic and shared environmental) factors.\nObjective: To examine associations of early-life internalizing and externalizing problems with adulthood unemployment and work disability, adjusting for familial factors.\nDesign, Setting, and Participants: This population-based prospective cohort study included Swedish twins who were born in 1985-1986 and surveyed at 4 consecutive waves across childhood and adolescence until 2005. Through linkage to nationwide registries, participants were followed up from 2006 to 2018. Data analyses were conducted between September 2022 and April 2023.\nExposures: Internalizing and externalizing problems, assessed with the Child Behavior Checklist. Participants were differentiated regarding duration of internalizing and externalizing problems (persistent, episodic, and noncases).\nMain Outcomes and Measures: Unemployment (180 days or more of being unemployed) and work disability (60 days or more of being sickness absent or disability pensioned) during follow-up. Cox proportional hazards regression models were calculated to obtain cause-specific hazard ratios (HRs) with 95% CIs in the whole cohort and exposure-discordant twin pairs.\nResults: Of 2845 participants, 1464 (51.5%) were female. Incident unemployment was experienced by 944 (33.2%) and incident work disability by 522 (18.3%) participants. Compared with noncases, persistent internalizing problems were associated with unemployment (HR, 1.56; 95% CI, 1.27-1.92) and work disability (HR, 2.32; 95% CI, 1.80-2.99). Similarly, compared with noncases, persistent externalizing problems were associated with unemployment (HR, 1.87; 95% CI, 1.55-2.26) and work disability (HR, 2.38; 95% CI, 1.87-3.03). Persistent cases had overall higher risks of adverse outcomes than episodic cases. After adjustment for familial factors, associations with unemployment were no longer statistically significant, whereas associations with work disability remained or were only slightly reduced.\nConclusions and Relevance: In this cohort study of young Swedish twins, familial factors explained the associations between early-life persistent internalizing and externalizing problems and unemployment; such factors were comparatively less important for the association with work disability. This suggests nonshared environmental factors may be important for the risk of future work disability among young individuals with persistent internalizing and externalizing problems.",
                "disciplines": [
                    "4202"
                ]
            }
        }
    },
    "13827012": {
        "title": "Semantic information compensation for color blindness support using deep learning",
        "abstract": "In this research project, we will address the following three issues in order to establish a color vision compensation technology that incorporates deep learning models and AR glasses to compensate for semantic information loss due to color vision impairment. (1) Focusing on users wearing AR Glasses, it links with a server equipped with a deep learning model to provide color vision support information to users. (2) Design two usage modes according to the user's situation and implement the deep learning model required for each. (3) In order to collect color-labeled image datasets required for learning the deep learning model to be implemented, we will develop an automatic collection method using existing deep learning models for object detection.",
        "disciplines": [
            "4611"
        ],
        "publications": {
            "10.1007/s00371-024-03454-8": {
                "title": "Fast image recoloring for red\u2013green anomalous trichromacy with contrast enhancement and naturalness preservation",
                "abstract": "Color vision deficiency (CVD) is an eye disease caused by genetics that reduces the ability to distinguish colors, affecting approximately 200 million people worldwide. In response, image recoloring approaches have been proposed in existing studies for CVD compensation, and a state-of-the-art recoloring algorithm has even been adapted to offer personalized CVD compensation; however, it is built on a color space that is lacking perceptual uniformity, and its low computation efficiency hinders its usage in daily life by individuals with CVD. In this paper, we propose a fast and personalized degree-adaptive image-recoloring algorithm for CVD compensation that considers naturalness preservation and contrast enhancement. Moreover, we transferred the simulated color gamut of the varying degrees of CVD in RGB color space to CIE L*a*b* color space, which offers perceptual uniformity. To verify the effectiveness of our method, we conducted quantitative and subject evaluation experiments, demonstrating that our method achieved the best scores for contrast enhancement and naturalness preservation.",
                "disciplines": [
                    "4603"
                ]
            },
            "10.1109/smc53992.2023.10394105": {
                "title": "Metamorphopsia Insepction System Based on Relevance Feedback",
                "abstract": "People with metamorphopsia suffer from perceiving things in a distorted way. Various methods for examining metamorphopsia have been suggested in the current literature, with the most advanced techniques demonstrating the ability to yield quantitative measurements. However, these cutting-edge methods necessitate extended examination durations and impose challenging manipulations on patients. In this study, our objective is to enhance the time efficiency of the inspection process and alleviate the burden placed on the user. We propose a novel user-friendly quantitative inspection system which utilizes interactive reinforcement learning. Instead of having users directly operate the system, we ask them to evaluate the stimuli generated by the system. Based on their evaluations, the system gradually refines the deformation map representing the distortion perceived by the user. The reinforcement learning scheme is implemented using relevance feedback approach based on optimum-path forest classifier. To evaluate the effectiveness of the proposed system, subjective evaluation experiments involving simulated and real metamorphopsia participants were conducted in this study. The experimental findings reveal that, when compared to the state-of-the-art method, our proposed system yields comparable inspection out-comes while significantly reducing both the inspection duration and the mental workload.",
                "disciplines": [
                    "4608"
                ]
            },
            "10.1007/s00521-023-09367-2": {
                "title": "Image recoloring for color vision deficiency compensation using Swin transformer",
                "abstract": "People with color vision deficiency (CVD) have difficulty in distinguishing differences between colors. To compensate for the loss of color contrast experienced by CVD individuals, a lot of image recoloring approaches have been proposed. However, the state-of-the-art methods suffer from the failures of simultaneously enhancing color contrast and preserving naturalness of colors [without reducing the Quality of Vision (QOV)], high computational cost, etc. In this paper, we propose an image recoloring method using deep neural network, whose loss function takes into consideration the naturalness and contrast, and the network is trained in an unsupervised manner. Moreover, Swin transformer layer, which has long-range dependency mechanism, is adopted in the proposed method. At the same time, a dataset, which contains confusing color pairs to CVD individuals, is newly collected in this study. To evaluate the performance of the proposed method, quantitative and subjective experiments have been conducted. The experimental results showed that the proposed method is competitive to the state-of-the-art methods in contrast enhancement and naturalness preservation and has a real-time advantage. The code and model will be made available at https://github.com/Ligeng-c/CVD_swin.",
                "disciplines": [
                    "4603"
                ]
            },
            "10.1145/3582700.3582707": {
                "title": "CC-Glasses: Color Communication Support for People with Color Vision Deficiency Using Augmented Reality and Deep Learning",
                "abstract": "People who suffer from color vision deficiency (CVD) can face difficulties when communicating with others by failing to identify target objects referred by their color names. While most existing studies on CVD compensation have focused on the issue of color contrast loss. Although there are approaches can provide clues of color name to users, these techniques either require training, or cannot protect users\u2019 privacy, i.e., the fact of having CVD. In this paper, based on augmented reality (AR) and deep learning technologies, we propose a novel system to provide supporting information to users affected by CVD for color communication assistance. The state-of-the-art deep neural network (DNN) model for referring segmentation (RS) is adopted to generate supporting information, and AR glasses are utilized for information presentation. To improve the performance of the proposed system further, a new dataset is constructed based on a novel concept called Color\u2013Object Noun Pair. The results of evaluation experiments show that the new dataset can enhance the performance of the adopted DNN model, and the proposed system can help users affected by CVD successfully identify target objects by their color names.",
                "disciplines": [
                    "4608"
                ]
            }
        }
    },
    "13037237": {
        "title": "Reward responsivity and depression in autism spectrum disorder: A multimethod approach",
        "abstract": "PROJECT SUMMARY Adolescents with Autism Spectrum Disorder experience depression at rates nearly twice that of their neurotypical peers (20% vs. 11%). Untreated depression is associated with adverse short (e.g., school refusal) and long-term outcomes (e.g., poor physical health, lower employment) that impair quality of life. Adolescents with autism also face a 10x increase in the risk for premature death by suicide than their neurotypical peers. Risk factors to depression in autism are not well understood and measurement efforts may be complicated by social communication difficulties (i.e., autism symptomatology) that complicate adolescents\u2019 efforts to identify and explain emotional experiences to providers and family members. Therefore, more objective measures (e.g., electroencephalogram [EEG], specifically event-related potentials [ERPs]) may provide a better understanding of risk factors to depression in adolescents with autism. Altered reward responsivity (Research Domain Criteria [RDoC] Positive Valence) and disrupted social processes (RDoC Affiliation and Attachment) are key risk factors to depression for neurotypical adolescents, but have not been investigated in autism. Clinical and neural measures of social and nonsocial reward responsivity and associations with depression symptoms have not been examined in autism, which may provide meaningful information about developmental trajectories. Consistent with the NIMH Strategic Plan, Strategic Goal 2, \u201cto identify and understand risk factors, biomarkers and behavioral indicators of mental illness,\u201d this K23 application aims to examine clinical and neural markers of social and nonsocial reward responsivity and associations with depression symptoms in adolescents with autism, including longitudinal investigations. Under the mentorship of a diverse team of experts in autism, depression, reward responsivity, psychophysiological methods, and longitudinal and statistical methodologies, this proposal will examine the predictive influences of these RDoC constructs to depression in adolescents 14-17 years old with autism. Adolescence is a key developmental period for early detection and intervention as it is characterized by spikes in depression prevalence and an increasing importance of peer relationships. Specifically, this proposal will use EEG/ERP techniques and clinician-rated interviews to measure social and nonsocial reward responsivity in adolescents with autism and test relationships with depression symptoms. Adolescents will be assessed one year later to investigate how clinical and neural measures predict depression symptoms over time, which will inform the developmental course of these RDoC constructs in this vulnerable population. The applicant\u2019s long- term goal is to understand the neurobiological and behavioral development of reward responsivity in autism and associations with depression from adolescence to adulthood so as to inform screening methods and intervention development. Mentored training will allow the applicant to gain expertise in multimethod measures (e.g., ERP methodologies, clinician-rated interviews) and longitudinal design and analysis, with an emphasis on assessing mechanisms associated with the onset, maintenance, and treatment of depression in autism.",
        "disciplines": [
            "5202"
        ],
        "publications": {
            "10.1007/s10803-024-06302-9": {
                "title": "A Pilot Randomized Controlled Trial of Motivation-Based Social Skills Group Treatment with Parent Training",
                "abstract": "Despite the popularity of social skills groups, there remains a need for empirical investigation of treatment effects, especially when targeting pivotal aspects of social functioning such as initiations to peers. The goal of the present study was to conduct a randomized controlled trial of a 12-week social intervention (SUCCESS), which combined an inclusive social group with a parent education program. Twenty-five 4- to 6-year-olds with Autism Spectrum Disorder (ASD) were randomized to SUCCESS (N\u2009=\u200911) or to treatment as usual (N\u2009=\u200914). Combining a peer group model with a parent training program, the SUCCESS intervention used naturalistic behavioral techniques (e.g., environmental arrangement, natural reinforcement) to increase social initiations to peers. After 12 weeks, children participating in the SUCCESS program made more frequent initiations to peers than children in the treatment-as-usual group, including more prompted and unprompted initiations to request. Additional gains in clinician-rated social functioning were observed in children randomized to SUCCESS, while differential treatment effects were not detected in parent-rated measures. However, lower baseline social motivation was associated with greater parent-reported initiation improvement. This study provides preliminary support for the efficacy of a naturalistic, behavioral social skills intervention to improve peer initiations for children with ASD. The findings suggest that using a motivation-based social skills group was effective in increasing both prompted and spontaneous initiations to peers, and highlights the need for further research into the role of baseline social motivation in predicting social skills treatment response.",
                "disciplines": []
            },
            "10.1016/j.psychres.2024.115838": {
                "title": "Sexual and gender minority stress and clinical symptom severity in psychiatrically hospitalized adolescents",
                "abstract": "This study examined the role of lifetime and past 30-day experiences of sexual and gender minority (SGM) stress on clinical symptom severity in 286 psychiatrically hospitalized adolescents. Participants completed measures of clinical symptoms, and SGM adolescents (n = 176, 61.5 %) reported on minority stress experiences across three domains (i.e., negative expectancies, internalized homonegativity, homonegative climate). SGM adolescents reported greater clinical symptom severity than non-SGM adolescents. Most SGM adolescents (77.3%) reported lifetime minority stress exposure, endorsing an average of 3.3 stressors (SD = 2.9). Among those endorsing lifetime minority stress history, 76.1% reported past 30-day minority stress exposure. Lifetime and recent minority stress exposure were positively associated with clinical symptom severity. Findings support the importance of assessing SGM identities and minority stress experiences in psychiatric settings and supporting youth in coping with these experiences.",
                "disciplines": [
                    "5203"
                ]
            },
            "10.1016/j.rasd.2024.102339": {
                "title": "Autistic traits in adolescents in psychiatric inpatient care: Clinical and demographic characteristics and correlates",
                "abstract": "Background: Rates of psychiatric hospitalization among adolescents in the United States are rising, with many adolescents presenting to these settings with diverse clinical presentations, including autistic traits. To our knowledge, there has been little research identifying clinical characteristics of adolescents with autistic traits admitted to psychiatric inpatient units, which may be leveraged to improve assessment and treatment practices.\nMethod: In the current study, we examined clinical and demographic characteristics of 195 adolescents admitted to an adolescent psychiatric inpatient unit. Specifically, we investigated the prevalence of adolescents endorsing elevated autistic traits and tested associations between autistic traits, psychiatric symptoms (anxiety, depression, suicidal thoughts), and key demographic variables (age, sex, gender, sexual orientation).\nResults: Results show that over half of the adolescents admitted to the psychiatric inpatient unit reported elevated autistic traits on a short screening questionnaire. Higher autistic traits were significantly associated with more severe depressive symptoms, though to a small degree. Autistic traits were not associated with anxiety symptoms, suicidal thoughts, nor social disconnectedness, and did not differ by sex, gender identity, nor sexual orientation.\nConclusions: Findings highlight the challenge of diagnostic overshadowing among adolescents in crisis and the need for more rigorous measures designed for an inpatient setting to improve risk stratification, clinical assessments, intervention approaches, and discharge planning.",
                "disciplines": [
                    "5203",
                    "5201"
                ]
            },
            "10.1177/13623613231213543": {
                "title": "Community-guided, autism-adapted group cognitive behavioral therapy for depression in autistic youth (CBT-DAY): Preliminary feasibility, acceptability, and efficacy.",
                "abstract": "LAY ABSTRACT: Depression in youth is a significant public health problem worldwide, particularly for autistic youth who are over twice as likely to experience depression than their non-autistic peers. Although pathways to depression are complex, emotional reactivity and negative self-esteem are two risk factors for depression in autistic and non-autistic youth. Although autistic youth are more likely to experience depression than their non-autistic peers, psychotherapy options for autistic youth are very limited; community guidance in the development and testing of psychotherapy programs is a promising approach in autism. Therefore, in this study, we designed an autism-adapted CBT-DAY, in collaboration with autistic community members. Specifically, CBT-DAY combined neurodiversity-affirming and cognitive behavioral approaches to target emotional reactivity and self-esteem in youth to improve depressive symptom severity in a group setting across 12\u2009weeks. We examined the preliminary feasibility, acceptability, and efficacy of CBT-DAY in a pilot non-randomized trial. In addition, we implemented a rigorous protocol for assessing, monitoring, and addressing potential harms in this intervention. Results from 24 autistic youth (11-17\u2009years old) suggest that CBT-DAY may be feasible to use in an outpatient clinical setting and generally acceptable to youth and their caregivers. Participation in CBT-DAY may be associated with significant improvements in youth emotional reactivity and self-esteem, as well as depressive symptom severity per self-report only. Exploratory analyses showed that participation in CBT-DAY may also be associated with significant improvements in internalizing symptoms. Findings demonstrate the potential promise of neurodiversity-affirming and cognitive behavioral approaches to treating depressive symptoms in some autistic youth.",
                "disciplines": [
                    "5203"
                ]
            },
            "10.1007/s10803-023-06039-x": {
                "title": "Behavioral and Social Activation in Autism and Associations with Youth Depressive Symptoms from Youth and Caregiver Perspectives",
                "abstract": "Autistic youth are more likely to experience depression than their non-autistic peers, yet research on risk and protective factors to depression in this population is limited. Behavioral activation (i.e., prioritizing and engaging in meaningful activities), including social activities, is an important mechanism in the pathway to depression in non-autistic youth that is understudied in autism. Ratings of youth depressive symptoms and behavioral and social activation at one timepoint from 100 autistic youth without intellectual disability and 100 of their caregivers were analyzed. The study aims were to examine caregiver and youth ratings of youth internalizing symptoms and behavioral and social activation, inter-rater reliability on study variables, and associations between depressive symptoms and behavioral and social activation in autistic youth by rater. Results revealed significant differences in youth and caregiver ratings on all variables and inter-rater reliability ranged from poor to moderate. Across both raters, more severe anxiety symptoms and lower behavioral activation were associated with more severe depressive symptoms; social activation, specifically the number of friends youth have, was significant in caregiver ratings only. Findings can be leveraged to enhance risk stratification and intervention efforts for autistic youth experiencing depression.",
                "disciplines": []
            }
        }
    },
    "13665532": {
        "title": "Functional characterization of SvUGTs potentially involved in tricine glycosylation in Setaria viridis",
        "abstract": "Lignin is an aromatic polymer abundantly present in the secondary cell wall of plants. Consequently, it constitutes a significant part of the plant biomass. Due to its recalcitrant nature, lignin is considered an obstacle to the extraction of fermentable sugars for the production of derived compounds, which are increasingly considered as sustainable and renewable alternatives to fossil fuels. Recently, the flavone tricine was identified as an authentic lignin monomer present primarily in grasses, where it acts as an initial polymerization site. Thus, tricine can be an important target for plant bioengineering aiming at more efficient delignification. Previously, we observed that leaves and stems of the C4 model grass Setaria viridis accumulate tricine in their lignins in a very contrasting way, despite expressing their biosynthetic genes in a similar way. Given the role of UDP-glycosyltransferases (UGTs) in phenylpropanoid storage, we hypothesize that these proteins possibly play important roles in regulating the incorporation of tricine into the lignin polymer. This project aims to identify and characterize SvUGTs involved in tricine glycosylation in Setaria viridis, a C4 model grass used in bioengineering studies, and to investigate their roles in controlling tricine incorporation into lignin polymers. Initially, a genome-wide characterization of the SvUGT family will be performed. Then, genes from the UGT706 and 707 subfamilies, which were previously implicated in the glycosylation of flavones and flavonols, preferentially expressed in stems, will be expressed in Escherichia coli, and the recombinant proteins will be characterized for their ability to glycosylate tricine in vitro. The gene with the best kinetic parameters will be overexpressed to evaluate its functions in planta. The resulting transgenic lines will be characterized for biomass parameters, cell wall deposition, incorporation of tricine into lignin and alterations in the phenolic profile. Finally, the effect of overexpression on plant biomass recalcitrance will be evaluated using saccharification assays. This work will provide not only unprecedented insights into tricine metabolism and its regulation, but also potential targets for future bioengineering strategies.",
        "disciplines": [
            "3108"
        ],
        "publications": {
            "10.1016/j.jplph.2023.154138": {
                "title": "Pour some sugar on me: The diverse functions of phenylpropanoid glycosylation",
                "abstract": "The phenylpropanoid metabolism is the source of a vast array of specialized metabolites that play diverse functions in plant growth and development and contribute to all aspects of plant interactions with their surrounding environment. These compounds protect plants from damaging ultraviolet radiation and reactive oxygen species, provide mechanical support for the plants to stand upright, and mediate plant-plant and plant-microorganism communications. The enormous metabolic diversity of phenylpropanoids is further expanded by chemical modifications known as \"decorative reactions\", including hydroxylation, methylation, glycosylation, and acylation. Among these modifications, glycosylation is the major driving force of phenylpropanoid structural diversification, also contributing to the expansion of their properties. Phenylpropanoid glycosylation is catalyzed by regioselective uridine diphosphate (UDP)-dependent glycosyltransferases (UGTs), whereas glycosyl hydrolases known as \u03b2-glucosidases are the major players in deglycosylation. In this article, we review how the glycosylation process affects key physicochemical properties of phenylpropanoids, such as molecular stability and solubility, as well as metabolite compartmentalization/storage and biological activity/toxicity. We also summarize the recent knowledge on the functional implications of glycosylation of different classes of phenylpropanoid compounds. A balance of glycosylation/deglycosylation might represent an essential molecular mechanism to regulate phenylpropanoid homeostasis, allowing plants to dynamically respond to diverse environmental signals.",
                "disciplines": [
                    "3108"
                ]
            }
        }
    },
    "13037338": {
        "title": "Neutrophil hyperexocytosis and hypochlorous acid exposure in early cystic fibrosis lung disease",
        "abstract": "PROJECT SUMMARY / ABSTRACT Current standard of care for cystic fibrosis (CF) does not include drugs unequivocally effective at curbing airway inflammation, in contrast to crucial gains made in correcting defects in the CF transmembrane conductance regulator (CFTR) via highly effective modulator therapy (HEMT) and an array of antimicrobial drugs. Effectively treating exuberant neutrophil-dominated inflammation in CF, particularly in the earliest stages of the disease, is a critical goal because doing so would increase patient lifespan and health span. This project is designed to test the hypothesis that neutrophil hyperexocytosis, which occurs in CF from a very young age, is a critical event that releases active myeloperoxidase (MPO) from neutrophil granules and enables the generation of extracellular hypochlorous acid (HOCl), a strong and promiscuous oxidant that can damage cells. We further hypothesize that the released MPO becomes associated with extracellular vesicles (EVs), providing MPO with sustained metabolism to fuel its HOCl-generating activity and conferring resistance to inhibitors. Ultimately, we hypothesize that increased airway HOCl injures airway epithelial cells (AECs) and promotes maladaptive cellular responses that contribute to bronchiectasis. Research from our group has shown that MPO is active in CF airways from the earliest stages of disease and is associated with initial manifestations of bronchiectasis. Furthermore, we have identified molecular products of HOCl exposure, such as methionine sulfoxide, that can be monitored by LC-MS across a broad range of biological specimens, including basic and translational models and clinical samples. Using state-of-the-art LC-MS, rigorous cell-, protein-, and EV- detection methods, highly translational models of neutrophils and EVs, and clinical sample validation, this project sets out a series of parallel experiments designed to identify the sequence of events leading from neutrophil transmigration into CF airways, to active MPO release and extracellular HOCl generation, to CF AEC injury and maladaptation to the potent oxidative insult. These experiments are enumerated in the following Specific Aims: (1) Determine the impact of hyperexocytosis on extracellular HOCl and innate defense; (2) Determine mechanisms of granule-releasing, immunomodulatory, and metabolically active (GRIM) neutrophil EV-based HOCl production; and (3) Determine mechanisms of CF airway epithelial cytotoxicity mediated by MPO and HOCl. Furthermore, these experiments account for potential impacts of novel HEMT therapy elexacaftor-tezacaftor-ivacaftor (ETI) in inflammatory pathways by comparing CF sputum samples with HEMT to the same samples from donors not receiving ETI. The ultimate goal of the proposed studies is to generate knowledge informing clinical and drug development research and forestall CF lung disease progression at the earliest stages and before end organ damage. Furthermore, owing to the prevalence of GRIM neutrophils in a number of lung diseases beyond CF, information pertinent to other lung diseases including neutrophil inflammation will also be gained by the completion of this project.",
        "disciplines": [
            "3101"
        ],
        "publications": {
            "10.1016/j.freeradbiomed.2024.04.217": {
                "title": "The therapeutic potential of thiocyanate and hypothiocyanous acid against pulmonary infections",
                "abstract": "Hypothiocyanous acid (HOSCN) is an endogenous oxidant produced by peroxidase oxidation of thiocyanate (SCN<sup>-</sup>), an ubiquitous sulfur-containing pseudohalide synthesized from cyanide. HOSCN serves as a potent microbicidal agent against pathogenic bacteria, viruses, and fungi, functioning through thiol-targeting mechanisms, independent of currently approved antimicrobials. Additionally, SCN<sup>-</sup> reacts with hypochlorous acid (HOCl), a highly reactive oxidant produced by myeloperoxidase (MPO) at sites of inflammation, also producing HOSCN. This imparts both antioxidant and antimicrobial potential to SCN<sup>-</sup>. In this review, we discuss roles of HOSCN/SCN<sup>-</sup> in immunity and potential therapeutic implications for combating infections.",
                "disciplines": [
                    "3101"
                ]
            },
            "10.1016/j.freeradbiomed.2023.06.021": {
                "title": "Substrate-dependent metabolomic signatures of myeloperoxidase activity in airway epithelial cells: Implications for early cystic fibrosis lung disease",
                "abstract": "Myeloperoxidase (MPO) is released by neutrophils in inflamed tissues. MPO oxidizes chloride, bromide, and thiocyanate to produce hypochlorous acid (HOCl), hypobromous acid (HOBr), and hypothiocyanous acid (HOSCN), respectively. These oxidants are toxic to pathogens, but may also react with host cells to elicit biological activity and potential toxicity. In cystic fibrosis (CF) and related diseases, increased neutrophil inflammation leads to increased airway MPO and airway epithelial cell (AEC) exposure to its oxidants. In this study, we investigated how equal dose-rate exposures of MPO-derived oxidants differentially impact the metabolome of human AECs (BEAS-2B cells). We utilized enzymatic oxidant production with rate-limiting glucose oxidase (GOX) coupled to MPO, and chloride, bromide (Br<sup>-</sup>), or thiocyanate (SCN<sup>-</sup>) as substrates. AECs exposed to GOX/MPO/SCN<sup>-</sup> (favoring HOSCN) were viable after 24\u00a0h, while exposure to GOX/MPO (favoring HOCl) or GOX/MPO/Br<sup>-</sup> (favoring HOBr) developed cytotoxicity after 6\u00a0h. Cell glutathione and peroxiredoxin-3 oxidation were insufficient to explain these differences. However, untargeted metabolomics revealed GOX/MPO and GOX/MPO/Br<sup>-</sup> diverged significantly from GOX/MPO/SCN<sup>-</sup> for dozens of metabolites. We noted methionine sulfoxide and dehydromethionine were significantly increased in GOX/MPO- or GOX/MPO/Br<sup>-</sup>-treated cells, and analyzed them as potential biomarkers of lung damage in bronchoalveolar lavage fluid from 5-year-olds with CF (n\u00a0=\u00a027). Both metabolites were associated with increasing bronchiectasis, neutrophils, and MPO activity. This suggests MPO production of HOCl and/or HOBr may contribute to inflammatory lung damage in early CF. In summary, our in vitro model enabled unbiased identification of exposure-specific metabolite products which may serve as biomarkers of lung damage in vivo. Continued research with this exposure model may yield additional oxidant-specific biomarkers and reveal explicit mechanisms of oxidant byproduct formation and cellular redox signaling.",
                "disciplines": [
                    "3205",
                    "3101"
                ]
            },
            "10.1093/jncimonographs/lgad014": {
                "title": "The \u2018omics of obesity in B-cell acute lymphoblastic leukemia",
                "abstract": "The obesity pandemic currently affects more than 70 million Americans and more than 650 million individuals worldwide. In addition to increasing susceptibility to pathogenic infections (eg, SARS-CoV-2), obesity promotes the development of many cancer subtypes and increases mortality rates in most cases. We and others have demonstrated that, in the context of B-cell acute lymphoblastic leukemia (B-ALL), adipocytes promote multidrug chemoresistance. Furthermore, others have demonstrated that B-ALL cells exposed to the adipocyte secretome alter their metabolic states to circumvent chemotherapy-mediated cytotoxicity. To better understand how adipocytes impact the function of human B-ALL cells, we used a multi-omic RNA-sequencing (single-cell and bulk transcriptomic) and mass spectroscopy (metabolomic and proteomic) approaches to define adipocyte-induced changes in normal and malignant B cells. These analyses revealed that the adipocyte secretome directly modulates programs in human B-ALL cells associated with metabolism, protection from oxidative stress, increased survival, B-cell development, and drivers of chemoresistance. Single-cell RNA sequencing analysis of mice on low- and high-fat diets revealed that obesity suppresses an immunologically active B-cell subpopulation and that the loss of this transcriptomic signature in patients with B-ALL is associated with poor survival outcomes. Analyses of sera and plasma samples from healthy donors and those with B-ALL revealed that obesity is associated with higher circulating levels of immunoglobulin-associated proteins, which support observations in obese mice of altered immunological homeostasis. In all, our multi-omics approach increases our understanding of pathways that may promote chemoresistance in human B-ALL and highlight a novel B-cell-specific signature in patients associated with survival outcomes.",
                "disciplines": [
                    "3205"
                ]
            },
            "10.1038/s41467-023-37269-3": {
                "title": "Multiplatform analyses reveal distinct drivers of systemic pathogenesis in adult versus pediatric severe acute COVID-19",
                "abstract": "The pathogenesis of multi-organ dysfunction associated with severe acute SARS-CoV-2 infection remains poorly understood. Endothelial damage and microvascular thrombosis have been identified as drivers of COVID-19 severity, yet the mechanisms underlying these processes remain elusive. Here we show alterations in fluid shear stress-responsive pathways in critically ill COVID-19 adults as compared to non-COVID critically ill adults using a multiomics approach. Mechanistic in-vitro studies, using microvasculature-on-chip devices, reveal that plasma from critically ill COVID-19 adults induces fibrinogen-dependent red blood cell aggregation that mechanically damages the microvascular glycocalyx. This mechanism appears unique to COVID-19, as plasma from non-COVID sepsis patients demonstrates greater red blood cell membrane stiffness but induces less significant alterations in overall blood rheology. Multiomics analyses in pediatric patients with acute COVID-19 or the post-infectious multi-inflammatory syndrome in children (MIS-C) demonstrate little overlap in plasma cytokine and metabolite changes compared to adult COVID-19 patients. Instead, pediatric acute COVID-19 and MIS-C patients show alterations strongly associated with cytokine upregulation. These findings link high fibrinogen and red blood cell aggregation with endotheliopathy in adult COVID-19 patients and highlight differences in the key mediators of pathogenesis between adult and pediatric populations.",
                "disciplines": [
                    "3202"
                ]
            }
        }
    },
    "12966861": {
        "title": "A Model for Human Liver Fibrosis",
        "abstract": "Abstract Liver fibrosis is a pathological condition that results from extracellular matrix (ECM) accumulation in response to chronic liver injury and is a major global cause of death in adults (~1M per year) due to inadequate therapeutic options. To address this limitation, we have developed human hepatic organoid models that enable hypothesis- driven, mechanistic evaluation of novel drug candidates for treatment of liver fibrosis. One model is produced by engineering iPSC to express a common causative mutation for Autosomal Recessive Polycystic Kidney Disease (ARPKD). ARPKD organoids develop the key hallmarks of hepatic fibrosis: they accumulate thick collagen fibers; and have a marked increase in collagen-producing myofibroblasts whose transcriptomic profile is like those present in liver tissues obtained from patients with commonly occurring (acquired) forms of liver fibrosis (viral- induced cirrhosis and advanced non-alcoholic steatohepatitis, NASH). We also developed a NASH organoid fibrosis model; along with two live cell imaging methods for monitoring for the appearance of collagen fibers and collagen producing cells. We hypothesize that since the fibrosis that develops in this human, multi-lineage, hepatic organoid resembles that in patients with congenital and acquired forms of liver fibrosis, it can be used to advance liver fibrosis research and to discover and characterize anti-fibrotic therapies. In Aim 1, ARPKD and NASH organoids are used to develop a novel platform for assessing the anti-fibrotic efficacy of 10 agents whose mechanism of action is relevant to liver fibrosis, and to identify drug combinations with increased anti-fibrotic efficacy. Since nine are FDA-approved drugs, but none are currently used to treat liver fibrosis, these studies could have significant translational importance. In Aim 2, these models evaluate the fibrogenic effect of ECM cues using a novel, fully chemically defined, biosynthetic matrix. ECM changes are widely thought to promote fibrotic remodeling. A novel, synthetic chemistry scheme enables tuning of the key mechanical (stiffness, viscoelasticity) and biochemical (cell-adhesive ligand identity) matrix properties. ARPKD and NASH organoids grown in synthetic matrices will enable us to examine the effects that matrix cues have on fibrosis, and this analysis includes single cell RNA sequencing (scRNA-Seq). In Aim 3, to identify common pathogenetic drivers that are shared among congenital and acquired forms of liver fibrosis, we extend our modeling approach to generate and characterize organoid models for Joubert Syndrome Related Disorder (JSRD), which is a multi- system genetic disease that causes liver fibrosis in some cases, and we characterize a unique NASH organoid model. JSRD liver disease cannot be modeled in animals. JSRD and NASH organoids and isogenic controls will be analyzed using scRNA-Seq, high-dimensional time of flight mass cytometry (CyTOF) and two semi-targeted metabolomic methods. JSRD organoids will also be used to test the anti-fibrotic effects of 10 drugs (Aim 1) and for characterizing ECM effects on fibrosis (Aim 2). This data will provide important information about shared mechanisms that mediate liver fibrosis of different etiologies.",
        "disciplines": [
            "4003"
        ],
        "publications": {
            "10.1111/liv.15893": {
                "title": "Hepatic organoids move from adolescence to maturity",
                "abstract": "Since organoids were developed 15\u2009years ago, they are now in their adolescence as a research tool. The ability to generate 'tissue in a dish' has created enormous opportunities for biomedical research. We examine the contributions that hepatic organoids have made to three areas of liver research: as a source of cells and tissue for basic research, for drug discovery and drug safety testing, and for understanding disease pathobiology. We discuss the features that enable hepatic organoids to provide useful models for human liver diseases and identify four types of advances that will enable them to become a mature (i.e., adult) research tool over the next 5\u2009years. During this period, advances in single-cell RNA sequencing and CRISPR technologies coupled with improved hepatic organoid methodology, which enables them to have a wider range of cell types that are present in liver and to be grown in microwells, will generate discoveries that will dramatically advance our understanding of liver development and the pathogenesis of liver diseases. It will generate also new approaches for treating liver fibrosis, which remains a major public health problem with few treatment options.",
                "disciplines": [
                    "3202"
                ]
            },
            "10.1101/2023.04.25.538102": {
                "title": "Characterization of Pro-Fibrotic Signaling Pathways using Human Hepatic Organoids",
                "abstract": "Abstract  Background  Due to the limitations of available in vitro systems and animal models, we lack a detailed understanding of the pathogenetic mechanisms and have minimal treatment options for liver fibrosis.    Methods To overcome this barrier, we engineered a live cell imaging system that identifies collagen producing cells in a human multi-lineage hepatic organoid. This system was adapted for use as a microwell-based platform (i.e., microHOs) where exposure to PDGF or TGF\u03b21 induced the formation of thick collagen fibers.   Results Transcriptomic analysis revealed that TGF\u03b21 exposure converted a sub-population of hepatic stellate-like cells into myofibroblast-like cells, which contribute to the development of liver fibrosis. When pro-fibrotic intracellular signaling pathways were examined using pharmacological probes, the anti-fibrotic effect of receptor-specific tyrosine kinase inhibitors was limited to the fibrosis induced by the corresponding growth factor, which indicates that their anti-fibrotic efficacy would be limited to fibrotic diseases that were solely mediated by that growth factor. In contrast, GSK3\u03b2 or p38 MAPK inhibitors could prevent TGF\u03b21-or PDGF-induced fibrosis in microHOs because they block intracellular signaling pathways that are commonly utilized by the TGF\u03b21 and PDGF receptors.   Conclusions These studies identified GSK3\u03b2 and p38 MAPK inhibitors as potential new broad-spectrum therapies for liver fibrosis, and it is likely that other new therapies could subsequently be identified using this microHO system. ",
                "disciplines": [
                    "3101"
                ]
            }
        }
    },
    "13022856": {
        "title": "Direct cold sintering of functional ceramics onto polymer circuit boards: a new low energy manufacturing route in electronics",
        "abstract": "Cold sintering is an emerging technology that permits densification of ceramics, ceramic/polymer and ceramic/metal composites at temperatures as low as 100 degrees C. A transient liquid is added to the ceramic powder which is then pressed and heated. Particle-sliding, dissolution and re-precipitation result in densification and the low temperatures enable co-sintering with polymers, metals and dissimilar ceramics. Metallised-polymer printed circuit boards (e.g. FR4 PCBs) are the basis of modern electronics. The metallisation is partially etched away and the required functional and passive components are soldered into position using 'pick and place' technology. Ceramic components such as varistors, thermistors and patch antennas are manufactured separately at high temperatures (>1100 degrees C) and are assembled on the PCB. Here, we propose a radically different approach in which functional ceramics for the fabrication of components are directly deposited/integrated onto the PCB through a cold sintering process at <150 degrees C, reducing the need for energy intensive manufacturing of separate ceramic components. The overall aim is to develop a disruptive technology that reduces both the cost and energy involved in the fabrication of printed circuits for modern consumer electronics.",
        "disciplines": [
            "4016"
        ],
        "publications": {
            "10.1063/5.0142200": {
                "title": "Pb, Bi, and rare earth free X6R barium titanate\u2013sodium niobate ceramics for high voltage capacitor applications",
                "abstract": "0.9Ba(Ti1\u2212xMgx)O3\u2212x-0.1NaNbO3 (BTNN-100xMg) solid solutions are investigated with a view to developing Bi, Pb, and rare earth free, high voltage multilayer ceramic capacitors. Mg doping on the B-site significantly reduced the electronic conductivity and resulted in ceramics that could withstand a pulsed unipolar field of >300 kV/cm (Emax) to give a recoverable energy density of 3.4 J/cm3 at 82.6% efficiency for x = 0.01. The high Emax is accompanied by a high dielectric permittivity (\u03b5\u2032 \u223c 1700 at room temperature) with temperature-stable dielectric permittivity of \u0394\u03b5/\u03b5298K \u2264 \u00b115% and loss tangent tan \u03b4 < 0.02 from 116 to 378 K, corresponding to an X6R designation in the Electronic Industry Alliance codes.",
                "disciplines": [
                    "4016"
                ]
            }
        }
    },
    "12964513": {
        "title": "Acoustic platform for separation, isolation, and enrichment in biomedical research",
        "abstract": "PROJECT ABSTRACT This focused technology research and development project will deliver a new class of acoustic separation/en- richment tools for multiple biomedical research applications. Acoustic microfluidics has emerged as a key ena- bling technology in biology and medicine, providing unmatched capability for non-contact, label-free object ma- nipulation and analysis. The proposed microfluidic platform is based on a novel concept: a longitudinal standing bulk acoustic wave (LSBAW) subunit that controls micro- to nanoscale objects for functional separation and/or confinement. The patented LSBAW subunits are highly configurable, which allows arrays of repeated subunits to meet varying capacity and throughput needs, from monitoring/detection in small-volume (sub-\u00b5L) reaction chambers to high-throughput enrichment of rare species. Outcomes of this project will include purpose-built prototype systems for: (i) high-throughput enrichment/fractionation, (ii) process control at high capacity, and (iii) multiplexed analyses with real-time monitoring. To establish the versatility and utility of the LSBAW platform, different configurations will be validated in research applications of value to, for example, cancer biologists (rare cell enrichment), synthetic biochemists (antibody conjugate synthesis on ultrasound-confined reaction sub- strates), and microbiologists (monitoring/measurement of biological mechanisms in bacterial cells). The technol- ogy outcomes of this project will be relevant not only to those applications, but will be broadly applicable to any field that relies on separation, isolation, and enrichment. The project includes three Aims: Aim 1: Demonstrate scalability of LSBAW subunits for high-volume, high-throughput enrichment of rare species. Aim 2: Validate series configurations of LSBAW subunit arrays for high-capacity cell modification/labeling or custom biomolecule synthesis. Aim 3: Validate multiplexed configurations of LSBAW subunit arrays for quantification and/or detection of a target species or biological mechanism. Validation experiments will be used to rigorously assess capabilities that are relevant to specific applications. Use of standard models (e.g., microparticles as proxies for biological cells) or well-characterized biological sys- tems (e.g., commercial antibodies; standard mammalian cell lines, mixtures of cells, and microbes) will ensure consistency and reproducibility of results. In each application, success will be defined using quantitative perfor- mance criteria (e.g., throughput, capacity, specificity, sensitivity) and comparison with appropriate existing tools and methods. The team merges expertise in microfluidics, synthesis and characterization of imaging agents, microbiology, and rare cell isolation/analysis, with strong track records of technology development and deploy- ment. Completion of these aims will translate a novel acoustic microfluidics concept to a suite of powerful and broadly accessible research tools that will accelerate research in a multitude of biomedical research fields.",
        "disciplines": [
            "5103"
        ],
        "publications": {
            "10.1016/b978-0-323-95124-1.00017-6": {
                "title": "Chapter 3 Electron transfer processes between microbes and electrodes in bioelectrochemical reactors",
                "abstract": "Over a century ago, researchers observed that certain microorganisms generate electrical current. This led to the discovery of dozens, if not hundreds of electroactive microbes able to produce and/or consume electrical current. In recent decades, electroactive microbes have been explored as biocatalysts in bioelectrochemical systems at laboratory scales. Today, we are on the precipice of deploying these systems at industrial scales for bio-commodity production, energy generation, bioremediation, and more. However, challenges remain before this is feasible. Among these are the electron transfer rates between microbes and electrodes, product yields, and bioreactor design, all of which affect economic feasibility and scalability. Therefore, it is important to take stock of where we are now with respect to microbe\u2013electrode interactions in bioelectrochemical systems and assess future directions. This chapter explores the current state of knowledge regarding topics related to electron transfer processes in bioelectrochemical systems while providing perspectives about the future of these technologies.",
                "disciplines": [
                    "3106"
                ]
            },
            "10.1101/2023.05.17.541187": {
                "title": "The phototrophic bacteria Rhodomicrobium spp. are novel chassis for bioplastic production",
                "abstract": "Polyhydroxybutyrate (PHB) is a bio-based, biodegradable alternative to petroleum-based plastics. PHB production at industrial scales remains infeasible, in part due to insufficient yields and high costs. Addressing these challenges requires identifying novel biological chassis for PHB production and modifying known biological chassis to enhance production using sustainable, renewable inputs. Here, we take the former approach and present the first description of PHB production by two prosthecate photosynthetic purple non-sulfur bacteria (PNSB), <i>Rhodomicrobium vannielii</i> and <i>Rhodomicrobium udaipurense.</i> We show that both species produce PHB across photoheterotrophic, photoautotrophic, photoferrotrophic, and photoelectrotrophic growth conditions. Both species show the greatest PHB titers during photoheterotrophic growth on butyrate with dinitrogen gas as a nitrogen source (up to 44.08 mg/L), while photoelectrotrophic growth demonstrated the lowest titers (up to 0.13 mg/L). These titers are both greater (photoheterotrophy) and less (photoelectrotrophy) than those observed previously in a related PNSB, <i>Rhodopseudomonas palustris</i> TIE-1. On the other hand, we observe the highest electron yields during photoautotrophic growth with hydrogen gas or ferrous iron electron donors, and these electron yields were generally greater than those observed previously in TIE-1. These data suggest that non model organisms like <i>Rhodomicrobium</i> should be explored for sustainable PHB production and highlights utility in exploring novel biological chassis.",
                "disciplines": [
                    "3106"
                ]
            },
            "10.1101/2023.05.17.541174": {
                "title": "Improving bioplastic production by Rhodopseudomonas palustris TIE-1 using synthetic biology and metabolic engineering",
                "abstract": "With the increasing demand for sustainably produced renewable resources, it is important to look towards microorganisms capable of producing bioproducts such as biofuels and bioplastics. Though many systems for bioproduct production are well documented and tested in model organisms, it is essential to look beyond to non-model organisms to expand the field and take advantage of metabolically versatile strains. This investigation centers on <i>Rhodopseudomonas palustris</i> TIE-1, a purple, non-sulfur autotrophic, and anaerobic bacterium capable of producing bioproducts that are comparable to their petroleum-based counterparts. To induce bioplastic overproduction, genes that might have a potential role in the PHB biosynthesis such as the regulator, <i>phaR,</i> and <i>phaZ</i> known for its ability to degrade PHB granules were deleted using markerless deletion. Mutants in pathways that might compete with polyhydroxybutyrate (PHB) production such as glycogen and nitrogen fixation previously created to increase <i>n</i> -butanol production by TIE-1 were also tested. In addition, a phage integration system was developed to insert RuBisCO (RuBisCO form I and II genes) driven by a constitutive promoter <i>P <sub>aphII</sub></i> into TIE- 1 genome. Our results show that deletion of the <i>phaR</i> gene of the PHB pathway increases PHB productivity when TIE-1 was grown photoheterotrophically with butyrate and ammonium chloride (NH <sub>4</sub> Cl). Mutants unable to make glycogen or fix dinitrogen gas show an increase in PHB productivity under photoautotrophic growth conditions with hydrogen. In addition, the engineered TIE-1 overexpressing RuBisCO form I and form II produces significantly more polyhydroxybutyrate than the wild type under photoheterotrophy with butyrate and photoautotrophy with hydrogen. Inserting RuBisCO genes into TIE-1 genome is a more effective strategy than deleting competitive pathways to increase PHB production in TIE-1. The phage integration system developed for TIE-1 thus creates numerous opportunities for synthetic biology in TIE-1.",
                "disciplines": [
                    "3106"
                ]
            }
        }
    },
    "12977502": {
        "title": "Targeting anhedonia to improve clinical and functional outcomes in depression",
        "abstract": "Anhedonia (loss of pleasure) is a key driver of disability in people with depression because it impairs functioning and responds poorly to treatment. This research aims to improve our understanding of anhedonia\u2019s underlying causes and will evaluate whether a novel intervention improves symptoms and functioning for people with anhedonic depression. By informing new treatment approaches for anhedonia, the findings would make significant progress toward reducing the global burden of depression.",
        "disciplines": [
            "3202"
        ],
        "publications": {
            "10.1007/s00415-024-12430-0": {
                "title": "Profiles of motivational impairment and their relationship to functional decline in frontotemporal dementia",
                "abstract": "Motivational disturbances are pervasive in frontotemporal dementia (FTD) and impact negatively on everyday functioning. Despite mounting evidence of anhedonia in FTD, it remains unclear how such changes fit within the broader motivational symptom profile of FTD, or how anhedonia relates to functional outcomes. Here we sought to comprehensively characterize motivational disturbances in FTD and their respective relationships with functional impairment. A cross-sectional study design was used including 211 participants\u201468 behavioral-variant FTD (bvFTD), 32 semantic dementia (SD), 43 Alzheimer\u2019s disease (AD), and 68 healthy older control participants. Anhedonia severity was measured using the Snaith\u2013Hamilton Pleasure Scale while severity of apathy was assessed across Emotional, Executive, and Initiation dimensions using the Dimensional Apathy Scale. Functional impairment was established using the FTD Functional Rating Scale (FRS). Distinct motivational profiles emerged in each dementia syndrome: a domain-general motivational impairment in bvFTD; a predominantly anhedonic profile in SD; and more pronounced initiation and executive apathy in AD. Correlation analyses revealed differential associations between motivational symptoms and severity of functional impairment in each group. Executive apathy was associated with functional impairment in bvFTD, while anhedonia was strongly correlated with functional decline in SD. Finally, executive and emotional apathy were associated with functional decline in AD. Our study indicates distinct profiles of apathy and anhedonia in FTD syndromes, which in turn are differentially associated with functional decline. This detailed characterization of motivational phenotypes can inform patient stratification for targeted interventions to improve functional outcomes.",
                "disciplines": [
                    "3209",
                    "3202"
                ]
            },
            "10.1093/ntr/ntae084": {
                "title": "Smoking Progression and Nicotine-Enhanced Reward Sensitivity Predicted by Resting-State Functional Connectivity in Salience and Executive Control Networks",
                "abstract": "INTRODUCTION: The neural underpinnings underlying individual differences in nicotine-enhanced reward sensitivity and smoking progression are poorly understood. Thus, we investigated whether brain resting-state functional connectivity (rsFC) during smoking abstinence predicts nicotine-enhanced reward sensitivity and smoking progression in young light smokers. We hypothesized that high rsFC between brain areas with high densities of nicotinic receptors (insula, anterior cingulate cortex [ACC], hippocampus, thalamus) and areas involved in reward-seeking (nucleus accumbens [NAcc], prefrontal cortex [PFC]) would predict nicotine-enhanced reward sensitivity and smoking progression.\nMETHODS: Young light smokers (N=64, age 18-24, M = 1.89 cigarettes/day) participated in the study. These individuals smoked between 5 to 35 cigarettes per week and lifetime use never exceeded 35 cigarettes per week. Their rsFC was assessed using functional magnetic resonance imaging after 14-hour nicotine-deprivation. Subjects also completed a probabilistic reward task after smoking a placebo on one day and a regular cigarette on another day.\nRESULTS: The probabilistic-reward-task assessed greater nicotine-enhanced reward sensitivity was associated with greater rsFC between the right anterior PFC and right NAcc, but with reduced rsFC between the ACC and left inferior prefrontal gyrus and the insula and ACC. Decreased rsFC within the salience network (ACC and insula) predicted increased smoking progression across 18 months and greater nicotine-enhanced reward sensitivity.\nCONCLUSIONS: These findings provide the first evidence that differences in rsFCs in young light smokers are associated with nicotine-enhanced reward sensitivity and smoking progression.\nIMPLICATIONS: Weaker rsFC within the salience network predicted greater nicotine-enhanced reward sensitivity and smoking progression. These findings suggest that salience network rsFC and drug-enhanced reward sensitivity may be useful tools and potential endophenotypes for reward sensitivity and drug-dependence research.",
                "disciplines": [
                    "4202",
                    "4206"
                ]
            },
            "10.1093/schbul/sbae024": {
                "title": "Using Computational Phenotyping to Identify Divergent Strategies for Effort Allocation Across the Psychosis Spectrum",
                "abstract": "BACKGROUND AND HYPOTHESIS: Disturbances in effort-cost decision-making have been highlighted as a potential transdiagnostic process underpinning negative symptoms in individuals with schizophrenia. However, recent studies using computational phenotyping show that individuals employ a range of strategies to allocate effort, and use of different strategies is associated with unique clinical and cognitive characteristics. Building on prior work in schizophrenia, this study evaluated whether effort allocation strategies differed in individuals with distinct psychotic disorders.\nSTUDY DESIGN: We applied computational modeling to effort-cost decision-making data obtained from individuals with psychotic disorders (n\u2005=\u2005190) who performed the Effort Expenditure for Rewards Task. The sample included 91 individuals with schizophrenia/schizoaffective disorder, 90 individuals with psychotic bipolar disorder, and 52 controls.\nSTUDY RESULTS: Different effort allocation strategies were observed both across and within different disorders. Relative to individuals with psychotic bipolar disorder, a greater proportion of individuals with schizophrenia/schizoaffective disorder did not use reward value or probability information to guide effort allocation. Furthermore, across disorders, different effort allocation strategies were associated with specific clinical and cognitive features. Those who did not use reward value or probability information to guide effort allocation had more severe positive and negative symptoms, and poorer cognitive and community functioning. In contrast, those who only used reward value information showed a trend toward more severe positive symptoms.\nCONCLUSIONS: These findings indicate that similar deficits in effort-cost decision-making may arise from different computational mechanisms across the psychosis spectrum.",
                "disciplines": [
                    "3214"
                ]
            },
            "10.1038/s41386-024-01842-1": {
                "title": "Brain-based graph-theoretical predictive modeling to map the trajectory of anhedonia, impulsivity, and hypomania from the human functional connectome",
                "abstract": "Clinical assessments often fail to discriminate between unipolar and bipolar depression and identify individuals who will develop future (hypo)manic episodes. To address this challenge, we developed a brain-based graph-theoretical predictive model (GPM) to prospectively map symptoms of anhedonia, impulsivity, and (hypo)mania. Individuals seeking treatment for mood disorders (n\u2009=\u200980) underwent an fMRI scan, including (i) resting-state and (ii) a reinforcement-learning (RL) task. Symptoms were assessed at baseline as well as at 3- and 6-month follow-ups. A whole-brain functional connectome was computed for each fMRI task, and the GPM was applied for symptom prediction using cross-validation. Prediction performance was evaluated by comparing the GPM to a corresponding null model. In addition, the GPM was compared to the connectome-based predictive modeling (CPM). Cross-sectionally, the GPM predicted anhedonia from the global efficiency (a graph theory metric that quantifies information transfer across the connectome) during the RL task, and impulsivity from the centrality (a metric that captures the importance of a region) of the left anterior cingulate cortex during resting-state. At 6-month follow-up, the GPM predicted (hypo)manic symptoms from the local efficiency of the left nucleus accumbens during the RL task and anhedonia from the centrality of the left caudate during resting-state. Notably, the GPM outperformed the CPM, and GPM derived from individuals with unipolar disorders predicted anhedonia and impulsivity symptoms for individuals with bipolar disorders. Importantly, the generalizability of cross-sectional models was demonstrated in an external validation sample. Taken together, across DSM mood diagnoses, efficiency and centrality of the reward circuit predicted symptoms of anhedonia, impulsivity, and (hypo)mania, cross-sectionally and prospectively. The GPM is an innovative modeling approach that may ultimately inform clinical prediction at the individual level.",
                "disciplines": [
                    "5202"
                ]
            },
            "10.21203/rs.3.rs-3168186/v1": {
                "title": "Brain-based graph-theoretical predictive modeling to map the trajectory of transdiagnostic symptoms of anhedonia, impulsivity, and hypomania from the human functional connectome",
                "abstract": "Clinical assessments often fail to discriminate between unipolar and bipolar depression and identify individuals who will develop future (hypo)manic episodes. To address this challenge, we developed a brain-based graph-theoretical predictive model (GPM) to prospectively map symptoms of anhedonia, impulsivity, and (hypo)mania. Individuals seeking treatment for mood disorders (n = 80) underwent an fMRI scan, including (i) resting-state and (ii) a reinforcement-learning (RL) task. Symptoms were assessed at baseline as well as at 3- and 6-month follow-ups. A whole-brain functional connectome was computed for each fMRI task, and the GPM was applied for symptom prediction using cross-validation. Prediction performance was evaluated by comparing the GPM's mean square error (MSE) to that of a corresponding null model. In addition, the GPM was compared to the connectome-based predictive modeling (CPM). Cross-sectionally, the GPM predicted anhedonia from the global efficiency (a graph theory metric that quantifies information transfer across the connectome) during the RL task, and impulsivity from the centrality (a metric that captures the importance of a region for information spread) of the left anterior cingulate cortex during resting-state. At 6-month follow-up, the GPM predicted (hypo)manic symptoms from the local efficiency of the left nucleus accumbens during the RL task and anhedonia from the centrality of the left caudate during resting-state. Notably, the GPM outperformed the CPM, and GPM derived from individuals with unipolar disorders predicted anhedonia and impulsivity symptoms for individuals with bipolar disorders, highlighting transdiagnostic generalization. Taken together, across DSM mood diagnoses, efficiency and centrality of the reward circuit predicted symptoms of anhedonia, impulsivity, and (hypo)mania, cross-sectionally and prospectively. The GPM is an innovative modeling approach that may ultimately inform clinical prediction at the individual level. ClinicalTrials.gov identifier: NCT01976975.",
                "disciplines": [
                    "5202"
                ]
            },
            "10.1101/2023.08.21.23294348": {
                "title": "While they wait: A cross-sectional survey on wait times for mental health treatment for anxiety and depression for Australian adolescents",
                "abstract": "ABSTRACT  Background Wait times are reported to impede adolescents\u2019 access to mental health treatment for anxiety and depression. However, there is limited quantitative research on current wait times for the treatment of anxiety and depression for Australian adolescents and the impact of these on young help-seekers.   Aims This study examined Australian adolescents\u2019 experiences of wait times for the treatment of anxiety and depression, including the providers they were waiting to access, the self-reported duration and perceived acceptability of wait times, the association between these wait times and psychological distress, and the support and coping behaviours used by adolescents during this time.   Method From April to June 2022, 375 Australian adolescents aged 13-17 years who were currently waiting, or had previously waited in the past 12 months, for mental health treatment for anxiety and depression completed an anonymous cross-sectional online survey.   Results The mean wait time across all treatment providers was 94.1 days (SD: 69.65). Psychologists and psychiatrists were the most utilised services. Most participants felt their wait times were \u2018too long\u2019 and longer wait times were significantly associated with increased psychological distress. Many participants perceived their mental health to have worsened during the wait time and engaged in maladaptive and risky coping behaviours while waiting. Most participants did not receive any support from their healthcare providers during the wait time. However, self-reported treatment attendance remained high.   Conclusions Many Australian adolescents face lengthy wait periods when trying to access mental health treatment and this period may exacerbate distress and maladaptive coping. ",
                "disciplines": [
                    "5203",
                    "4203"
                ]
            },
            "10.1038/s41380-023-02165-1": {
                "title": "Distinct profiles of anhedonia and reward processing and their prospective associations with quality of life among individuals with mood disorders",
                "abstract": "Leading professional health bodies have called for the wider adoption of Patient Reported Outcome Measures, such as quality of life, in research and clinical practice as a means for understanding why the global burden of depression continues to climb despite increased rates of treatment use. Here, we examined whether anhedonia\u2014an often recalcitrant and impairing symptom of depression\u2014along with its neural correlates, was associated with longitudinal changes in patient-reported quality of life among individuals seeking treatment for mood disorders. We recruited 112 participants, including n\u2009=\u200980 individuals with mood disorders (58 unipolar, 22 bipolar) and n\u2009=\u200932 healthy controls (63.4% female). We assessed anhedonia severity along with two electroencephalographic markers of neural reward responsiveness (scalp-level \u2018Reward Positivity\u2019 amplitude and source-localized reward-related activation in the dorsal anterior cingulate cortex), and assessed quality of life at baseline, 3- and 6-month follow-up. Anhedonia emerged as a robust correlate of quality of life cross-sectionally and longitudinally among individuals with mood disorders. Furthermore, increased neural reward responsiveness at baseline was associated with greater improvements in quality of life over time, and this improvement was mediated by longitudinal improvements in anhedonia severity. Finally, differences in quality of life observed between individuals with unipolar and bipolar mood disorders were mediated by differences in anhedonia severity. Our findings indicate that anhedonia and its reward-related neural correlates are linked to variability in quality of life over time in individuals with mood disorders. Treatments capable of improving anhedonia and normalizing brain reward function may be necessary for improving broader health outcomes for individuals seeking treatment for depression.ClinicalTrials.gov identifier: NCT01976975",
                "disciplines": [
                    "5202",
                    "3202",
                    "3214"
                ]
            },
            "10.1136/bmjopen-2022-066249": {
                "title": "Protocol for a bandit-based response adaptive trial to evaluate the effectiveness of brief self-guided digital interventions for reducing psychological distress in university students: the Vibe Up study",
                "abstract": "INTRODUCTION: Meta-analytical evidence confirms a range of interventions, including mindfulness, physical activity and sleep hygiene, can reduce psychological distress in university students. However, it is unclear which intervention is most effective. Artificial intelligence (AI)-driven adaptive trials may be an efficient method to determine what works best and for whom. The primary purpose of the study is to rank the effectiveness of mindfulness, physical activity, sleep hygiene and an active control on reducing distress, using a multiarm contextual bandit-based AI-adaptive trial method. Furthermore, the study will explore which interventions have the largest effect for students with different levels of baseline distress severity.\nMETHODS AND ANALYSIS: The Vibe Up study is a pragmatically oriented, decentralised AI-adaptive group sequential randomised controlled trial comparing the effectiveness of one of three brief, 2-week digital self-guided interventions (mindfulness, physical activity or sleep hygiene) or active control (ecological momentary assessment) in reducing self-reported psychological distress in Australian university students. The adaptive trial methodology involves up to 12 sequential mini-trials that allow for the optimisation of allocation ratios. The primary outcome is change in psychological distress (Depression, Anxiety and Stress Scale, 21-item version, DASS-21 total score) from preintervention to postintervention. Secondary outcomes include change in physical activity, sleep quality and mindfulness from preintervention to postintervention. Planned contrasts will compare the four groups (ie, the three intervention and control) using self-reported psychological distress at prespecified time points for interim analyses. The study aims to determine the best performing intervention, as well as ranking of other interventions.\nETHICS AND DISSEMINATION: Ethical approval was sought and obtained from the UNSW Sydney Human Research Ethics Committee (HREC A, HC200466). A trial protocol adhering to the requirements of the Guideline for Good Clinical Practice was prepared for and approved by the Sponsor, UNSW Sydney (Protocol number: HC200466_CTP).\nTRIAL REGISTRATION NUMBER: ACTRN12621001223820.",
                "disciplines": [
                    "5203"
                ]
            }
        }
    },
    "12943024": {
        "title": "Disrupting Access to Intracellular Lipid Depots to Treat Advanced Prostate Cancer",
        "abstract": "PUBLIC ABSTRACT\n\nRationale:  Despite the development and approval of several new treatments for advanced prostate cancer, this stage of the disease remains largely incurable.  Hence, there is a pressing need to identify novel therapeutic approaches.  It is now known that a defining hallmark of prostate cancer is increased lipid metabolism.  Accordingly, there is great interest in targeting lipid metabolism for the treatment of advanced prostate cancer.  Current efforts to target lipid metabolism have centered on blocking the cancer cell\u2019s ability to take up lipids from the environment (lipid uptake) or synthesize these molecules themselves from other building blocks (de novo lipogenesis).  However, targeting lipid uptake or de novo lipogenesis has not yet led to any clinical benefit for men with prostate cancer.  Further, there may be compensation between the two pathways, indicating that targeting either pathway may be insufficient.  Alternatively, we have identified that inhibition of an enzyme called adipose triglyceride lipase (ATGL), which regulates the first step in the breakdown of all stored fats within cells, blocks the growth of advanced prostate cancer in cell culture and in animal models.  Preliminary data suggest that blocking ATGL may also be effective for the treatment of metastatic disease and/or prostate cancers that are resistant to all androgen receptor (AR)-targeted therapies.  These findings indicate that ATGL may represent a mechanistically alternative therapeutic target.  To drive the development of new ATGL-directed therapies, several issues still need to be addressed.  First, we need to identify which disease state would benefit the most and whether there would be potential side effects, if any, of systemic targeting of ATGL.  Second, it is not clear why prostate tumors require ATGL.  Third, a faithful biomarker of ATGL-targeted therapy is needed.  These three issues (determining patient population and potential side effects, understanding the fundamental biology, establishing a biomarker of activity) need to be addressed to evaluate any mechanistically new therapy to determine whether it can be safely and effectively administered to the correct patient population. \n\n \n\nObjectives:  The primary objective of this study is to rigorously test whether ATGL is a bona fide therapeutic target in diverse preclinical models of advanced prostate cancer.  Further, we will characterize whether this approach enhances the efficacy of existing drugs and assess whether there are potential side effects (positive or negative).  We will also determine how ATGL regulates lipid metabolism to promote prostate cancer progression.  Finally, we will test whether a non-invasive imaging agent that is already FDA-approved for the detection of recurrent and metastatic prostate cancer can be used as a biomarker of drug effectiveness and potentially, future patient selection. \n\n \n\nAims:  Aim 1 will test whether inhibition of ATGL blocks disease progression in rigorous, preclinical animal models of advanced prostate cancer.  We will use new and established mouse models that mimic different stages of the disease (castration-resistant prostate cancer, metastasis, AR-positive and AR-negative), and that will allow us to test whether genetic or pharmacological inhibition of ATGL blocks disease progression.  These experiments will also enable the initial assessment of potential side effects that could result from ATGL inhibitors.  Aim 2 will establish ATGL\u2019s role in prostate cancer lipid metabolism.  Hence, these experiments will provide a biological explanation for how this therapeutic approach works.  Aim 3 will evaluate whether 11C-choline, an FDA-approved agent used for positron emission tomography imaging (PET) of advanced prostate cancer, can function as a biomarker of ATGL activity and thus, ATGL inhibitors. \n\n \n\nApplicability of the Research:  Given the focus on developing novel therapies for the treatment of the advanced disease and defining the underlying mechanism of action for this approach, this study directly addresses the Overarching Challenges to develop treatments that improve outcomes for men with lethal prostate cancer and define the biology of lethal prostate cancer to reduce death.  We will validate a new therapeutic target that we propose can be used to treat a wide range of aggressive cancer subtypes including high-risk, localized disease, bone-metastatic prostate cancer, and possibly cancers that are completely refractory to all AR-targeted therapies.  Our preclinical models will also test whether this new treatment approach can safely enhance the effectiveness of current standard of care treatments.  Finally, this research will develop a complementary, non-invasive, and clinically viable imaging approach that will provide a readout of treatment response and, in future, could help identify the most appropriate patient populations and therefore build the foundation for a new precision medicine approach.",
        "disciplines": [
            "3211",
            "3202"
        ],
        "publications": {
            "10.1038/s41585-024-00869-9": {
                "title": "Unlocking ferroptosis in prostate cancer \u2014 the road to novel therapies and imaging markers",
                "abstract": "Ferroptosis is a distinct form of regulated cell death that is predominantly driven by the build-up of intracellular iron and lipid peroxides. Ferroptosis suppression is widely accepted to contribute to the pathogenesis of several tumours including prostate cancer. Results from some studies reported that prostate cancer cells can be highly susceptible to ferroptosis inducers, providing potential for an interesting new avenue of therapeutic intervention for advanced prostate cancer. In this Perspective, we describe novel molecular underpinnings and metabolic drivers of ferroptosis, analyse the functions and mechanisms of ferroptosis in tumours, and highlight prostate cancer-specific susceptibilities to ferroptosis by connecting ferroptosis pathways to the distinctive metabolic reprogramming of prostate cancer cells. Leveraging these novel mechanistic insights could provide innovative therapeutic opportunities in which ferroptosis induction augments the efficacy of currently available prostate cancer treatment regimens, pending the elimination of major bottlenecks for the clinical translation of these treatment combinations, such as the development of clinical-grade inhibitors of the anti-ferroptotic enzymes as well as non-invasive biomarkers of ferroptosis. These biomarkers could be exploited for diagnostic imaging and treatment decision-making.",
                "disciplines": [
                    "3202",
                    "3211"
                ]
            },
            "10.1158/0008-5472.can-23-0555": {
                "title": "Adipose Triglyceride Lipase Is a Therapeutic Target in Advanced Prostate Cancer That Promotes Metabolic Plasticity.",
                "abstract": "Lipid metabolism plays a central role in prostate cancer. To date, the major focus has centered on de novo lipogenesis and lipid uptake in prostate cancer, but inhibitors of these processes have not benefited patients. A better understanding of how cancer cells access lipids once they are created or taken up and stored could uncover more effective strategies to perturb lipid metabolism and treat patients. Here, we identified that expression of adipose triglyceride lipase (ATGL), an enzyme that controls lipid droplet homeostasis and a previously suspected tumor suppressor, correlates with worse overall survival in men with advanced, castration-resistant prostate cancer (CRPC). Molecular, genetic, or pharmacologic inhibition of ATGL impaired human and murine prostate cancer growth in vivo and in cell culture or organoids under conditions mimicking the tumor microenvironment. Mass spectrometry imaging demonstrated that ATGL profoundly regulates lipid metabolism in vivo, remodeling membrane composition. ATGL inhibition induced metabolic plasticity, causing a glycolytic shift that could be exploited therapeutically by cotargeting both metabolic pathways. Patient-derived phosphoproteomics identified ATGL serine 404 as a target of CAMKK2-AMPK signaling in CRPC cells. Mutation of serine 404 did not alter the lipolytic activity of ATGL but did decrease CRPC growth, migration, and invasion, indicating that noncanonical ATGL activity also contributes to disease progression. Unbiased immunoprecipitation/mass spectrometry suggested that mutation of serine 404 not only disrupts existing ATGL protein interactions but also leads to new protein-protein interactions. Together, these data nominate ATGL as a therapeutic target for CRPC and provide insights for future drug development and combination therapies.\nSIGNIFICANCE: ATGL promotes prostate cancer metabolic plasticity and progression through both lipase-dependent and lipase-independent activity, informing strategies to target ATGL and lipid metabolism for cancer treatment.",
                "disciplines": [
                    "3101",
                    "3211"
                ]
            },
            "10.1101/2022.11.02.514910": {
                "title": "Adipose triglyceride lipase is regulated by CAMKK2-AMPK signaling and drives advanced prostate cancer",
                "abstract": "Summary  Lipid metabolism plays a central role in prostate cancer. To date, the major focus on prostate cancer lipid metabolism has centered on de novo lipogenesis and lipid uptake with little consideration for how cancer cells access these lipids once they are created or taken up and stored. Patient-derived phosphoproteomics identified adipose triglyceride lipase (ATGL), a previously suspected tumor suppressor, as a CAMKK2-AMPK signaling target that, conversely, promotes castration-resistant prostate cancer (CRPC) progression. Phosphorylation of ATGL increased its lipase activity, cancer cell proliferation, migration, and invasion. Shotgun lipidomics and mass spectrometry imaging demonstrated ATGL\u2019s profound regulation of lipid metabolism in vitro and in vivo , remodeling membrane composition. Inhibition of ATGL induced metabolic plasticity, causing a glycolytic shift that could be exploited therapeutically by co-targeting both metabolic pathways. Together, these data nominate ATGL and intracellular lipolysis as potential therapeutic targets for the treatment of CRPC and provide insights for future combination therapies. ",
                "disciplines": [
                    "3101",
                    "3205",
                    "3211"
                ]
            }
        }
    },
    "12949229": {
        "title": "ASCENT: Reconfigurable Metal-Free Microsystems with Alternative Power Sources",
        "abstract": "This Addressing Systems Challenges through Engineering Teams (ASCENT) project will enable a suite of technologies for sustainable micro- and nano-electronics development. The emerging Internet-of-Things and efforts to realize a fully \u201cconnected\u201d society and infrastructure requires the mass distribution of electronics, and to do this in a sustainable manner requires the development of eco-friendly electronic materials, circuits, and power sources. The research team will investigate the materials, low-power circuits, and alternative power sources (i.e., non-battery to engineer reconfigurable-metal-free microsystems that can operate with alternative power sources). These systems will (i) be completely composed of carbon-based materials, (ii) be operated from a bio-derived power source, (iii) provide sustained recording of a local environmental metric and (iv) achieve complete biodegradation or recycling upon the end of their operational lifetime. The combination of novel materials science, circuit design, and biofuel cells will enable the next-generation green electronics that can be mass produced at lower cost, at larger scales, distributed throughout our environment, and have minimal ecological impact, while achieving comparable performance when compared to silicon-based microsystems. The project\u2019s multidisciplinary team is strategically set for integrating research with a plan for adding to the engineering curriculum, engaging with the local microelectronics industries, and supporting the national infrastructure and efforts for hybrid manufacturing of electronics. Devices and micros and microsystems for the Internet-of-Things are supposed to be deployed everywhere and to be accessed anytime from anywhere. These simple prerequisites imply significant challenges for the sustainability of the production, distribution, and operation of Internet-of-Things electronics. Notably, the necessary quantity of a microsystem requires the mass use of non-sustainable materials and expensive manufacturing processes. Moreover, the mass distribution of microsystems is tantamount to large scale pollution via electronics waster, if means for recapture, environmental integration, or recycling are not realized. In response to these challenges, this project will engineer sensing-communications nodes composed of metal-free, biodegradable materials, carbon-biological-organic-polymer devices and circuits, and enzymatic fuel cells. Citric acid-based elastomers and cellulosic nanocomposites will be developed for biodegradable elastomeric circuit boards and packaging. Low-power sensors and circuits will be developed from carbon, biological, organic, and polymer-based devices. The sensing-communications node will include an array of organic electrochemical transistors distributed across the biodegradable circuit boards to perform continuous monitoring of humidity, temperature, pH, and volatile organic compounds. The sensing-communications node will be powered by a modular biochemical fuel cell, which employs custom engineered direct electron transfer-type enzymes that convert eco-friendly fuel sources, e.g., glucose and lactate, to suitable electrical power. This completely metal-free sensing-communications node will be integrated, benchmarked against conventional commercial-off-the-shelf systems, and demonstrated in different simulated food storage and supply chain application scenarios. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4009"
        ],
        "publications": {
            "10.3390/s24072335": {
                "title": "Evaluating Bacterial Nanocellulose Interfaces for Recording Surface Biopotentials from Plants",
                "abstract": "The study of plant electrophysiology offers promising techniques to track plant health and stress in vivo for both agricultural and environmental monitoring applications. Use of superficial electrodes on the plant body to record surface potentials may provide new phenotyping insights. Bacterial nanocellulose (BNC) is a flexible, optically translucent, and water-vapor-permeable material with low manufacturing costs, making it an ideal substrate for non-invasive and non-destructive plant electrodes. This work presents BNC electrodes with screen-printed carbon (graphite) ink-based conductive traces and pads. It investigates the potential of these electrodes for plant surface electrophysiology measurements in comparison to commercially available standard wet gel and needle electrodes. The electrochemically active surface area and impedance of the BNC electrodes varied based on the annealing temperature and time over the ranges of 50 \u00b0C to 90 \u00b0C and 5 to 60 min, respectively. The water vapor transfer rate and optical transmittance of the BNC substrate were measured to estimate the level of occlusion caused by these surface electrodes on the plant tissue. The total reduction in chlorophyll content under the electrodes was measured after the electrodes were placed on maize leaves for up to 300 h, showing that the BNC caused only a 16% reduction. Maize leaf transpiration was reduced by only 20% under the BNC electrodes after 72 h compared to a 60% reduction under wet gel electrodes in 48 h. On three different model plants, BNC-carbon ink surface electrodes and standard invasive needle electrodes were shown to have a comparable signal quality, with a correlation coefficient of >0.9, when measuring surface biopotentials induced by acute environmental stressors. These are strong indications of the superior performance of the BNC substrate with screen-printed graphite ink as an electrode material for plant surface biopotential recordings.",
                "disciplines": [
                    "4008",
                    "4009"
                ]
            },
            "10.1109/sensors56945.2023.10324963": {
                "title": "Conformal Micropatterned Organic-Metal Electrodes for Physiological Recording",
                "abstract": "Conformal electrodes provide a soft and conforming interface with the skin for reduced impedance, comfortable skin contact, and improved signal quality compared to commercial electrodes. In this paper, we present conformal micropatterned organic-metal (CMOM) electrodes and our investigation on the effect of perforation micropatterning and PEDOT:PSS coating. CMOM electrodes were characterized then evaluated in vivo against commercial-off-the-shelf electrodes. PEDOT:PSS was found to reduce the overall impedance in each electrode variant, resulting in a >97% decrease in impedance at low frequencies. The change in impedance at high frequencies was not significant for the control or $30\\ \\mu \\mathrm{m}$ vias electrodes, but the impedance was significantly greater following EPD for $60\\ \\mu \\mathrm{m}$ vias electrodes.",
                "disciplines": [
                    "4009"
                ]
            },
            "10.1038/s41528-023-00258-z": {
                "title": "Biodegradable elastomeric circuit boards from citric acid-based polyesters",
                "abstract": "Recyclable and biodegradable microelectronics, i.e., \u201cgreen\u201d electronics, are emerging as a viable solution to the global challenge of electronic waste. Specifically, flexible circuit boards represent a prime target for materials development and increasing the utility of green electronics in biomedical applications. Circuit board substrates and packaging are good dielectrics, mechanically and thermally robust, and are compatible with microfabrication processes. Poly(octamethylene maleate (anhydride) citrate) (POMaC) \u2013 a citric acid-based elastomer with tunable degradation and mechanical properties \u2013 presents a promising alternative for circuit board substrates and packaging. Here, we report the characterization of Elastomeric Circuit Boards (ECBs). Synthesis and processing conditions were optimized to achieve desired degradation and mechanical properties for production of stretchable circuits. ECB traces were characterized and exhibited sheet resistance of 0.599\u2009\u03a9 cm\u22122, crosstalk distance of <0.6\u2009mm, and exhibited stable 0% strain resistances after 1000 strain cycles to 20%. Fabrication of single layer and encapsulated ECBs was demonstrated.",
                "disciplines": [
                    "4016",
                    "4009"
                ]
            },
            "10.3390/bios12050322": {
                "title": "Towards Wearable Health Monitoring Devices",
                "abstract": "Humans have searched far beyond our planet to understand the fundamental principles and mechanisms of life [...].",
                "disciplines": [
                    "3401",
                    "3101"
                ]
            }
        }
    },
    "12963032": {
        "title": "Isolated Abnormality in the Diffusion Capacity for Carbon Monoxide in People Living with HIV \u2013 Epidemiology, Etiology and Pathogenesis",
        "abstract": "Project Abstract/Summary People with HIV (PWH) have a high burden of respiratory symptoms due to chronic lung disease, of which COPD, diagnosed by spirometric obstruction on pulmonary function testing (PFT), is best studied. The most common finding on PFTs, however, is an abnormal diffusing capacity for carbon monoxide (DLco) with normal spirometry, or iso\u2193DLco. The clinical relevance of the iso\u2193DLco PFT phenotype is not known. Iso\u2193DLco is more common in PWH than in the general population, and HIV is an independent risk factor for reduced DLco. Preliminary work from our lab has shown that PWH with iso\u2193DLco have an increased respiratory symptom burden compared to PWH with normal PFTs. Iso\u2193DLco is also associated with a unique set of plasma inflammatory/immune biomarkers compared to other PFT phenotypes like spirometric obstruction, suggesting that the iso\u2193DLco PFT and biomarker pattern has a unique clinical correlate. The pathophysiology underlying this finding is not known but may be related to early structural lung disease (emphysema or interstitial lung disease) or pulmonary hypertension. Alternatively, iso\u2193DLco may be a sequela of chronic inflammation in the setting of long-standing HIV infection and possibly co-infection with other viruses like cytomegalovirus (CMV), which affect HIV persistence and immune activation. The central hypothesis for this study is that iso\u2193DLco is a unique HIV phenotype, possibly mediated by CMV-induced vasculopathy. The study will be nested within I AM OLD-DA, an established longitudinal cohort of PWH in San Francisco, USA and Kampala, Uganda, and will leverage the existing research infrastructure. In San Francisco we will use advanced imaging analyses of chest CTs to understand the etiology and potential causes of iso\u2193DLco. In Aim 1, we will evaluate CTs for emphysema, interstitial lung disease, pulmonary hypertension and air trapping; based on our pilot study, we expect that in about half of the PWH with iso\u2193DLco, imaging analysis will not identify a reason for the PFT finding. In Aim 3, we will test for association between iso\u2193DLco, CMV and distal pulmonary vascular remodeling (\u2018vascular pruning\u2019) using quantitative CT methods with a working hypothesis that CMV-mediated vascular pruning is associated with iso\u2193DLco. In Kampala, Uganda, we will study a demographically and clinically distinct cohort or PWH and HIV-negative controls to determine the prevalence of iso\u2193DLco and its associated respiratory symptom burden (Aim 2). Altogether, the results from this study will help generate a deeper understanding of this PFT phenotype and determine if CMV is a modifiable risk factor for iso\u2193DLco and a target for therapeutic intervention. Completion of this project will also provide a platform for training Dr. Katerina Byanova, a pulmonary and critical care fellow at the University of California San Francisco, in the conduct of high-quality, patient-oriented clinical research. This grant will provide Dr. Byanova with the support necessary to acquire the knowledge and skills to become an independent clinical investigator and a leader in HIV-related lung disease. .",
        "disciplines": [
            "3204",
            "3207"
        ],
        "publications": {
            "10.1371/journal.pone.0288803": {
                "title": "Isolated abnormal diffusing capacity for carbon monoxide (iso\u2193DLco) is associated with increased respiratory symptom burden in people with HIV infection",
                "abstract": "OBJECTIVES: An isolated reduction in the diffusing capacity for carbon monoxide (DLco; iso\u2193DLco) is one of the most common pulmonary function test (PFT) abnormalities in people living with HIV (PWH), but its clinical implications are incompletely understood. In this study, we explored whether iso\u2193DLco in PWH is associated with a greater respiratory symptom burden.\nSTUDY DESIGN: Cross-sectional analysis.\nMETHODS: We used ATS/ERS compliant PFTs from PWH with normal spirometry (post-bronchodilator FEV1/FVC \u22650.7; FEV1, FVC \u226580% predicted) from the I AM OLD cohort in San Francisco, CA and Seattle, WA, grouped by DLco categorized as normal (DLco \u2265lower limit of normal, LLN), mild iso\u2193DLco (LLN >DLco >60% predicted), and moderate-severe iso\u2193DLco (DLco \u226460% predicted). We performed multivariable analyses to test for associations between DLco and validated symptom-severity and quality of life questionnaires, including the modified Medical Research Council dyspnea scale (mMRC), the COPD Assessment Test (CAT), and St. George's Respiratory Questionnaire (SGRQ), as well as between DLco and individual CAT symptoms.\nRESULTS: Mild iso\u2193DLco was associated only with a significantly higher SGRQ score. Moderate-severe iso\u2193DLco was associated with significantly higher odds of mMRC \u22652 and significantly higher CAT and SGRQ scores. PWH with moderate-severe iso\u2193DLco had increased odds of breathlessness, decreased activity, lower confidence leaving home, and less energy.\nCONCLUSIONS: Iso\u2193DLco is associated with worse respiratory symptom scores, and this association becomes stronger with worsening DLco, suggesting that impaired gas exchange alone has a significant negative impact on the quality of life in PWH. Additional studies are ongoing to understand the etiology of this finding and design appropriate interventions.",
                "disciplines": [
                    "3202"
                ]
            }
        }
    },
    "12963155": {
        "title": "Informatics-Based Digital Application to Promote Safe Exercise in Middle-Aged Adults with Type 1 Diabetes",
        "abstract": "ABSTRACT Type 1 diabetes (T1D) affects ~1 million American adults and increases the risk of mortality attributable to cardiovascular disease by 800%. Current evidence-based T1D self-management interventions target glycemic control but ignore other modifiable health concerns prevalent in T1D such as hypertension and obesity. Exercise interventions could provide a novel solution if they could innovatively address the diabetes management and psychosocial challenges around exercise posed by T1D. Continuous glucose monitoring (CGM) allows patients and providers to comprehensively track the short- and long-term outcomes of exercise. Evidence-based interventions to translate CGM technology into sustainable adherence to exercise-related behaviors are lacking. Our human-delivered pilot intervention provided previously sedentary adults with T1D access to exercise videos and monthly client-centered discussions of their CGM and exercise data with an exercise coach. Participants said these improved exercise management behavioral skills and motivation, but only transiently. They stated a need for more frequent and sustained contact, requiring automated mobile tools that this proposal will develop. These tools include just-in-time adaptive text messages to overcome exercise barriers at times of vulnerability, weekly personalized reviews of short-term exercise safety hazards with tips to avoid them, and monthly personalized evaluation of long-term impact of exercise on blood glucose levels via Bayesian modeling. The program represents stage 1 of the NIH intervention development model: intervention generation, refinement, modification, adaptation. These steps will be accomplished by a feasibility study evaluating user satisfaction and mathematical robustness of an alpha version, using these results to modify the alpha version into a beta version, and then testing the beta version in a nonrandomized crossover clinical trial. Lastly, the databank of biobehavioral metrics generated by this trial (exercise, CGM, mood and sleep diaries for ~ 7,000 person-days) will be subjected to dimensionality reduction to identify biobehavioral subtypes of baseline and early intervention data. We will test whether these subtypes help predict longer-term intervention response and/or flag specific biobehavioral feature combinations that drive intervention responsiveness. These findings will lay a foundation for Dr. Ash\u2019s future work developing precision medicine approaches. Alongside this research Dr. Ash will complete training in the domains of 1) diabetes management and technology; 2) mobile health (mHealth) intervention development; and 3) dimensionality reduction analytics. The training plan includes a strategic combination of mentor-led trainings, coursework, grant writing, and attendance at relevant conferences and workshops. Dr. Ash has assembled a mentoring team in T1D self-management and technology, multiple health behavior change intervention development, mHealth development, and informatics. FitscriptLLC and PiLR Health will provide customized intervention tools and data capture software. Dr. Gerstein\u2019s laboratory will support data storage, processing, and analytics.",
        "disciplines": [
            "4206"
        ],
        "publications": {
            "10.3389/fpubh.2023.1219676": {
                "title": "Health policy considerations for combining exercise prescription into noncommunicable diseases treatment: a narrative literature review",
                "abstract": "Objectives: In this review, we aim to highlight the evidence base for the benefits of exercise in relation to the treatment of noncommunicable diseases (NCDs), draw on the Health Triangular Policy Framework to outline the principal facilitators and barriers for implementing exercise in health policy, and make concrete suggestions for action.\nMethods: Literature review and framework analysis were conducted to deal with the research questions.\nResults: Exercise prescription is a safe solution for noncommunicable diseases prevention and treatment that enables physicians to provide and instruct patients how to apply exercise as an important aspect of disease treatment and management. Combining exercise prescription within routine care, in inpatient and outpatient settings, will improve patients' life quality and fitness levels.\nConclusion: Inserting exercise prescription into the healthcare system would improve population health status and healthy lifestyles. The suggestions outlined in this study need combined efforts from the medical profession, governments, and policymakers to facilitate practice into reality in the healthcare arena.",
                "disciplines": [
                    "4203",
                    "4206"
                ]
            },
            "10.1016/j.soard.2023.09.026": {
                "title": "Role of the exercise professional in metabolic and bariatric surgery",
                "abstract": "BACKGROUND: Physical activity (PA) is important for the long-term health and weight management of patients who undergo metabolic and bariatric surgery (MBS). However, the roles of exercise professionals in MBS settings have not been systematically determined.\nOBJECTIVES: To investigate: (1) who are the professionals implementing PA programming in MBS clinical settings; and (2) what patient-centric tasks do they perform?\nSETTING: Clinical and academic exercise settings worldwide.\nMETHODS: This multimethod study included a scoping review of PA programs in MBS described in the research literature. Data about job tasks were extracted and provided to 10 experts to sort into categories. Cluster analysis was utilized to find the hierarchical structure of tasks. A Delphi process was used to agree on a final model.\nRESULTS: The majority of PA professionals were exercise physiologists in the USA and physiotherapists or other types of exercise professionals elsewhere. Forty-three tasks were identified, the most reported being supervision of exercise, fitness testing, and exercise prescription. Seven higher-order categories were determined: (1) Exercise-related health assessment, (2) Body composition and physical fitness assessment, (3) Lifestyle physical activity and sedentary behavior assessment, (4) Education, instruction, and prescription, (5) Exercise monitoring, (6) Behavioral counseling and psychosocial support, and (7) Dietary support. The following statements were rated an average of 9.0, classifying them as \"imperative\": 1) \"Pre- and postoperative PA/exercise guidelines for MBS patients are needed\", 2) \"MBS programs need to include PA/exercise as part of multidisciplinary care\".\nCONCLUSIONS: The expert group reached a consensus on 7 major classifications of job tasks for the exercise professional. It is important for governing medical associations across the world to formally recognize experienced exercise professionals as playing pivotal roles in continuing, multidisciplinary care for MBS patients. These findings also provide evidence-based information in the effort to solidify these positions within the greater context of healthcare.",
                "disciplines": [
                    "4206",
                    "3202"
                ]
            },
            "10.3389/fpsyg.2023.1106571": {
                "title": "The CRAVE and ARGE scales for motivation states for physical activity and sedentarism: Brazilian Portuguese translation and single-item versions",
                "abstract": "Motivation states for physical activity and sedentarism potentially vary from moment to moment. The CRAVE scale (Cravings for Rest and Volitional Energy Expenditure) was developed to assess transient wants and desires to move. Three studies were conducted with the aims of: (1) translating and validating the scale in Brazilian Portuguese, (2) examining changes with exercise, and (3) determining the best single-item for Move and Rest subscales for English and Portuguese. In Study 1, six bilingual speakers translated the scale into Brazilian Portuguese [named <i>Anseios por Repouso e Gastos com Energia</i> (ARGE)]. The ARGE had good content validity coefficients across three dimensions (0.89-0.91), as determined by three independent, bilingual referees. 1,168 participants (mean age\u2009=\u200930.6, SD\u2009=\u200912.2) from across Brazil completed an online version of the ARGE. An Exploratory Factor Analysis found two clear, oblique, and inversely related factors (Move and Rest; GFI\u2009=\u20091.00, RMSR\u2009=\u20090.03). Reliability was good (Cronbach \u03b1's: 0.93 and 0.92). Two models of the scale (10 vs. 13 items) were compared with Confirmatory Factor Analysis. The previously validated version using 10 scored items (GFI\u2009=\u20091.00, RMSEA\u2009=\u20090.07, RMSR\u2009=\u20090.02) outperformed the version scored with 13 items. State anxiety and exercise behavior had small associations with Move and Rest (-0.20 to 0.26). In Study 2, ARGE Move scores had high correspondence post-session (ICC\u2009=\u20090.83) for 9 women performing short Sprint Interval Training (sSIT; 6 sessions). Large, but non-significant, effects were detected for changes in motivation states with sSIT. In Study 3, IRT analyses found that for the United States sample, \"be physically active\" and \"be still\" were the most representative items for Move and Rest, respectively, while for the Brazil sample they were \"exert my muscles\" and \"be a couch potato.\" Overall, it was found that: (A) the ARGE scale demonstrated good psychometric properties, (B) the original scoring (with 10 items) resulted in the best model, (C) it had small associations with exercise behavior, and (D) the subscales were reduced to single items that varied by country, indicating potential cultural differences in the concept of motivation states for physical activity.",
                "disciplines": []
            },
            "10.2196/46415": {
                "title": "Internet-Based Recruitment and Retention of Young Adults With Type 1 Diabetes: Cross-Sectional Study",
                "abstract": "BACKGROUND: Multiple research strategies are required to recruit and engage a representative cohort of young adults in diabetes research. In this report, we describe an approach for internet-based recruitment for a repeated-measures descriptive study.\nOBJECTIVE: The objective of this cross-sectional study was to determine whether internet-based recruitment through multiple social media platforms, a clinical research platform, and cooperation with community partnerships-College Diabetes Network and Beyond Type 1-would serve as an effective way to recruit a representative sample of young adults aged 18-25 years with type 1 diabetes (T1D).\nMETHODS: We conducted a repeated-measures descriptive study. We captured enrollment rates and participant characteristics acquired from each social media platform through survey data and Facebook analytics. This study was advertised via paid postings across a combination of different social media platforms (eg, Facebook, Instagram, Twitter, and Reddit). We used quarterly application postings, quarterly newsletters, and participation in the ResearchMatch registry to identify potentially eligible participants from February 3, 2021, to June 6, 2022.\nRESULTS: ResearchMatch proved to be the most cost-effective strategy overall, yielding the highest gender and racial diversity compared to other internet platforms (eg, Facebook, Instagram, Twitter, and Reddit), application postings (eg, Beyond Type 1), and newsletters (eg, College Diabetes Network and a local area college). However, we propose that the combination of these approaches yielded a larger, more diverse sample compared to any individual strategy. Our recruitment cost was US $16.69 per eligible participant, with a 1.27% conversion rate and a 30% eligibility rate.\nCONCLUSIONS: Recruiting young adults with T1D across multiple internet-based platforms was an effective strategy to yield a moderately diverse sample. Leveraging various recruitment strategies is necessary to produce a representative sample of young adults with T1D. As the internet becomes a larger forum for study recruitment, participants from underrepresented backgrounds may continue engaging in research through advertisements on the internet and other internet-based recruitment platforms.",
                "disciplines": []
            },
            "10.1101/2023.04.20.23288698": {
                "title": "Role of the exercise professional in metabolic and bariatric surgery",
                "abstract": "Background: Physical activity (PA) is important for the long-term health and weight management of patients who undergo metabolic and bariatric surgery (MBS). However, the roles of exercise professionals in MBS settings have not been systematically determined.\nObjectives: To investigate: (1) who are the professionals implementing PA programming in MBS clinical settings; and (2) what patient-centric tasks do they perform?\nSetting: Clinical and academic exercise settings worldwide.\nMethods: This multimethod study included a scoping review of PA programs in MBS described in the research literature. Data about job tasks were extracted and provided to 10 experts to sort into categories. Cluster analysis was utilized to find the hierarchical structure of tasks. A Delphi process was used to agree on a final model.\nResults: The majority of PA professionals were exercise physiologists in the USA and physiotherapists or other types of exercise professionals elsewhere. Forty-three tasks were identified, the most reported being: supervision of exercise, fitness testing, and exercise prescription. Seven higher-order categories were determined: (1) Exercise-related health assessment, (2) Body composition and physical fitness assessment, (3) Lifestyle physical activity and sedentary behavior assessment, (4) Education, instruction, and prescription, (5) Exercise monitoring, (6) Behavioral counseling and psychosocial support, and (7) Dietary support. The following statements were rated an average of 9.0, classifying them as \"imperative\": 1) \"Pre- and post-operative PA/exercise guidelines for MBS patients are needed\", 2) \"MBS programs need to include PA/exercise as part of multidisciplinary care\".\nConclusions: The expert group reached a consensus on 7 major classifications of job tasks for the exercise professional. It is important for governing medical associations across the world to formally recognize experienced exercise professionals as playing pivotal roles in continuing, multidisciplinary care for MBS patients. These findings also provide evidence-based information in the effort to solidify these positions within the greater context of healthcare.",
                "disciplines": [
                    "4206",
                    "3202"
                ]
            }
        }
    },
    "12976065": {
        "title": "The Missing Entrepreneurs? The Diversity of Female Entrepreneurship in Europe, 1900-2020",
        "abstract": "Female entrepreneurship is not a recent phenomenon. Nevertheless, we still know little about the historical \ndevelopment of female entrepreneurship, let alone about the explanations behind it. This project will collect new comparable time-series data on female business-owners and innovators in Europe since 1900. Based on this evidence, it will demonstrate the factors that explain the change in female entrepreneurship.",
        "disciplines": [
            "3507"
        ],
        "publications": {
            "10.1111/joes.12620": {
                "title": "Synthesizing explanations behind global gender (in)equality: Identifying the gaps and moving forward with more economic history",
                "abstract": "Abstract This article aims to bridge the mainstream social science and the economic history literatures on the drivers of gender equality across contexts. We discuss the explanations in the social science literature on five central dimensions of global gender equality\u2014health, work, education, marriage, and political representation\u2014and survey the economic history literature that studied these explanations in the historical context. We analyze the commonalities and contradictions in the theoretical and methodological approaches of the two strands. The survey then offers an interdisciplinary theoretical framework that can bridge the two strands. By doing so, the review article discusses how incorporating the economic history literature into the social science literature can improve our current understanding of global gender equality in two ways. First, the long dur\u00e9e perspective provides insight into the diversity in the historical turning points in gender equality across world regions over the 20th century. Second, it suggests that the integration of a historical perspective can tackle the difficulties in isolating causal mechanisms and identify why standard economic and institutional conditions have varying impacts on gender equality outcomes across world regions. It also identifies the limitations in the current social science and economic history literatures and provide directions for future research.",
                "disciplines": [
                    "3502",
                    "3801"
                ]
            }
        }
    },
    "12963419": {
        "title": "Elucidating sex-specific risk for Alzheimer's disease through state-of-the-art genetics and multi-omics",
        "abstract": "ABSTRACT Alzheimer\u2019s disease (AD) manifests itself differently across men and women, but the genetic and molecular factors that drive this remain largely elusive. AD is the most common cause of dementia, affecting over 5 million people in the USA alone, and till today remains essentially untreatable. Because AD has a strong genetic component, with inheritance estimates between 50-80%, studying the genetics of AD can importantly aid the discovery of novel drug targets. However, evidence from various lines of research suggests that sex differences are an integral part of AD. It is therefore crucial to study the genetics of AD in a sex-specific manner, as this will help the field gain important insights into disease pathophysiology, identify novel sex-specific risk factors relevant to personalized genetic medicine, and uncover potential new AD drug targets that may benefit both sexes. To date, surprisingly few sex-specific variants/genes have been identified, which we hypothesize is because prior studies were faced with several obstacles such as data limitations and unexplored research avenues. This project proposes to use big data together with state-of-the-art approaches in order to leverage established sex differences in AD as a means of elucidating novel AD risk genes. Aim 1 will improve on prior sex-stratified genome-wide association studies (GWAS) by using larger sample sizes and extensively harmonized data. This includes a cross-cohort phenotype harmonization and powerful models using age information to improve AD risk associations. In addition, we will, for the first time, explore the role of rare variants on AD in a sex-specific manner. Aim 2 will use parallel strategies to Aim 1, but will focus on the X chromosome, which has remained largely unexplored in the field of AD genetics. For both Aims 1 and 2, we will further validate putative associations by evaluating their sex-specific effects on gene transcript expression and protein levels in brain tissue. Similarly, associations will be validated in a sex-specific manner using AD-relevant endophenotypes (e.g. tau levels in the cerebrospinal fluid) from deeply phenotyped cohorts. Aim 3 will follow a different innovative approach to sex- specific AD gene discovery by identifying sex-specific AD-related protein changes in brain tissue and determining the genetic variants that drive them. The latter variants will then be validated by relating them to risk for AD. The independent phase of this project will focus on the use of multi-omics data to corroborate sex-specific gene associations with AD risk, as well as proteomics data to discover new AD risk genes. Central to the success of this proposal, Dr. Belloy will have the support from an established group of experts in genetics, imaging, and neurology (Dr. Michael Greicius), multi-omics data integration (Dr. Stephen Montgomery), proteomics analyses (Dr. Nicholas Seyfried), sexual dimorphism (Dr. Marcia Stefanick), and rare variant analyses (Dr. Zihuai He), providing him with the necessary skillsets to embark on a career as an independent scientist.",
        "disciplines": [
            "3105"
        ],
        "publications": {
            "10.1101/2024.04.22.24306094": {
                "title": "The Role of X Chromosome in Alzheimer\u2019s Disease Genetics",
                "abstract": "Importance: The X chromosome has remained enigmatic in Alzheimer's disease (AD), yet it makes up 5% of the genome and carries a high proportion of genes expressed in the brain, making it particularly appealing as a potential source of unexplored genetic variation in AD.\nObjectives: Perform the first large-scale X chromosome-wide association study (XWAS) of AD. Primary analyses are non-stratified, while secondary analyses evaluate sex-stratified effects.\nDesign: Meta-analysis of genetic association studies in case-control, family-based, population-based, and longitudinal AD-related cohorts from the US Alzheimer's Disease Genetics Consortium (ADGC) and Alzheimer's Disease Sequencing Project (ADSP), the UK Biobank (UKB), the Finnish health registry (FinnGen), and the US Million Veterans Program (MVP). Risk for AD evaluated through case-control logistic regression analyses. Data were analyzed between January 2023 and March 2024.\nSetting: Genetic data available from high-density single-nucleotide polymorphism (SNP) microarrays and whole-genome sequencing (WGS). Summary statistics for multi-tissue expression and protein quantitative trait loci (QTL) available from published studies, enabling follow-up genetic colocalization analyses.\nParticipants: 1,629,863 eligible participants were selected from referred and volunteer samples, of which 477,596 were excluded for analysis exclusion criteria. Number of participants who declined to participate in original studies was not available.\nMain Outcome and Measures: Risk for AD (odds ratio; OR) with 95% confidence intervals (CI). Associations were considered at X-chromosome-wide (P-value<1e-5) and genome-wide (P-value<5e-8) significance.\nResults: Analyses included 1,152,284 non-Hispanic White European ancestry subjects (57.3% females), including 138,558 cases. 6 independent genetic loci passed X-chromosome-wide significance, with 4 showing support for causal links between the genetic signal for AD and expression of nearby genes in brain and non-brain tissues. One of these 4 loci passed conservative genome-wide significance, with its lead variant centered on an intron of <i>SLC9A7</i> (OR=1.054, 95%-CI=[1.035, 1.075]) and colocalization analyses prioritizing both the <i>SLC9A7</i> and nearby <i>CHST7</i> genes.\nConclusion and Relevance: We performed the first large-scale XWAS of AD and identified the novel <i>SLC9A7</i> locus. <i>SLC9A7</i> regulates pH homeostasis in Golgi secretory compartments and is anticipated to have downstream effects on amyloid beta accumulation. Overall, this study significantly advances our knowledge of AD genetics and may provide novel biological drug targets.",
                "disciplines": [
                    "3105",
                    "4202",
                    "4203",
                    "4905"
                ]
            },
            "10.1007/s00401-024-02721-1": {
                "title": "Rare genetic variation in fibronectin 1 (FN1) protects against APOE\u03b54 in Alzheimer\u2019s disease",
                "abstract": "The risk of developing Alzheimer\u2019s disease (AD) significantly increases in individuals carrying the APOE\u03b54 allele. Elderly cognitively healthy individuals with APOE\u03b54 also exist, suggesting the presence of cellular mechanisms that counteract the pathological effects of APOE\u03b54; however, these mechanisms are unknown. We hypothesized that APOE\u03b54 carriers without dementia might carry genetic variations that could protect them from developing APOE\u03b54-mediated AD pathology. To test this, we leveraged whole-genome sequencing (WGS) data in the National\u00a0Institute on Aging Alzheimer's Disease Family Based Study (NIA-AD\u00a0FBS), Washington Heights/Inwood Columbia Aging Project (WHICAP), and Estudio Familiar de Influencia Genetica en Alzheimer (EFIGA) cohorts and identified potentially protective variants segregating exclusively among unaffected APOE\u03b54 carriers. In homozygous unaffected carriers above 70 years old, we identified 510 rare coding variants. Pathway analysis of the genes harboring these variants showed significant enrichment in extracellular matrix (ECM)-related processes, suggesting protective effects of functional modifications in ECM proteins. We prioritized two genes that were highly represented in the ECM-related gene ontology terms, (FN1) and collagen type VI alpha 2 chain (COL6A2) and are known to be expressed at the blood\u2013brain barrier (BBB), for postmortem validation and in vivo functional studies. An independent analysis in a large cohort of 7185 APOE\u03b54 homozygous carriers found that rs140926439 variant in FN1 was protective of AD (OR\u2009=\u20090.29; 95% CI [0.11, 0.78], P\u2009=\u20090.014) and delayed age at onset of disease by 3.37 years (95% CI [0.42, 6.32], P\u2009=\u20090.025). The FN1 and COL6A2 protein levels were increased at the BBB in APOE\u03b54 carriers with AD. Brain expression of cognitively unaffected homozygous APOE\u03b54 carriers had significantly lower FN1 deposition and less reactive gliosis compared to homozygous APOE\u03b54 carriers with AD, suggesting that FN1 might be a downstream driver of APOE\u03b54-mediated AD-related pathology and cognitive decline. To validate our findings, we used zebrafish models with loss-of-function (LOF) mutations in fn1b\u2014the ortholog for human FN1. We found that fibronectin LOF reduced gliosis, enhanced gliovascular remodeling, and potentiated the microglial response, suggesting that pathological accumulation of FN1 could impair toxic protein clearance, which is ameliorated with FN1 LOF. Our study suggests that vascular deposition of FN1 is related to the pathogenicity of APOE\u03b54, and LOF variants in FN1 may reduce APOE\u03b54-related AD risk, providing novel clues to potential therapeutic interventions targeting the ECM to mitigate AD risk.",
                "disciplines": [
                    "3209"
                ]
            },
            "10.1101/2024.02.28.582621": {
                "title": "Beyond guilty by association at scale: searching for causal variants on the basis of genome-wide summary statistics",
                "abstract": "Understanding the causal genetic architecture of complex phenotypes is essential for future research into disease mechanisms and potential therapies. Here, we present a novel framework for genome-wide detection of sets of variants that carry non-redundant information on the phenotypes and are therefore more likely to be causal in a biological sense. Crucially, our framework requires only summary statistics obtained from standard genome-wide marginal association testing. The described approach, implemented in open-source software, is also computationally efficient, requiring less than 15 minutes on a single CPU to perform genome-wide analysis. Through extensive genome-wide simulation studies, we show that the method can substantially outperform usual two-stage marginal association testing and fine-mapping procedures in precision and recall. In applications to a meta-analysis of ten large-scale genetic studies of Alzheimer's disease (AD), we identified 82 loci associated with AD, including 37 additional loci missed by conventional GWAS pipeline. The identified putative causal variants achieve state-of-the-art agreement with massively parallel reporter assays and CRISPR-Cas9 experiments. Additionally, we applied the method to a retrospective analysis of 67 large-scale GWAS summary statistics since 2013 for a variety of phenotypes. Results reveal the method's capacity to robustly discover additional loci for polygenic traits and pinpoint potential causal variants underpinning each locus beyond conventional GWAS pipeline, contributing to a deeper understanding of complex genetic architectures in post-GWAS analyses.",
                "disciplines": [
                    "4202",
                    "3105"
                ]
            },
            "10.1016/j.neuron.2024.01.008": {
                "title": "APOE loss-of-function variants: Compatible with longevity and associated with resistance to Alzheimer\u2019s disease pathology",
                "abstract": "The \u03b54 allele of apolipoprotein E (APOE) is the strongest genetic risk factor for sporadic Alzheimer's disease (AD). Knockdown of \u03b54 may provide a therapeutic strategy for AD, but the effect of APOE loss of function (LoF) on AD pathogenesis is unknown. We searched for APOE LoF variants in a large cohort of controls and patients with AD and identified seven heterozygote carriers of APOE LoF variants. Five carriers were controls (aged 71-90 years), one carrier was affected by progressive supranuclear palsy, and one carrier was affected by AD with an unremarkable age at onset of 75 years. Two APOE \u03b53/\u03b54 controls carried a stop-gain affecting \u03b54: one was cognitively normal at 90 years and had no neuritic plaques at autopsy; the other was cognitively healthy at 79 years, and lumbar puncture at 76 years showed normal levels of amyloid. These results suggest that \u03b54 drives AD risk through the gain of abnormal function and support \u03b54 knockdown as a viable therapeutic option.",
                "disciplines": [
                    "5202",
                    "3209"
                ]
            },
            "10.1002/alz.13576": {
                "title": "Post\u2010translational modifications linked to preclinical Alzheimer's disease\u2013related pathological and cognitive changes",
                "abstract": "INTRODUCTION: In this study, we leverage proteomic techniques to identify communities of proteins underlying Alzheimer's disease (AD) risk among clinically unimpaired (CU) older adults.\nMETHODS: We constructed a protein co-expression network using 3869 cerebrospinal fluid (CSF) proteins quantified by SomaLogic, Inc., in a cohort of participants along the AD clinical spectrum. We then replicated this network in an independent cohort of CU older adults and related these modules to clinically-relevant outcomes.\nRESULTS: We discovered modules enriched for phosphorylation and ubiquitination that were associated with abnormal amyloid status, as well as p-tau<sub>181</sub> (M4: \u03b2\u00a0=\u00a02.44, p\u00a0&lt;\u00a00.001, M7: \u03b2\u00a0=\u00a02.57, p\u00a0&lt;\u00a00.001) and executive function performance (M4: \u03b2\u00a0=\u00a0-2.00, p\u00a0=\u00a00.005, M7: \u03b2\u00a0=\u00a0-2.39, p\u00a0&lt;\u00a00.001).\nDISCUSSION: In leveraging CSF proteomic data from individuals spanning the clinical spectrum of AD, we highlight the importance of post-translational modifications for early cognitive and pathological changes.",
                "disciplines": [
                    "5202",
                    "3202",
                    "3209"
                ]
            },
            "10.1001/jamaneurol.2023.3599": {
                "title": "APOE Genotype and Alzheimer Disease Risk Across Age, Sex, and Population Ancestry",
                "abstract": "Importance: Apolipoprotein E (APOE)*2 and APOE*4 are, respectively, the strongest protective and risk-increasing, common genetic variants for late-onset Alzheimer disease (AD), making APOE status highly relevant toward clinical trial design and AD research broadly. The associations of APOE genotypes with AD are modulated by age, sex, race and ethnicity, and ancestry, but these associations remain unclear, particularly among racial and ethnic groups understudied in the AD and genetics research fields.\nObjective: To assess the stratified associations of APOE genotypes with AD risk across sex, age, race and ethnicity, and global population ancestry.\nDesign, Setting, Participants: This genetic association study included case-control, family-based, population-based, and longitudinal AD-related cohorts that recruited referred and volunteer participants. Data were analyzed between March 2022 and April 2023. Genetic data were available from high-density, single-nucleotide variant microarrays, exome microarrays, and whole-exome and whole-genome sequencing. Summary statistics were ascertained from published AD genetic studies.\nMain Outcomes and Measures: The main outcomes were risk for AD (odds ratios [ORs]) and risk of conversion to AD (hazard ratios [HRs]), with 95% CIs. Risk for AD was evaluated through case-control logistic regression analyses. Risk of conversion to AD was evaluated through Cox proportional hazards regression survival analyses.\nResults: Among 68\u202f756 unique individuals, analyses included 21\u202f852 East Asian (demographic data not available), 5738 Hispanic (68.2% female; mean [SD] age, 75.4 [8.8] years), 7145 non-Hispanic Black (hereafter referred to as Black) (70.8% female; mean [SD] age, 78.4 [8.2] years), and 34\u202f021 non-Hispanic White (hereafter referred to as White) (59.3% female; mean [SD] age, 77.0 [9.1] years) individuals. There was a general, stepwise pattern of ORs for APOE*4 genotypes and AD risk across race and ethnicity groups. Odds ratios for APOE*34 and AD risk attenuated following East Asian (OR, 4.54; 95% CI, 3.99-5.17),White (OR, 3.46; 95% CI, 3.27-3.65), Black (OR, 2.18; 95% CI, 1.90-2.49) and Hispanic (OR, 1.90; 95% CI, 1.65-2.18) individuals. Similarly, ORs for APOE*22+23 and AD risk attenuated following White (OR, 0.53, 95% CI, 0.48-0.58), Black (OR, 0.69, 95% CI, 0.57-0.84), and Hispanic (OR, 0.89; 95% CI, 0.72-1.10) individuals, with no association for Hispanic individuals. Deviating from the global pattern of ORs, APOE*22+23 was not associated with AD risk in East Asian individuals (OR, 0.97; 95% CI, 0.77-1.23). Global population ancestry could not explain why Hispanic individuals showed APOE associations with less pronounced AD risk compared with Black and White individuals. Within Black individuals, decreased global African ancestry or increased global European ancestry showed a pattern of APOE*4 dosage associated with increasing AD risk, but no such pattern was apparent for APOE*2 dosage with AD risk. The sex-by-age-specific interaction effect of APOE*34 among White individuals (higher risk in women) was reproduced but shifted to ages 60 to 70 years (OR, 1.48; 95% CI, 1.10-2.01) and was additionally replicated in a meta-analysis of Black individuals and Hispanic individuals (OR, 1.72; 95% CI, 1.01-2.94).\nConclusion and Relevance: Through recent advances in AD-related genetic cohorts, this study provided the largest-to-date overview of the association of APOE with AD risk across age, sex, race and ethnicity, and population ancestry. These novel insights are critical to guide AD clinical trial design and research.",
                "disciplines": [
                    "3209",
                    "3202"
                ]
            },
            "10.1186/s40478-023-01626-6": {
                "title": "APOE-\u03b54 and BIN1 increase risk of Alzheimer\u2019s disease pathology but not specifically of Lewy body pathology",
                "abstract": "Lewy body (LB) pathology commonly occurs in individuals with Alzheimer\u2019s disease (AD) pathology. However, it remains unclear which genetic risk factors underlie AD pathology, LB pathology, or AD-LB co-pathology. Notably, whether APOE-\u03b54 affects risk of LB pathology independently from AD pathology is controversial. We adapted criteria from the literature to classify 4,985 subjects from the National Alzheimer\u2019s Coordinating Center (NACC) and the Rush University Medical Center as AD-LB co-pathology (AD+LB+), sole AD pathology (AD+LB\u2013), sole LB pathology (AD\u2013LB+), or no pathology (AD\u2013LB\u2013). We performed a meta-analysis of a genome-wide association study (GWAS) per subpopulation (NACC/Rush) for each disease phenotype compared to the control group (AD\u2013LB\u2013), and compared the AD+LB+ to AD+LB\u2013 groups. APOE-\u03b54 was significantly associated with risk of AD+LB\u2013 and AD+LB+ compared to AD\u2013LB\u2013. However, APOE-\u03b54 was not associated with risk of AD\u2013LB+ compared to AD\u2013LB\u2013 or risk of AD+LB+ compared to AD+LB\u2013. Associations at the BIN1 locus exhibited qualitatively similar results. These results suggest that APOE-\u03b54 is a risk factor for AD pathology, but not for LB pathology when decoupled from AD pathology. The same holds for BIN1 risk variants. These findings, in the largest AD-LB neuropathology GWAS to date, distinguish the genetic risk factors for sole and dual AD-LB pathology phenotypes. Our GWAS meta-analysis summary statistics, derived from phenotypes based on postmortem pathologic evaluation, may provide more accurate disease-specific polygenic risk scores compared to GWAS based on clinical diagnoses, which are likely confounded by undetected dual pathology and clinical misdiagnoses of dementia type.",
                "disciplines": [
                    "3101",
                    "3105"
                ]
            },
            "10.1111/acel.13938": {
                "title": "Sex\u2010 and APOE\u2010specific genetic risk factors for late\u2010onset Alzheimer's disease: Evidence from gene\u2013gene interaction of longevity\u2010related loci",
                "abstract": "Advanced age is the largest risk factor for late-onset Alzheimer's disease (LOAD), a disease in which susceptibility correlates to almost all hallmarks of aging. Shared genetic signatures between LOAD and longevity were frequently hypothesized, likely characterized by distinctive epistatic and pleiotropic interactions. Here, we applied a multidimensional reduction approach to detect gene-gene interactions affecting LOAD in a large dataset of genomic variants harbored by genes in the insulin/IGF1 signaling, DNA repair, and oxidative stress pathways, previously investigated in human longevity. The dataset was generated from a collection of publicly available Genome Wide Association Studies, comprising a total of 2,469 gene variants genotyped in 20,766 subjects of Northwestern European ancestry (11,038 LOAD cases and 9,728 controls). The stratified analysis according to APOE*4 status and sex corroborated evidence that pathways leading to longevity also contribute to LOAD. Among the significantly interacting genes, PTPN1, TXNRD1, and IGF1R were already found enriched in gene-gene interactions affecting survival to old age. Furthermore, interacting variants associated with LOAD in a sex- and APOE-specific way. Indeed, while in APOE*4 female carriers we found several inter-pathway interactions, no significant epistasis was found in APOE*4 negative females; conversely, in males, significant intra- and inter-pathways epistasis emerged according to APOE*4 status. These findings suggest that interactions of risk factors may drive different trajectories of cognitive aging. Beyond helping to disentangle the genetic architecture of LOAD, such knowledge may improve precision in predicting the risk of dementia and enable effective sex- and APOE-stratified preventive and therapeutic interventions for LOAD.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.1101/2023.07.20.23292771": {
                "title": "APOE loss-of-function variants: Compatible with longevity and associated with resistance to Alzheimer\u2019s Disease pathology",
                "abstract": "The \u03b54 allele of apolipoprotein E (<i>APOE</i>) is the strongest genetic risk factor for sporadic Alzheimer's Disease (AD). Knockdown of this allele may provide a therapeutic strategy for AD, but the effect of <i>APOE</i> loss-of-function (LoF) on AD pathogenesis is unknown. We searched for <i>APOE</i> LoF variants in a large cohort of older controls and patients with AD and identified six heterozygote carriers of <i>APOE</i> LoF variants. Five carriers were controls (ages 71-90) and one was an AD case with an unremarkable age-at-onset between 75-79. Two <i>APOE</i> \u03b53/\u03b54 controls (Subjects 1 and 2) carried a stop-gain affecting the \u03b54 allele. Subject 1 was cognitively normal at 90+ and had no neuritic plaques at autopsy. Subject 2 was cognitively healthy within the age range 75-79 and underwent lumbar puncture at between ages 75-79 with normal levels of amyloid. The results provide the strongest human genetics evidence yet available suggesting that \u03b54 drives AD risk through a gain of abnormal function and support knockdown of <i>APOE</i> \u03b54 or its protein product as a viable therapeutic option.",
                "disciplines": [
                    "3101",
                    "3105"
                ]
            },
            "10.1101/2023.07.06.23292312": {
                "title": "A 3\u2019UTR Insertion Is a Candidate Causal Variant at the TMEM106B Locus Associated with Increased Risk for FTLD-TDP",
                "abstract": "Background and Objectives: Single nucleotide variants near <i>TMEM106B</i> associate with risk of frontotemporal lobar dementia with TDP-43 inclusions (FTLD-TDP) and Alzheimer's disease (AD) in genome-wide association studies (GWAS), but the causal variant at this locus remains unclear. Here we asked whether a novel structural variant on <i>TMEM106B</i> is the causal variant.\nMethods: An exploratory analysis identified structural variants on neurodegeneration-related genes. Subsequent analyses focused on an <i>Alu</i> element insertion on the 3'UTR of <i>TMEM106B</i>. This study included data from longitudinal aging and neurogenerative disease cohorts at Stanford University, case-control cohorts in the Alzheimer's Disease Sequencing Project (ADSP), and expression and proteomics data from Washington University in St. Louis (WUSTL). 432 individuals from two Stanford aging cohorts were whole-genome long-read and short-read sequenced. 16,906 samples from ADSP were short-read sequenced. Genotypes, transcriptomics, and proteomics data were available in 1,979 participants from an aging and dementia cohort at WUSTL. Selection criteria were specific to each cohort. In primary analyses, the linkage disequilibrium between the <i>TMEM106B</i> locus variants in the FTLD-TDP GWAS and the 3'UTR insertion was estimated. We then estimated linkage by ancestry in the ADSP and evaluated the effect of the <i>TMEM106B</i> lead variant on mRNA and protein levels.\nResults: The primary analysis included 432 participants (52.5% females, age range 45-92 years old). We identified a 316 bp <i>Alu</i> insertion overlapping the <i>TMEM106B</i> 3'UTR tightly linked with top GWAS variants rs3173615(C) and rs1990622(A). In ADSP European-ancestry participants, this insertion is in equivalent linkage with rs1990622(A) (R<sup>2</sup>=0.962, D'=0.998) and rs3173615(C) (R<sup>2</sup>=0.960, D'=0.996). In African-ancestry participants, the insertion is in stronger linkage with rs1990622(A) (R<sup>2</sup>=0.992, D'=0.998) than with rs3173615(C) (R<sup>2</sup>=0.811, D'=0.994). In public datasets, rs1990622 was consistently associated with TMEM106B protein levels but not with mRNA expression. In the WUSTL dataset, rs1990622 is associated with TMEM106B protein levels in plasma and cerebrospinal fluid, but not with <i>TMEM106B</i> mRNA expression.\nDiscussion: We identified a novel <i>Alu</i> element insertion in the 3'UTR of <i>TMEM106B</i> in tight linkage with the lead FTLD-TDP risk variant. The lead variant is associated with TMEM106B protein levels, but not expression. The 3'UTR insertion is a lead candidate for the causal variant at this complex locus, pending confirmation with functional studies.",
                "disciplines": [
                    "4202",
                    "3105"
                ]
            },
            "10.1101/2023.04.21.23288938": {
                "title": "APOE-\u03b54 and BIN1 increase risk of Alzheimer\u2019s disease pathology but not specifically of Lewy body pathology",
                "abstract": "Lewy body (LB) pathology commonly occurs in individuals with Alzheimer's disease (AD) pathology. However, it remains unclear which genetic risk factors underlie AD pathology, LB pathology, or AD-LB co-pathology. Notably, whether <i>APOE</i> - <i>\u03b5</i> 4 affects risk of LB pathology independently from AD pathology is controversial. We adapted criteria from the literature to classify 4,985 subjects from the National Alzheimer's Coordinating Center (NACC) and the Rush University Medical Center as AD-LB co-pathology (AD <sup>+</sup> LB <sup>+</sup> ), sole AD pathology (AD <sup>+</sup> LB <sup>-</sup> ), sole LB pathology (AD <sup>-</sup> LB <sup>+</sup> ), or no pathology (AD <sup>-</sup> LB <sup>-</sup> ). We performed a meta-analysis of a genome-wide association study (GWAS) per subpopulation (NACC/Rush) for each disease phenotype compared to the control group (AD <sup>-</sup> LB <sup>-</sup> ), and compared the AD <sup>+</sup> LB <sup>+</sup> to AD <sup>+</sup> LB <sup>-</sup> groups. <i>APOE</i> - <i>\u03b5</i> 4 was significantly associated with risk of AD <sup>+</sup> LB <sup>-</sup> and AD <sup>+</sup> LB <sup>+</sup> compared to AD <sup>-</sup> LB <sup>-</sup> . However, <i>APOE</i> - <i>\u03b5</i> 4 was not associated with risk of AD <sup>-</sup> LB <sup>+</sup> compared to AD <sup>-</sup> LB <sup>-</sup> or risk of AD <sup>+</sup> LB <sup>+</sup> compared to AD <sup>+</sup> LB <sup>-</sup> . Associations at the <i>BIN1</i> locus exhibited qualitatively similar results. These results suggest that <i>APOE</i> - <i>\u03b5</i> 4 is a risk factor for AD pathology, but not for LB pathology when decoupled from AD pathology. The same holds for <i>BIN1</i> risk variants. These findings, in the largest AD-LB neuropathology GWAS to date, distinguish the genetic risk factors for sole and dual AD-LB pathology phenotypes. Our GWAS meta-analysis summary statistics, derived from phenotypes based on postmortem pathologic evaluation, may provide more accurate disease-specific polygenic risk scores compared to GWAS based on clinical diagnoses, which are likely confounded by undetected dual pathology and clinical misdiagnoses of dementia type.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.1186/s13024-022-00590-4": {
                "title": "APOE effects on regional tau in preclinical Alzheimer\u2019s disease",
                "abstract": "BackgroundAPOE variants are strongly associated with abnormal amyloid aggregation and additional direct effects of APOE on tau aggregation are reported in animal and human cell models. The degree to which these effects are present in humans when individuals are clinically unimpaired (CU) but have abnormal amyloid (A\u03b2+) remains unclear.MethodsWe analyzed data from CU individuals in the Anti-Amyloid Treatment in Asymptomatic AD (A4) and Longitudinal Evaluation of Amyloid Risk and Neurodegeneration (LEARN) studies. Amyloid PET data were available for 4486 participants (3163 A\u03b2-, 1323 A\u03b2+) and tau PET data were available for a subset of 447 participants (55 A\u03b2-, 392 A\u03b2+). Linear models examined APOE (number of e2 and e4 alleles) associations with global amyloid and regional tau burden in medial temporal lobe (entorhinal, amygdala) and early neocortical regions (inferior temporal, inferior parietal, precuneus). Consistency of APOE4 effects on regional tau were examined in 220 A\u03b2\u00a0+\u2009CU and mild cognitive impairment (MCI) participants from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI).ResultsAPOE2 and APOE4 were associated with lower and higher amyloid positivity rates, respectively. Among A\u03b2+\u2009CU, e2 and e4 were associated with reduced (\u221212 centiloids\u00a0per allele) and greater (+15 centiloids\u00a0per allele) continuous amyloid burden, respectively. APOE2 was associated with reduced regional tau in all regions (-0.05 to -0.09 SUVR per allele), whereas APOE4 was associated with greater regional tau (+0.02 to +0.07 SUVR per allele). APOE differences were confirmed by contrasting e3/e3 with e2/e3 and e3/e4. Mediation analyses among A\u03b2+\u2009s showed that direct effects of e2 on regional tau were present in medial temporal lobe and early neocortical regions, beyond an indirect pathway mediated by continuous amyloid burden. For e4, direct effects on regional tau were only significant in medial temporal lobe. The magnitude of protective e2 effects on regional tau was consistent across brain regions, whereas detrimental e4 effects were greatest in medial temporal lobe. APOE4 patterns were confirmed in A\u03b2+\u2009ADNI participants.ConclusionsAPOE influences early regional tau PET burden, above and beyond effects related to cross-sectional amyloid PET burden. Therapeutic strategies targeting underlying mechanisms related to APOE may modify tau accumulation among A\u03b2+\u2009individuals.",
                "disciplines": [
                    "3101"
                ]
            }
        }
    },
    "13057676": {
        "title": "Detecting Mammographically-Occult Cancer in Women with Dense Breasts Using Digital Breast Tomosynthesis",
        "abstract": "Most women in the USA who have dense breasts at screening mammography receive a letter notifying them that mammography is less effective for them and having dense breasts increases the risk of breast cancer. The letter advises women to talk with their physician whether they should have additional screening with ultrasound or magnetic resonance imaging (MRI). The possible benefit of additional screening is detecting a mammographically occult (MO) cancer. However, the likelihood that a woman has a missed cancer is not known. Thus, women are left with a difficult decision, balancing the uncertain potential benefit of additional screening against the known costs. These known costs are financial (as some states do not cover the supplemental screen) and the risk of an unnecessary biopsy, as the specificity of ultrasound and MRI are lower than mammography. We have developed a novel technique using a Radon Cumulative Distribution Transform (RCDT) to detect MO cancers. The RCDT can highlight subtle suspicious signals by detecting asymmetries between the left and right mammograms. Our technique achieved an area under the ROC curve of 0.81 using screening mammograms. Digital breast tomosynthesis (DBT), a pseudo-3D imaging technique, is replacing mammography in the USA, because of its higher sensitivity and specificity. However, MO cancers still exist in DBT. The goal of our research is to develop imaging biomarkers for MO cancers on screening DBT of women with dense breasts. This would allow women to know the likelihood that they have an MO cancer and, thereby, allow them to make a more informed choice regarding supplemental screening. The key difference between DBT and standard 2D mammography is the available information in the z-direction. Such additional information provides advantages for cancer detection, but it also adds technical complexity when applying RCDT on DBT images. There are three ways to process DBT exams for RCDT: 1) applying RCDT on 2D DBT slices, 2) applying RCDT on synthetic mammograms from DBT, and 3) applying the 3D RCDT on DBT volumes. To develop imaging biomarkers for MO cancer in screening DBT, we need to investigate the optimal method to process DBT for RCDT. We will develop imaging biomarkers for the three methods using a developmental dataset of 900 MO cancer cases (clinical cases read as normal, but the woman has breast cancer detected on her next screening DBT) and 1800 cases (clinical cases read as normal and the woman does not have breast cancer detected on her next two screening DBTs). We will utilize a 2D convolutional neural network (CNN) and a 3D CNN as robust classifiers to analyze the RCDT processed DBT for MO cancer detection. Using a 5-fold cross-validation, we will train CNNs for each method and find the optimal method to process DBT for MO cancer detection. Finally, we will use an independent dataset of 100 cases to validate the classifier. If we are successful, then up to 15 million women each year who have dense breasts will have needed information upon which to base their decision for getting supplemental screening.",
        "disciplines": [
            "3211",
            "4203"
        ],
        "publications": {
            "10.1186/s13058-024-01777-x": {
                "title": "Improving lesion detection in mammograms by leveraging a Cycle-GAN-based lesion remover",
                "abstract": "BackgroundThe wide heterogeneity in the appearance of breast lesions and normal breast structures can confuse computerized detection algorithms. Our purpose was therefore to develop a Lesion Highlighter (LH) that can improve the performance of computer-aided detection algorithms for detecting breast cancer on screening mammograms.MethodsWe hypothesized that a Cycle-GAN based Lesion Remover (LR) could act as an LH, which can improve the performance of lesion detection algorithms. We used 10,310 screening mammograms from 4,832 women that included 4,942 recalled lesions (BI-RADS 0) and 5,368 normal results (BI-RADS 1). We divided the dataset into Train:Validate:Test folds with the ratios of 0.64:0.16:0.2. We segmented image patches (400\u2009\u00d7\u2009400 pixels) from either lesions marked by MQSA radiologists or normal tissue in mammograms. We trained a Cycle-GAN to develop two GANs, where each GAN transferred the style of one image to another. We refer to the GAN transferring the style of a lesion to normal breast tissue as the LR. We then highlighted the lesion by color-fusing the mammogram after applying the LR to its original. Using ResNet18, DenseNet201, EfficientNetV2, and Vision Transformer as backbone architectures, we trained three deep networks for each architecture, one trained on lesion highlighted mammograms (Highlighted), another trained on the original mammograms (Baseline), and Highlighted and Baseline combined (Combined). We conducted ROC analysis for the three versions of each deep network on the test set.ResultsThe Combined version of all networks achieved AUCs ranging from 0.963 to 0.974 for identifying the image with a recalled lesion from a normal breast tissue image, which was statistically improved (p-value\u2009<\u20090.001) over their Baseline versions with AUCs that ranged from 0.914 to 0.967.ConclusionsOur results showed that a Cycle-GAN based LR is effective for enhancing lesion conspicuity and this can improve the performance of a detection algorithm.",
                "disciplines": [
                    "3211"
                ]
            },
            "10.1117/1.jmi.10.5.054503": {
                "title": "Impact of GAN artifacts for simulating mammograms on identifying mammographically occult cancer",
                "abstract": "Purpose: Generative adversarial networks (GANs) can synthesize various feasible-looking images. We showed that a GAN, specifically a conditional GAN (CGAN), can simulate breast mammograms with normal, healthy appearances and can help detect mammographically-occult (MO) cancer. However, similar to other GANs, CGANs can suffer from various artifacts, e.g., checkerboard artifacts, that may impact the quality of the final synthesized image, as well as the performance of detecting MO cancer. We explored the types of GAN artifacts that exist in mammogram simulations and their effect on MO cancer detection.\nApproach: We first trained a CGAN using digital mammograms (FFDMs) of 1366 women with normal/healthy breasts. Then, we tested the trained CGAN on an independent MO cancer dataset with 333 women with dense breasts (97 MO cancers). We trained a convolutional neural network (CNN) on the MO cancer dataset, in which real and simulated mammograms were fused, to identify women with MO cancer. Then, a radiologist who was independent of the development of the CGAN algorithms evaluated the entire MO cancer dataset to identify and annotate artifacts in the simulated mammograms.\nResults: We found four artifact types, including checkerboard, breast boundary, nipple-areola complex, and black spots around calcification artifacts, with an overall incidence rate over 69% (the individual incident rate ranged from 9% to 53%) from both normal and MO cancer samples. We then evaluated their potential impact on MO cancer detection. Even though various artifacts existed in the simulated mammogram, we found that it still provided complementary information for MO cancer detection when it was combined with the real mammograms.\nConclusions: We found that artifacts were pervasive in the CGAN-simulated mammograms. However, they did not negatively affect our MO cancer detection algorithm; the simulated mammograms still provided complementary information for MO cancer detection when combined with real mammograms.",
                "disciplines": [
                    "3211"
                ]
            }
        }
    },
    "12969747": {
        "title": "Four-dimensional multi-modality microimaging-microdevice system for high throughput drug screening in vivo",
        "abstract": "Project Summary Guigen Liu, Ph.D., is a mechanical and optical engineer whose overarching career goal is to develop and translate optical fiber based biomedical optical imaging and sensing technologies. The research, entitled \u201cFour- dimensional multi-modality microimaging-microdevice system for high throughput drug screening in vivo\u201d, combines the advanced optical microimaging system with an emerging microdevice, which has the huge potential impact on drug development, individualized health care, and fundamental biomedical research. Candidate: Dr. Liu is an Instructor at the Radiology Department of Brigham and Women\u2019s Hospital, Harvard Medical School. During his previous postdoctoral training, he and colleagues pioneered a silicon-tipped fiber- optic sensing platform featuring high speed and high resolution, which earned the 2015 Alan Berman Research Publication Award from the U.S. Naval Research Laboratory. While Dr. Liu has shown a successful track of record in engineering, his training in biomedical research is limited. Through the career development plans: 1) Gain more experience in two-photon fluorescence and Raman microimaging; 2) Learn to design and implement the microimaging-microdevice system; 3) Establish in vivo drug delivery and tissue response testing skills; and 4) Enhance leadership and career development skills, Dr. Liu will launch his independent career in the new field. Mentors/Environment: Dr. Liu has assembled a strong team of mentors to guide him through the proposed training and research activities. The proposed career development plan includes the rich resources available through Brigham & Women\u2019s Hospital and Harvard Medical School, the Tearney Laboratory at the Wellman Center for Photomedicine, and the Laser Biomedical Research Center at Massachusetts Institute of Technology. Research: The research seeks to build an in situ multi-modality optical histological laboratory for the biomedical microdevice, through four specific research aims: 1) To implement quantitative 4D multi-color two-photon fluorescence microimaging; 2) To test drug efficacy in vivo using the 4D two-photon fluorescence MI-MD system; 3) To develop label-free MI-MD system using Raman microscopy; and 4) To investigate microimaging through long and flexible GRIN probes. Completion of these aims will push the microdevice a big step toward potential clinical adoptions in the future. Summary: Innovation of the proposed research is the integration of 3D microimaging and microdevice for 4D testing of drug efficacy and tissue response in vivo, which will meet the pressing needs of high throughput drug screening. The candidate has identified a group of experts who provide complementary training and mentoring on all the aspects for him to complete the proposed research and develop an independent research career.",
        "disciplines": [
            "4003"
        ],
        "publications": {
            "10.1002/mp.17040": {
                "title": "Superparamagnetic iron oxide nanoparticle enhanced percutaneous microwave ablation: Ex\u2010vivo characterization using magnetic resonance thermometry",
                "abstract": "BACKGROUND: Percutaneous microwave ablation (pMWA) is a minimally invasive procedure that uses a microwave antenna placed at the tip of a needle to induce lethal tissue heating. It can treat cancer and other diseases with lower morbidity than conventional surgery, but one major limitation is the lack of control over the heating region around the ablation needle. Superparamagnetic iron oxide nanoparticles have the potential to enhance and control pMWA heating due to their ability to absorb microwave energy and their ease of local delivery.\nPURPOSE: The purpose of this study is to experimentally quantify the capabilities of FDA-approved superparamagnetic iron oxide Feraheme nanoparticles (FHNPs) to enhance and control pMWA heating. This study aims to determine the effectiveness of locally injected FHNPs in increasing the maximum temperature during pMWA and to investigate the ability of FHNPs to create a controlled ablation zone around the pMWA needle.\nMETHODS: PMWA was performed using a clinical ablation system at 915\u00a0MHz in ex-vivo porcine liver tissues. Prior to ablation, 50\u00a0uL 5\u00a0mg/mL FHNP injections were made on one side of the pMWA needle via a 23-gauge needle. Local temperatures at the FHNP injection site were directly compared to equidistant control sites without FHNP. First, temperatures were compared using directly inserted thermocouples. Next, temperatures were measured non-invasively using magnetic resonance thermometry (MRT), which enabled comprehensive four-dimensional (volumetric and temporal) assessment of heating effects relative to nanoparticle distribution, which was quantified using dual-echo ultrashort echo time (UTE) subtraction MR imaging. Maximum heating within FHNP-exposed tissues versus control tissues were compared at multiple pMWA energy delivery settings. The ability to generate a controlled asymmetric ablation zone using multiple FHNP injections was also tested. Finally, intra-procedural MRT-derived heat maps were correlated with gold standard gross pathology using Dice similarity analysis.\nRESULTS: Maximum temperatures at the FHNP injection site were significantly higher than control (without FHNP) sites when measured using direct thermocouples (93.1\u00a0\u00b1\u00a06.0\u00b0C vs. 57.2\u00a0\u00b1\u00a08.1\u00b0C, p\u00a0=\u00a00.002) and using non-invasive MRT (115.6\u00a0\u00b1\u00a013.4\u00b0C vs. 49.0\u00a0\u00b1\u00a010.6\u00b0C, p\u00a0=\u00a00.02). Temperature difference between FHNP-exposed and control sites correlated with total energy deposition: 66.6\u00a0\u00b1\u00a017.6\u00b0C, 58.1\u00a0\u00b1\u00a08.5\u00b0C, and 20.8\u00a0\u00b1\u00a09.2\u00b0C at high (17.5\u00a0\u00b1\u00a02.2\u00a0kJ), medium (13.6\u00a0\u00b1\u00a01.8\u00a0kJ), and low (8.8\u00a0\u00b1\u00a01.1\u00a0kJ) energies, respectively (all pairwise p\u00a0<\u00a00.05). Each FHNP injection resulted in a nanoparticle distribution within 0.9\u00a0\u00b1\u00a00.2\u00a0cm radially of the injection site and a local lethal heating zone confined to within 1.1\u00a0\u00b1\u00a00.4\u00a0cm radially of the injection epicenter. Multiple injections enabled a controllable, asymmetric ablation zone to be generated around the ablation needle, with maximal ablation radius on the FHNP injection side of 1.6\u00a0\u00b1\u00a00.2\u00a0cm compared to 0.7\u00a0\u00b1\u00a00.2\u00a0cm on the non-FHNP side (p\u00a0=\u00a00.02). MRT intra-procedural predicted ablation zone correlated strongly with post procedure gold-standard gross pathology assessment (Dice similarity 0.9).\nCONCLUSIONS: Locally injected FHNPs significantly enhanced pMWA heating in liver tissues, and were able to control the ablation zone shape around a pMWA needle. MRI and MRT allowed volumetric real-time visualization of both FHNP distribution and FHNP-enhanced pMWA heating that was useful for intra-procedural monitoring. This work strongly supports further development of a FHNP-enhanced pMWA paradigm; as all individual components of this approach are approved for patient use, there is low barrier for clinical translation.",
                "disciplines": [
                    "4003"
                ]
            }
        }
    },
    "12969822": {
        "title": "Implementation and Effectiveness of Mindfulness Oriented Recovery Enhancement as an Adjunct to Methadone Treatment for Opioid Use Disorder",
        "abstract": "PROJECT SUMMARY The United States is experiencing an opioid use and overdose crisis. To address this crisis, programs that provide medication for opioid use disorder (MOUD) are being expanded and enhanced. MOUD is the most effective intervention for an OUD, and methadone treatment (MT) is the most commonly prescribed MOUD; however, approximately half of people who begin MT discontinue within a year, and half of people retained in MT use opioids within six months. Physical pain, emotion dysregulation, and reward processing deficits, affecting most people on MT, could be contributing to their ongoing opioid use. Novel behavioral interventions that address physical pain, emotion dysregulation, reward processing deficits and opioid use among people on MOUD are needed. Mindfulness-Oriented Recovery Enhancement (MORE) integrates training in mindfulness, reappraisal, and savoring skills into an 8-week group therapy designed to remediate hedonic dysregulation in brain reward systems underpinning OUD. Across multiple trials, MORE has demonstrated efficacy for reducing opioid use, craving, emotional distress, and pain in other healthcare settings. Our R21 pilot randomized controlled trial of MORE was the first to demonstrate MORE\u2019s feasibility and acceptability as delivered in MT clinics, with indications of preliminary efficacy for decreasing drug use, craving, depression, anxiety, and pain for people with OUD. Further, expedited implementation and dissemination of effective interventions is needed. However, uptake of novel interventions may be slow in MT because time and resources are often limited. Therefore, to best address potential implementation issues and to optimize future MORE implementation and dissemination, in this study, we will utilize a Type 2, Hybrid Implementation-Effectiveness study design. We will not only evaluate MORE\u2019s effectiveness but also assess barriers and facilitators to integrating MORE into MT and evaluate the impact of a sustainable train-the-trainer model on provider burden, intervention fidelity and engagement, and patient outcomes. We will randomize MT clinicians to receive training in 1) a higher intensity MORE implementation strategy consisting of a train-the- trainer model with training in the full MORE treatment manual plus supervision and feedback or 2) a minimal intensity implementation strategy consisting of a simple, scripted mindfulness practice (SMP) extracted from the MORE treatment manual with minimal training, no supervision, and minimal feedback. Specifically, we aim to: 1) using a RE-AIM (reach, effectiveness, adoption, implementation, and maintenance) framework, examine barriers and facilitators to implementation of MORE and SMP in MT and evaluate strategies for optimizing training, fidelity, and engagement, 2) optimize existing MORE and SMP training and implementation toolkits, including adaptable resources that can accelerate the translation of evidence into practice, and 3) evaluate effectiveness and treatment fidelity of a higher intensity MORE implementation strategy versus a lower intensity SMP implementation strategy as an adjunct to MT (N=420).",
        "disciplines": [
            "3214",
            "5202"
        ],
        "publications": {
            "10.1016/j.brat.2024.104494": {
                "title": "Mindfulness-induced self-transcendence promotes universal love with consequent effects on opioid misuse",
                "abstract": "In addition to its health benefits, mindfulness has been theorized in classical contemplative frameworks to elicit self-transcendent experiences as a means of promoting universal love and compassion. Increasing feelings of love may be especially clinically relevant for the treatment of opioid misuse, in that addictive use of opioids dysregulates neurobiological processes implicated in the experience of love. Here we tested these hypotheses in a secondary analysis (n\u00a0=\u00a0187) of data from a randomized clinical trial of Mindfulness-Oriented Recovery Enhancement (MORE) versus supportive psychotherapy for comorbid opioid misuse and chronic pain. At pre- and post-treatment, participants completed a measure of state self-transcendence immediately following a laboratory-based mindfulness task. Through 9-month follow-up, we assessed changes in universal love and opioid misuse. Participants also completed ecological momentary assessments of opioid craving during the 8-week study interventions and for the following month. Compared to supportive psychotherapy, participants in MORE reported significantly greater increases in mindfulness-induced self-transcendence, which mediated the effect of MORE on increased feelings of universal love. In turn, increases in universal love significantly predicted decreased opioid craving and lower odds opioid misuse through 1- and 9-month follow-ups, respectively. Findings suggest mindfulness-induced self-transcendence may promote feelings of universal love, with possible downstream benefits on reducing addictive behavior.",
                "disciplines": [
                    "5203"
                ]
            },
            "10.1176/appi.ajp.20230272": {
                "title": "Mindfulness-Oriented Recovery Enhancement for Veterans and Military Personnel on Long-Term Opioid Therapy for Chronic Pain: A Randomized Clinical Trial",
                "abstract": "OBJECTIVE: This randomized clinical trial evaluated the efficacy of Mindfulness-Oriented Recovery Enhancement (MORE) among past and present U.S. military personnel with prescriptions for long-term opioid therapy for chronic pain.\nMETHODS: In this clinical trial, 230 past and present military personnel with prescriptions for long-term opioid therapy were randomized in a 1:1 ratio to MORE or supportive psychotherapy (initially delivered in person and then via videoconferencing after the onset of the COVID-19 pandemic). Primary outcomes were chronic pain, measured by the Brief Pain Inventory, and aberrant drug-related behaviors, measured by the Current Opioid Misuse Measure, through 8 months of follow-up. Opioid dose was a key secondary outcome. Other outcomes included psychiatric symptoms, catastrophizing, positive affect, ecological momentary assessments of opioid craving, and opioid attentional bias.\nRESULTS: MORE was superior to supportive psychotherapy through the 8-month follow-up in reducing pain-related functional interference, pain severity, and opioid dose. MORE reduced daily opioid dose by 20.7%, compared with a dose reduction of 3.9% with supportive psychotherapy. Although there was no overall between-group difference in opioid misuse, the in-person MORE intervention outperformed supportive psychotherapy for reducing opioid misuse. MORE reduced anhedonia, pain catastrophizing, craving, and opioid attentional bias and increased positive affect to a greater extent than supportive psychotherapy. MORE also modulated therapeutic processes, including mindful reinterpretation of pain sensations, nonreactivity, savoring, positive attention, and reappraisal.\nCONCLUSIONS: Among past and present U.S. military personnel, MORE led to sustained decreases in chronic pain, opioid use, craving, and opioid cue reactivity. MORE facilitated opioid dose reduction while preserving adequate pain control and preventing mood disturbances, suggesting its utility for safe opioid tapering.",
                "disciplines": [
                    "5203",
                    "3202",
                    "3214"
                ]
            },
            "10.1001/jamapsychiatry.2023.5138": {
                "title": "Telehealth Mindfulness-Oriented Recovery Enhancement vs Usual Care in Individuals With Opioid Use Disorder and Pain",
                "abstract": "Importance: Methadone treatment (MT) fails to address the emotion dysregulation, pain, and reward processing deficits that often drive opioid use disorder (OUD). New interventions are needed to address these factors.\nObjective: To evaluate the efficacy of MT as usual (usual care) vs telehealth Mindfulness-Oriented Recovery Enhancement (MORE) plus usual care among people with an OUD and pain.\nDesign, Setting, and Participants: This study was a randomized clinical trial conducted from August 2020 to June 2022. Participants receiving MT for OUD and experiencing chronic pain were recruited at 5 clinics in New Jersey.\nInterventions: In usual care, participants received MT, including medication and counseling. Participants receiving MORE plus usual care attended 8 weekly, 2-hour telehealth groups that provided training in mindfulness, reappraisal, and savoring in addition to usual care.\nMain Outcomes and Measure: Primary outcomes were return to drug use and MT dropout over 16 weeks. Secondary outcomes were days of drug use, methadone adherence, pain, depression, and anxiety. Analyses were based on an intention-to-treat approach.\nResults: A total of 154 participants (mean [SD] age, 48.5 [11.8] years; 88 female [57%]) were included in the study. Participants receiving MORE plus usual care had significantly less return to drug use (hazard ratio [HR],\u20090.58; 95% CI, 0.37-0.90; P\u2009=\u2009.02) and MT dropout (HR,\u20090.41; 95% CI, 0.18-0.96; P\u2009=\u2009.04) than those receiving usual care only after adjusting for a priori-specified covariates (eg, methadone dose and recent drug use, at baseline). A total of 44 participants (57.1%) in usual care and 39 participants (50.6%) in MORE plus usual care returned to drug use. A total of 17 participants (22.1%) in usual care and 10 participants (13.0%) in MORE plus usual care dropped out of MT. In zero-inflated models, participants receiving MORE plus usual care had significantly fewer days of any drug use (ratio of means\u2009=\u20090.58; 95% CI, 0.53-0.63; P\u2009<\u2009.001) than those receiving usual care only through 16 weeks. A significantly greater percentage of participants receiving MORE plus usual care maintained methadone adherence (64 of 67 [95.5%]) at the 16-week follow-up than those receiving usual care only (56 of 67 [83.6%]; \u03c72\u2009=\u20094.49; P\u2009=\u2009.04). MORE reduced depression scores and ecological momentary assessments of pain through the 16-week follow-up to a significantly greater extent than usual care (group \u00d7 time F2,272\u2009=\u20093.13; P\u2009=\u2009.05 and group \u00d7 time F16,13000\u2009=\u20096.44; P\u2009<\u2009.001, respectively). Within the MORE plus usual care group, EMA pain ratings decreased from a mean (SD) of 5.79 (0.29) at baseline to 5.17 (0.30) at week 16; for usual care only, pain decreased from 5.19 (0.28) at baseline to 4.96 (0.29) at week 16. Within the MORE plus usual care group, mean (SD) depression scores were 22.52 (1.32) at baseline and 18.98 (1.38) at 16 weeks. In the usual care-only group, mean (SD) depression scores were 22.65 (1.25) at baseline and 20.03 (1.27) at 16 weeks. Although anxiety scores increased in the usual care-only group and decreased in the MORE group, this difference between groups did not reach significance (group \u00d7 time unadjusted F2,272\u2009= 2.10; P= .12; Cohen d = .44; adjusted F2,268 = 2.33; P = .09). Within the MORE plus usual care group, mean (SD) anxiety scores were 25.5 (1.60) at baseline and 23.45 (1.73) at 16 weeks. In the usual care-only group, mean (SD) anxiety scores were 23.27 (1.75) at baseline and 24.07 (1.73) at 16 weeks.\nConclusions and Relevance: This randomized clinical trial demonstrated that telehealth MORE was a feasible adjunct to MT with significant effects on drug use, pain, depression, treatment retention, and adherence.\nTrial Registration: ClinicalTrials.gov Identifier: NCT04491968.",
                "disciplines": [
                    "4203"
                ]
            },
            "10.1016/j.addbeh.2023.107911": {
                "title": "Alcohol consumption and opioid craving among chronic pain patients prescribed long-term opioid therapy",
                "abstract": "BACKGROUND: Concurrent use of alcohol with opioids is common among chronic pain patients, heightening the risk for disordered opioid use and overdose, yet the relationship between alcohol consumption and opioid craving among chronic pain patients remains largely unexplored. Here we examined the relationship between alcohol consumption and opioid craving among chronic pain patients on long-term opioid therapy.\nMETHODS: A cross-sectional study was conducted with 335 chronic pain patients on long-term opioid therapy. Participants completed the Timeline Followback to assess alcohol consumption, as well as measures of opioid craving, pain severity, and pain interference. Linear regression analyses examined the relationship between alcohol consumption and opioid craving, controlling for pain severity, pain interference, and opioid misuse severity.\nRESULTS: Alcohol consumption (total number of drinks and amount consumed in one sitting) was positively associated with opioid craving (p\u00a0<\u00a00.001 and p\u00a0=\u00a00.005, respectively). Pain severity did not predict opioid craving. The relationship between alcohol consumption and opioid craving remained significant after controlling for pain severity, pain interference, and opioid misuse severity.\nCONCLUSION: Alcohol consumption is linked with more severe opioid craving among chronic pain patients prescribed long-term opioid therapy. Patients receiving opioid analgesics should be carefully screened for co-use of alcohol.",
                "disciplines": [
                    "5202",
                    "5203",
                    "4206"
                ]
            },
            "10.1016/j.explore.2023.11.001": {
                "title": "Mindfulness-oriented recovery enhancement in opioid use disorder: Extended emotional regulation and neural effects and immediate effects of guided meditation in a pilot sample",
                "abstract": "OBJECTIVE: Mindfulness-Oriented Recovery Enhancement (MORE) is an efficacious intervention to aid recovery from substance use disorder. This study in a pilot sample of individuals in treatment for opioid use disorder (OUD) characterizes longer-term changes after the MORE intervention and immediate effects of a brief MORE guided meditation session.\nDESIGN: Twelve female participants in residential treatment for OUD completed an 8-week MORE intervention. Participants completed two sessions: one before and one after the 8-week MORE intervention. Each session included an emotional regulation questionnaire outside an MRI scanner first and then a 10-minute guided MORE meditation inside the scanner during which functional magnetic resonance imaging (fMRI) data were collected. Emotional regulation was measured after 8-weeks of MORE intervention. In addition, functional connectivity (i.e. correlated fMRI signal) between regions in a hypothesized affect regulation network was measured during the meditation state to assess change in brain network function due to 8-weeks of MORE. For each 10-min guided meditation, we also assessed their mood and opioid craving.\nRESULTS: Nine participants completed all measurements. Participants' emotional regulation difficulty significantly decreased after 8-weeks of MORE intervention. Furthermore, after 8-weeks of MORE, there was significantly increased connectivity between left ventromedial prefrontal cortex and left amygdala and between left ventrolateral prefrontal cortex and left nucleus accumbens captured during a meditation state. In both sessions, positive mood significantly increased after 10-min of guided mediation, however opioid craving was not significantly influenced.\nCONCLUSIONS: This pilot study characterizes potential benefits of 8-week MORE intervention in improving emotional regulation difficulty and brain function. A 10-min guided MORE meditation may immediately improve mood, with potential to reduce acute stress- or cue-provoked craving. These results warrant future studies with larger sample size.",
                "disciplines": [
                    "4208"
                ]
            },
            "10.1038/s44220-023-00084-2": {
                "title": "Mindfulness-Oriented Recovery Enhancement reduces post-traumatic stress via reappraisal among patients with chronic pain and co-occurring opioid misuse",
                "abstract": "Chronic pain and post-traumatic stress disorder (PTSD) are co-occurring conditions that exacerbate the risk of opioid misuse. In this secondary analysis of a randomized clinical trial (NCT02602535), we examined the efficacy of Mindfulness-Oriented Recovery Enhancement (MORE) for reducing PTSD symptoms in patients with chronic pain who misused opioids (N\u2009=\u2009241) and who were randomized to MORE or supportive group psychotherapy. Self-reported cognitive reappraisal and skin conductance during an emotion regulation task were tested as mediators of the effect of MORE on changes in PTSD symptoms, and changes in PTSD symptoms were tested as a mediator of the effect of MORE on opioid misuse. MORE led to larger improvements in PTSD symptoms than supportive group psychotherapy across 9\u2009months of follow-up, with 59% of those meeting criteria for a PTSD diagnosis showing clinically significant reductions in PTSD symptoms following treatment with MORE. Changes in reappraisal mediated the effect of MORE on PTSD symptoms, which in turn mediated reduced opioid misuse following MORE. Enhancing reappraisal through MORE may be efficacious for reducing PTSD in opioid-treated chronic pain.",
                "disciplines": [
                    "5203",
                    "3214"
                ]
            },
            "10.1007/s40429-023-00501-7": {
                "title": "The Effects of Mindfulness-Based Intervention on Emotion-Related Impulsivity in Addictive Disorders",
                "abstract": "Purpose of ReviewEmotion-related impulsivity is a well-established risk factor for a multitude of addictive disorders. Mindfulness-based interventions (MBIs) target a number of interrelated processes involved in both impulsivity and addiction, suggesting that they may be especially well-suited to address this confluence. The aim of this paper was to review the effects of MBIs on emotion-driven impulsivity in addiction.Recent FindingsMindfulness training has been shown to counter a number of neurocognitive mechanisms linked with addiction and emotion-driven impulsivity, including cognitive control, attention regulation, response inhibition, negative urgency, and positive urgency.SummaryInterventions that address emotion-driven impulsivity may offer substantial benefits across a wide range of addictive disorders. MBIs have emerged as a promising means for countering impulsivity in addiction. However, more research is needed to better understand how MBIs may impact emotion-related impulsivity and, in turn, how these changes impact addictive behaviors.",
                "disciplines": [
                    "5202"
                ]
            },
            "10.1016/j.drugalcdep.2023.109890": {
                "title": "To be aware, or to accept, that is the question: Differential roles of awareness of automaticity and pain acceptance in opioid misuse",
                "abstract": "BACKGROUND: Individuals with chronic low back pain (CLBP) are commonly prescribed long-term opioid therapy (LTOT) for analgesia, placing this population at increased risk for opioid misuse and opioid use disorder. Acceptance of aversive experiences (e.g., chronic pain) and awareness of automatic thoughts and behaviors (i.e., automaticity) are two facets of dispositional mindfulness that may serve as protective mechanisms against opioid misuse risk. Therefore, the aim of the current study was to examine the differential contributions of these constructs to opioid misuse risk among adults with CLBP receiving LTOT.\nMETHODS: Data were obtained from a sample of 770 adults with opioid-treated CLBP. Bivariate correlations and hierarchical linear regression analyses were used to determine whether chronic pain acceptance and awareness of automatic thoughts and behaviors explained a statistically significant portion of variance in opioid misuse risk after accounting for the effects of other relevant confounders.\nRESULTS: Hierarchical regression results revealed that chronic pain acceptance and awareness of automatic thoughts and behaviors contributed a significant portion in the variance of opioid misuse risk. Awareness of automatic thoughts and behaviors was negatively associated with opioid misuse risk, such that individuals with lower levels of awareness of automaticity were at higher risk of opioid misuse. By contrast, pain acceptance was not associated with opioid misuse.\nCONCLUSIONS: Findings suggest that awareness of automaticity may buffer against opioid misuse risk. Interventions designed to strengthen awareness of automaticity (e.g., mindfulness-based interventions) might be especially efficacious among this population.",
                "disciplines": [
                    "3214",
                    "3202"
                ]
            }
        }
    },
    "12929089": {
        "title": "Collaborative Research: SaTC: CORE: Small: Bankrupting Attackers in Dynamic Networks",
        "abstract": "In dynamic computer networks, participants may freely join and depart with little administrative control by the network, while enjoying significant anonymity. This makes dynamic networks vulnerable to the Sybil attack, where an adversary misrepresents itself as multiple participants in order to disrupt the network. Many Sybil defenses employ resource burning (RB), which is the verifiable expenditure of a network resource, such as computing power, computer memory, or bandwidth. Unfortunately, existing approaches require legitimate participants to constantly perform RB, regardless of whether an attack is occurring. The goal of this project is to design new Sybil defenses that are scalable; that is, the amount of RB is low in the absence of malicious behavior, and grows slowly as a function of the resources expended by the adversary to launch its attack. The outcomes of this research have the potential to secure a broad range of dynamic networks, such as content-sharing systems, e-commerce review platforms, and public-access server settings. This project will foster collaboration between cybersecurity practitioners and academia in the form of two research workshops. The objectives of this project are also integrated with curriculum development, along with research opportunities for both undergraduate and graduate students. Three general application areas are addressed under this project: efficient group maintenance for secure peer-to-peer networks; defending against spam in e-commerce review systems; and cloud-based methods for mitigating denial-of-service attacks. In each area, defenses will be designed that protect critical security invariants at an RB cost to legitimate participants that is scalable: growing slowly with both the RB cost paid by an attacker and the rate at which legitimate participants join and depart the system. To achieve this, the project leverages a novel framework, whereby the amount of adversarial activity is estimated, and then participants are charged an RB cost based on this estimate. This framework can leverage existing machine learning (ML) results to estimate adversarial activity. Importantly, the guarantees provided by these defenses hold over persistent attacks, even with ML error. The theoretical components of this research effort will be complemented by empirical evaluations of the proposed defenses. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4604"
        ],
        "publications": {
            "10.1145/3631461.3631550": {
                "title": "Defending Hash Tables from Subterfuge with Depth Charge",
                "abstract": "We consider the problem of defending a hash table against a Byzantine attacker that is trying to degrade the performance of query, insertion and deletion operations. Our defense makes use of resource burning (RB)\u2014the verifiable expenditure of network resources\u2014where the issuer of a request incurs some RB cost. Our algorithm, Depth Charge, charges RB costs for operations based on the depth of the appropriate object in the list that the object hashes to in the table. By appropriately setting the RB costs, our algorithm mitigates the impact of an attacker on the hash table\u2019s performance. In particular, in the presence of a significant attack, our algorithm incurs a cost which is asymptotically less that the attacker\u2019s cost.",
                "disciplines": [
                    "4606"
                ]
            },
            "10.1016/j.jcss.2023.02.004": {
                "title": "Bankrupting Sybil despite churn",
                "abstract": "A Sybil attack occurs when an adversary controls multiple system identifiers (IDs). Limiting the number of Sybil (bad) IDs to a minority is critical for tolerating malicious behavior. A popular tool for enforcing a bad minority is resource burning (RB): the verifiable consumption of a network resource. Unfortunately, typical RB defenses require non-Sybil (good) IDs to consume at least as many resources as the adversary. We present a new defense, Ergo, that guarantees (1) there is always a bad minority; and (2) during a significant attack, the good IDs consume asymptotically less resources than the bad. Specifically, despite high churn, the good-ID RB rate is O ( T J + J ) , where T is the adversary's RB rate, and J is the good-ID join rate. We show this RB rate is asymptotically optimal for a large class of algorithms, and we empirically demonstrate the benefits of Ergo.",
                "disciplines": [
                    "4604"
                ]
            }
        }
    },
    "12965173": {
        "title": "Novel targets of CRL4 ligase within Cohesinopathy pathways",
        "abstract": "Every year, approximately ~120,000 infants are born with birth defects that require special care and interventions to survive. In fact, birth defects are the leading cause of infant death. Thus, developmental maladies represent a significant emotional and financial burden on both families and the health care system. Transcription dysregulation, or gene mutations affecting developmental programs, account for the majority of birth defects. While numerous gene mutations that underlie developmental maladies have been identified, this often does not provide insight into treatments or symptom amelioration through pharmacological approaches. Here, we leverage our expertise on two related genetic syndromes, Roberts Syndrome (RBS) and Cornelia de Lange Syndrome (CdLS). RBS and CdLS patients exhibit a range of severe phenotypes that include craniofacial defects (microcephaly, eye defects, hearing loss), reduced limb size (phocomelia), abnormalities of the heart, GI and respiratory tracts, and intellectual disabilities. The genetic basis of RBS and CdLS are known - both arise through mutation of a cohesin-based pathway that regulates gene transcription and ensures genome integrity. We recently discovered that the cohesin pathway regulates the transcription of ddb1 - encoding a key component of the Cullin4 Ring Ligase (CRL4) ubiquitination complex. We hypothesize that RBS (esco2 mutated) and CdLS (smc3 mutated), and likely other developmental maladies, arise in large part through reduced CRL4 activity. In support of this hypothesis, exogenous expression of ddb1 reduces the severity of developmental defects that otherwise arise in smc3 knockdown zebrafish embryos. We performed liquid chromatography\u2013mass spectrometry on embryos knocked down for esco2 (RBS), smc3 (CdLS) and ddb1. We obtained a prioritized list of candidates, common across all treatments, that we predict are downstream of CRL4 activity and involved in RBS/CdLS phenotypes. In Specific Aim 1 of this proposal, we validate the LC-MS data and further test the extent to which knockdown of these targets impact RBS/CdLS-type developmental defects in zebrafish embryos simultaneously reduced in either esco2 or smc3 expression. In Specific Aim 2, we test our hypothesis that exogenous expression of these candidates is teratogenic. In combination, these studies will reveal new targets through which birth defect severity can be reduced.",
        "disciplines": [
            "3213",
            "3105"
        ],
        "publications": {
            "10.1080/15384101.2021.2023304": {
                "title": "Esco2 and cohesin regulate CRL4 ubiquitin ligase ddb1 expression and thalidomide teratogenicity",
                "abstract": "Cornelia de Lange syndrome (CdLS) and Roberts syndrome (RBS) are severe developmental maladies that arise from mutation of cohesin (including <i>SMC3</i>, CdLS) and <i>ESCO2</i> (RBS). Though ESCO2 activates cohesin, CdLS and RBS etiologies are currently considered non-synonymous and for which pharmacological treatments are unavailable. Here, we identify a unifying mechanism that integrates these genetic maladies to pharmacologically-induced teratogenicity via thalidomide. Our results reveal that Esco2 and cohesin co-regulate the transcription of a component of CRL4 ubiquitin ligase through which thalidomide exerts teratogenic effects. These findings are the first to link RBS and CdLS to thalidomide teratogenicity and offer new insights into treatments.",
                "disciplines": [
                    "3105"
                ]
            }
        }
    },
    "13037135": {
        "title": "A nanocoating for continuous disinfection of frequently touched surfaces",
        "abstract": "A nanocoating for continuous disinfection of frequently touched surfaces Healthcare-associated infections (HAIs) represent a constant risk for patients and healthcare workers and have a large impact on public health. Fomites, inanimate surfaces contaminated by pathogens, are a passive source of infection and their role in infection propagation in hospitals has been recognized as an important health problem. Fomites can be contaminated with microbes by direct contact with body fluids such as blood or saliva or by airborne microbial particles, like sneeze droplets. In the nosocomial setting, noncritical frequently touched surfaces (FTS) such as doorknobs, countertops, bedrails, and bedside tables may contribute to fomite-mediated HAIs by contaminating the hands of health care providers or by contact with medical equipment that will subsequently come in contact with patients. To prevent and reduce the risk of HAIs transmission, the low-level disinfection (LLD) of FTS is a widely used strategy. LLD aims to inactivate vegetative bacteria, virus, and fungi, but not spores. To do so, liquid disinfectants or wipes are used to wet the surface for the amount of time recommended by the manufacturer, usually 10 minutes or less. LLD has been found to be highly effective (>4- log10 reduction) in removing/inactivating epidemiologically important pathogens. Nevertheless, since recontamination can occur at any moment after cleaning, an important drawback of LLD is the need for repeated disinfectant application. To address this, here we propose the use of a nanocoating (NC) for continuous LLD of FTS. The NC will be able to attain >4-log10 reduction of gram positive and gram-negative bacteria in 15 minutes or less by using visible light to kill pathogens via oxidative stress. It will be formulated for an environmental- friendly application and will keep its antibacterial activity for about 60 days. The specific aims to reach the objective are: AIM 1. Formulation and optimization of NCs. The material will be formulated and optimized for high bacterial reduction (>4-log10) in 15 min or less against S. aureus and E. coli. AIM 2. Characterization and optimization of NC properties. The mechanical, physiochemical, and antibacterial properties of new and aged coatings will be assessed to optimize performance and duration. AIM 3. In vitro and in vivo studies to assess the safeness of NCs. Studies using human cells and animal models will be performed to evaluate adverse health effects of NCs.",
        "disciplines": [
            "3107"
        ],
        "publications": {
            "10.3390/ijms241713272": {
                "title": "Photocatalytic and Photothermal Antimicrobial Mussel-Inspired Nanocomposites for Biomedical Applications",
                "abstract": "Bacterial infection has traditionally been treated with antibiotics, but their overuse is leading to the development of antibiotic resistance. This may be mitigated by alternative approaches to prevent or treat bacterial infections without utilization of antibiotics. Among the alternatives is the use of photo-responsive antimicrobial nanoparticles and/or nanocomposites, which present unique properties activated by light. In this study, we explored the combined use of titanium oxide and polydopamine to create nanoparticles with photocatalytic and photothermal antibacterial properties triggered by visible or near-infrared light. Furthermore, as a proof-of-concept, these photo-responsive nanoparticles were combined with mussel-inspired catechol-modified hyaluronic acid hydrogels to form novel light-driven antibacterial nanocomposites. The materials were challenged with models of Gram-negative and Gram-positive bacteria. For visible light, the average percentage killed (PK) was 94.6 for <i>E. coli</i> and 92.3 for <i>S. aureus</i>. For near-infrared light, PK for <i>E. coli</i> reported 52.8 and 99.2 for <i>S. aureus</i>. These results confirm the exciting potential of these nanocomposites to prevent the development of antibiotic resistance and also to open the door for further studies to optimize their composition in order to increase their bactericidal efficacy for biomedical applications.",
                "disciplines": [
                    "3406"
                ]
            }
        }
    },
    "13489554": {
        "title": "Target trial emulation for transparent and robust estimation of treatment effects for health technology assessment using real-world data.",
        "abstract": "Research question How can target trial emulation (TTE) improve the estimation of treatment effects for health technology assessment (HTA) using real-world data (RWD)? Background HTA agencies, such as NICE, are increasingly using RWD to estimate the effectiveness and cost-effectiveness of health interventions, but unless HTA studies appropriately address the potential pitfalls arising from RWD, they will lead to biased estimates of treatment effects. By applying design and analysis principles from randomised controlled trials (RCTs), TTE can enable a more transparent and robust estimation of treatment effects from RWD. However, there are several methodological and practical challenges that need to be addressed to enable the adoption of TTE in HTA. AimTo exploit the target trial approach to enable transparent and robust estimation of treatment effects for HTA using RWD, and develop a roadmap for its implementation in HTA. Objectives 1. Extend the target trial approach to evaluate personalised, adaptive treatment strategies 2. Devise a framework to aid the analysis and interpretation of uncontrolled studies in HTA. 3. Exploit target trial emulation to improve indirect treatment comparisons. 4. Develop a roadmap for the adoption of TTE in HTA. MethodsWork-package 1 (months 1-15): Extend TTE to accommodate the personalisation of treatment strategies by incorporating: i) adaptive treatment strategies, ii) stratification of target trial according to key prognostic factors, and iii) new machine learning methods to improve the targeting of the right treatments for the right patients. Work-package 2 (months 12-27): Devise and illustrate a framework to improve the relevance and interpretation of uncontrolled studies, such as single-arm trials, and contextualise them with RWD. This will involve: i) develop protocol of target trial in line with research question of uncontrolled study, ii) derive relevant control group from RWD, iii) devise a strategy for sensitivity analysis to address discrepancies between the protocol and emulated target trial, and iv) develop general recommendations to inform future data collection. Work-package 3 (months 21-36): Demonstrate how the target trial approach can improve indirect treatment comparisons in the absence of head-to-head RCTs: i) allow head-to-head comparisons using routine datasets, ii) assess the plausibility of assumptions made by the evidence synthesis approaches, and iii) include comparisons of relevant outcomes not included across all RCTs. Work-package 4 (months 1-36): Develop accessible guidance, software tools, and training to facilitate the implementation of TTE in HTA. ImpactThis research will lead to better clinical and resource allocation decisions by improving treatment recommendations within NICE's HTA programme and clinical guideline development. By exploiting large-scale RWD, this research will provide measures of treatment effectiveness and cost-effectiveness that are of greater relevance to patients, practitioners and commissioners, because they will reflect more closely the diversity of patients and the care they receive in routine practice. More generally, the project will help researchers gain greater utility from routinely-collected data through more rigorous design and analysis of observational studies in HTA.",
        "disciplines": [
            "4905"
        ],
        "publications": {
            "10.1016/j.jval.2024.01.020": {
                "title": "Acceptability of Using Real-World Data to Estimate Relative Treatment Effects in Health Technology Assessments: Barriers and Future Steps",
                "abstract": "OBJECTIVES: Evidence about the comparative effects of new treatments is typically collected in randomized controlled trials (RCTs). In some instances, RCTs are not possible, or their value is limited by an inability to capture treatment effects over the longer term or in all relevant population subgroups. In these cases, nonrandomized studies (NRS) using real-world data (RWD) are increasingly used to complement trial evidence on treatment effects for health technology assessment (HTA). However, there have been concerns over a lack of acceptability of this evidence by HTA agencies. This article aims to identify the barriers to the acceptance of NRS and steps that may facilitate increases in the acceptability of NRS in the future.\nMETHODS: Opinions of the authorship team based on their experience in real-world evidence research in academic, HTA, and industry settings, supported by a critical assessment of existing studies.\nRESULTS: Barriers were identified that are applicable to key stakeholder groups, including HTA agencies (eg, the lack of comprehensive methodological guidelines for using RWD), evidence generators (eg, avoidable deviations from best practices), and external stakeholders (eg, data controllers providing timely access to high-quality RWD). Future steps that may facilitate future acceptability of NRS include improvements in the quality, integration, and accessibility of RWD, wider use of demonstration projects to highlight the value and applicability of nonrandomized designs, living, and more detailed HTA guidelines, and improvements in HTA infrastructure relating to RWD.\nCONCLUSION: NRS can represent a crucial source of evidence on treatment effects for use in HTA when RCT evidence is limited.",
                "disciplines": [
                    "4206"
                ]
            },
            "10.1038/s41366-023-01396-0": {
                "title": "On the estimation of the effect of weight change on a health outcome using observational data, by utilising the target trial emulation framework",
                "abstract": "Background/ObjectivesWhen studying the effect of weight change between two time points on a health outcome using observational data, two main problems arise initially (i) \u2018when is time zero?\u2019 and (ii) \u2018which confounders should we account for?\u2019 From the baseline date or the 1st follow-up (when the weight change can be measured)? Different methods have been previously used in the literature that carry different sources of bias and hence produce different results.MethodsWe utilised the target trial emulation framework and considered weight change as a hypothetical intervention. First, we used a simplified example from a hypothetical randomised trial where no modelling is required. Then we simulated data from an observational study where modelling is needed. We demonstrate the problems of each of these methods and suggest a strategy.Interventionsweight loss/gain vs maintenance.ResultsThe recommended method defines time-zero at enrolment, but adjustment for confounders (or exclusion of individuals based on levels of confounders) should be performed both at enrolment and the 1st follow-up.ConclusionsThe implementation of our suggested method [adjusting for (or excluding based on) confounders measured both at baseline and the 1st follow-up] can help researchers attenuate bias by avoiding some common pitfalls. Other methods that have been widely used in the past to estimate the effect of weight change on a health outcome are more biased. However, two issues remain (i) the exposure is not well-defined as there are different ways of changing weight (however we tried to reduce this problem by excluding individuals who develop a chronic disease); and (ii) immortal time bias, which may be small if the time to first follow up is short.",
                "disciplines": [
                    "4202"
                ]
            }
        }
    },
    "12909971": {
        "title": "Direct Interfacial Charge Separation in Plasmonic Heterostructures Revealed by Single-Particle Spectroscopy",
        "abstract": "Non-Technical Description This project is developing methods to understand how metal nanoparticles, 1000 times smaller than the width of a hair, capture and convert light into usable energy when contacting metal oxide semiconductors. Although metal nanoparticles efficiently absorb light, most of the absorbed energy is converted into heat. On the other hand, metal oxide semiconductors can store light energy for much longer times than metals making them useful for applications such as photodetection. However, metal oxide semiconductors do not absorb as strongly or often only at specific wavelengths, while metal nanoparticle can be designed to strongly interact with light of any color. This project overcomes these limitations by combining the high absorption of metal nanoparticles with the longer lifetimes of the absorbed light energy in metal oxide semiconductors. The principal investigator uses techniques that allow him to study how the light energy absorbed by a metal nanoparticle is transferred to an adjacent metal oxide semiconductor layer. These experiments are carried out for one nanoparticle at a time to resolve heterogeneities that arise from materials synthesis. In addition, the PI is continuing his longstanding participation in Rice University\u2019s Civic Scientist Program and Research Experience for Teachers, allowing him to educate K-12 students about nanotechnology and inspire them to pursue scientific careers as well as to provide teachers with experience to in turn help students in those pursuits. Technical Description The goal of this project is to understand and maximize plasmon decay into charge separated states between a metal nanoparticle and an adjacent metal oxide semiconductor via direct charge transfer following plasmon excitation. The principal investigator will accomplish this goal by addressing the following objectives: 1) Design and fabricate plasmonic metal\u2013semiconductor heterostructures and establish a correlation with interface induced plasmon decay via changes to the homogeneous plasmon linewidth; 2) Quantitatively determine charge injection into semiconductors surrounding plasmonic nanostructures using single particle ultrafast spectroscopy and correlate with efficiencies obtained from plasmon damping; 3) Apply Stokes and anti-Stokes emission spectroscopy to independently follow interfacial charge transfer through emission quenching under both one- and multi-photon excitation conditions. These proposed studies will elucidate the mechanism of interfacial charge transfer in plasmonic heterostructures and the underlying material parameters that determine efficiencies with a focus on excess energy as determined by the plasmon resonance and the relative band alignment including Schottky barrier height. Such detailed mechanistic information would be impossible to obtain without single-particle techniques due to the heterogeneity of plasmonic nanoparticle sizes and local environments. The proposed studies will potentially have a transformative impact on developing efficient photovoltaic devices based on plasmonic metal-semiconductor heterostructures taking advantage of a wide wavelength sensitivity, large absorption cross section, and long hot carrier lifetime. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4018"
        ],
        "publications": {
            "10.1021/acs.jpcc.3c04680": {
                "title": "Electron\u2013Phonon Relaxation Dynamics of Hot Electrons in Gold Nanoparticles Are Independent of Excitation Pathway",
                "abstract": "We report on a pump wavelength-dependent study of electron\u2013phonon relaxation in colloidal solutions of isolated gold nanospheres and nanorods. We varied the pump wavelength over a broad spectral range that covers plasmon-resonant and off-resonant excitations in 40 nm gold nanospheres with a plasmon resonance at 525 nm and 34 \u00d7 91 nm gold nanorods with a longitudinal plasmon resonance at 720 nm. We also performed an excitation power dependence at each pump wavelength and plotted the measured plasmon bleach recovery kinetics against the initial change in the electron temperature, as obtained from the incident fluence and gold nanoparticle absorption. These plots were all linear and revealed as they intercept the intrinsic electron\u2013phonon relaxation time, which we found to be independent of pump wavelength and hence the same regardless of how the nanoparticles were excited. The plasmon bleach recovery dynamics at a given pump wavelength and excitation power simply describe the collective cooling of a hot thermalized electron distribution with the lattice to reach thermal equilibrium and are longer the larger the initial temperature rise is. Finally, we observed a nonlinear trend in the electron\u2013phonon relaxation time when the nanorods were excited at the longitudinal mode with linearly polarized excitation, indicating a potential photoselection that created an even larger electron temperature. These results provide important guidance when comparing the dynamics of different plasmonic nanomaterials by using transient absorption spectroscopy.",
                "disciplines": [
                    "4018",
                    "3406"
                ]
            },
            "10.1021/acs.jpcc.4c01814": {
                "title": "On-Chip Lock-In Detection for Ultrafast Spectroscopy of Single Particles",
                "abstract": "Time-resolved spectroscopy of plasmonic nanoparticles is a vital technique for probing their ultrafast electron dynamics and subsequent acoustic and photothermal properties. Traditionally, these experiments are performed with spectrally broad probe beams on the ensemble level to achieve high signal amplitudes. However, the relaxation dynamics of plasmonic nanoparticles is highly dependent on their size, shape, and crystallinity. As such, the inherent heterogeneity of most nanoparticle samples can complicate efforts to build microscopic models for these dynamics solely on the basis of ensemble measurements. Although approaches for collecting time-resolved microscopy signals from individual nanoparticles at selected probe wavelengths have been demonstrated, acquiring time-resolved spectra from single objects remains challenging. Here, we demonstrate an alternate method that efficiently yields the time-resolved spectra of a single gold nanodisk in one measurement. By modulating the frequency-doubled output of a 96 MHz Ti:sapphire oscillator at 8 kHz, we are able to use a lock-in pixel-array camera to detect photoinduced changes in the transmission of a white light continuum probe derived from a photonic crystal fiber to produce broadband femtosecond transmission spectra of a single gold nanodisk. We also compare the performance of the lock-in camera for the same single nanoparticle to measurements with a single-element photodiode and find comparable sensitivities. The lock-in camera thus provides a major advantage due to its ability to multiplex spectral detection, which we utilize here to capture both the electronic dynamics and acoustic vibrations of a single gold nanodisk following ultrafast laser excitation.",
                "disciplines": [
                    "4018"
                ]
            }
        }
    },
    "13620362": {
        "title": "Terminological equivalence from the diachronic point of view: divorce, separation and Brazilian and French matrimonial regimes",
        "abstract": "This research internship project abroad aims to expand our studies at the post-doctoral level and proposes, therefore, to establish equivalents between the denominative terms of the types of divorce, separation and property regimes within the scope of Brazilian Law and French: for that, we will deepen our readings regarding bilingual (or multilingual) terminology from the diachronic point of view; we will identify the equivalence relations between the terms in Brazilian Portuguese (BP) and French French (FF) regarding divorce, separation and property regimes in a diachronic perspective; we will reflect on the characteristics of the equivalence relations found; and we will register the data related to the different semantic states, their respective equivalents and the relevant extralinguistic information in order to improve the understanding of these data in terminological sheets. The theoretical framework adopted comprises the assumptions of Terminology (ALVES, 2006; BARROS, 2004; CABR\u00c9, 1999; among others), more specifically of Diachronic Terminology (DURY, 1999; TARTIER, 2006; and others) and Bi-/Multilingual Terminology (CABR\u00c9, 1993; DUBUC, 2002; FELBER, 1987; LERAT, 1995; etc.) ), and a bibliography on the Law and History of Brazil and France (COULON, 1890; HOUDAILLE; BOLOGNE, 1999; MARQUES, 2004; PERROT, 1995; PINHEIRO, 2012; SOARES, 1895; and others). In this way, we hope to contribute to diachronic studies in Bi-/Multilingual Terminology, as well as to provide linguistic elements that can improve specialized communication in the legal field. (AU)",
        "disciplines": [
            "4704",
            "4703"
        ],
        "publications": {
            "10.4025/actascilangcult.v45i2.67723": {
                "title": "O(s) lugar(es) da diacronia na Terminologia: de onde partir para realizar um estudo terminol\u00f3gico-diacr\u00f4nico hoje?",
                "abstract": "This paper brings theoretical reflections on the different views of diachrony within the scope of five terminological schools, based on the conceptions of \u2018term\u2019, \u2018concept\u2019 and \u2018variation\u2019 adopted by each of them in their respective theoretical framework. As each of the terminological approaches considers diachrony from a particular place, this paper shows that, consequently, diachrony occupies different places in Terminology. Among these approaches, there is also the diachronic terminology (DT). Although it is not a theory per se \u2013 and, for this reason, it is associated with one of these schools (or more) depending on the objectives of the terminological work \u2013 DT has been adopted by several investigations in the area as a field of study apart from the others (Picton, Condamines, & Humbert-Droz, 2021). Given the relatively recent interest devoted to DT and the thematic diversity of research carried out in light of this perspective (Humbley, 2011), there are different investigative lines associated with it. This work therefore proposes schemes that organize these approaches, which have been found in research carried out so far (Curti-Contessoto, 2022), and some specificities attributed to \u2018diachrony\u2019. The discussion woven in this paper is important since there is still a lack of theoretical contributions, especially in the sense of systematizing the different diachronic approaches that exist in Terminology \u2013 something that is one of the obstacles that currently most need attention (Picton, 2018). Then, this paper intends to contribute in this sense, bringing our reflections on the subject in Brazilian Portuguese since there is a mainly theoretical gap in relation to DT in Brazil, as well as possible paths for research in the area and future perspectives.",
                "disciplines": [
                    "4703"
                ]
            }
        }
    },
    "12949629": {
        "title": "High Order Wave Equation Algorithms for the Frequency Domain",
        "abstract": "A defining feature of waves is their ability to carry information over large distances by propagating without changing their shape. It is this ability that allow waves to probe and image the human body, the interior of the earth and engineered structures like bridges and tunnels. Such images can then be turned into scientific and engineering knowledge that can be used to improve medical diagnostics and prevent failure of buildings and mechanical devices. In this project the principal investigator will develop computational simulation tools that increases our ability to exploit the properties of wave propagation for the common good. The tools developed in the project can also be used to design advanced materials that can enable better acoustic, elastic and electromagnetic components as well as faster and more accurate sensing technologies. Students will be trained as a part of this work. The research will further develop and apply advanced computational methods for solving systems of partial differential equations modeling wave propagation. The approximation methods will be designed to be robust and flexible while effectively utilizing emerging computational architectures. The research will dramatically improve the WaveHoltz method, a recently discovered idea that enables the use of time domain methods for wave equations to design frequency domain Helmholtz type solvers. WaveHoltz is remarkable in that its underlying linear operator corresponds to a symmetric positive definite matrix and allows a coercive problem to be solved rather than a highly indefinite Helmholtz problem. The research will analyze and develop wavefront preconditioners and deflation techniques for preconditioning WaveHoltz; design implicit and explicit error corrected methods for removing the temporal error in the WaveHoltz method; and consider multi-frequency versions of the WaveHoltz method. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
        "disciplines": [
            "4006"
        ],
        "publications": {
            "10.1007/s10915-023-02353-9": {
                "title": "Universal AMG Accelerated Embedded Boundary Method Without Small Cell Stiffness",
                "abstract": "We develop a universally applicable embedded boundary finite difference method, which results in a symmetric positive definite linear system and does not suffer from small cell stiffness. Our discretization is efficient for the wave, heat and Poisson equation with Dirichlet boundary conditions. When the system needs to be inverted we can use the conjugate gradient method, accelerated by algebraic multigrid techniques. A series of numerical tests for the wave, heat and Poisson equation and applications to shape optimization problems verify the accuracy, stability, and efficiency of our method. Our fast computational techniques can be extended to moving boundary problems (e.g. Stefan problem), to the Navier\u2013Stokes equations, and to the Grad-Shafranov equations for which problems are posed on domains with complex geometry and fast simulations are of great interest.",
                "disciplines": [
                    "4901",
                    "4903"
                ]
            },
            "10.1007/s42967-023-00287-5": {
                "title": "The Hermite-Taylor Correction Function Method for Maxwell\u2019s Equations",
                "abstract": "The Hermite-Taylor method, introduced in 2005 by Goodrich et al. is highly efficient and accurate when applied to linear hyperbolic systems on periodic domains. Unfortunately, its widespread use has been prevented by the lack of a systematic approach to implementing boundary conditions. In this paper we present the Hermite-Taylor correction function method (CFM), which provides exactly such a systematic approach for handling boundary conditions. Here we focus on Maxwell\u2019s equations but note that the method is easily extended to other hyperbolic problems.",
                "disciplines": [
                    "4008"
                ]
            },
            "10.1007/s10543-023-00954-2": {
                "title": "An energy-based discontinuous Galerkin method with tame CFL numbers for the wave equation",
                "abstract": "We extend and analyze the energy-based discontinuous Galerkin method for second order wave equations on staggered and structured meshes. By combining spatial staggering with local time-stepping near boundaries, the method overcomes the typical numerical stiffness associated with high order piecewise polynomial approximations. In one space dimension with periodic boundary conditions and suitably chosen numerical fluxes, we prove bounds on the spatial operators that establish stability for CFL numbers c\u0394th<C$$c \\frac{\\Delta t}{h} < C$$ independent of order when stability-enhanced explicit time-stepping schemes of matching order are used. For problems on bounded domains and in higher dimensions we demonstrate numerically that one can march explicitly with large time steps at high order temporal and spatial accuracy.",
                "disciplines": [
                    "4901",
                    "4903"
                ]
            }
        }
    },
    "13057655": {
        "title": "Subversion of Cellular Mitotic and Antiviral Signaling by Poxviral Kinases",
        "abstract": "Viral manipulation of mitotic and antiviral signal transduction determines the outcome of infection, but remains poorly understood. To address this knowledge gap, our laboratory studies a family of protein kinases comprised of homologs widely expressed in poxviruses and in all multicellular eukaryotes. The long term goal of our research is to determine how poxviruses usurp and redirect signaling cascades governing mitotic and host defense effectors responsive to foreign DNA. Mammalian poxviruses express two proteins, B1 and B12, which are homologous to each other and to three eukaryotic protein kinases named vaccinia related kinases (VRKs). Comparative studies of B1 and VRK1 revealed that both enzymes directly modify the cellular protein BAF. Importantly, BAF acts as both a mitotic regulator and antiviral effector by binding and compacting dsDNA, a property that is inactivated via phosphorylation by B1 or VRK1. Our new data argue that B1 and cellular VRKs co-regulate other pathways as well, including an antiviral pathway activated by the B12 protein. Our data indicate that B12 directs strong repression of vaccinia DNA replication via partly unknown mechanisms also governed by B1. Intriguingly, B12 is a nuclear poxviral protein and a non-catalytic kinase or `pseudokinase', which are of key innovative importance for this proposal. Pseudokinases are members of the pseudoenzyme family, about which little is known in viruses. It is our central hypothesis that vaccinia B1 and B12 form a novel signaling axis that supplants and redirects cellular VRK pathways regulating BAF and other VRK substrates such as histones and the HUSH (Human Silencing Hub) complex. To test our hypothesis, we propose three aims. AIM 1) Determine how B1 and B12 remodel VRK1-responsive signaling during poxvirus infection. This Aim tests the hypothesis that B12 interacts with VRKs in the nucleus, thereby altering H2A, BAF, and HUSH regulation. Characterization of B12 interaction with BAF, B1, and cellular VRKs in vitro and in cultured cells will be achieved. AIM 2) Determine the molecular mechanisms governing B12 repression of poxvirus DNA replication. This Aim tests the hypothesis that the B12/VRK1 complex plays key roles in the mechanism of B12 signaling dysregulation. Structure/function analysis of B12 through targeted mutational analysis, novel loss of function screens, and investigation of B12 phosphoregulation are outlined in this Aim. AIM 3) Determine how viral/cellular pseudokinases mediate repression of the poxvirus lifecycle and converge with protein phosphatase signaling. This Aim will test the hypotheses that B1 and VRK2 kinases regulate B12 via direct phosphorylation while VRK3 and the phosphatase PP2A control dynamic regulation of B1/VRK1 substrates, leading to manipulation of downstream antiviral responses. The completion of this work will: fill gaps in our understanding of poxvirus manipulation of nuclear processes, yield broadly relevant insights to the field of kinase-pseudokinase biology, and provide needed information of how mitotic and antiviral signaling interweave.",
        "disciplines": [
            "3101"
        ],
        "publications": {
            "10.1128/jvi.00398-22": {
                "title": "Dysregulation of Cellular VRK1, BAF, and Innate Immune Signaling by the Vaccinia Virus B12 Pseudokinase",
                "abstract": "Poxvirus proteins remodel signaling throughout the cell by targeting host enzymes for inhibition and redirection. Recently, it was discovered that early in infection the vaccinia virus (VACV) B12 pseudokinase copurifies with the cellular kinase VRK1, a proviral factor, in the nucleus. Although the formation of this complex correlates with inhibition of cytoplasmic VACV DNA replication and likely has other downstream signaling consequences, the molecular mechanisms involved are poorly understood. Here, we further characterize how B12 and VRK1 regulate one another during poxvirus infection. First, we demonstrate that B12 is stabilized in the presence of VRK1 and that VRK1 and B12 coinfluence their respective solubility and subcellular localization. In this regard, we find that B12 promotes VRK1 colocalization with cellular DNA during mitosis and that B12 and VRK1 may be tethered cooperatively to chromatin. Next, we observe that the C-terminal tail of VRK1 is unnecessary for B12-VRK1 complex formation or its proviral activity. Interestingly, we identify a point mutation of B12 capable of abrogating interaction with VRK1 and which renders B12 nonrepressive during infection. Lastly, we investigated the influence of B12 on the host factor BAF and antiviral signaling pathways and find that B12 triggers redistribution of BAF from the cytoplasm to the nucleus. In addition, B12 increases DNA-induced innate immune signaling, revealing a new functional consequence of the B12 pseudokinase. Together, this study characterizes the multifaceted roles B12 plays during poxvirus infection that impact VRK1, BAF, and innate immune signaling. <b>IMPORTANCE</b> Protein pseudokinases comprise a considerable fraction of the human kinome, as well as other forms of life. Recent studies have demonstrated that their lack of key catalytic residues compared to their kinase counterparts does not negate their ability to intersect with molecular signal transduction. While the multifaceted roles pseudokinases can play are known, their contribution to virus infection remains understudied. Here, we further characterize the mechanism of how the VACV B12 pseudokinase and human VRK1 kinase regulate one another in the nucleus during poxvirus infection and inhibit VACV DNA replication. We find that B12 disrupts regulation of VRK1 and its downstream target BAF, while also enhancing DNA-dependent innate immune signaling. Combined with previous data, these studies contribute to the growing field of nuclear pathways targeted by poxviruses and provide evidence of unexplored roles of B12 in the activation of antiviral immunity.",
                "disciplines": [
                    "3207",
                    "3101"
                ]
            }
        }
    },
    "12984796": {
        "title": "Preventing Age-Associated Oocyte Aneuploidy: Mechanisms Behind the Drosophila melanogaster Centromere Effect",
        "abstract": "Project Summary/Abstract During meiosis, crossing-over between homologs facilitates accurate chromosome segregation and prevents aneuploidy, which in turn forestalls miscarriages and chromosomal disorders such as Down syndrome. The regulation and placement of meiotic crossovers acts as a vital safeguard against age-associated meiotic defects and infertility, as the risk of non-disjunction (NDJ) increases with increasing maternal age. Meiotic crossovers (COs) are formed when programmed double-strand breaks (DSBs) are repaired through homologous recombination. However, only a subset of DSBs are repaired to form COs; the rest are repaired as non-crossovers (NCOs). Despite meiotic DSBs being distributed throughout the chromosome, CO placement is intricately regulated by three types of patterning phenomena. One of these, the centromere effect (CE), ensures the exclusion of COs in centromere-proximal regions and is crucial to the meiotic cell as centromere-proximal COs increase the risk of NDJ. Furthermore, increasing maternal age has been shown to weaken the CE, potentially explaining why NDJ incidence increases in older women. Although first observed in Drosophila in 1932, the mechanisms behind the CE remain unknown even today. The experiments proposed here aim to address this gap in knowledge regarding a vital cellular process that prevents mis-segregation events, especially in those with advanced maternal age. Recently, our lab showed that the CE is differentially established in the two classes of heterochromatin found at the Drosophila pericentromere. In the highly repetitive alpha heterochromatin immediately adjacent to the centromere, a complete exclusion of COs is observed, while the less repetitive beta heterochromatin adjacent to proximal euchromatin shows a distance dependent CO suppression. I will build on these results by investigating the mechanisms of how the CE is established in these two classes of pericentric heterochromatin. A prominent question regarding CE mechanisms centers around how pericentromeric heterochromatin and the centromere itself contribute to the CE. The few studies that have addressed pericentric crossing-over in the past century have attempted to establish one as more important than the other in Drosophila but failed to arrive at a consensus. Thus, pericentric heterochromatin has been considered everything from an active participant in CO reduction in adjacent intervals to nothing more than a passive spacer between euchromatin and the centromere. Through the experiments outlined in this proposal, I will ask how pericentric heterochromatin and the centromere contribute to the CE independently of each other, particularly focusing on highly repetitive alpha heterochromatin. Investigating the role of alpha heterochromatin as separate from that of pericentric heterochromatin as a whole in manifesting the CE is a novel area of research within the broader question of how the CE is established. In summary, this proposal will increase our understanding of the mechanisms that safeguard against age- related aneuploidy and infertility through shedding light on meiotic crossover patterning.",
        "disciplines": [
            "3215"
        ],
        "publications": {
            "10.1093/genetics/iyad216": {
                "title": "Centromere-proximal suppression of meiotic crossovers in Drosophila is robust to changes in centromere number, repetitive DNA content, and centromere-clustering",
                "abstract": "Accurate segregation of homologous chromosomes during meiosis depends on both the presence and the regulated placement of crossovers (COs). The centromere effect, or CO exclusion in pericentromeric regions of the chromosome, is a meiotic CO patterning phenomenon that helps prevent nondisjunction, thereby protecting against chromosomal disorders and other meiotic defects. Despite being identified nearly a century ago, the mechanisms behind this fundamental cellular process remain unknown, with most studies of the Drosophila centromere effect focusing on local influences of the centromere and pericentric heterochromatin. In this study, we sought to investigate whether dosage changes in centromere number and repetitive DNA content affect the strength of the centromere effect, using phenotypic recombination mapping. Additionally, we studied the effects of repetitive DNA function on centromere effect strength using satellite DNA-binding protein mutants displaying defective centromere-clustering in meiotic nuclei. Despite what previous studies suggest, our results show that the Drosophila centromere effect is robust to changes in centromere number, repetitive DNA content, as well as repetitive DNA function. Our study suggests that the centromere effect is unlikely to be spatially controlled, providing novel insight into the mechanisms behind the Drosophila centromere effect.",
                "disciplines": [
                    "3105"
                ]
            },
            "10.1101/2023.10.17.562696": {
                "title": "Centromere-Proximal Suppression of Meiotic Crossovers in Drosophila is Robust to Changes in Centromere Number and Repetitive DNA Content",
                "abstract": "Accurate segregation of homologous chromosomes during meiosis depends on both the presence and regulated placement of crossovers (COs). The centromere effect (CE), or CO exclusion in pericentromeric regions of the chromosome, is a meiotic CO patterning phenomenon that helps prevent nondisjunction (NDJ), thereby protecting against chromosomal disorders and other meiotic defects. Despite being identified nearly a century ago, the mechanisms behind this fundamental cellular process remain unknown, with most studies of the <i>Drosophila</i> CE focusing on local influences of the centromere and pericentric heterochromatin. In this study, we sought to investigate whether dosage changes in centromere number and repetitive DNA content affect the strength of the CE, using phenotypic recombination mapping. Additionally, we also studied the effects of repetitive DNA function on CE strength using satellite-DNA binding protein mutants shown to have defective centromere clustering. Despite what previous studies suggest, our results show that the <i>Drosophila</i> CE is robust to dosage changes in centromere number and repetitive DNA content, and potentially also to repetitive DNA function. Our study suggests that the CE is unlikely to be spatially controlled, providing novel insight into the mechanisms behind the <i>Drosophila</i> centromere effect.",
                "disciplines": [
                    "3105"
                ]
            }
        }
    }
}